I1126 11:58:53.785187      19 e2e.go:116] Starting e2e run "96bdeaf3-8155-4385-8ac0-63e14c6369d4" on Ginkgo node 1
Nov 26 11:58:53.817: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1669463933 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Nov 26 11:58:54.313: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 11:58:54.316: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov 26 11:58:54.348: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 26 11:58:54.377: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov 26 11:58:54.377: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Nov 26 11:58:54.377: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 26 11:58:54.382: INFO: e2e test version: v1.25.4
Nov 26 11:58:54.384: INFO: kube-apiserver version: v1.25.4
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Nov 26 11:58:54.384: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 11:58:54.391: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.082 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Nov 26 11:58:54.313: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 11:58:54.316: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Nov 26 11:58:54.348: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Nov 26 11:58:54.377: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Nov 26 11:58:54.377: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
    Nov 26 11:58:54.377: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Nov 26 11:58:54.382: INFO: e2e test version: v1.25.4
    Nov 26 11:58:54.384: INFO: kube-apiserver version: v1.25.4
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Nov 26 11:58:54.384: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 11:58:54.391: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 11:58:54.419
Nov 26 11:58:54.419: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 11:58:54.42
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:58:54.449
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:58:54.456
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 11/26/22 11:58:54.464
Nov 26 11:58:54.479: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec" in namespace "downward-api-4144" to be "Succeeded or Failed"
Nov 26 11:58:54.485: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec": Phase="Pending", Reason="", readiness=false. Elapsed: 5.87349ms
Nov 26 11:58:56.494: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014924187s
Nov 26 11:58:58.491: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01152861s
Nov 26 11:59:00.491: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec": Phase="Running", Reason="", readiness=false. Elapsed: 6.011256547s
Nov 26 11:59:02.491: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011551082s
STEP: Saw pod success 11/26/22 11:59:02.491
Nov 26 11:59:02.491: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec" satisfied condition "Succeeded or Failed"
Nov 26 11:59:02.496: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec container client-container: <nil>
STEP: delete the pod 11/26/22 11:59:02.526
Nov 26 11:59:02.544: INFO: Waiting for pod downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec to disappear
Nov 26 11:59:02.550: INFO: Pod downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 11:59:02.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4144" for this suite. 11/26/22 11:59:02.556
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":1,"skipped":10,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.153 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 11:58:54.419
    Nov 26 11:58:54.419: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 11:58:54.42
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:58:54.449
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:58:54.456
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 11/26/22 11:58:54.464
    Nov 26 11:58:54.479: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec" in namespace "downward-api-4144" to be "Succeeded or Failed"
    Nov 26 11:58:54.485: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec": Phase="Pending", Reason="", readiness=false. Elapsed: 5.87349ms
    Nov 26 11:58:56.494: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014924187s
    Nov 26 11:58:58.491: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01152861s
    Nov 26 11:59:00.491: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec": Phase="Running", Reason="", readiness=false. Elapsed: 6.011256547s
    Nov 26 11:59:02.491: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011551082s
    STEP: Saw pod success 11/26/22 11:59:02.491
    Nov 26 11:59:02.491: INFO: Pod "downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec" satisfied condition "Succeeded or Failed"
    Nov 26 11:59:02.496: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec container client-container: <nil>
    STEP: delete the pod 11/26/22 11:59:02.526
    Nov 26 11:59:02.544: INFO: Waiting for pod downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec to disappear
    Nov 26 11:59:02.550: INFO: Pod downwardapi-volume-d29ea806-6874-4604-ab47-a0a811f83dec no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 11:59:02.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4144" for this suite. 11/26/22 11:59:02.556
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 11:59:02.573
Nov 26 11:59:02.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 11:59:02.574
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:02.603
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:02.609
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 11/26/22 11:59:02.62
Nov 26 11:59:02.638: INFO: Waiting up to 5m0s for pod "downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c" in namespace "downward-api-3358" to be "Succeeded or Failed"
Nov 26 11:59:02.643: INFO: Pod "downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.738362ms
Nov 26 11:59:04.649: INFO: Pod "downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010494518s
Nov 26 11:59:06.649: INFO: Pod "downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010764996s
STEP: Saw pod success 11/26/22 11:59:06.649
Nov 26 11:59:06.649: INFO: Pod "downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c" satisfied condition "Succeeded or Failed"
Nov 26 11:59:06.655: INFO: Trying to get logs from node ip-172-31-43-82 pod downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c container dapi-container: <nil>
STEP: delete the pod 11/26/22 11:59:06.664
Nov 26 11:59:06.679: INFO: Waiting for pod downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c to disappear
Nov 26 11:59:06.686: INFO: Pod downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 26 11:59:06.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3358" for this suite. 11/26/22 11:59:06.693
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":2,"skipped":12,"failed":0}
------------------------------
â€¢ [4.130 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 11:59:02.573
    Nov 26 11:59:02.573: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 11:59:02.574
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:02.603
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:02.609
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 11/26/22 11:59:02.62
    Nov 26 11:59:02.638: INFO: Waiting up to 5m0s for pod "downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c" in namespace "downward-api-3358" to be "Succeeded or Failed"
    Nov 26 11:59:02.643: INFO: Pod "downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.738362ms
    Nov 26 11:59:04.649: INFO: Pod "downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010494518s
    Nov 26 11:59:06.649: INFO: Pod "downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010764996s
    STEP: Saw pod success 11/26/22 11:59:06.649
    Nov 26 11:59:06.649: INFO: Pod "downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c" satisfied condition "Succeeded or Failed"
    Nov 26 11:59:06.655: INFO: Trying to get logs from node ip-172-31-43-82 pod downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c container dapi-container: <nil>
    STEP: delete the pod 11/26/22 11:59:06.664
    Nov 26 11:59:06.679: INFO: Waiting for pod downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c to disappear
    Nov 26 11:59:06.686: INFO: Pod downward-api-8da8d451-6dd0-4b29-a83d-17ed8c72232c no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 26 11:59:06.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3358" for this suite. 11/26/22 11:59:06.693
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 11:59:06.705
Nov 26 11:59:06.706: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 11:59:06.708
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:06.736
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:06.748
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/26/22 11:59:06.754
Nov 26 11:59:06.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-726 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Nov 26 11:59:06.968: INFO: stderr: ""
Nov 26 11:59:06.968: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 11/26/22 11:59:06.968
Nov 26 11:59:06.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-726 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Nov 26 11:59:07.326: INFO: stderr: ""
Nov 26 11:59:07.326: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/26/22 11:59:07.326
Nov 26 11:59:07.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-726 delete pods e2e-test-httpd-pod'
Nov 26 11:59:14.998: INFO: stderr: ""
Nov 26 11:59:14.999: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 11:59:14.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-726" for this suite. 11/26/22 11:59:15.006
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":3,"skipped":14,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.312 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 11:59:06.705
    Nov 26 11:59:06.706: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 11:59:06.708
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:06.736
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:06.748
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/26/22 11:59:06.754
    Nov 26 11:59:06.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-726 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Nov 26 11:59:06.968: INFO: stderr: ""
    Nov 26 11:59:06.968: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 11/26/22 11:59:06.968
    Nov 26 11:59:06.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-726 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Nov 26 11:59:07.326: INFO: stderr: ""
    Nov 26 11:59:07.326: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/26/22 11:59:07.326
    Nov 26 11:59:07.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-726 delete pods e2e-test-httpd-pod'
    Nov 26 11:59:14.998: INFO: stderr: ""
    Nov 26 11:59:14.999: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 11:59:14.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-726" for this suite. 11/26/22 11:59:15.006
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 11:59:15.02
Nov 26 11:59:15.020: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 11:59:15.021
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:15.05
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:15.056
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-0f0f14bb-7f11-4b19-b494-7b106ff3b7d5 11/26/22 11:59:15.061
STEP: Creating a pod to test consume configMaps 11/26/22 11:59:15.075
Nov 26 11:59:15.088: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8" in namespace "projected-2110" to be "Succeeded or Failed"
Nov 26 11:59:15.093: INFO: Pod "pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.120491ms
Nov 26 11:59:17.098: INFO: Pod "pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010642896s
Nov 26 11:59:19.099: INFO: Pod "pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011247717s
STEP: Saw pod success 11/26/22 11:59:19.099
Nov 26 11:59:19.099: INFO: Pod "pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8" satisfied condition "Succeeded or Failed"
Nov 26 11:59:19.104: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8 container agnhost-container: <nil>
STEP: delete the pod 11/26/22 11:59:19.113
Nov 26 11:59:19.126: INFO: Waiting for pod pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8 to disappear
Nov 26 11:59:19.131: INFO: Pod pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 26 11:59:19.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2110" for this suite. 11/26/22 11:59:19.137
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":4,"skipped":52,"failed":0}
------------------------------
â€¢ [4.127 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 11:59:15.02
    Nov 26 11:59:15.020: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 11:59:15.021
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:15.05
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:15.056
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-0f0f14bb-7f11-4b19-b494-7b106ff3b7d5 11/26/22 11:59:15.061
    STEP: Creating a pod to test consume configMaps 11/26/22 11:59:15.075
    Nov 26 11:59:15.088: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8" in namespace "projected-2110" to be "Succeeded or Failed"
    Nov 26 11:59:15.093: INFO: Pod "pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.120491ms
    Nov 26 11:59:17.098: INFO: Pod "pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010642896s
    Nov 26 11:59:19.099: INFO: Pod "pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011247717s
    STEP: Saw pod success 11/26/22 11:59:19.099
    Nov 26 11:59:19.099: INFO: Pod "pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8" satisfied condition "Succeeded or Failed"
    Nov 26 11:59:19.104: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8 container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 11:59:19.113
    Nov 26 11:59:19.126: INFO: Waiting for pod pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8 to disappear
    Nov 26 11:59:19.131: INFO: Pod pod-projected-configmaps-873aab29-0fd9-4ebe-b555-3080db41dab8 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 26 11:59:19.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2110" for this suite. 11/26/22 11:59:19.137
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 11:59:19.147
Nov 26 11:59:19.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 11:59:19.149
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:19.182
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:19.186
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-69b85490-1cf1-4c71-9467-6a86e5a457c1 11/26/22 11:59:19.203
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 26 11:59:19.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-295" for this suite. 11/26/22 11:59:19.213
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":5,"skipped":64,"failed":0}
------------------------------
â€¢ [0.077 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 11:59:19.147
    Nov 26 11:59:19.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 11:59:19.149
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:19.182
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:19.186
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-69b85490-1cf1-4c71-9467-6a86e5a457c1 11/26/22 11:59:19.203
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 11:59:19.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-295" for this suite. 11/26/22 11:59:19.213
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 11:59:19.226
Nov 26 11:59:19.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 11:59:19.229
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:19.256
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:19.26
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 11:59:19.292
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 11:59:19.771
STEP: Deploying the webhook pod 11/26/22 11:59:19.781
STEP: Wait for the deployment to be ready 11/26/22 11:59:19.803
Nov 26 11:59:19.814: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 26 11:59:21.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 11, 59, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 11, 59, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 11, 59, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 11, 59, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/26/22 11:59:23.856
STEP: Verifying the service has paired with the endpoint 11/26/22 11:59:23.933
Nov 26 11:59:24.934: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 11/26/22 11:59:24.948
STEP: create a pod 11/26/22 11:59:24.977
Nov 26 11:59:25.201: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-9870" to be "running"
Nov 26 11:59:25.206: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.959059ms
Nov 26 11:59:27.211: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009684555s
Nov 26 11:59:27.211: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 11/26/22 11:59:27.211
Nov 26 11:59:27.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=webhook-9870 attach --namespace=webhook-9870 to-be-attached-pod -i -c=container1'
Nov 26 11:59:27.324: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 11:59:27.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9870" for this suite. 11/26/22 11:59:27.399
STEP: Destroying namespace "webhook-9870-markers" for this suite. 11/26/22 11:59:27.415
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":6,"skipped":94,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.483 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 11:59:19.226
    Nov 26 11:59:19.227: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 11:59:19.229
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:19.256
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:19.26
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 11:59:19.292
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 11:59:19.771
    STEP: Deploying the webhook pod 11/26/22 11:59:19.781
    STEP: Wait for the deployment to be ready 11/26/22 11:59:19.803
    Nov 26 11:59:19.814: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Nov 26 11:59:21.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 11, 59, 19, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 11, 59, 19, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 11, 59, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 11, 59, 19, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/26/22 11:59:23.856
    STEP: Verifying the service has paired with the endpoint 11/26/22 11:59:23.933
    Nov 26 11:59:24.934: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 11/26/22 11:59:24.948
    STEP: create a pod 11/26/22 11:59:24.977
    Nov 26 11:59:25.201: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-9870" to be "running"
    Nov 26 11:59:25.206: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.959059ms
    Nov 26 11:59:27.211: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009684555s
    Nov 26 11:59:27.211: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 11/26/22 11:59:27.211
    Nov 26 11:59:27.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=webhook-9870 attach --namespace=webhook-9870 to-be-attached-pod -i -c=container1'
    Nov 26 11:59:27.324: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 11:59:27.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9870" for this suite. 11/26/22 11:59:27.399
    STEP: Destroying namespace "webhook-9870-markers" for this suite. 11/26/22 11:59:27.415
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 11:59:27.71
Nov 26 11:59:27.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 11:59:27.711
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:27.801
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:27.807
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/26/22 11:59:27.813
Nov 26 11:59:27.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1258 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Nov 26 11:59:27.912: INFO: stderr: ""
Nov 26 11:59:27.912: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 11/26/22 11:59:27.912
STEP: verifying the pod e2e-test-httpd-pod was created 11/26/22 11:59:32.966
Nov 26 11:59:32.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1258 get pod e2e-test-httpd-pod -o json'
Nov 26 11:59:33.064: INFO: stderr: ""
Nov 26 11:59:33.064: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-11-26T11:59:27Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1258\",\n        \"resourceVersion\": \"2222\",\n        \"uid\": \"57779008-cf07-44fd-a697-aa429f1625e8\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-k26k8\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-43-82\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-k26k8\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-26T11:59:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-26T11:59:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-26T11:59:28Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-26T11:59:27Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://4525d785d2e1f202d01fc7e61ad0c230b9b9a1fbadbefc016f630d01ca6f8525\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-11-26T11:59:28Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.43.82\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.34.7\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.34.7\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-11-26T11:59:27Z\"\n    }\n}\n"
STEP: replace the image in the pod 11/26/22 11:59:33.064
Nov 26 11:59:33.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1258 replace -f -'
Nov 26 11:59:33.528: INFO: stderr: ""
Nov 26 11:59:33.528: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 11/26/22 11:59:33.528
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Nov 26 11:59:33.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1258 delete pods e2e-test-httpd-pod'
Nov 26 11:59:35.061: INFO: stderr: ""
Nov 26 11:59:35.061: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 11:59:35.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1258" for this suite. 11/26/22 11:59:35.066
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":7,"skipped":99,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.374 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 11:59:27.71
    Nov 26 11:59:27.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 11:59:27.711
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:27.801
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:27.807
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/26/22 11:59:27.813
    Nov 26 11:59:27.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1258 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Nov 26 11:59:27.912: INFO: stderr: ""
    Nov 26 11:59:27.912: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 11/26/22 11:59:27.912
    STEP: verifying the pod e2e-test-httpd-pod was created 11/26/22 11:59:32.966
    Nov 26 11:59:32.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1258 get pod e2e-test-httpd-pod -o json'
    Nov 26 11:59:33.064: INFO: stderr: ""
    Nov 26 11:59:33.064: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-11-26T11:59:27Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1258\",\n        \"resourceVersion\": \"2222\",\n        \"uid\": \"57779008-cf07-44fd-a697-aa429f1625e8\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-k26k8\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-43-82\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-k26k8\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-26T11:59:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-26T11:59:28Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-26T11:59:28Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-26T11:59:27Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://4525d785d2e1f202d01fc7e61ad0c230b9b9a1fbadbefc016f630d01ca6f8525\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-11-26T11:59:28Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.43.82\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.34.7\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.34.7\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-11-26T11:59:27Z\"\n    }\n}\n"
    STEP: replace the image in the pod 11/26/22 11:59:33.064
    Nov 26 11:59:33.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1258 replace -f -'
    Nov 26 11:59:33.528: INFO: stderr: ""
    Nov 26 11:59:33.528: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 11/26/22 11:59:33.528
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Nov 26 11:59:33.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1258 delete pods e2e-test-httpd-pod'
    Nov 26 11:59:35.061: INFO: stderr: ""
    Nov 26 11:59:35.061: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 11:59:35.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1258" for this suite. 11/26/22 11:59:35.066
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 11:59:35.085
Nov 26 11:59:35.085: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename prestop 11/26/22 11:59:35.086
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:35.121
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:35.125
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-988 11/26/22 11:59:35.129
STEP: Waiting for pods to come up. 11/26/22 11:59:35.142
Nov 26 11:59:35.143: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-988" to be "running"
Nov 26 11:59:35.148: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 5.060653ms
Nov 26 11:59:37.154: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.011523383s
Nov 26 11:59:37.154: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-988 11/26/22 11:59:37.159
Nov 26 11:59:37.167: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-988" to be "running"
Nov 26 11:59:37.178: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 11.394539ms
Nov 26 11:59:39.185: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.018313313s
Nov 26 11:59:39.185: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 11/26/22 11:59:39.185
Nov 26 11:59:44.203: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 11/26/22 11:59:44.203
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Nov 26 11:59:44.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-988" for this suite. 11/26/22 11:59:44.226
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":8,"skipped":106,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.151 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 11:59:35.085
    Nov 26 11:59:35.085: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename prestop 11/26/22 11:59:35.086
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:35.121
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:35.125
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-988 11/26/22 11:59:35.129
    STEP: Waiting for pods to come up. 11/26/22 11:59:35.142
    Nov 26 11:59:35.143: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-988" to be "running"
    Nov 26 11:59:35.148: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 5.060653ms
    Nov 26 11:59:37.154: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.011523383s
    Nov 26 11:59:37.154: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-988 11/26/22 11:59:37.159
    Nov 26 11:59:37.167: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-988" to be "running"
    Nov 26 11:59:37.178: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 11.394539ms
    Nov 26 11:59:39.185: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.018313313s
    Nov 26 11:59:39.185: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 11/26/22 11:59:39.185
    Nov 26 11:59:44.203: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 11/26/22 11:59:44.203
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Nov 26 11:59:44.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-988" for this suite. 11/26/22 11:59:44.226
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 11:59:44.237
Nov 26 11:59:44.237: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename subpath 11/26/22 11:59:44.238
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:44.27
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:44.275
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/26/22 11:59:44.281
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-tst9 11/26/22 11:59:44.294
STEP: Creating a pod to test atomic-volume-subpath 11/26/22 11:59:44.295
Nov 26 11:59:44.312: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-tst9" in namespace "subpath-6322" to be "Succeeded or Failed"
Nov 26 11:59:44.316: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.828239ms
Nov 26 11:59:46.322: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 2.010639373s
Nov 26 11:59:48.323: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 4.011521925s
Nov 26 11:59:50.323: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 6.011128034s
Nov 26 11:59:52.322: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 8.01079466s
Nov 26 11:59:54.323: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 10.011386499s
Nov 26 11:59:56.324: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 12.012246671s
Nov 26 11:59:58.322: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 14.010561039s
Nov 26 12:00:00.322: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 16.010673766s
Nov 26 12:00:02.323: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 18.011386268s
Nov 26 12:00:04.322: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 20.010686096s
Nov 26 12:00:06.323: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=false. Elapsed: 22.011581888s
Nov 26 12:00:08.325: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013674323s
STEP: Saw pod success 11/26/22 12:00:08.325
Nov 26 12:00:08.326: INFO: Pod "pod-subpath-test-downwardapi-tst9" satisfied condition "Succeeded or Failed"
Nov 26 12:00:08.331: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-subpath-test-downwardapi-tst9 container test-container-subpath-downwardapi-tst9: <nil>
STEP: delete the pod 11/26/22 12:00:08.341
Nov 26 12:00:08.355: INFO: Waiting for pod pod-subpath-test-downwardapi-tst9 to disappear
Nov 26 12:00:08.360: INFO: Pod pod-subpath-test-downwardapi-tst9 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-tst9 11/26/22 12:00:08.36
Nov 26 12:00:08.360: INFO: Deleting pod "pod-subpath-test-downwardapi-tst9" in namespace "subpath-6322"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 26 12:00:08.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6322" for this suite. 11/26/22 12:00:08.372
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":9,"skipped":114,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.147 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 11:59:44.237
    Nov 26 11:59:44.237: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename subpath 11/26/22 11:59:44.238
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 11:59:44.27
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 11:59:44.275
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/26/22 11:59:44.281
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-tst9 11/26/22 11:59:44.294
    STEP: Creating a pod to test atomic-volume-subpath 11/26/22 11:59:44.295
    Nov 26 11:59:44.312: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-tst9" in namespace "subpath-6322" to be "Succeeded or Failed"
    Nov 26 11:59:44.316: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.828239ms
    Nov 26 11:59:46.322: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 2.010639373s
    Nov 26 11:59:48.323: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 4.011521925s
    Nov 26 11:59:50.323: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 6.011128034s
    Nov 26 11:59:52.322: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 8.01079466s
    Nov 26 11:59:54.323: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 10.011386499s
    Nov 26 11:59:56.324: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 12.012246671s
    Nov 26 11:59:58.322: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 14.010561039s
    Nov 26 12:00:00.322: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 16.010673766s
    Nov 26 12:00:02.323: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 18.011386268s
    Nov 26 12:00:04.322: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=true. Elapsed: 20.010686096s
    Nov 26 12:00:06.323: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Running", Reason="", readiness=false. Elapsed: 22.011581888s
    Nov 26 12:00:08.325: INFO: Pod "pod-subpath-test-downwardapi-tst9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.013674323s
    STEP: Saw pod success 11/26/22 12:00:08.325
    Nov 26 12:00:08.326: INFO: Pod "pod-subpath-test-downwardapi-tst9" satisfied condition "Succeeded or Failed"
    Nov 26 12:00:08.331: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-subpath-test-downwardapi-tst9 container test-container-subpath-downwardapi-tst9: <nil>
    STEP: delete the pod 11/26/22 12:00:08.341
    Nov 26 12:00:08.355: INFO: Waiting for pod pod-subpath-test-downwardapi-tst9 to disappear
    Nov 26 12:00:08.360: INFO: Pod pod-subpath-test-downwardapi-tst9 no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-tst9 11/26/22 12:00:08.36
    Nov 26 12:00:08.360: INFO: Deleting pod "pod-subpath-test-downwardapi-tst9" in namespace "subpath-6322"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 26 12:00:08.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-6322" for this suite. 11/26/22 12:00:08.372
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:00:08.386
Nov 26 12:00:08.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename deployment 11/26/22 12:00:08.389
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:08.425
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:08.433
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Nov 26 12:00:08.459: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 26 12:00:13.467: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/26/22 12:00:13.467
Nov 26 12:00:13.467: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 11/26/22 12:00:13.482
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 26 12:00:13.501: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-384  40f384d0-fa8a-4252-b0f8-3c3f48f94602 2466 1 2022-11-26 12:00:13 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2022-11-26 12:00:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035939d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Nov 26 12:00:13.510: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Nov 26 12:00:13.510: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov 26 12:00:13.511: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-384  4e771736-8f1c-43bc-b8b5-ef4cc40c2d12 2468 1 2022-11-26 12:00:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 40f384d0-fa8a-4252-b0f8-3c3f48f94602 0xc001978faf 0xc001978fc0}] [] [{e2e.test Update apps/v1 2022-11-26 12:00:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:00:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-26 12:00:13 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"40f384d0-fa8a-4252-b0f8-3c3f48f94602\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001979078 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:00:13.538: INFO: Pod "test-cleanup-controller-xl7t5" is available:
&Pod{ObjectMeta:{test-cleanup-controller-xl7t5 test-cleanup-controller- deployment-384  a4a48db8-324a-42af-a6f2-690a74331ad7 2450 0 2022-11-26 12:00:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 4e771736-8f1c-43bc-b8b5-ef4cc40c2d12 0xc003593e9f 0xc003593eb0}] [] [{kube-controller-manager Update v1 2022-11-26 12:00:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4e771736-8f1c-43bc-b8b5-ef4cc40c2d12\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:00:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.11\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8bwjk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8bwjk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:00:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:00:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:00:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:00:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.11,StartTime:2022-11-26 12:00:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:00:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cbfb549ddb6636ad4df68e1fbcded42aac2bb13b32e13f779b1d2175b7a75c8c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.11,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 26 12:00:13.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-384" for this suite. 11/26/22 12:00:13.545
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":10,"skipped":120,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.176 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:00:08.386
    Nov 26 12:00:08.387: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename deployment 11/26/22 12:00:08.389
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:08.425
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:08.433
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Nov 26 12:00:08.459: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Nov 26 12:00:13.467: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/26/22 12:00:13.467
    Nov 26 12:00:13.467: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 11/26/22 12:00:13.482
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 26 12:00:13.501: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-384  40f384d0-fa8a-4252-b0f8-3c3f48f94602 2466 1 2022-11-26 12:00:13 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] [{e2e.test Update apps/v1 2022-11-26 12:00:13 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0035939d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

    Nov 26 12:00:13.510: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
    Nov 26 12:00:13.510: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
    Nov 26 12:00:13.511: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-384  4e771736-8f1c-43bc-b8b5-ef4cc40c2d12 2468 1 2022-11-26 12:00:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 40f384d0-fa8a-4252-b0f8-3c3f48f94602 0xc001978faf 0xc001978fc0}] [] [{e2e.test Update apps/v1 2022-11-26 12:00:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:00:10 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-26 12:00:13 +0000 UTC FieldsV1 {"f:metadata":{"f:ownerReferences":{".":{},"k:{\"uid\":\"40f384d0-fa8a-4252-b0f8-3c3f48f94602\"}":{}}}} }]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001979078 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:00:13.538: INFO: Pod "test-cleanup-controller-xl7t5" is available:
    &Pod{ObjectMeta:{test-cleanup-controller-xl7t5 test-cleanup-controller- deployment-384  a4a48db8-324a-42af-a6f2-690a74331ad7 2450 0 2022-11-26 12:00:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 4e771736-8f1c-43bc-b8b5-ef4cc40c2d12 0xc003593e9f 0xc003593eb0}] [] [{kube-controller-manager Update v1 2022-11-26 12:00:08 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4e771736-8f1c-43bc-b8b5-ef4cc40c2d12\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:00:10 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.11\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8bwjk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8bwjk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:00:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:00:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:00:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:00:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.11,StartTime:2022-11-26 12:00:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:00:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://cbfb549ddb6636ad4df68e1fbcded42aac2bb13b32e13f779b1d2175b7a75c8c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.11,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 26 12:00:13.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-384" for this suite. 11/26/22 12:00:13.545
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:00:13.564
Nov 26 12:00:13.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:00:13.566
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:13.618
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:13.628
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 11/26/22 12:00:13.634
Nov 26 12:00:13.635: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: mark a version not serverd 11/26/22 12:00:21.868
STEP: check the unserved version gets removed 11/26/22 12:00:21.906
STEP: check the other version is not changed 11/26/22 12:00:26.115
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:00:33.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4243" for this suite. 11/26/22 12:00:33.422
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":11,"skipped":122,"failed":0}
------------------------------
â€¢ [SLOW TEST] [19.872 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:00:13.564
    Nov 26 12:00:13.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:00:13.566
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:13.618
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:13.628
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 11/26/22 12:00:13.634
    Nov 26 12:00:13.635: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: mark a version not serverd 11/26/22 12:00:21.868
    STEP: check the unserved version gets removed 11/26/22 12:00:21.906
    STEP: check the other version is not changed 11/26/22 12:00:26.115
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:00:33.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4243" for this suite. 11/26/22 12:00:33.422
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:00:33.437
Nov 26 12:00:33.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 12:00:33.438
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:33.459
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:33.466
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-e4f058e9-cdfd-48d7-9c58-eb1321975bef 11/26/22 12:00:33.474
STEP: Creating a pod to test consume configMaps 11/26/22 12:00:33.482
Nov 26 12:00:33.501: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828" in namespace "configmap-2055" to be "Succeeded or Failed"
Nov 26 12:00:33.515: INFO: Pod "pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828": Phase="Pending", Reason="", readiness=false. Elapsed: 13.470303ms
Nov 26 12:00:35.521: INFO: Pod "pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019240778s
Nov 26 12:00:37.527: INFO: Pod "pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025676519s
STEP: Saw pod success 11/26/22 12:00:37.527
Nov 26 12:00:37.527: INFO: Pod "pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828" satisfied condition "Succeeded or Failed"
Nov 26 12:00:37.533: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828 container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:00:37.554
Nov 26 12:00:37.575: INFO: Waiting for pod pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828 to disappear
Nov 26 12:00:37.580: INFO: Pod pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 12:00:37.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2055" for this suite. 11/26/22 12:00:37.586
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":12,"skipped":124,"failed":0}
------------------------------
â€¢ [4.160 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:00:33.437
    Nov 26 12:00:33.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 12:00:33.438
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:33.459
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:33.466
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-e4f058e9-cdfd-48d7-9c58-eb1321975bef 11/26/22 12:00:33.474
    STEP: Creating a pod to test consume configMaps 11/26/22 12:00:33.482
    Nov 26 12:00:33.501: INFO: Waiting up to 5m0s for pod "pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828" in namespace "configmap-2055" to be "Succeeded or Failed"
    Nov 26 12:00:33.515: INFO: Pod "pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828": Phase="Pending", Reason="", readiness=false. Elapsed: 13.470303ms
    Nov 26 12:00:35.521: INFO: Pod "pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019240778s
    Nov 26 12:00:37.527: INFO: Pod "pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025676519s
    STEP: Saw pod success 11/26/22 12:00:37.527
    Nov 26 12:00:37.527: INFO: Pod "pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828" satisfied condition "Succeeded or Failed"
    Nov 26 12:00:37.533: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828 container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:00:37.554
    Nov 26 12:00:37.575: INFO: Waiting for pod pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828 to disappear
    Nov 26 12:00:37.580: INFO: Pod pod-configmaps-8ab07d02-6d40-48f7-979f-108131542828 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 12:00:37.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2055" for this suite. 11/26/22 12:00:37.586
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:00:37.598
Nov 26 12:00:37.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:00:37.599
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:37.629
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:37.637
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:00:37.672
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:00:38.548
STEP: Deploying the webhook pod 11/26/22 12:00:38.562
STEP: Wait for the deployment to be ready 11/26/22 12:00:38.584
Nov 26 12:00:38.600: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/26/22 12:00:40.618
STEP: Verifying the service has paired with the endpoint 11/26/22 12:00:40.634
Nov 26 12:00:41.634: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Nov 26 12:00:41.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7865-crds.webhook.example.com via the AdmissionRegistration API 11/26/22 12:00:42.16
STEP: Creating a custom resource that should be mutated by the webhook 11/26/22 12:00:42.183
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:00:44.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8020" for this suite. 11/26/22 12:00:44.783
STEP: Destroying namespace "webhook-8020-markers" for this suite. 11/26/22 12:00:44.794
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":13,"skipped":126,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.309 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:00:37.598
    Nov 26 12:00:37.598: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:00:37.599
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:37.629
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:37.637
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:00:37.672
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:00:38.548
    STEP: Deploying the webhook pod 11/26/22 12:00:38.562
    STEP: Wait for the deployment to be ready 11/26/22 12:00:38.584
    Nov 26 12:00:38.600: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/26/22 12:00:40.618
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:00:40.634
    Nov 26 12:00:41.634: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Nov 26 12:00:41.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7865-crds.webhook.example.com via the AdmissionRegistration API 11/26/22 12:00:42.16
    STEP: Creating a custom resource that should be mutated by the webhook 11/26/22 12:00:42.183
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:00:44.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8020" for this suite. 11/26/22 12:00:44.783
    STEP: Destroying namespace "webhook-8020-markers" for this suite. 11/26/22 12:00:44.794
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:00:44.91
Nov 26 12:00:44.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-runtime 11/26/22 12:00:44.911
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:44.971
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:44.986
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 11/26/22 12:00:45.009
STEP: wait for the container to reach Succeeded 11/26/22 12:00:45.027
STEP: get the container status 11/26/22 12:00:49.079
STEP: the container should be terminated 11/26/22 12:00:49.084
STEP: the termination message should be set 11/26/22 12:00:49.084
Nov 26 12:00:49.084: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 11/26/22 12:00:49.084
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 26 12:00:49.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6073" for this suite. 11/26/22 12:00:49.123
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":14,"skipped":138,"failed":0}
------------------------------
â€¢ [4.229 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:00:44.91
    Nov 26 12:00:44.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-runtime 11/26/22 12:00:44.911
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:44.971
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:44.986
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 11/26/22 12:00:45.009
    STEP: wait for the container to reach Succeeded 11/26/22 12:00:45.027
    STEP: get the container status 11/26/22 12:00:49.079
    STEP: the container should be terminated 11/26/22 12:00:49.084
    STEP: the termination message should be set 11/26/22 12:00:49.084
    Nov 26 12:00:49.084: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 11/26/22 12:00:49.084
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 26 12:00:49.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-6073" for this suite. 11/26/22 12:00:49.123
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:00:49.14
Nov 26 12:00:49.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:00:49.141
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:49.161
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:49.169
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-ee615e99-d5f7-40bf-8176-4d67a1d4216f 11/26/22 12:00:49.176
STEP: Creating a pod to test consume secrets 11/26/22 12:00:49.185
Nov 26 12:00:49.200: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b" in namespace "projected-2951" to be "Succeeded or Failed"
Nov 26 12:00:49.210: INFO: Pod "pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.232314ms
Nov 26 12:00:51.216: INFO: Pod "pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016165969s
Nov 26 12:00:53.217: INFO: Pod "pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017279904s
STEP: Saw pod success 11/26/22 12:00:53.217
Nov 26 12:00:53.217: INFO: Pod "pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b" satisfied condition "Succeeded or Failed"
Nov 26 12:00:53.223: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b container projected-secret-volume-test: <nil>
STEP: delete the pod 11/26/22 12:00:53.236
Nov 26 12:00:53.253: INFO: Waiting for pod pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b to disappear
Nov 26 12:00:53.258: INFO: Pod pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 26 12:00:53.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2951" for this suite. 11/26/22 12:00:53.264
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":15,"skipped":144,"failed":0}
------------------------------
â€¢ [4.138 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:00:49.14
    Nov 26 12:00:49.140: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:00:49.141
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:49.161
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:49.169
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-ee615e99-d5f7-40bf-8176-4d67a1d4216f 11/26/22 12:00:49.176
    STEP: Creating a pod to test consume secrets 11/26/22 12:00:49.185
    Nov 26 12:00:49.200: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b" in namespace "projected-2951" to be "Succeeded or Failed"
    Nov 26 12:00:49.210: INFO: Pod "pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.232314ms
    Nov 26 12:00:51.216: INFO: Pod "pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016165969s
    Nov 26 12:00:53.217: INFO: Pod "pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017279904s
    STEP: Saw pod success 11/26/22 12:00:53.217
    Nov 26 12:00:53.217: INFO: Pod "pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b" satisfied condition "Succeeded or Failed"
    Nov 26 12:00:53.223: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:00:53.236
    Nov 26 12:00:53.253: INFO: Waiting for pod pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b to disappear
    Nov 26 12:00:53.258: INFO: Pod pod-projected-secrets-e4d56d25-6e16-4f98-a9bf-0c50baf5cd8b no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 26 12:00:53.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2951" for this suite. 11/26/22 12:00:53.264
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:00:53.278
Nov 26 12:00:53.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pod-network-test 11/26/22 12:00:53.279
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:53.305
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:53.318
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-4371 11/26/22 12:00:53.325
STEP: creating a selector 11/26/22 12:00:53.325
STEP: Creating the service pods in kubernetes 11/26/22 12:00:53.325
Nov 26 12:00:53.326: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 26 12:00:53.390: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4371" to be "running and ready"
Nov 26 12:00:53.404: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.295955ms
Nov 26 12:00:53.405: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:00:55.410: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020216142s
Nov 26 12:00:55.411: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:00:57.412: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021313677s
Nov 26 12:00:57.412: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:00:59.412: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021356756s
Nov 26 12:00:59.412: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:01:01.413: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.0224141s
Nov 26 12:01:01.413: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:01:03.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.02162553s
Nov 26 12:01:03.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:01:05.411: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.020448056s
Nov 26 12:01:05.411: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:01:07.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.022141392s
Nov 26 12:01:07.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:01:09.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.021676091s
Nov 26 12:01:09.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:01:11.411: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.021104186s
Nov 26 12:01:11.411: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:01:13.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.022605854s
Nov 26 12:01:13.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:01:15.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.022395926s
Nov 26 12:01:15.413: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 26 12:01:15.413: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 26 12:01:15.418: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4371" to be "running and ready"
Nov 26 12:01:15.423: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.486991ms
Nov 26 12:01:15.423: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 26 12:01:15.424: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 26 12:01:15.429: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4371" to be "running and ready"
Nov 26 12:01:15.435: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 5.980911ms
Nov 26 12:01:15.435: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 26 12:01:15.435: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/26/22 12:01:15.441
Nov 26 12:01:15.461: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4371" to be "running"
Nov 26 12:01:15.473: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.29004ms
Nov 26 12:01:17.479: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018077838s
Nov 26 12:01:17.479: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 26 12:01:17.485: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-4371" to be "running"
Nov 26 12:01:17.491: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.542973ms
Nov 26 12:01:17.491: INFO: Pod "host-test-container-pod" satisfied condition "running"
Nov 26 12:01:17.496: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 26 12:01:17.496: INFO: Going to poll 192.168.150.136 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov 26 12:01:17.503: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.150.136:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:17.503: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:17.504: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:17.504: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.150.136%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 26 12:01:17.605: INFO: Found all 1 expected endpoints: [netserver-0]
Nov 26 12:01:17.606: INFO: Going to poll 192.168.46.195 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov 26 12:01:17.614: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.46.195:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:17.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:17.615: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:17.615: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.46.195%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 26 12:01:17.697: INFO: Found all 1 expected endpoints: [netserver-1]
Nov 26 12:01:17.697: INFO: Going to poll 192.168.34.16 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov 26 12:01:17.703: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.34.16:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:17.703: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:17.704: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:17.704: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.34.16%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 26 12:01:17.793: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 26 12:01:17.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4371" for this suite. 11/26/22 12:01:17.8
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":16,"skipped":148,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.535 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:00:53.278
    Nov 26 12:00:53.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pod-network-test 11/26/22 12:00:53.279
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:00:53.305
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:00:53.318
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-4371 11/26/22 12:00:53.325
    STEP: creating a selector 11/26/22 12:00:53.325
    STEP: Creating the service pods in kubernetes 11/26/22 12:00:53.325
    Nov 26 12:00:53.326: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 26 12:00:53.390: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4371" to be "running and ready"
    Nov 26 12:00:53.404: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.295955ms
    Nov 26 12:00:53.405: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:00:55.410: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020216142s
    Nov 26 12:00:55.411: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:00:57.412: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021313677s
    Nov 26 12:00:57.412: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:00:59.412: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021356756s
    Nov 26 12:00:59.412: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:01:01.413: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.0224141s
    Nov 26 12:01:01.413: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:01:03.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.02162553s
    Nov 26 12:01:03.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:01:05.411: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.020448056s
    Nov 26 12:01:05.411: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:01:07.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.022141392s
    Nov 26 12:01:07.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:01:09.412: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.021676091s
    Nov 26 12:01:09.412: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:01:11.411: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.021104186s
    Nov 26 12:01:11.411: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:01:13.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.022605854s
    Nov 26 12:01:13.413: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:01:15.413: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.022395926s
    Nov 26 12:01:15.413: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 26 12:01:15.413: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 26 12:01:15.418: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4371" to be "running and ready"
    Nov 26 12:01:15.423: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.486991ms
    Nov 26 12:01:15.423: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 26 12:01:15.424: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 26 12:01:15.429: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4371" to be "running and ready"
    Nov 26 12:01:15.435: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 5.980911ms
    Nov 26 12:01:15.435: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 26 12:01:15.435: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/26/22 12:01:15.441
    Nov 26 12:01:15.461: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4371" to be "running"
    Nov 26 12:01:15.473: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 12.29004ms
    Nov 26 12:01:17.479: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018077838s
    Nov 26 12:01:17.479: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 26 12:01:17.485: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-4371" to be "running"
    Nov 26 12:01:17.491: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.542973ms
    Nov 26 12:01:17.491: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Nov 26 12:01:17.496: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 26 12:01:17.496: INFO: Going to poll 192.168.150.136 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov 26 12:01:17.503: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.150.136:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:17.503: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:17.504: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:17.504: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.150.136%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 26 12:01:17.605: INFO: Found all 1 expected endpoints: [netserver-0]
    Nov 26 12:01:17.606: INFO: Going to poll 192.168.46.195 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov 26 12:01:17.614: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.46.195:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:17.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:17.615: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:17.615: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.46.195%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 26 12:01:17.697: INFO: Found all 1 expected endpoints: [netserver-1]
    Nov 26 12:01:17.697: INFO: Going to poll 192.168.34.16 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov 26 12:01:17.703: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.34.16:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4371 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:17.703: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:17.704: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:17.704: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4371/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.34.16%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 26 12:01:17.793: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 26 12:01:17.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-4371" for this suite. 11/26/22 12:01:17.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:01:17.814
Nov 26 12:01:17.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:01:17.816
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:17.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:17.844
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-a702b8f8-f0eb-45dc-b73f-e13826c6cb48 11/26/22 12:01:17.85
STEP: Creating a pod to test consume configMaps 11/26/22 12:01:17.858
Nov 26 12:01:17.871: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3" in namespace "projected-4363" to be "Succeeded or Failed"
Nov 26 12:01:17.877: INFO: Pod "pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.575544ms
Nov 26 12:01:19.884: INFO: Pod "pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013382956s
Nov 26 12:01:21.888: INFO: Pod "pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017158485s
STEP: Saw pod success 11/26/22 12:01:21.888
Nov 26 12:01:21.889: INFO: Pod "pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3" satisfied condition "Succeeded or Failed"
Nov 26 12:01:21.895: INFO: Trying to get logs from node ip-172-31-29-104 pod pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3 container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:01:21.929
Nov 26 12:01:21.953: INFO: Waiting for pod pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3 to disappear
Nov 26 12:01:21.959: INFO: Pod pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 26 12:01:21.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4363" for this suite. 11/26/22 12:01:21.965
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":17,"skipped":157,"failed":0}
------------------------------
â€¢ [4.164 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:01:17.814
    Nov 26 12:01:17.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:01:17.816
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:17.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:17.844
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-a702b8f8-f0eb-45dc-b73f-e13826c6cb48 11/26/22 12:01:17.85
    STEP: Creating a pod to test consume configMaps 11/26/22 12:01:17.858
    Nov 26 12:01:17.871: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3" in namespace "projected-4363" to be "Succeeded or Failed"
    Nov 26 12:01:17.877: INFO: Pod "pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.575544ms
    Nov 26 12:01:19.884: INFO: Pod "pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013382956s
    Nov 26 12:01:21.888: INFO: Pod "pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017158485s
    STEP: Saw pod success 11/26/22 12:01:21.888
    Nov 26 12:01:21.889: INFO: Pod "pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3" satisfied condition "Succeeded or Failed"
    Nov 26 12:01:21.895: INFO: Trying to get logs from node ip-172-31-29-104 pod pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3 container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:01:21.929
    Nov 26 12:01:21.953: INFO: Waiting for pod pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3 to disappear
    Nov 26 12:01:21.959: INFO: Pod pod-projected-configmaps-78141002-f08f-44a3-a080-684d5cdac1a3 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 26 12:01:21.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4363" for this suite. 11/26/22 12:01:21.965
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:01:21.981
Nov 26 12:01:21.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename runtimeclass 11/26/22 12:01:21.982
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:22.004
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:22.012
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 26 12:01:22.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7482" for this suite. 11/26/22 12:01:22.038
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":18,"skipped":165,"failed":0}
------------------------------
â€¢ [0.069 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:01:21.981
    Nov 26 12:01:21.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename runtimeclass 11/26/22 12:01:21.982
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:22.004
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:22.012
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 26 12:01:22.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7482" for this suite. 11/26/22 12:01:22.038
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:01:22.052
Nov 26 12:01:22.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename deployment 11/26/22 12:01:22.054
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:22.085
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:22.09
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Nov 26 12:01:22.097: INFO: Creating simple deployment test-new-deployment
Nov 26 12:01:22.118: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource 11/26/22 12:01:24.142
STEP: updating a scale subresource 11/26/22 12:01:24.149
STEP: verifying the deployment Spec.Replicas was modified 11/26/22 12:01:24.16
STEP: Patch a scale subresource 11/26/22 12:01:24.169
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 26 12:01:24.213: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-2632  e52d02a9-4bb5-47b8-927b-b3b59b012ac9 3031 3 2022-11-26 12:01:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-11-26 12:01:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:01:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002e3fcb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-26 12:01:23 +0000 UTC,LastTransitionTime:2022-11-26 12:01:23 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-11-26 12:01:23 +0000 UTC,LastTransitionTime:2022-11-26 12:01:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 26 12:01:24.227: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-2632  b644d23e-7684-44f3-9d01-a872e55b1431 3036 2 2022-11-26 12:01:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment e52d02a9-4bb5-47b8-927b-b3b59b012ac9 0xc002dd7e40 0xc002dd7e41}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:01:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e52d02a9-4bb5-47b8-927b-b3b59b012ac9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:01:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002dd7ee8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:01:24.239: INFO: Pod "test-new-deployment-845c8977d9-ms8vr" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-ms8vr test-new-deployment-845c8977d9- deployment-2632  08c42bf9-d2f4-4a26-9ade-3ffc19ad39b1 3002 0 2022-11-26 12:01:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b644d23e-7684-44f3-9d01-a872e55b1431 0xc002e74200 0xc002e74201}] [] [{kube-controller-manager Update v1 2022-11-26 12:01:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b644d23e-7684-44f3-9d01-a872e55b1431\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:01:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n9dx9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n9dx9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.18,StartTime:2022-11-26 12:01:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:01:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://86de7598c7f72b53a566ce15092ae63451c67f539fc2eb426e6f6f9418e29d0e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:01:24.240: INFO: Pod "test-new-deployment-845c8977d9-mvtkm" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-mvtkm test-new-deployment-845c8977d9- deployment-2632  0f92fbae-d6dc-47df-856d-05a2158f4347 3039 0 2022-11-26 12:01:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b644d23e-7684-44f3-9d01-a872e55b1431 0xc002e74467 0xc002e74468}] [] [{kube-controller-manager Update v1 2022-11-26 12:01:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b644d23e-7684-44f3-9d01-a872e55b1431\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9cqdm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9cqdm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:01:24.240: INFO: Pod "test-new-deployment-845c8977d9-nwdn9" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-nwdn9 test-new-deployment-845c8977d9- deployment-2632  52910744-d697-42c4-95f2-237188af2b95 3038 0 2022-11-26 12:01:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b644d23e-7684-44f3-9d01-a872e55b1431 0xc002e74607 0xc002e74608}] [] [{kube-controller-manager Update v1 2022-11-26 12:01:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b644d23e-7684-44f3-9d01-a872e55b1431\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:01:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gdsg6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gdsg6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:,StartTime:2022-11-26 12:01:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 26 12:01:24.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2632" for this suite. 11/26/22 12:01:24.254
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":19,"skipped":186,"failed":0}
------------------------------
â€¢ [2.226 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:01:22.052
    Nov 26 12:01:22.053: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename deployment 11/26/22 12:01:22.054
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:22.085
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:22.09
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Nov 26 12:01:22.097: INFO: Creating simple deployment test-new-deployment
    Nov 26 12:01:22.118: INFO: deployment "test-new-deployment" doesn't have the required revision set
    STEP: getting scale subresource 11/26/22 12:01:24.142
    STEP: updating a scale subresource 11/26/22 12:01:24.149
    STEP: verifying the deployment Spec.Replicas was modified 11/26/22 12:01:24.16
    STEP: Patch a scale subresource 11/26/22 12:01:24.169
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 26 12:01:24.213: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-2632  e52d02a9-4bb5-47b8-927b-b3b59b012ac9 3031 3 2022-11-26 12:01:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-11-26 12:01:22 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:01:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002e3fcb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-26 12:01:23 +0000 UTC,LastTransitionTime:2022-11-26 12:01:23 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-11-26 12:01:23 +0000 UTC,LastTransitionTime:2022-11-26 12:01:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 26 12:01:24.227: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-2632  b644d23e-7684-44f3-9d01-a872e55b1431 3036 2 2022-11-26 12:01:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment e52d02a9-4bb5-47b8-927b-b3b59b012ac9 0xc002dd7e40 0xc002dd7e41}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:01:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"e52d02a9-4bb5-47b8-927b-b3b59b012ac9\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:01:24 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002dd7ee8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:01:24.239: INFO: Pod "test-new-deployment-845c8977d9-ms8vr" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-ms8vr test-new-deployment-845c8977d9- deployment-2632  08c42bf9-d2f4-4a26-9ade-3ffc19ad39b1 3002 0 2022-11-26 12:01:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b644d23e-7684-44f3-9d01-a872e55b1431 0xc002e74200 0xc002e74201}] [] [{kube-controller-manager Update v1 2022-11-26 12:01:22 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b644d23e-7684-44f3-9d01-a872e55b1431\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:01:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.18\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-n9dx9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-n9dx9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.18,StartTime:2022-11-26 12:01:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:01:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://86de7598c7f72b53a566ce15092ae63451c67f539fc2eb426e6f6f9418e29d0e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.18,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:01:24.240: INFO: Pod "test-new-deployment-845c8977d9-mvtkm" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-mvtkm test-new-deployment-845c8977d9- deployment-2632  0f92fbae-d6dc-47df-856d-05a2158f4347 3039 0 2022-11-26 12:01:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b644d23e-7684-44f3-9d01-a872e55b1431 0xc002e74467 0xc002e74468}] [] [{kube-controller-manager Update v1 2022-11-26 12:01:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b644d23e-7684-44f3-9d01-a872e55b1431\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9cqdm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9cqdm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:01:24.240: INFO: Pod "test-new-deployment-845c8977d9-nwdn9" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-nwdn9 test-new-deployment-845c8977d9- deployment-2632  52910744-d697-42c4-95f2-237188af2b95 3038 0 2022-11-26 12:01:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 b644d23e-7684-44f3-9d01-a872e55b1431 0xc002e74607 0xc002e74608}] [] [{kube-controller-manager Update v1 2022-11-26 12:01:24 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b644d23e-7684-44f3-9d01-a872e55b1431\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:01:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gdsg6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gdsg6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:01:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:,StartTime:2022-11-26 12:01:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 26 12:01:24.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2632" for this suite. 11/26/22 12:01:24.254
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:01:24.28
Nov 26 12:01:24.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename init-container 11/26/22 12:01:24.282
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:24.306
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:24.312
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 11/26/22 12:01:24.318
Nov 26 12:01:24.319: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 26 12:01:29.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2199" for this suite. 11/26/22 12:01:29.46
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":20,"skipped":188,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.193 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:01:24.28
    Nov 26 12:01:24.281: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename init-container 11/26/22 12:01:24.282
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:24.306
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:24.312
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 11/26/22 12:01:24.318
    Nov 26 12:01:24.319: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 26 12:01:29.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-2199" for this suite. 11/26/22 12:01:29.46
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:01:29.473
Nov 26 12:01:29.474: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:01:29.475
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:29.505
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:29.514
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-4976 11/26/22 12:01:29.522
STEP: creating service affinity-nodeport-transition in namespace services-4976 11/26/22 12:01:29.522
STEP: creating replication controller affinity-nodeport-transition in namespace services-4976 11/26/22 12:01:29.589
I1126 12:01:29.605361      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4976, replica count: 3
I1126 12:01:32.656825      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 12:01:32.674: INFO: Creating new exec pod
Nov 26 12:01:32.681: INFO: Waiting up to 5m0s for pod "execpod-affinitylzm8n" in namespace "services-4976" to be "running"
Nov 26 12:01:32.692: INFO: Pod "execpod-affinitylzm8n": Phase="Pending", Reason="", readiness=false. Elapsed: 10.281682ms
Nov 26 12:01:34.697: INFO: Pod "execpod-affinitylzm8n": Phase="Running", Reason="", readiness=true. Elapsed: 2.015882758s
Nov 26 12:01:34.697: INFO: Pod "execpod-affinitylzm8n" satisfied condition "running"
Nov 26 12:01:35.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Nov 26 12:01:35.889: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Nov 26 12:01:35.889: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:01:35.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.221 80'
Nov 26 12:01:36.087: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.221 80\nConnection to 10.152.183.221 80 port [tcp/http] succeeded!\n"
Nov 26 12:01:36.087: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:01:36.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.82 30026'
Nov 26 12:01:36.304: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.43.82 30026\nConnection to 172.31.43.82 30026 port [tcp/*] succeeded!\n"
Nov 26 12:01:36.304: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:01:36.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 30026'
Nov 26 12:01:36.509: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.29.104 30026\nConnection to 172.31.29.104 30026 port [tcp/*] succeeded!\n"
Nov 26 12:01:36.509: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:01:36.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.249:30026/ ; done'
Nov 26 12:01:36.866: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n"
Nov 26 12:01:36.866: INFO: stdout: "\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-fbm8m"
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
Nov 26 12:01:36.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.249:30026/ ; done'
Nov 26 12:01:37.189: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n"
Nov 26 12:01:37.190: INFO: stdout: "\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd"
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
Nov 26 12:01:37.190: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4976, will wait for the garbage collector to delete the pods 11/26/22 12:01:37.211
Nov 26 12:01:37.281: INFO: Deleting ReplicationController affinity-nodeport-transition took: 11.930987ms
Nov 26 12:01:37.381: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.123117ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:01:39.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4976" for this suite. 11/26/22 12:01:39.534
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":21,"skipped":188,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.078 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:01:29.473
    Nov 26 12:01:29.474: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:01:29.475
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:29.505
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:29.514
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-4976 11/26/22 12:01:29.522
    STEP: creating service affinity-nodeport-transition in namespace services-4976 11/26/22 12:01:29.522
    STEP: creating replication controller affinity-nodeport-transition in namespace services-4976 11/26/22 12:01:29.589
    I1126 12:01:29.605361      19 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-4976, replica count: 3
    I1126 12:01:32.656825      19 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 12:01:32.674: INFO: Creating new exec pod
    Nov 26 12:01:32.681: INFO: Waiting up to 5m0s for pod "execpod-affinitylzm8n" in namespace "services-4976" to be "running"
    Nov 26 12:01:32.692: INFO: Pod "execpod-affinitylzm8n": Phase="Pending", Reason="", readiness=false. Elapsed: 10.281682ms
    Nov 26 12:01:34.697: INFO: Pod "execpod-affinitylzm8n": Phase="Running", Reason="", readiness=true. Elapsed: 2.015882758s
    Nov 26 12:01:34.697: INFO: Pod "execpod-affinitylzm8n" satisfied condition "running"
    Nov 26 12:01:35.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Nov 26 12:01:35.889: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Nov 26 12:01:35.889: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:01:35.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.221 80'
    Nov 26 12:01:36.087: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.221 80\nConnection to 10.152.183.221 80 port [tcp/http] succeeded!\n"
    Nov 26 12:01:36.087: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:01:36.087: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.82 30026'
    Nov 26 12:01:36.304: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.43.82 30026\nConnection to 172.31.43.82 30026 port [tcp/*] succeeded!\n"
    Nov 26 12:01:36.304: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:01:36.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 30026'
    Nov 26 12:01:36.509: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.29.104 30026\nConnection to 172.31.29.104 30026 port [tcp/*] succeeded!\n"
    Nov 26 12:01:36.509: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:01:36.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.249:30026/ ; done'
    Nov 26 12:01:36.866: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n"
    Nov 26 12:01:36.866: INFO: stdout: "\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-fbm8m\naffinity-nodeport-transition-99j6c\naffinity-nodeport-transition-fbm8m"
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-99j6c
    Nov 26 12:01:36.866: INFO: Received response from host: affinity-nodeport-transition-fbm8m
    Nov 26 12:01:36.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4976 exec execpod-affinitylzm8n -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.249:30026/ ; done'
    Nov 26 12:01:37.189: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:30026/\n"
    Nov 26 12:01:37.190: INFO: stdout: "\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd\naffinity-nodeport-transition-2swrd"
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Received response from host: affinity-nodeport-transition-2swrd
    Nov 26 12:01:37.190: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-4976, will wait for the garbage collector to delete the pods 11/26/22 12:01:37.211
    Nov 26 12:01:37.281: INFO: Deleting ReplicationController affinity-nodeport-transition took: 11.930987ms
    Nov 26 12:01:37.381: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.123117ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:01:39.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4976" for this suite. 11/26/22 12:01:39.534
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:01:39.554
Nov 26 12:01:39.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-lifecycle-hook 11/26/22 12:01:39.555
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:39.588
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:39.596
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/26/22 12:01:39.61
Nov 26 12:01:39.625: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2531" to be "running and ready"
Nov 26 12:01:39.630: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 5.068616ms
Nov 26 12:01:39.630: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:01:41.639: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.013815079s
Nov 26 12:01:41.639: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 26 12:01:41.639: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 11/26/22 12:01:41.645
Nov 26 12:01:41.656: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-2531" to be "running and ready"
Nov 26 12:01:41.661: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.038205ms
Nov 26 12:01:41.661: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:01:43.668: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011642489s
Nov 26 12:01:43.668: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Nov 26 12:01:43.668: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 11/26/22 12:01:43.676
STEP: delete the pod with lifecycle hook 11/26/22 12:01:43.685
Nov 26 12:01:43.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 26 12:01:43.704: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 26 12:01:45.704: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 26 12:01:45.711: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 26 12:01:47.704: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 26 12:01:47.711: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 26 12:01:47.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2531" for this suite. 11/26/22 12:01:47.717
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":22,"skipped":203,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.173 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:01:39.554
    Nov 26 12:01:39.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/26/22 12:01:39.555
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:39.588
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:39.596
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/26/22 12:01:39.61
    Nov 26 12:01:39.625: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2531" to be "running and ready"
    Nov 26 12:01:39.630: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 5.068616ms
    Nov 26 12:01:39.630: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:01:41.639: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.013815079s
    Nov 26 12:01:41.639: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 26 12:01:41.639: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 11/26/22 12:01:41.645
    Nov 26 12:01:41.656: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-2531" to be "running and ready"
    Nov 26 12:01:41.661: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.038205ms
    Nov 26 12:01:41.661: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:01:43.668: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011642489s
    Nov 26 12:01:43.668: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Nov 26 12:01:43.668: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 11/26/22 12:01:43.676
    STEP: delete the pod with lifecycle hook 11/26/22 12:01:43.685
    Nov 26 12:01:43.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov 26 12:01:43.704: INFO: Pod pod-with-poststart-exec-hook still exists
    Nov 26 12:01:45.704: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov 26 12:01:45.711: INFO: Pod pod-with-poststart-exec-hook still exists
    Nov 26 12:01:47.704: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov 26 12:01:47.711: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 26 12:01:47.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-2531" for this suite. 11/26/22 12:01:47.717
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:01:47.73
Nov 26 12:01:47.731: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:01:47.732
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:47.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:47.758
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-081acf03-f9bc-433c-857a-f34cccca9ecd 11/26/22 12:01:47.764
STEP: Creating a pod to test consume configMaps 11/26/22 12:01:47.771
Nov 26 12:01:47.788: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f" in namespace "projected-7791" to be "Succeeded or Failed"
Nov 26 12:01:47.797: INFO: Pod "pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.711122ms
Nov 26 12:01:49.804: INFO: Pod "pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015598513s
Nov 26 12:01:51.807: INFO: Pod "pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018736177s
STEP: Saw pod success 11/26/22 12:01:51.807
Nov 26 12:01:51.807: INFO: Pod "pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f" satisfied condition "Succeeded or Failed"
Nov 26 12:01:51.812: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:01:51.821
Nov 26 12:01:51.845: INFO: Waiting for pod pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f to disappear
Nov 26 12:01:51.850: INFO: Pod pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 26 12:01:51.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7791" for this suite. 11/26/22 12:01:51.856
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":23,"skipped":225,"failed":0}
------------------------------
â€¢ [4.155 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:01:47.73
    Nov 26 12:01:47.731: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:01:47.732
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:47.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:47.758
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-081acf03-f9bc-433c-857a-f34cccca9ecd 11/26/22 12:01:47.764
    STEP: Creating a pod to test consume configMaps 11/26/22 12:01:47.771
    Nov 26 12:01:47.788: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f" in namespace "projected-7791" to be "Succeeded or Failed"
    Nov 26 12:01:47.797: INFO: Pod "pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.711122ms
    Nov 26 12:01:49.804: INFO: Pod "pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015598513s
    Nov 26 12:01:51.807: INFO: Pod "pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018736177s
    STEP: Saw pod success 11/26/22 12:01:51.807
    Nov 26 12:01:51.807: INFO: Pod "pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f" satisfied condition "Succeeded or Failed"
    Nov 26 12:01:51.812: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:01:51.821
    Nov 26 12:01:51.845: INFO: Waiting for pod pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f to disappear
    Nov 26 12:01:51.850: INFO: Pod pod-projected-configmaps-6868c20c-137f-4ecb-85ed-8bf96ba12f4f no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 26 12:01:51.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7791" for this suite. 11/26/22 12:01:51.856
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:01:51.886
Nov 26 12:01:51.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 11/26/22 12:01:51.887
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:51.915
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:51.929
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 11/26/22 12:01:51.935
STEP: Creating hostNetwork=false pod 11/26/22 12:01:51.935
Nov 26 12:01:51.949: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-4608" to be "running and ready"
Nov 26 12:01:51.958: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.445577ms
Nov 26 12:01:51.958: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:01:53.964: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014998438s
Nov 26 12:01:53.965: INFO: The phase of Pod test-pod is Running (Ready = true)
Nov 26 12:01:53.965: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 11/26/22 12:01:53.971
Nov 26 12:01:53.982: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-4608" to be "running and ready"
Nov 26 12:01:53.991: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 9.05792ms
Nov 26 12:01:53.991: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:01:55.998: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015825597s
Nov 26 12:01:55.998: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Nov 26 12:01:55.998: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 11/26/22 12:01:56.003
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 11/26/22 12:01:56.004
Nov 26 12:01:56.004: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:56.004: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:56.005: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:56.005: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 26 12:01:56.078: INFO: Exec stderr: ""
Nov 26 12:01:56.078: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:56.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:56.079: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:56.079: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 26 12:01:56.151: INFO: Exec stderr: ""
Nov 26 12:01:56.151: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:56.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:56.152: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:56.152: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 26 12:01:56.232: INFO: Exec stderr: ""
Nov 26 12:01:56.232: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:56.232: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:56.233: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:56.233: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 26 12:01:56.311: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 11/26/22 12:01:56.312
Nov 26 12:01:56.312: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:56.312: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:56.312: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:56.312: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Nov 26 12:01:56.401: INFO: Exec stderr: ""
Nov 26 12:01:56.401: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:56.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:56.402: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:56.402: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Nov 26 12:01:56.476: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 11/26/22 12:01:56.476
Nov 26 12:01:56.476: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:56.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:56.477: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:56.477: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 26 12:01:56.576: INFO: Exec stderr: ""
Nov 26 12:01:56.577: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:56.577: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:56.578: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:56.578: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov 26 12:01:56.658: INFO: Exec stderr: ""
Nov 26 12:01:56.658: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:56.658: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:56.659: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:56.659: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 26 12:01:56.767: INFO: Exec stderr: ""
Nov 26 12:01:56.768: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:01:56.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:01:56.768: INFO: ExecWithOptions: Clientset creation
Nov 26 12:01:56.768: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov 26 12:01:56.852: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Nov 26 12:01:56.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4608" for this suite. 11/26/22 12:01:56.858
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":24,"skipped":226,"failed":0}
------------------------------
â€¢ [4.986 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:01:51.886
    Nov 26 12:01:51.886: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 11/26/22 12:01:51.887
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:51.915
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:51.929
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 11/26/22 12:01:51.935
    STEP: Creating hostNetwork=false pod 11/26/22 12:01:51.935
    Nov 26 12:01:51.949: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-4608" to be "running and ready"
    Nov 26 12:01:51.958: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.445577ms
    Nov 26 12:01:51.958: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:01:53.964: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014998438s
    Nov 26 12:01:53.965: INFO: The phase of Pod test-pod is Running (Ready = true)
    Nov 26 12:01:53.965: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 11/26/22 12:01:53.971
    Nov 26 12:01:53.982: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-4608" to be "running and ready"
    Nov 26 12:01:53.991: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 9.05792ms
    Nov 26 12:01:53.991: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:01:55.998: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015825597s
    Nov 26 12:01:55.998: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Nov 26 12:01:55.998: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 11/26/22 12:01:56.003
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 11/26/22 12:01:56.004
    Nov 26 12:01:56.004: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:56.004: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:56.005: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:56.005: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 26 12:01:56.078: INFO: Exec stderr: ""
    Nov 26 12:01:56.078: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:56.078: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:56.079: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:56.079: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 26 12:01:56.151: INFO: Exec stderr: ""
    Nov 26 12:01:56.151: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:56.151: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:56.152: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:56.152: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 26 12:01:56.232: INFO: Exec stderr: ""
    Nov 26 12:01:56.232: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:56.232: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:56.233: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:56.233: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 26 12:01:56.311: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 11/26/22 12:01:56.312
    Nov 26 12:01:56.312: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:56.312: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:56.312: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:56.312: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Nov 26 12:01:56.401: INFO: Exec stderr: ""
    Nov 26 12:01:56.401: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:56.401: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:56.402: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:56.402: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Nov 26 12:01:56.476: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 11/26/22 12:01:56.476
    Nov 26 12:01:56.476: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:56.476: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:56.477: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:56.477: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 26 12:01:56.576: INFO: Exec stderr: ""
    Nov 26 12:01:56.577: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:56.577: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:56.578: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:56.578: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov 26 12:01:56.658: INFO: Exec stderr: ""
    Nov 26 12:01:56.658: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:56.658: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:56.659: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:56.659: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 26 12:01:56.767: INFO: Exec stderr: ""
    Nov 26 12:01:56.768: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4608 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:01:56.768: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:01:56.768: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:01:56.768: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-4608/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov 26 12:01:56.852: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Nov 26 12:01:56.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-4608" for this suite. 11/26/22 12:01:56.858
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:01:56.877
Nov 26 12:01:56.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename deployment 11/26/22 12:01:56.878
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:56.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:56.904
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Nov 26 12:01:56.911: INFO: Creating deployment "test-recreate-deployment"
Nov 26 12:01:56.926: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 26 12:01:56.951: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov 26 12:01:58.964: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 26 12:01:58.969: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 1, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 1, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 1, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 1, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 12:02:00.976: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 26 12:02:00.991: INFO: Updating deployment test-recreate-deployment
Nov 26 12:02:00.991: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 26 12:02:01.208: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-7088  779e5960-cf0c-4978-b857-d4ae7f562047 3557 2 2022-11-26 12:01:56 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-26 12:02:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037d5bc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-26 12:02:01 +0000 UTC,LastTransitionTime:2022-11-26 12:02:01 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-11-26 12:02:01 +0000 UTC,LastTransitionTime:2022-11-26 12:01:56 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov 26 12:02:01.214: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-7088  f2c194b9-f151-4443-a1dd-a377ac72ae13 3553 1 2022-11-26 12:02:01 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 779e5960-cf0c-4978-b857-d4ae7f562047 0xc0012e5200 0xc0012e5201}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"779e5960-cf0c-4978-b857-d4ae7f562047\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0012e5298 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:02:01.214: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 26 12:02:01.214: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-7088  c6dda084-1b96-41af-b541-a153eadbc0a3 3545 2 2022-11-26 12:01:56 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 779e5960-cf0c-4978-b857-d4ae7f562047 0xc0012e50f7 0xc0012e50f8}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:02:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"779e5960-cf0c-4978-b857-d4ae7f562047\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0012e51a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:02:01.219: INFO: Pod "test-recreate-deployment-9d58999df-rd76s" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-rd76s test-recreate-deployment-9d58999df- deployment-7088  9a69c0ff-7c6d-4bfb-b1bc-1063494b1008 3556 0 2022-11-26 12:02:01 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df f2c194b9-f151-4443-a1dd-a377ac72ae13 0xc0012e5700 0xc0012e5701}] [] [{kube-controller-manager Update v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f2c194b9-f151-4443-a1dd-a377ac72ae13\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x55lj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x55lj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:02:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:02:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:02:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:02:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:,StartTime:2022-11-26 12:02:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 26 12:02:01.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7088" for this suite. 11/26/22 12:02:01.226
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":25,"skipped":252,"failed":0}
------------------------------
â€¢ [4.360 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:01:56.877
    Nov 26 12:01:56.877: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename deployment 11/26/22 12:01:56.878
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:01:56.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:01:56.904
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Nov 26 12:01:56.911: INFO: Creating deployment "test-recreate-deployment"
    Nov 26 12:01:56.926: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Nov 26 12:01:56.951: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Nov 26 12:01:58.964: INFO: Waiting deployment "test-recreate-deployment" to complete
    Nov 26 12:01:58.969: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 1, 56, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 1, 56, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 1, 57, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 1, 56, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 12:02:00.976: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Nov 26 12:02:00.991: INFO: Updating deployment test-recreate-deployment
    Nov 26 12:02:00.991: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 26 12:02:01.208: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-7088  779e5960-cf0c-4978-b857-d4ae7f562047 3557 2 2022-11-26 12:01:56 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-26 12:02:00 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0037d5bc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-26 12:02:01 +0000 UTC,LastTransitionTime:2022-11-26 12:02:01 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-11-26 12:02:01 +0000 UTC,LastTransitionTime:2022-11-26 12:01:56 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Nov 26 12:02:01.214: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-7088  f2c194b9-f151-4443-a1dd-a377ac72ae13 3553 1 2022-11-26 12:02:01 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 779e5960-cf0c-4978-b857-d4ae7f562047 0xc0012e5200 0xc0012e5201}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"779e5960-cf0c-4978-b857-d4ae7f562047\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0012e5298 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:02:01.214: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Nov 26 12:02:01.214: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-7088  c6dda084-1b96-41af-b541-a153eadbc0a3 3545 2 2022-11-26 12:01:56 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 779e5960-cf0c-4978-b857-d4ae7f562047 0xc0012e50f7 0xc0012e50f8}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:02:00 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"779e5960-cf0c-4978-b857-d4ae7f562047\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0012e51a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:02:01.219: INFO: Pod "test-recreate-deployment-9d58999df-rd76s" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-rd76s test-recreate-deployment-9d58999df- deployment-7088  9a69c0ff-7c6d-4bfb-b1bc-1063494b1008 3556 0 2022-11-26 12:02:01 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df f2c194b9-f151-4443-a1dd-a377ac72ae13 0xc0012e5700 0xc0012e5701}] [] [{kube-controller-manager Update v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f2c194b9-f151-4443-a1dd-a377ac72ae13\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:02:01 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-x55lj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-x55lj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:02:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:02:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:02:01 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:02:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:,StartTime:2022-11-26 12:02:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 26 12:02:01.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7088" for this suite. 11/26/22 12:02:01.226
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:02:01.238
Nov 26 12:02:01.238: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 12:02:01.24
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:02:01.276
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:02:01.284
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 11/26/22 12:02:01.29
Nov 26 12:02:01.305: INFO: Waiting up to 5m0s for pod "pod-7nrgv" in namespace "pods-3889" to be "running"
Nov 26 12:02:01.314: INFO: Pod "pod-7nrgv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.714084ms
Nov 26 12:02:03.322: INFO: Pod "pod-7nrgv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016869287s
Nov 26 12:02:05.321: INFO: Pod "pod-7nrgv": Phase="Running", Reason="", readiness=true. Elapsed: 4.01615999s
Nov 26 12:02:05.321: INFO: Pod "pod-7nrgv" satisfied condition "running"
STEP: patching /status 11/26/22 12:02:05.321
Nov 26 12:02:05.332: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 26 12:02:05.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3889" for this suite. 11/26/22 12:02:05.338
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":26,"skipped":256,"failed":0}
------------------------------
â€¢ [4.110 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:02:01.238
    Nov 26 12:02:01.238: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 12:02:01.24
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:02:01.276
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:02:01.284
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 11/26/22 12:02:01.29
    Nov 26 12:02:01.305: INFO: Waiting up to 5m0s for pod "pod-7nrgv" in namespace "pods-3889" to be "running"
    Nov 26 12:02:01.314: INFO: Pod "pod-7nrgv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.714084ms
    Nov 26 12:02:03.322: INFO: Pod "pod-7nrgv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016869287s
    Nov 26 12:02:05.321: INFO: Pod "pod-7nrgv": Phase="Running", Reason="", readiness=true. Elapsed: 4.01615999s
    Nov 26 12:02:05.321: INFO: Pod "pod-7nrgv" satisfied condition "running"
    STEP: patching /status 11/26/22 12:02:05.321
    Nov 26 12:02:05.332: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 26 12:02:05.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3889" for this suite. 11/26/22 12:02:05.338
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:02:05.355
Nov 26 12:02:05.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename conformance-tests 11/26/22 12:02:05.357
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:02:05.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:02:05.384
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 11/26/22 12:02:05.391
Nov 26 12:02:05.391: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Nov 26 12:02:05.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-1663" for this suite. 11/26/22 12:02:05.406
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":27,"skipped":292,"failed":0}
------------------------------
â€¢ [0.060 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:02:05.355
    Nov 26 12:02:05.356: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename conformance-tests 11/26/22 12:02:05.357
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:02:05.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:02:05.384
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 11/26/22 12:02:05.391
    Nov 26 12:02:05.391: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Nov 26 12:02:05.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-1663" for this suite. 11/26/22 12:02:05.406
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:02:05.424
Nov 26 12:02:05.425: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir-wrapper 11/26/22 12:02:05.425
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:02:05.446
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:02:05.454
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 11/26/22 12:02:05.464
STEP: Creating RC which spawns configmap-volume pods 11/26/22 12:02:05.884
Nov 26 12:02:05.942: INFO: Pod name wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3: Found 1 pods out of 5
Nov 26 12:02:10.953: INFO: Pod name wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/26/22 12:02:10.953
Nov 26 12:02:10.953: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:10.959: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 5.763582ms
Nov 26 12:02:12.967: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013270107s
Nov 26 12:02:14.971: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01716997s
Nov 26 12:02:16.967: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013476799s
Nov 26 12:02:18.968: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014423151s
Nov 26 12:02:20.966: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012502057s
Nov 26 12:02:22.966: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Running", Reason="", readiness=true. Elapsed: 12.012304863s
Nov 26 12:02:22.966: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn" satisfied condition "running"
Nov 26 12:02:22.966: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-64tzq" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:22.976: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-64tzq": Phase="Running", Reason="", readiness=true. Elapsed: 9.885331ms
Nov 26 12:02:22.976: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-64tzq" satisfied condition "running"
Nov 26 12:02:22.976: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-bvz49" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:22.981: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-bvz49": Phase="Running", Reason="", readiness=true. Elapsed: 5.228992ms
Nov 26 12:02:22.981: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-bvz49" satisfied condition "running"
Nov 26 12:02:22.981: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-d77hj" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:22.987: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-d77hj": Phase="Running", Reason="", readiness=true. Elapsed: 5.660291ms
Nov 26 12:02:22.987: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-d77hj" satisfied condition "running"
Nov 26 12:02:22.987: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-gb9g8" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:22.993: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-gb9g8": Phase="Running", Reason="", readiness=true. Elapsed: 5.507948ms
Nov 26 12:02:22.993: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-gb9g8" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3 in namespace emptydir-wrapper-3041, will wait for the garbage collector to delete the pods 11/26/22 12:02:22.993
Nov 26 12:02:23.061: INFO: Deleting ReplicationController wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3 took: 9.940263ms
Nov 26 12:02:23.161: INFO: Terminating ReplicationController wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3 pods took: 100.37299ms
STEP: Creating RC which spawns configmap-volume pods 11/26/22 12:02:25.769
Nov 26 12:02:25.802: INFO: Pod name wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb: Found 0 pods out of 5
Nov 26 12:02:30.814: INFO: Pod name wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/26/22 12:02:30.814
Nov 26 12:02:30.814: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:30.820: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.591702ms
Nov 26 12:02:32.827: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013733267s
Nov 26 12:02:34.828: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014327372s
Nov 26 12:02:36.828: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014186462s
Nov 26 12:02:38.831: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017513929s
Nov 26 12:02:40.828: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.013973028s
Nov 26 12:02:42.828: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Running", Reason="", readiness=true. Elapsed: 12.013973423s
Nov 26 12:02:42.828: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd" satisfied condition "running"
Nov 26 12:02:42.828: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-mrw4f" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:42.838: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-mrw4f": Phase="Running", Reason="", readiness=true. Elapsed: 10.272942ms
Nov 26 12:02:42.838: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-mrw4f" satisfied condition "running"
Nov 26 12:02:42.838: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-tlrln" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:42.843: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-tlrln": Phase="Running", Reason="", readiness=true. Elapsed: 4.922427ms
Nov 26 12:02:42.843: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-tlrln" satisfied condition "running"
Nov 26 12:02:42.843: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-x9jhm" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:42.849: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-x9jhm": Phase="Running", Reason="", readiness=true. Elapsed: 6.01867ms
Nov 26 12:02:42.850: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-x9jhm" satisfied condition "running"
Nov 26 12:02:42.850: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-z7r84" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:42.856: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-z7r84": Phase="Running", Reason="", readiness=true. Elapsed: 6.613974ms
Nov 26 12:02:42.856: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-z7r84" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb in namespace emptydir-wrapper-3041, will wait for the garbage collector to delete the pods 11/26/22 12:02:42.856
Nov 26 12:02:42.926: INFO: Deleting ReplicationController wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb took: 13.427661ms
Nov 26 12:02:43.027: INFO: Terminating ReplicationController wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb pods took: 100.804804ms
STEP: Creating RC which spawns configmap-volume pods 11/26/22 12:02:46.433
Nov 26 12:02:46.456: INFO: Pod name wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998: Found 0 pods out of 5
Nov 26 12:02:51.467: INFO: Pod name wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/26/22 12:02:51.467
Nov 26 12:02:51.467: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:02:51.473: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.556381ms
Nov 26 12:02:53.480: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012662701s
Nov 26 12:02:55.480: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01247594s
Nov 26 12:02:57.482: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01486344s
Nov 26 12:02:59.515: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.047620043s
Nov 26 12:03:01.482: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014308059s
Nov 26 12:03:03.482: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Running", Reason="", readiness=true. Elapsed: 12.014105854s
Nov 26 12:03:03.482: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8" satisfied condition "running"
Nov 26 12:03:03.482: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-6bmkf" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:03:03.489: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-6bmkf": Phase="Running", Reason="", readiness=true. Elapsed: 7.517294ms
Nov 26 12:03:03.489: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-6bmkf" satisfied condition "running"
Nov 26 12:03:03.489: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-h8nzp" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:03:03.495: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-h8nzp": Phase="Running", Reason="", readiness=true. Elapsed: 5.513601ms
Nov 26 12:03:03.495: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-h8nzp" satisfied condition "running"
Nov 26 12:03:03.495: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-j64hf" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:03:03.501: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-j64hf": Phase="Running", Reason="", readiness=true. Elapsed: 6.010032ms
Nov 26 12:03:03.501: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-j64hf" satisfied condition "running"
Nov 26 12:03:03.501: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-sgz97" in namespace "emptydir-wrapper-3041" to be "running"
Nov 26 12:03:03.508: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-sgz97": Phase="Running", Reason="", readiness=true. Elapsed: 6.363519ms
Nov 26 12:03:03.508: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-sgz97" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998 in namespace emptydir-wrapper-3041, will wait for the garbage collector to delete the pods 11/26/22 12:03:03.508
Nov 26 12:03:03.577: INFO: Deleting ReplicationController wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998 took: 11.87472ms
Nov 26 12:03:03.778: INFO: Terminating ReplicationController wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998 pods took: 201.010386ms
STEP: Cleaning up the configMaps 11/26/22 12:03:06.778
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Nov 26 12:03:07.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3041" for this suite. 11/26/22 12:03:07.28
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":28,"skipped":330,"failed":0}
------------------------------
â€¢ [SLOW TEST] [61.865 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:02:05.424
    Nov 26 12:02:05.425: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir-wrapper 11/26/22 12:02:05.425
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:02:05.446
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:02:05.454
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 11/26/22 12:02:05.464
    STEP: Creating RC which spawns configmap-volume pods 11/26/22 12:02:05.884
    Nov 26 12:02:05.942: INFO: Pod name wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3: Found 1 pods out of 5
    Nov 26 12:02:10.953: INFO: Pod name wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/26/22 12:02:10.953
    Nov 26 12:02:10.953: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:10.959: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 5.763582ms
    Nov 26 12:02:12.967: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013270107s
    Nov 26 12:02:14.971: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01716997s
    Nov 26 12:02:16.967: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013476799s
    Nov 26 12:02:18.968: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014423151s
    Nov 26 12:02:20.966: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012502057s
    Nov 26 12:02:22.966: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn": Phase="Running", Reason="", readiness=true. Elapsed: 12.012304863s
    Nov 26 12:02:22.966: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-2x7zn" satisfied condition "running"
    Nov 26 12:02:22.966: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-64tzq" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:22.976: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-64tzq": Phase="Running", Reason="", readiness=true. Elapsed: 9.885331ms
    Nov 26 12:02:22.976: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-64tzq" satisfied condition "running"
    Nov 26 12:02:22.976: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-bvz49" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:22.981: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-bvz49": Phase="Running", Reason="", readiness=true. Elapsed: 5.228992ms
    Nov 26 12:02:22.981: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-bvz49" satisfied condition "running"
    Nov 26 12:02:22.981: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-d77hj" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:22.987: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-d77hj": Phase="Running", Reason="", readiness=true. Elapsed: 5.660291ms
    Nov 26 12:02:22.987: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-d77hj" satisfied condition "running"
    Nov 26 12:02:22.987: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-gb9g8" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:22.993: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-gb9g8": Phase="Running", Reason="", readiness=true. Elapsed: 5.507948ms
    Nov 26 12:02:22.993: INFO: Pod "wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3-gb9g8" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3 in namespace emptydir-wrapper-3041, will wait for the garbage collector to delete the pods 11/26/22 12:02:22.993
    Nov 26 12:02:23.061: INFO: Deleting ReplicationController wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3 took: 9.940263ms
    Nov 26 12:02:23.161: INFO: Terminating ReplicationController wrapped-volume-race-7b581b85-671a-4579-b10f-3db479ca41e3 pods took: 100.37299ms
    STEP: Creating RC which spawns configmap-volume pods 11/26/22 12:02:25.769
    Nov 26 12:02:25.802: INFO: Pod name wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb: Found 0 pods out of 5
    Nov 26 12:02:30.814: INFO: Pod name wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/26/22 12:02:30.814
    Nov 26 12:02:30.814: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:30.820: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.591702ms
    Nov 26 12:02:32.827: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013733267s
    Nov 26 12:02:34.828: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014327372s
    Nov 26 12:02:36.828: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014186462s
    Nov 26 12:02:38.831: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.017513929s
    Nov 26 12:02:40.828: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.013973028s
    Nov 26 12:02:42.828: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd": Phase="Running", Reason="", readiness=true. Elapsed: 12.013973423s
    Nov 26 12:02:42.828: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-6whtd" satisfied condition "running"
    Nov 26 12:02:42.828: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-mrw4f" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:42.838: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-mrw4f": Phase="Running", Reason="", readiness=true. Elapsed: 10.272942ms
    Nov 26 12:02:42.838: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-mrw4f" satisfied condition "running"
    Nov 26 12:02:42.838: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-tlrln" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:42.843: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-tlrln": Phase="Running", Reason="", readiness=true. Elapsed: 4.922427ms
    Nov 26 12:02:42.843: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-tlrln" satisfied condition "running"
    Nov 26 12:02:42.843: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-x9jhm" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:42.849: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-x9jhm": Phase="Running", Reason="", readiness=true. Elapsed: 6.01867ms
    Nov 26 12:02:42.850: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-x9jhm" satisfied condition "running"
    Nov 26 12:02:42.850: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-z7r84" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:42.856: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-z7r84": Phase="Running", Reason="", readiness=true. Elapsed: 6.613974ms
    Nov 26 12:02:42.856: INFO: Pod "wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb-z7r84" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb in namespace emptydir-wrapper-3041, will wait for the garbage collector to delete the pods 11/26/22 12:02:42.856
    Nov 26 12:02:42.926: INFO: Deleting ReplicationController wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb took: 13.427661ms
    Nov 26 12:02:43.027: INFO: Terminating ReplicationController wrapped-volume-race-e356175d-2a66-4767-9fee-beee5d1896fb pods took: 100.804804ms
    STEP: Creating RC which spawns configmap-volume pods 11/26/22 12:02:46.433
    Nov 26 12:02:46.456: INFO: Pod name wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998: Found 0 pods out of 5
    Nov 26 12:02:51.467: INFO: Pod name wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/26/22 12:02:51.467
    Nov 26 12:02:51.467: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:02:51.473: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.556381ms
    Nov 26 12:02:53.480: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012662701s
    Nov 26 12:02:55.480: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01247594s
    Nov 26 12:02:57.482: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01486344s
    Nov 26 12:02:59.515: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.047620043s
    Nov 26 12:03:01.482: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014308059s
    Nov 26 12:03:03.482: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8": Phase="Running", Reason="", readiness=true. Elapsed: 12.014105854s
    Nov 26 12:03:03.482: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-58gg8" satisfied condition "running"
    Nov 26 12:03:03.482: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-6bmkf" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:03:03.489: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-6bmkf": Phase="Running", Reason="", readiness=true. Elapsed: 7.517294ms
    Nov 26 12:03:03.489: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-6bmkf" satisfied condition "running"
    Nov 26 12:03:03.489: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-h8nzp" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:03:03.495: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-h8nzp": Phase="Running", Reason="", readiness=true. Elapsed: 5.513601ms
    Nov 26 12:03:03.495: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-h8nzp" satisfied condition "running"
    Nov 26 12:03:03.495: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-j64hf" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:03:03.501: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-j64hf": Phase="Running", Reason="", readiness=true. Elapsed: 6.010032ms
    Nov 26 12:03:03.501: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-j64hf" satisfied condition "running"
    Nov 26 12:03:03.501: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-sgz97" in namespace "emptydir-wrapper-3041" to be "running"
    Nov 26 12:03:03.508: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-sgz97": Phase="Running", Reason="", readiness=true. Elapsed: 6.363519ms
    Nov 26 12:03:03.508: INFO: Pod "wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998-sgz97" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998 in namespace emptydir-wrapper-3041, will wait for the garbage collector to delete the pods 11/26/22 12:03:03.508
    Nov 26 12:03:03.577: INFO: Deleting ReplicationController wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998 took: 11.87472ms
    Nov 26 12:03:03.778: INFO: Terminating ReplicationController wrapped-volume-race-aea6a120-3d30-42ce-8908-8480ee125998 pods took: 201.010386ms
    STEP: Cleaning up the configMaps 11/26/22 12:03:06.778
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:03:07.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-3041" for this suite. 11/26/22 12:03:07.28
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:03:07.298
Nov 26 12:03:07.298: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 12:03:07.303
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:07.323
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:07.331
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-8131/configmap-test-2fd807b5-d818-4346-bd76-fb338fd8f168 11/26/22 12:03:07.372
STEP: Creating a pod to test consume configMaps 11/26/22 12:03:07.379
Nov 26 12:03:07.390: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902" in namespace "configmap-8131" to be "Succeeded or Failed"
Nov 26 12:03:07.396: INFO: Pod "pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902": Phase="Pending", Reason="", readiness=false. Elapsed: 5.425519ms
Nov 26 12:03:09.401: INFO: Pod "pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011110808s
Nov 26 12:03:11.408: INFO: Pod "pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017509428s
STEP: Saw pod success 11/26/22 12:03:11.408
Nov 26 12:03:11.408: INFO: Pod "pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902" satisfied condition "Succeeded or Failed"
Nov 26 12:03:11.414: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902 container env-test: <nil>
STEP: delete the pod 11/26/22 12:03:11.422
Nov 26 12:03:11.439: INFO: Waiting for pod pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902 to disappear
Nov 26 12:03:11.445: INFO: Pod pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 12:03:11.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8131" for this suite. 11/26/22 12:03:11.455
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":29,"skipped":352,"failed":0}
------------------------------
â€¢ [4.169 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:03:07.298
    Nov 26 12:03:07.298: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 12:03:07.303
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:07.323
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:07.331
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-8131/configmap-test-2fd807b5-d818-4346-bd76-fb338fd8f168 11/26/22 12:03:07.372
    STEP: Creating a pod to test consume configMaps 11/26/22 12:03:07.379
    Nov 26 12:03:07.390: INFO: Waiting up to 5m0s for pod "pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902" in namespace "configmap-8131" to be "Succeeded or Failed"
    Nov 26 12:03:07.396: INFO: Pod "pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902": Phase="Pending", Reason="", readiness=false. Elapsed: 5.425519ms
    Nov 26 12:03:09.401: INFO: Pod "pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011110808s
    Nov 26 12:03:11.408: INFO: Pod "pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017509428s
    STEP: Saw pod success 11/26/22 12:03:11.408
    Nov 26 12:03:11.408: INFO: Pod "pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902" satisfied condition "Succeeded or Failed"
    Nov 26 12:03:11.414: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902 container env-test: <nil>
    STEP: delete the pod 11/26/22 12:03:11.422
    Nov 26 12:03:11.439: INFO: Waiting for pod pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902 to disappear
    Nov 26 12:03:11.445: INFO: Pod pod-configmaps-ec7135ba-b1a0-4bf6-be72-679b32171902 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 12:03:11.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8131" for this suite. 11/26/22 12:03:11.455
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:03:11.473
Nov 26 12:03:11.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename deployment 11/26/22 12:03:11.474
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:11.503
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:11.511
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 11/26/22 12:03:11.526
STEP: waiting for Deployment to be created 11/26/22 12:03:11.543
STEP: waiting for all Replicas to be Ready 11/26/22 12:03:11.547
Nov 26 12:03:11.552: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 26 12:03:11.552: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 26 12:03:11.562: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 26 12:03:11.562: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 26 12:03:11.582: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 26 12:03:11.582: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 26 12:03:11.636: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 26 12:03:11.636: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov 26 12:03:12.694: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Nov 26 12:03:12.695: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Nov 26 12:03:13.550: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 11/26/22 12:03:13.55
W1126 12:03:13.565249      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 26 12:03:13.568: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 11/26/22 12:03:13.568
Nov 26 12:03:13.571: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
Nov 26 12:03:13.571: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
Nov 26 12:03:13.571: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
Nov 26 12:03:13.571: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:13.586: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:13.586: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:13.615: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:13.615: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:13.635: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
Nov 26 12:03:13.635: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
Nov 26 12:03:13.657: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
Nov 26 12:03:13.657: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
Nov 26 12:03:14.707: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:14.707: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:14.738: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
STEP: listing Deployments 11/26/22 12:03:14.738
Nov 26 12:03:14.744: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 11/26/22 12:03:14.744
Nov 26 12:03:14.760: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 11/26/22 12:03:14.76
Nov 26 12:03:14.770: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 26 12:03:14.777: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 26 12:03:14.808: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 26 12:03:14.835: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov 26 12:03:16.581: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 26 12:03:16.748: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Nov 26 12:03:16.807: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 26 12:03:16.835: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov 26 12:03:26.612: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 11/26/22 12:03:26.65
STEP: fetching the DeploymentStatus 11/26/22 12:03:26.662
Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 3
Nov 26 12:03:26.672: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:26.672: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
Nov 26 12:03:26.672: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 3
STEP: deleting the Deployment 11/26/22 12:03:26.672
Nov 26 12:03:26.702: INFO: observed event type MODIFIED
Nov 26 12:03:26.702: INFO: observed event type MODIFIED
Nov 26 12:03:26.704: INFO: observed event type MODIFIED
Nov 26 12:03:26.704: INFO: observed event type MODIFIED
Nov 26 12:03:26.704: INFO: observed event type MODIFIED
Nov 26 12:03:26.704: INFO: observed event type MODIFIED
Nov 26 12:03:26.704: INFO: observed event type MODIFIED
Nov 26 12:03:26.705: INFO: observed event type MODIFIED
Nov 26 12:03:26.705: INFO: observed event type MODIFIED
Nov 26 12:03:26.705: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 26 12:03:26.717: INFO: Log out all the ReplicaSets if there is no deployment created
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 26 12:03:26.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-783" for this suite. 11/26/22 12:03:26.74
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":30,"skipped":416,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.357 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:03:11.473
    Nov 26 12:03:11.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename deployment 11/26/22 12:03:11.474
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:11.503
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:11.511
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 11/26/22 12:03:11.526
    STEP: waiting for Deployment to be created 11/26/22 12:03:11.543
    STEP: waiting for all Replicas to be Ready 11/26/22 12:03:11.547
    Nov 26 12:03:11.552: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 26 12:03:11.552: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 26 12:03:11.562: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 26 12:03:11.562: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 26 12:03:11.582: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 26 12:03:11.582: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 26 12:03:11.636: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 26 12:03:11.636: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov 26 12:03:12.694: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Nov 26 12:03:12.695: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Nov 26 12:03:13.550: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 11/26/22 12:03:13.55
    W1126 12:03:13.565249      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 26 12:03:13.568: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 11/26/22 12:03:13.568
    Nov 26 12:03:13.571: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
    Nov 26 12:03:13.571: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
    Nov 26 12:03:13.571: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
    Nov 26 12:03:13.571: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
    Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
    Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
    Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
    Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 0
    Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:13.572: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:13.586: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:13.586: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:13.615: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:13.615: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:13.635: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    Nov 26 12:03:13.635: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    Nov 26 12:03:13.657: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    Nov 26 12:03:13.657: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    Nov 26 12:03:14.707: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:14.707: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:14.738: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    STEP: listing Deployments 11/26/22 12:03:14.738
    Nov 26 12:03:14.744: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 11/26/22 12:03:14.744
    Nov 26 12:03:14.760: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 11/26/22 12:03:14.76
    Nov 26 12:03:14.770: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 26 12:03:14.777: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 26 12:03:14.808: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 26 12:03:14.835: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 26 12:03:16.581: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 26 12:03:16.748: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 26 12:03:16.807: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 26 12:03:16.835: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov 26 12:03:26.612: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 11/26/22 12:03:26.65
    STEP: fetching the DeploymentStatus 11/26/22 12:03:26.662
    Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 1
    Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:26.671: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 3
    Nov 26 12:03:26.672: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:26.672: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 2
    Nov 26 12:03:26.672: INFO: observed Deployment test-deployment in namespace deployment-783 with ReadyReplicas 3
    STEP: deleting the Deployment 11/26/22 12:03:26.672
    Nov 26 12:03:26.702: INFO: observed event type MODIFIED
    Nov 26 12:03:26.702: INFO: observed event type MODIFIED
    Nov 26 12:03:26.704: INFO: observed event type MODIFIED
    Nov 26 12:03:26.704: INFO: observed event type MODIFIED
    Nov 26 12:03:26.704: INFO: observed event type MODIFIED
    Nov 26 12:03:26.704: INFO: observed event type MODIFIED
    Nov 26 12:03:26.704: INFO: observed event type MODIFIED
    Nov 26 12:03:26.705: INFO: observed event type MODIFIED
    Nov 26 12:03:26.705: INFO: observed event type MODIFIED
    Nov 26 12:03:26.705: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 26 12:03:26.717: INFO: Log out all the ReplicaSets if there is no deployment created
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 26 12:03:26.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-783" for this suite. 11/26/22 12:03:26.74
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:03:26.836
Nov 26 12:03:26.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 12:03:26.837
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:26.862
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:26.87
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-6fbf12ef-cd07-4e6b-963a-44099d05da84 11/26/22 12:03:26.874
STEP: Creating a pod to test consume secrets 11/26/22 12:03:26.883
Nov 26 12:03:26.895: INFO: Waiting up to 5m0s for pod "pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3" in namespace "secrets-8776" to be "Succeeded or Failed"
Nov 26 12:03:26.902: INFO: Pod "pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.689979ms
Nov 26 12:03:28.911: INFO: Pod "pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015738726s
Nov 26 12:03:30.911: INFO: Pod "pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01561814s
STEP: Saw pod success 11/26/22 12:03:30.911
Nov 26 12:03:30.911: INFO: Pod "pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3" satisfied condition "Succeeded or Failed"
Nov 26 12:03:30.916: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3 container secret-env-test: <nil>
STEP: delete the pod 11/26/22 12:03:30.924
Nov 26 12:03:30.944: INFO: Waiting for pod pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3 to disappear
Nov 26 12:03:30.949: INFO: Pod pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 26 12:03:30.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8776" for this suite. 11/26/22 12:03:30.956
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":31,"skipped":486,"failed":0}
------------------------------
â€¢ [4.130 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:03:26.836
    Nov 26 12:03:26.836: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 12:03:26.837
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:26.862
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:26.87
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-6fbf12ef-cd07-4e6b-963a-44099d05da84 11/26/22 12:03:26.874
    STEP: Creating a pod to test consume secrets 11/26/22 12:03:26.883
    Nov 26 12:03:26.895: INFO: Waiting up to 5m0s for pod "pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3" in namespace "secrets-8776" to be "Succeeded or Failed"
    Nov 26 12:03:26.902: INFO: Pod "pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.689979ms
    Nov 26 12:03:28.911: INFO: Pod "pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015738726s
    Nov 26 12:03:30.911: INFO: Pod "pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01561814s
    STEP: Saw pod success 11/26/22 12:03:30.911
    Nov 26 12:03:30.911: INFO: Pod "pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3" satisfied condition "Succeeded or Failed"
    Nov 26 12:03:30.916: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3 container secret-env-test: <nil>
    STEP: delete the pod 11/26/22 12:03:30.924
    Nov 26 12:03:30.944: INFO: Waiting for pod pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3 to disappear
    Nov 26 12:03:30.949: INFO: Pod pod-secrets-f70b64aa-0149-40b2-a36a-b9a14c3142e3 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 12:03:30.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8776" for this suite. 11/26/22 12:03:30.956
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:03:30.967
Nov 26 12:03:30.967: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:03:30.968
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:30.991
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:30.996
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/26/22 12:03:31.002
Nov 26 12:03:31.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-2246 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Nov 26 12:03:31.097: INFO: stderr: ""
Nov 26 12:03:31.097: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 11/26/22 12:03:31.097
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Nov 26 12:03:31.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-2246 delete pods e2e-test-httpd-pod'
Nov 26 12:03:33.793: INFO: stderr: ""
Nov 26 12:03:33.793: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:03:33.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2246" for this suite. 11/26/22 12:03:33.798
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":32,"skipped":496,"failed":0}
------------------------------
â€¢ [2.842 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:03:30.967
    Nov 26 12:03:30.967: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:03:30.968
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:30.991
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:30.996
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/26/22 12:03:31.002
    Nov 26 12:03:31.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-2246 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Nov 26 12:03:31.097: INFO: stderr: ""
    Nov 26 12:03:31.097: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 11/26/22 12:03:31.097
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Nov 26 12:03:31.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-2246 delete pods e2e-test-httpd-pod'
    Nov 26 12:03:33.793: INFO: stderr: ""
    Nov 26 12:03:33.793: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:03:33.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2246" for this suite. 11/26/22 12:03:33.798
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:03:33.812
Nov 26 12:03:33.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename statefulset 11/26/22 12:03:33.813
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:33.837
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:33.841
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3056 11/26/22 12:03:33.848
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 11/26/22 12:03:33.859
STEP: Creating pod with conflicting port in namespace statefulset-3056 11/26/22 12:03:33.867
STEP: Waiting until pod test-pod will start running in namespace statefulset-3056 11/26/22 12:03:33.881
Nov 26 12:03:33.881: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-3056" to be "running"
Nov 26 12:03:33.889: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.983425ms
Nov 26 12:03:35.895: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013610803s
Nov 26 12:03:35.895: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-3056 11/26/22 12:03:35.895
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3056 11/26/22 12:03:35.906
Nov 26 12:03:35.939: INFO: Observed stateful pod in namespace: statefulset-3056, name: ss-0, uid: 538d651d-9ac8-44c6-9f02-cad2db783ccb, status phase: Pending. Waiting for statefulset controller to delete.
Nov 26 12:03:35.964: INFO: Observed stateful pod in namespace: statefulset-3056, name: ss-0, uid: 538d651d-9ac8-44c6-9f02-cad2db783ccb, status phase: Failed. Waiting for statefulset controller to delete.
Nov 26 12:03:36.011: INFO: Observed stateful pod in namespace: statefulset-3056, name: ss-0, uid: 538d651d-9ac8-44c6-9f02-cad2db783ccb, status phase: Failed. Waiting for statefulset controller to delete.
Nov 26 12:03:36.020: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3056
STEP: Removing pod with conflicting port in namespace statefulset-3056 11/26/22 12:03:36.02
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3056 and will be in running state 11/26/22 12:03:36.039
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 26 12:03:38.054: INFO: Deleting all statefulset in ns statefulset-3056
Nov 26 12:03:38.060: INFO: Scaling statefulset ss to 0
Nov 26 12:03:48.095: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 12:03:48.100: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 26 12:03:48.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3056" for this suite. 11/26/22 12:03:48.15
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":33,"skipped":533,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.351 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:03:33.812
    Nov 26 12:03:33.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename statefulset 11/26/22 12:03:33.813
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:33.837
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:33.841
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3056 11/26/22 12:03:33.848
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 11/26/22 12:03:33.859
    STEP: Creating pod with conflicting port in namespace statefulset-3056 11/26/22 12:03:33.867
    STEP: Waiting until pod test-pod will start running in namespace statefulset-3056 11/26/22 12:03:33.881
    Nov 26 12:03:33.881: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-3056" to be "running"
    Nov 26 12:03:33.889: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.983425ms
    Nov 26 12:03:35.895: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.013610803s
    Nov 26 12:03:35.895: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-3056 11/26/22 12:03:35.895
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3056 11/26/22 12:03:35.906
    Nov 26 12:03:35.939: INFO: Observed stateful pod in namespace: statefulset-3056, name: ss-0, uid: 538d651d-9ac8-44c6-9f02-cad2db783ccb, status phase: Pending. Waiting for statefulset controller to delete.
    Nov 26 12:03:35.964: INFO: Observed stateful pod in namespace: statefulset-3056, name: ss-0, uid: 538d651d-9ac8-44c6-9f02-cad2db783ccb, status phase: Failed. Waiting for statefulset controller to delete.
    Nov 26 12:03:36.011: INFO: Observed stateful pod in namespace: statefulset-3056, name: ss-0, uid: 538d651d-9ac8-44c6-9f02-cad2db783ccb, status phase: Failed. Waiting for statefulset controller to delete.
    Nov 26 12:03:36.020: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3056
    STEP: Removing pod with conflicting port in namespace statefulset-3056 11/26/22 12:03:36.02
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3056 and will be in running state 11/26/22 12:03:36.039
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 26 12:03:38.054: INFO: Deleting all statefulset in ns statefulset-3056
    Nov 26 12:03:38.060: INFO: Scaling statefulset ss to 0
    Nov 26 12:03:48.095: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 12:03:48.100: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 26 12:03:48.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3056" for this suite. 11/26/22 12:03:48.15
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:03:48.17
Nov 26 12:03:48.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename job 11/26/22 12:03:48.173
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:48.198
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:48.204
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 11/26/22 12:03:48.209
STEP: Ensuring active pods == parallelism 11/26/22 12:03:48.22
STEP: Orphaning one of the Job's Pods 11/26/22 12:03:50.228
Nov 26 12:03:50.753: INFO: Successfully updated pod "adopt-release-6vkjf"
STEP: Checking that the Job readopts the Pod 11/26/22 12:03:50.753
Nov 26 12:03:50.753: INFO: Waiting up to 15m0s for pod "adopt-release-6vkjf" in namespace "job-6947" to be "adopted"
Nov 26 12:03:50.763: INFO: Pod "adopt-release-6vkjf": Phase="Running", Reason="", readiness=true. Elapsed: 9.915652ms
Nov 26 12:03:52.769: INFO: Pod "adopt-release-6vkjf": Phase="Running", Reason="", readiness=true. Elapsed: 2.01606798s
Nov 26 12:03:52.769: INFO: Pod "adopt-release-6vkjf" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 11/26/22 12:03:52.769
Nov 26 12:03:53.287: INFO: Successfully updated pod "adopt-release-6vkjf"
STEP: Checking that the Job releases the Pod 11/26/22 12:03:53.288
Nov 26 12:03:53.288: INFO: Waiting up to 15m0s for pod "adopt-release-6vkjf" in namespace "job-6947" to be "released"
Nov 26 12:03:53.292: INFO: Pod "adopt-release-6vkjf": Phase="Running", Reason="", readiness=true. Elapsed: 4.632104ms
Nov 26 12:03:55.299: INFO: Pod "adopt-release-6vkjf": Phase="Running", Reason="", readiness=true. Elapsed: 2.011206449s
Nov 26 12:03:55.300: INFO: Pod "adopt-release-6vkjf" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 26 12:03:55.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6947" for this suite. 11/26/22 12:03:55.306
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":34,"skipped":562,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.146 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:03:48.17
    Nov 26 12:03:48.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename job 11/26/22 12:03:48.173
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:48.198
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:48.204
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 11/26/22 12:03:48.209
    STEP: Ensuring active pods == parallelism 11/26/22 12:03:48.22
    STEP: Orphaning one of the Job's Pods 11/26/22 12:03:50.228
    Nov 26 12:03:50.753: INFO: Successfully updated pod "adopt-release-6vkjf"
    STEP: Checking that the Job readopts the Pod 11/26/22 12:03:50.753
    Nov 26 12:03:50.753: INFO: Waiting up to 15m0s for pod "adopt-release-6vkjf" in namespace "job-6947" to be "adopted"
    Nov 26 12:03:50.763: INFO: Pod "adopt-release-6vkjf": Phase="Running", Reason="", readiness=true. Elapsed: 9.915652ms
    Nov 26 12:03:52.769: INFO: Pod "adopt-release-6vkjf": Phase="Running", Reason="", readiness=true. Elapsed: 2.01606798s
    Nov 26 12:03:52.769: INFO: Pod "adopt-release-6vkjf" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 11/26/22 12:03:52.769
    Nov 26 12:03:53.287: INFO: Successfully updated pod "adopt-release-6vkjf"
    STEP: Checking that the Job releases the Pod 11/26/22 12:03:53.288
    Nov 26 12:03:53.288: INFO: Waiting up to 15m0s for pod "adopt-release-6vkjf" in namespace "job-6947" to be "released"
    Nov 26 12:03:53.292: INFO: Pod "adopt-release-6vkjf": Phase="Running", Reason="", readiness=true. Elapsed: 4.632104ms
    Nov 26 12:03:55.299: INFO: Pod "adopt-release-6vkjf": Phase="Running", Reason="", readiness=true. Elapsed: 2.011206449s
    Nov 26 12:03:55.300: INFO: Pod "adopt-release-6vkjf" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 26 12:03:55.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6947" for this suite. 11/26/22 12:03:55.306
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:03:55.317
Nov 26 12:03:55.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replication-controller 11/26/22 12:03:55.319
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:55.337
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:55.348
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 11/26/22 12:03:55.354
STEP: When the matched label of one of its pods change 11/26/22 12:03:55.363
Nov 26 12:03:55.371: INFO: Pod name pod-release: Found 0 pods out of 1
Nov 26 12:04:00.382: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 11/26/22 12:04:00.401
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 26 12:04:01.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2120" for this suite. 11/26/22 12:04:01.424
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":35,"skipped":563,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.118 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:03:55.317
    Nov 26 12:03:55.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replication-controller 11/26/22 12:03:55.319
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:03:55.337
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:03:55.348
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 11/26/22 12:03:55.354
    STEP: When the matched label of one of its pods change 11/26/22 12:03:55.363
    Nov 26 12:03:55.371: INFO: Pod name pod-release: Found 0 pods out of 1
    Nov 26 12:04:00.382: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 11/26/22 12:04:00.401
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 26 12:04:01.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2120" for this suite. 11/26/22 12:04:01.424
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:01.437
Nov 26 12:04:01.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename endpointslice 11/26/22 12:04:01.438
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:01.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:01.466
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 26 12:04:03.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-8510" for this suite. 11/26/22 12:04:03.576
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":36,"skipped":564,"failed":0}
------------------------------
â€¢ [2.151 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:01.437
    Nov 26 12:04:01.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename endpointslice 11/26/22 12:04:01.438
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:01.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:01.466
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 26 12:04:03.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-8510" for this suite. 11/26/22 12:04:03.576
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:03.588
Nov 26 12:04:03.588: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir-wrapper 11/26/22 12:04:03.589
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:03.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:03.627
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Nov 26 12:04:03.673: INFO: Waiting up to 5m0s for pod "pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91" in namespace "emptydir-wrapper-5187" to be "running and ready"
Nov 26 12:04:03.685: INFO: Pod "pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91": Phase="Pending", Reason="", readiness=false. Elapsed: 11.918509ms
Nov 26 12:04:03.685: INFO: The phase of Pod pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:04:05.690: INFO: Pod "pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017880503s
Nov 26 12:04:05.691: INFO: The phase of Pod pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:04:07.693: INFO: Pod "pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91": Phase="Running", Reason="", readiness=true. Elapsed: 4.02023366s
Nov 26 12:04:07.693: INFO: The phase of Pod pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91 is Running (Ready = true)
Nov 26 12:04:07.693: INFO: Pod "pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91" satisfied condition "running and ready"
STEP: Cleaning up the secret 11/26/22 12:04:07.704
STEP: Cleaning up the configmap 11/26/22 12:04:07.715
STEP: Cleaning up the pod 11/26/22 12:04:07.724
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Nov 26 12:04:07.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5187" for this suite. 11/26/22 12:04:07.818
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":37,"skipped":567,"failed":0}
------------------------------
â€¢ [4.242 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:03.588
    Nov 26 12:04:03.588: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir-wrapper 11/26/22 12:04:03.589
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:03.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:03.627
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Nov 26 12:04:03.673: INFO: Waiting up to 5m0s for pod "pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91" in namespace "emptydir-wrapper-5187" to be "running and ready"
    Nov 26 12:04:03.685: INFO: Pod "pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91": Phase="Pending", Reason="", readiness=false. Elapsed: 11.918509ms
    Nov 26 12:04:03.685: INFO: The phase of Pod pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:04:05.690: INFO: Pod "pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017880503s
    Nov 26 12:04:05.691: INFO: The phase of Pod pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:04:07.693: INFO: Pod "pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91": Phase="Running", Reason="", readiness=true. Elapsed: 4.02023366s
    Nov 26 12:04:07.693: INFO: The phase of Pod pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91 is Running (Ready = true)
    Nov 26 12:04:07.693: INFO: Pod "pod-secrets-42c78063-f857-42c8-a646-234fd2e00f91" satisfied condition "running and ready"
    STEP: Cleaning up the secret 11/26/22 12:04:07.704
    STEP: Cleaning up the configmap 11/26/22 12:04:07.715
    STEP: Cleaning up the pod 11/26/22 12:04:07.724
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:04:07.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-5187" for this suite. 11/26/22 12:04:07.818
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:07.834
Nov 26 12:04:07.835: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename server-version 11/26/22 12:04:07.836
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:07.867
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:07.878
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 11/26/22 12:04:07.885
STEP: Confirm major version 11/26/22 12:04:07.888
Nov 26 12:04:07.888: INFO: Major version: 1
STEP: Confirm minor version 11/26/22 12:04:07.888
Nov 26 12:04:07.888: INFO: cleanMinorVersion: 25
Nov 26 12:04:07.888: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Nov 26 12:04:07.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-8813" for this suite. 11/26/22 12:04:07.896
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":38,"skipped":605,"failed":0}
------------------------------
â€¢ [0.083 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:07.834
    Nov 26 12:04:07.835: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename server-version 11/26/22 12:04:07.836
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:07.867
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:07.878
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 11/26/22 12:04:07.885
    STEP: Confirm major version 11/26/22 12:04:07.888
    Nov 26 12:04:07.888: INFO: Major version: 1
    STEP: Confirm minor version 11/26/22 12:04:07.888
    Nov 26 12:04:07.888: INFO: cleanMinorVersion: 25
    Nov 26 12:04:07.888: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Nov 26 12:04:07.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-8813" for this suite. 11/26/22 12:04:07.896
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:07.919
Nov 26 12:04:07.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename disruption 11/26/22 12:04:07.921
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:07.982
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:07.994
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 11/26/22 12:04:08.002
STEP: Waiting for the pdb to be processed 11/26/22 12:04:08.022
STEP: updating the pdb 11/26/22 12:04:10.036
STEP: Waiting for the pdb to be processed 11/26/22 12:04:10.057
STEP: patching the pdb 11/26/22 12:04:12.071
STEP: Waiting for the pdb to be processed 11/26/22 12:04:12.086
STEP: Waiting for the pdb to be deleted 11/26/22 12:04:14.112
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 26 12:04:14.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9305" for this suite. 11/26/22 12:04:14.125
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":39,"skipped":622,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.227 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:07.919
    Nov 26 12:04:07.919: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename disruption 11/26/22 12:04:07.921
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:07.982
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:07.994
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 11/26/22 12:04:08.002
    STEP: Waiting for the pdb to be processed 11/26/22 12:04:08.022
    STEP: updating the pdb 11/26/22 12:04:10.036
    STEP: Waiting for the pdb to be processed 11/26/22 12:04:10.057
    STEP: patching the pdb 11/26/22 12:04:12.071
    STEP: Waiting for the pdb to be processed 11/26/22 12:04:12.086
    STEP: Waiting for the pdb to be deleted 11/26/22 12:04:14.112
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 26 12:04:14.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9305" for this suite. 11/26/22 12:04:14.125
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:14.148
Nov 26 12:04:14.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:04:14.149
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:14.176
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:14.184
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 11/26/22 12:04:14.191
Nov 26 12:04:14.208: INFO: Waiting up to 5m0s for pod "pod-d88019d4-1207-4df4-8071-2d7032372606" in namespace "emptydir-7955" to be "Succeeded or Failed"
Nov 26 12:04:14.224: INFO: Pod "pod-d88019d4-1207-4df4-8071-2d7032372606": Phase="Pending", Reason="", readiness=false. Elapsed: 16.33637ms
Nov 26 12:04:16.231: INFO: Pod "pod-d88019d4-1207-4df4-8071-2d7032372606": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022604416s
Nov 26 12:04:18.231: INFO: Pod "pod-d88019d4-1207-4df4-8071-2d7032372606": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023378704s
STEP: Saw pod success 11/26/22 12:04:18.231
Nov 26 12:04:18.232: INFO: Pod "pod-d88019d4-1207-4df4-8071-2d7032372606" satisfied condition "Succeeded or Failed"
Nov 26 12:04:18.237: INFO: Trying to get logs from node ip-172-31-29-104 pod pod-d88019d4-1207-4df4-8071-2d7032372606 container test-container: <nil>
STEP: delete the pod 11/26/22 12:04:18.255
Nov 26 12:04:18.275: INFO: Waiting for pod pod-d88019d4-1207-4df4-8071-2d7032372606 to disappear
Nov 26 12:04:18.280: INFO: Pod pod-d88019d4-1207-4df4-8071-2d7032372606 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:04:18.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7955" for this suite. 11/26/22 12:04:18.285
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":40,"skipped":628,"failed":0}
------------------------------
â€¢ [4.147 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:14.148
    Nov 26 12:04:14.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:04:14.149
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:14.176
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:14.184
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 11/26/22 12:04:14.191
    Nov 26 12:04:14.208: INFO: Waiting up to 5m0s for pod "pod-d88019d4-1207-4df4-8071-2d7032372606" in namespace "emptydir-7955" to be "Succeeded or Failed"
    Nov 26 12:04:14.224: INFO: Pod "pod-d88019d4-1207-4df4-8071-2d7032372606": Phase="Pending", Reason="", readiness=false. Elapsed: 16.33637ms
    Nov 26 12:04:16.231: INFO: Pod "pod-d88019d4-1207-4df4-8071-2d7032372606": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022604416s
    Nov 26 12:04:18.231: INFO: Pod "pod-d88019d4-1207-4df4-8071-2d7032372606": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023378704s
    STEP: Saw pod success 11/26/22 12:04:18.231
    Nov 26 12:04:18.232: INFO: Pod "pod-d88019d4-1207-4df4-8071-2d7032372606" satisfied condition "Succeeded or Failed"
    Nov 26 12:04:18.237: INFO: Trying to get logs from node ip-172-31-29-104 pod pod-d88019d4-1207-4df4-8071-2d7032372606 container test-container: <nil>
    STEP: delete the pod 11/26/22 12:04:18.255
    Nov 26 12:04:18.275: INFO: Waiting for pod pod-d88019d4-1207-4df4-8071-2d7032372606 to disappear
    Nov 26 12:04:18.280: INFO: Pod pod-d88019d4-1207-4df4-8071-2d7032372606 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:04:18.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7955" for this suite. 11/26/22 12:04:18.285
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:18.297
Nov 26 12:04:18.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:04:18.298
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:18.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:18.327
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 11/26/22 12:04:18.331
Nov 26 12:04:18.346: INFO: Waiting up to 5m0s for pod "pod-33d0ee65-2386-4a7a-9082-82a0820731b9" in namespace "emptydir-4747" to be "Succeeded or Failed"
Nov 26 12:04:18.355: INFO: Pod "pod-33d0ee65-2386-4a7a-9082-82a0820731b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.055356ms
Nov 26 12:04:20.364: INFO: Pod "pod-33d0ee65-2386-4a7a-9082-82a0820731b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017538083s
Nov 26 12:04:22.364: INFO: Pod "pod-33d0ee65-2386-4a7a-9082-82a0820731b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018098666s
STEP: Saw pod success 11/26/22 12:04:22.365
Nov 26 12:04:22.365: INFO: Pod "pod-33d0ee65-2386-4a7a-9082-82a0820731b9" satisfied condition "Succeeded or Failed"
Nov 26 12:04:22.370: INFO: Trying to get logs from node ip-172-31-29-104 pod pod-33d0ee65-2386-4a7a-9082-82a0820731b9 container test-container: <nil>
STEP: delete the pod 11/26/22 12:04:22.382
Nov 26 12:04:22.473: INFO: Waiting for pod pod-33d0ee65-2386-4a7a-9082-82a0820731b9 to disappear
Nov 26 12:04:22.481: INFO: Pod pod-33d0ee65-2386-4a7a-9082-82a0820731b9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:04:22.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4747" for this suite. 11/26/22 12:04:22.487
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":41,"skipped":652,"failed":0}
------------------------------
â€¢ [4.201 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:18.297
    Nov 26 12:04:18.297: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:04:18.298
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:18.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:18.327
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 11/26/22 12:04:18.331
    Nov 26 12:04:18.346: INFO: Waiting up to 5m0s for pod "pod-33d0ee65-2386-4a7a-9082-82a0820731b9" in namespace "emptydir-4747" to be "Succeeded or Failed"
    Nov 26 12:04:18.355: INFO: Pod "pod-33d0ee65-2386-4a7a-9082-82a0820731b9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.055356ms
    Nov 26 12:04:20.364: INFO: Pod "pod-33d0ee65-2386-4a7a-9082-82a0820731b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017538083s
    Nov 26 12:04:22.364: INFO: Pod "pod-33d0ee65-2386-4a7a-9082-82a0820731b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018098666s
    STEP: Saw pod success 11/26/22 12:04:22.365
    Nov 26 12:04:22.365: INFO: Pod "pod-33d0ee65-2386-4a7a-9082-82a0820731b9" satisfied condition "Succeeded or Failed"
    Nov 26 12:04:22.370: INFO: Trying to get logs from node ip-172-31-29-104 pod pod-33d0ee65-2386-4a7a-9082-82a0820731b9 container test-container: <nil>
    STEP: delete the pod 11/26/22 12:04:22.382
    Nov 26 12:04:22.473: INFO: Waiting for pod pod-33d0ee65-2386-4a7a-9082-82a0820731b9 to disappear
    Nov 26 12:04:22.481: INFO: Pod pod-33d0ee65-2386-4a7a-9082-82a0820731b9 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:04:22.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4747" for this suite. 11/26/22 12:04:22.487
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:22.5
Nov 26 12:04:22.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubelet-test 11/26/22 12:04:22.501
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:22.522
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:22.527
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 26 12:04:26.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6477" for this suite. 11/26/22 12:04:26.563
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":42,"skipped":663,"failed":0}
------------------------------
â€¢ [4.073 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:22.5
    Nov 26 12:04:22.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubelet-test 11/26/22 12:04:22.501
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:22.522
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:22.527
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 26 12:04:26.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6477" for this suite. 11/26/22 12:04:26.563
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:26.575
Nov 26 12:04:26.575: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 12:04:26.576
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:26.593
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:26.602
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-fee89a36-8fc8-4470-b006-ea23d73343b1 11/26/22 12:04:26.609
STEP: Creating a pod to test consume configMaps 11/26/22 12:04:26.615
Nov 26 12:04:26.631: INFO: Waiting up to 5m0s for pod "pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56" in namespace "configmap-2018" to be "Succeeded or Failed"
Nov 26 12:04:26.645: INFO: Pod "pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56": Phase="Pending", Reason="", readiness=false. Elapsed: 13.748143ms
Nov 26 12:04:28.651: INFO: Pod "pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019866326s
Nov 26 12:04:30.664: INFO: Pod "pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033564115s
STEP: Saw pod success 11/26/22 12:04:30.664
Nov 26 12:04:30.665: INFO: Pod "pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56" satisfied condition "Succeeded or Failed"
Nov 26 12:04:30.673: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56 container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:04:30.687
Nov 26 12:04:30.714: INFO: Waiting for pod pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56 to disappear
Nov 26 12:04:30.719: INFO: Pod pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 12:04:30.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2018" for this suite. 11/26/22 12:04:30.725
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":43,"skipped":674,"failed":0}
------------------------------
â€¢ [4.161 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:26.575
    Nov 26 12:04:26.575: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 12:04:26.576
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:26.593
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:26.602
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-fee89a36-8fc8-4470-b006-ea23d73343b1 11/26/22 12:04:26.609
    STEP: Creating a pod to test consume configMaps 11/26/22 12:04:26.615
    Nov 26 12:04:26.631: INFO: Waiting up to 5m0s for pod "pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56" in namespace "configmap-2018" to be "Succeeded or Failed"
    Nov 26 12:04:26.645: INFO: Pod "pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56": Phase="Pending", Reason="", readiness=false. Elapsed: 13.748143ms
    Nov 26 12:04:28.651: INFO: Pod "pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019866326s
    Nov 26 12:04:30.664: INFO: Pod "pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033564115s
    STEP: Saw pod success 11/26/22 12:04:30.664
    Nov 26 12:04:30.665: INFO: Pod "pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56" satisfied condition "Succeeded or Failed"
    Nov 26 12:04:30.673: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56 container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:04:30.687
    Nov 26 12:04:30.714: INFO: Waiting for pod pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56 to disappear
    Nov 26 12:04:30.719: INFO: Pod pod-configmaps-322c6285-4f88-4479-9bcd-aab638a1ef56 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 12:04:30.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2018" for this suite. 11/26/22 12:04:30.725
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:30.739
Nov 26 12:04:30.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:04:30.74
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:30.767
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:30.772
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:04:30.805
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:04:31.222
STEP: Deploying the webhook pod 11/26/22 12:04:31.237
STEP: Wait for the deployment to be ready 11/26/22 12:04:31.253
Nov 26 12:04:31.268: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/26/22 12:04:33.288
STEP: Verifying the service has paired with the endpoint 11/26/22 12:04:33.305
Nov 26 12:04:34.306: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/26/22 12:04:34.312
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/26/22 12:04:34.333
STEP: Creating a dummy validating-webhook-configuration object 11/26/22 12:04:34.354
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 11/26/22 12:04:34.366
STEP: Creating a dummy mutating-webhook-configuration object 11/26/22 12:04:34.376
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 11/26/22 12:04:34.393
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:04:34.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7860" for this suite. 11/26/22 12:04:34.456
STEP: Destroying namespace "webhook-7860-markers" for this suite. 11/26/22 12:04:34.473
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":44,"skipped":692,"failed":0}
------------------------------
â€¢ [3.864 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:30.739
    Nov 26 12:04:30.739: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:04:30.74
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:30.767
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:30.772
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:04:30.805
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:04:31.222
    STEP: Deploying the webhook pod 11/26/22 12:04:31.237
    STEP: Wait for the deployment to be ready 11/26/22 12:04:31.253
    Nov 26 12:04:31.268: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/26/22 12:04:33.288
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:04:33.305
    Nov 26 12:04:34.306: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/26/22 12:04:34.312
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/26/22 12:04:34.333
    STEP: Creating a dummy validating-webhook-configuration object 11/26/22 12:04:34.354
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 11/26/22 12:04:34.366
    STEP: Creating a dummy mutating-webhook-configuration object 11/26/22 12:04:34.376
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 11/26/22 12:04:34.393
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:04:34.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7860" for this suite. 11/26/22 12:04:34.456
    STEP: Destroying namespace "webhook-7860-markers" for this suite. 11/26/22 12:04:34.473
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:34.604
Nov 26 12:04:34.604: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename namespaces 11/26/22 12:04:34.605
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:34.629
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:34.637
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 11/26/22 12:04:34.645
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:34.672
STEP: Creating a service in the namespace 11/26/22 12:04:34.676
STEP: Deleting the namespace 11/26/22 12:04:34.694
STEP: Waiting for the namespace to be removed. 11/26/22 12:04:34.709
STEP: Recreating the namespace 11/26/22 12:04:40.715
STEP: Verifying there is no service in the namespace 11/26/22 12:04:40.736
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:04:40.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9553" for this suite. 11/26/22 12:04:40.75
STEP: Destroying namespace "nsdeletetest-8129" for this suite. 11/26/22 12:04:40.765
Nov 26 12:04:40.771: INFO: Namespace nsdeletetest-8129 was already deleted
STEP: Destroying namespace "nsdeletetest-4813" for this suite. 11/26/22 12:04:40.771
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":45,"skipped":695,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.178 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:34.604
    Nov 26 12:04:34.604: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename namespaces 11/26/22 12:04:34.605
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:34.629
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:34.637
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 11/26/22 12:04:34.645
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:34.672
    STEP: Creating a service in the namespace 11/26/22 12:04:34.676
    STEP: Deleting the namespace 11/26/22 12:04:34.694
    STEP: Waiting for the namespace to be removed. 11/26/22 12:04:34.709
    STEP: Recreating the namespace 11/26/22 12:04:40.715
    STEP: Verifying there is no service in the namespace 11/26/22 12:04:40.736
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:04:40.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-9553" for this suite. 11/26/22 12:04:40.75
    STEP: Destroying namespace "nsdeletetest-8129" for this suite. 11/26/22 12:04:40.765
    Nov 26 12:04:40.771: INFO: Namespace nsdeletetest-8129 was already deleted
    STEP: Destroying namespace "nsdeletetest-4813" for this suite. 11/26/22 12:04:40.771
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:04:40.782
Nov 26 12:04:40.783: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename subpath 11/26/22 12:04:40.783
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:40.803
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:40.81
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/26/22 12:04:40.816
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-2pz6 11/26/22 12:04:40.837
STEP: Creating a pod to test atomic-volume-subpath 11/26/22 12:04:40.837
Nov 26 12:04:40.851: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-2pz6" in namespace "subpath-171" to be "Succeeded or Failed"
Nov 26 12:04:40.861: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.169443ms
Nov 26 12:04:42.868: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 2.016920889s
Nov 26 12:04:44.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 4.018250733s
Nov 26 12:04:46.867: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 6.016042687s
Nov 26 12:04:48.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 8.017639968s
Nov 26 12:04:50.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 10.017777376s
Nov 26 12:04:52.871: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 12.019879509s
Nov 26 12:04:54.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 14.017814047s
Nov 26 12:04:56.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 16.017822871s
Nov 26 12:04:58.868: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 18.01672568s
Nov 26 12:05:00.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 20.017782128s
Nov 26 12:05:02.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=false. Elapsed: 22.017892772s
Nov 26 12:05:04.867: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.016416378s
STEP: Saw pod success 11/26/22 12:05:04.868
Nov 26 12:05:04.868: INFO: Pod "pod-subpath-test-projected-2pz6" satisfied condition "Succeeded or Failed"
Nov 26 12:05:04.875: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-subpath-test-projected-2pz6 container test-container-subpath-projected-2pz6: <nil>
STEP: delete the pod 11/26/22 12:05:04.888
Nov 26 12:05:04.918: INFO: Waiting for pod pod-subpath-test-projected-2pz6 to disappear
Nov 26 12:05:04.924: INFO: Pod pod-subpath-test-projected-2pz6 no longer exists
STEP: Deleting pod pod-subpath-test-projected-2pz6 11/26/22 12:05:04.924
Nov 26 12:05:04.924: INFO: Deleting pod "pod-subpath-test-projected-2pz6" in namespace "subpath-171"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 26 12:05:04.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-171" for this suite. 11/26/22 12:05:04.945
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":46,"skipped":720,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.175 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:04:40.782
    Nov 26 12:04:40.783: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename subpath 11/26/22 12:04:40.783
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:04:40.803
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:04:40.81
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/26/22 12:04:40.816
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-2pz6 11/26/22 12:04:40.837
    STEP: Creating a pod to test atomic-volume-subpath 11/26/22 12:04:40.837
    Nov 26 12:04:40.851: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-2pz6" in namespace "subpath-171" to be "Succeeded or Failed"
    Nov 26 12:04:40.861: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.169443ms
    Nov 26 12:04:42.868: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 2.016920889s
    Nov 26 12:04:44.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 4.018250733s
    Nov 26 12:04:46.867: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 6.016042687s
    Nov 26 12:04:48.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 8.017639968s
    Nov 26 12:04:50.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 10.017777376s
    Nov 26 12:04:52.871: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 12.019879509s
    Nov 26 12:04:54.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 14.017814047s
    Nov 26 12:04:56.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 16.017822871s
    Nov 26 12:04:58.868: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 18.01672568s
    Nov 26 12:05:00.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=true. Elapsed: 20.017782128s
    Nov 26 12:05:02.869: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Running", Reason="", readiness=false. Elapsed: 22.017892772s
    Nov 26 12:05:04.867: INFO: Pod "pod-subpath-test-projected-2pz6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.016416378s
    STEP: Saw pod success 11/26/22 12:05:04.868
    Nov 26 12:05:04.868: INFO: Pod "pod-subpath-test-projected-2pz6" satisfied condition "Succeeded or Failed"
    Nov 26 12:05:04.875: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-subpath-test-projected-2pz6 container test-container-subpath-projected-2pz6: <nil>
    STEP: delete the pod 11/26/22 12:05:04.888
    Nov 26 12:05:04.918: INFO: Waiting for pod pod-subpath-test-projected-2pz6 to disappear
    Nov 26 12:05:04.924: INFO: Pod pod-subpath-test-projected-2pz6 no longer exists
    STEP: Deleting pod pod-subpath-test-projected-2pz6 11/26/22 12:05:04.924
    Nov 26 12:05:04.924: INFO: Deleting pod "pod-subpath-test-projected-2pz6" in namespace "subpath-171"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 26 12:05:04.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-171" for this suite. 11/26/22 12:05:04.945
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:04.96
Nov 26 12:05:04.961: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename containers 11/26/22 12:05:04.962
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:04.997
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:05.006
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 11/26/22 12:05:05.015
Nov 26 12:05:05.038: INFO: Waiting up to 5m0s for pod "client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6" in namespace "containers-7675" to be "Succeeded or Failed"
Nov 26 12:05:05.048: INFO: Pod "client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.545203ms
Nov 26 12:05:07.057: INFO: Pod "client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6": Phase="Running", Reason="", readiness=false. Elapsed: 2.018666972s
Nov 26 12:05:09.059: INFO: Pod "client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021418306s
STEP: Saw pod success 11/26/22 12:05:09.059
Nov 26 12:05:09.060: INFO: Pod "client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6" satisfied condition "Succeeded or Failed"
Nov 26 12:05:09.066: INFO: Trying to get logs from node ip-172-31-43-82 pod client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6 container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:05:09.075
Nov 26 12:05:09.160: INFO: Waiting for pod client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6 to disappear
Nov 26 12:05:09.166: INFO: Pod client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 26 12:05:09.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7675" for this suite. 11/26/22 12:05:09.176
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":47,"skipped":737,"failed":0}
------------------------------
â€¢ [4.230 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:04.96
    Nov 26 12:05:04.961: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename containers 11/26/22 12:05:04.962
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:04.997
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:05.006
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 11/26/22 12:05:05.015
    Nov 26 12:05:05.038: INFO: Waiting up to 5m0s for pod "client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6" in namespace "containers-7675" to be "Succeeded or Failed"
    Nov 26 12:05:05.048: INFO: Pod "client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.545203ms
    Nov 26 12:05:07.057: INFO: Pod "client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6": Phase="Running", Reason="", readiness=false. Elapsed: 2.018666972s
    Nov 26 12:05:09.059: INFO: Pod "client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021418306s
    STEP: Saw pod success 11/26/22 12:05:09.059
    Nov 26 12:05:09.060: INFO: Pod "client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6" satisfied condition "Succeeded or Failed"
    Nov 26 12:05:09.066: INFO: Trying to get logs from node ip-172-31-43-82 pod client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6 container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:05:09.075
    Nov 26 12:05:09.160: INFO: Waiting for pod client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6 to disappear
    Nov 26 12:05:09.166: INFO: Pod client-containers-4d350c57-56b9-4fe1-91fa-454ce6a455d6 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 26 12:05:09.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7675" for this suite. 11/26/22 12:05:09.176
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:09.199
Nov 26 12:05:09.199: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 12:05:09.2
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:09.229
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:09.236
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Nov 26 12:05:09.242: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: creating the pod 11/26/22 12:05:09.244
STEP: submitting the pod to kubernetes 11/26/22 12:05:09.244
Nov 26 12:05:09.258: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1" in namespace "pods-985" to be "running and ready"
Nov 26 12:05:09.267: INFO: Pod "pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.876245ms
Nov 26 12:05:09.268: INFO: The phase of Pod pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:05:11.274: INFO: Pod "pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.015457207s
Nov 26 12:05:11.274: INFO: The phase of Pod pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1 is Running (Ready = true)
Nov 26 12:05:11.274: INFO: Pod "pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 26 12:05:11.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-985" for this suite. 11/26/22 12:05:11.301
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":48,"skipped":831,"failed":0}
------------------------------
â€¢ [2.114 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:09.199
    Nov 26 12:05:09.199: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 12:05:09.2
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:09.229
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:09.236
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Nov 26 12:05:09.242: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: creating the pod 11/26/22 12:05:09.244
    STEP: submitting the pod to kubernetes 11/26/22 12:05:09.244
    Nov 26 12:05:09.258: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1" in namespace "pods-985" to be "running and ready"
    Nov 26 12:05:09.267: INFO: Pod "pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.876245ms
    Nov 26 12:05:09.268: INFO: The phase of Pod pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:05:11.274: INFO: Pod "pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.015457207s
    Nov 26 12:05:11.274: INFO: The phase of Pod pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1 is Running (Ready = true)
    Nov 26 12:05:11.274: INFO: Pod "pod-logs-websocket-85a721dd-629a-44b5-92e2-3b499f7e83b1" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 26 12:05:11.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-985" for this suite. 11/26/22 12:05:11.301
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:11.318
Nov 26 12:05:11.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:05:11.319
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:11.341
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:11.346
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:05:11.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3053" for this suite. 11/26/22 12:05:11.364
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":49,"skipped":860,"failed":0}
------------------------------
â€¢ [0.057 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:11.318
    Nov 26 12:05:11.318: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:05:11.319
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:11.341
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:11.346
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:05:11.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3053" for this suite. 11/26/22 12:05:11.364
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:11.376
Nov 26 12:05:11.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename containers 11/26/22 12:05:11.377
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:11.399
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:11.405
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 11/26/22 12:05:11.41
Nov 26 12:05:11.428: INFO: Waiting up to 5m0s for pod "client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe" in namespace "containers-5433" to be "Succeeded or Failed"
Nov 26 12:05:11.437: INFO: Pod "client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe": Phase="Pending", Reason="", readiness=false. Elapsed: 8.469635ms
Nov 26 12:05:13.444: INFO: Pod "client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015621821s
Nov 26 12:05:15.444: INFO: Pod "client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015447446s
STEP: Saw pod success 11/26/22 12:05:15.444
Nov 26 12:05:15.444: INFO: Pod "client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe" satisfied condition "Succeeded or Failed"
Nov 26 12:05:15.450: INFO: Trying to get logs from node ip-172-31-43-82 pod client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:05:15.459
Nov 26 12:05:15.479: INFO: Waiting for pod client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe to disappear
Nov 26 12:05:15.485: INFO: Pod client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 26 12:05:15.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5433" for this suite. 11/26/22 12:05:15.491
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":50,"skipped":862,"failed":0}
------------------------------
â€¢ [4.127 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:11.376
    Nov 26 12:05:11.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename containers 11/26/22 12:05:11.377
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:11.399
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:11.405
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 11/26/22 12:05:11.41
    Nov 26 12:05:11.428: INFO: Waiting up to 5m0s for pod "client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe" in namespace "containers-5433" to be "Succeeded or Failed"
    Nov 26 12:05:11.437: INFO: Pod "client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe": Phase="Pending", Reason="", readiness=false. Elapsed: 8.469635ms
    Nov 26 12:05:13.444: INFO: Pod "client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015621821s
    Nov 26 12:05:15.444: INFO: Pod "client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015447446s
    STEP: Saw pod success 11/26/22 12:05:15.444
    Nov 26 12:05:15.444: INFO: Pod "client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe" satisfied condition "Succeeded or Failed"
    Nov 26 12:05:15.450: INFO: Trying to get logs from node ip-172-31-43-82 pod client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:05:15.459
    Nov 26 12:05:15.479: INFO: Waiting for pod client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe to disappear
    Nov 26 12:05:15.485: INFO: Pod client-containers-3cefb7c9-dad4-4608-9d48-a386e7bbaffe no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 26 12:05:15.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-5433" for this suite. 11/26/22 12:05:15.491
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:15.506
Nov 26 12:05:15.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename custom-resource-definition 11/26/22 12:05:15.508
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:15.586
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:15.593
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Nov 26 12:05:15.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:05:18.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9811" for this suite. 11/26/22 12:05:18.875
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":51,"skipped":874,"failed":0}
------------------------------
â€¢ [3.382 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:15.506
    Nov 26 12:05:15.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename custom-resource-definition 11/26/22 12:05:15.508
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:15.586
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:15.593
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Nov 26 12:05:15.600: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:05:18.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-9811" for this suite. 11/26/22 12:05:18.875
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:18.889
Nov 26 12:05:18.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename gc 11/26/22 12:05:18.892
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:18.912
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:18.919
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Nov 26 12:05:18.971: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"cee7af2f-3615-4042-a060-d709eca25b54", Controller:(*bool)(0xc00370c6e6), BlockOwnerDeletion:(*bool)(0xc00370c6e7)}}
Nov 26 12:05:18.986: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"188a6eb8-8043-49c3-bd8e-e14b7ab1ccc2", Controller:(*bool)(0xc00370c96e), BlockOwnerDeletion:(*bool)(0xc00370c96f)}}
Nov 26 12:05:19.004: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"8d157711-1153-4021-b1f4-b1f0cec3bd1a", Controller:(*bool)(0xc00370cbb6), BlockOwnerDeletion:(*bool)(0xc00370cbb7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 26 12:05:24.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3734" for this suite. 11/26/22 12:05:24.042
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":52,"skipped":887,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.166 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:18.889
    Nov 26 12:05:18.889: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename gc 11/26/22 12:05:18.892
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:18.912
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:18.919
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Nov 26 12:05:18.971: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"cee7af2f-3615-4042-a060-d709eca25b54", Controller:(*bool)(0xc00370c6e6), BlockOwnerDeletion:(*bool)(0xc00370c6e7)}}
    Nov 26 12:05:18.986: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"188a6eb8-8043-49c3-bd8e-e14b7ab1ccc2", Controller:(*bool)(0xc00370c96e), BlockOwnerDeletion:(*bool)(0xc00370c96f)}}
    Nov 26 12:05:19.004: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"8d157711-1153-4021-b1f4-b1f0cec3bd1a", Controller:(*bool)(0xc00370cbb6), BlockOwnerDeletion:(*bool)(0xc00370cbb7)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 26 12:05:24.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3734" for this suite. 11/26/22 12:05:24.042
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:24.058
Nov 26 12:05:24.059: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:05:24.06
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:24.108
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:24.116
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-167 11/26/22 12:05:24.122
STEP: creating service affinity-clusterip in namespace services-167 11/26/22 12:05:24.122
STEP: creating replication controller affinity-clusterip in namespace services-167 11/26/22 12:05:24.145
I1126 12:05:24.176601      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-167, replica count: 3
I1126 12:05:27.228960      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 12:05:27.240: INFO: Creating new exec pod
Nov 26 12:05:27.251: INFO: Waiting up to 5m0s for pod "execpod-affinitynjj4k" in namespace "services-167" to be "running"
Nov 26 12:05:27.257: INFO: Pod "execpod-affinitynjj4k": Phase="Pending", Reason="", readiness=false. Elapsed: 5.723383ms
Nov 26 12:05:29.266: INFO: Pod "execpod-affinitynjj4k": Phase="Running", Reason="", readiness=true. Elapsed: 2.014355156s
Nov 26 12:05:29.266: INFO: Pod "execpod-affinitynjj4k" satisfied condition "running"
Nov 26 12:05:30.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-167 exec execpod-affinitynjj4k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Nov 26 12:05:30.474: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Nov 26 12:05:30.474: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:05:30.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-167 exec execpod-affinitynjj4k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.125 80'
Nov 26 12:05:30.668: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.125 80\nConnection to 10.152.183.125 80 port [tcp/http] succeeded!\n"
Nov 26 12:05:30.668: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:05:30.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-167 exec execpod-affinitynjj4k -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.125:80/ ; done'
Nov 26 12:05:30.946: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n"
Nov 26 12:05:30.946: INFO: stdout: "\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt"
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
Nov 26 12:05:30.946: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-167, will wait for the garbage collector to delete the pods 11/26/22 12:05:30.971
Nov 26 12:05:31.040: INFO: Deleting ReplicationController affinity-clusterip took: 12.119742ms
Nov 26 12:05:31.140: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.774158ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:05:33.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-167" for this suite. 11/26/22 12:05:33.192
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":53,"skipped":890,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.157 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:24.058
    Nov 26 12:05:24.059: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:05:24.06
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:24.108
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:24.116
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-167 11/26/22 12:05:24.122
    STEP: creating service affinity-clusterip in namespace services-167 11/26/22 12:05:24.122
    STEP: creating replication controller affinity-clusterip in namespace services-167 11/26/22 12:05:24.145
    I1126 12:05:24.176601      19 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-167, replica count: 3
    I1126 12:05:27.228960      19 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 12:05:27.240: INFO: Creating new exec pod
    Nov 26 12:05:27.251: INFO: Waiting up to 5m0s for pod "execpod-affinitynjj4k" in namespace "services-167" to be "running"
    Nov 26 12:05:27.257: INFO: Pod "execpod-affinitynjj4k": Phase="Pending", Reason="", readiness=false. Elapsed: 5.723383ms
    Nov 26 12:05:29.266: INFO: Pod "execpod-affinitynjj4k": Phase="Running", Reason="", readiness=true. Elapsed: 2.014355156s
    Nov 26 12:05:29.266: INFO: Pod "execpod-affinitynjj4k" satisfied condition "running"
    Nov 26 12:05:30.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-167 exec execpod-affinitynjj4k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Nov 26 12:05:30.474: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Nov 26 12:05:30.474: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:05:30.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-167 exec execpod-affinitynjj4k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.125 80'
    Nov 26 12:05:30.668: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.125 80\nConnection to 10.152.183.125 80 port [tcp/http] succeeded!\n"
    Nov 26 12:05:30.668: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:05:30.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-167 exec execpod-affinitynjj4k -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.125:80/ ; done'
    Nov 26 12:05:30.946: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.125:80/\n"
    Nov 26 12:05:30.946: INFO: stdout: "\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt\naffinity-clusterip-rmggt"
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Received response from host: affinity-clusterip-rmggt
    Nov 26 12:05:30.946: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-167, will wait for the garbage collector to delete the pods 11/26/22 12:05:30.971
    Nov 26 12:05:31.040: INFO: Deleting ReplicationController affinity-clusterip took: 12.119742ms
    Nov 26 12:05:31.140: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.774158ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:05:33.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-167" for this suite. 11/26/22 12:05:33.192
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:33.217
Nov 26 12:05:33.217: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename csistoragecapacity 11/26/22 12:05:33.218
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:33.245
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:33.25
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 11/26/22 12:05:33.26
STEP: getting /apis/storage.k8s.io 11/26/22 12:05:33.264
STEP: getting /apis/storage.k8s.io/v1 11/26/22 12:05:33.267
STEP: creating 11/26/22 12:05:33.269
STEP: watching 11/26/22 12:05:33.294
Nov 26 12:05:33.294: INFO: starting watch
STEP: getting 11/26/22 12:05:33.307
STEP: listing in namespace 11/26/22 12:05:33.313
STEP: listing across namespaces 11/26/22 12:05:33.318
STEP: patching 11/26/22 12:05:33.324
STEP: updating 11/26/22 12:05:33.336
Nov 26 12:05:33.345: INFO: waiting for watch events with expected annotations in namespace
Nov 26 12:05:33.346: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 11/26/22 12:05:33.346
STEP: deleting a collection 11/26/22 12:05:33.369
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Nov 26 12:05:33.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-3862" for this suite. 11/26/22 12:05:33.407
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":54,"skipped":906,"failed":0}
------------------------------
â€¢ [0.201 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:33.217
    Nov 26 12:05:33.217: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename csistoragecapacity 11/26/22 12:05:33.218
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:33.245
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:33.25
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 11/26/22 12:05:33.26
    STEP: getting /apis/storage.k8s.io 11/26/22 12:05:33.264
    STEP: getting /apis/storage.k8s.io/v1 11/26/22 12:05:33.267
    STEP: creating 11/26/22 12:05:33.269
    STEP: watching 11/26/22 12:05:33.294
    Nov 26 12:05:33.294: INFO: starting watch
    STEP: getting 11/26/22 12:05:33.307
    STEP: listing in namespace 11/26/22 12:05:33.313
    STEP: listing across namespaces 11/26/22 12:05:33.318
    STEP: patching 11/26/22 12:05:33.324
    STEP: updating 11/26/22 12:05:33.336
    Nov 26 12:05:33.345: INFO: waiting for watch events with expected annotations in namespace
    Nov 26 12:05:33.346: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 11/26/22 12:05:33.346
    STEP: deleting a collection 11/26/22 12:05:33.369
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Nov 26 12:05:33.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-3862" for this suite. 11/26/22 12:05:33.407
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:33.419
Nov 26 12:05:33.419: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 12:05:33.42
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:33.443
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:33.449
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Nov 26 12:05:33.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: creating the pod 11/26/22 12:05:33.458
STEP: submitting the pod to kubernetes 11/26/22 12:05:33.458
Nov 26 12:05:33.475: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48" in namespace "pods-7626" to be "running and ready"
Nov 26 12:05:33.484: INFO: Pod "pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48": Phase="Pending", Reason="", readiness=false. Elapsed: 8.909777ms
Nov 26 12:05:33.484: INFO: The phase of Pod pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:05:35.490: INFO: Pod "pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.014851128s
Nov 26 12:05:35.490: INFO: The phase of Pod pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48 is Running (Ready = true)
Nov 26 12:05:35.490: INFO: Pod "pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 26 12:05:35.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7626" for this suite. 11/26/22 12:05:35.595
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":55,"skipped":921,"failed":0}
------------------------------
â€¢ [2.186 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:33.419
    Nov 26 12:05:33.419: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 12:05:33.42
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:33.443
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:33.449
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Nov 26 12:05:33.457: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: creating the pod 11/26/22 12:05:33.458
    STEP: submitting the pod to kubernetes 11/26/22 12:05:33.458
    Nov 26 12:05:33.475: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48" in namespace "pods-7626" to be "running and ready"
    Nov 26 12:05:33.484: INFO: Pod "pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48": Phase="Pending", Reason="", readiness=false. Elapsed: 8.909777ms
    Nov 26 12:05:33.484: INFO: The phase of Pod pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:05:35.490: INFO: Pod "pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48": Phase="Running", Reason="", readiness=true. Elapsed: 2.014851128s
    Nov 26 12:05:35.490: INFO: The phase of Pod pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48 is Running (Ready = true)
    Nov 26 12:05:35.490: INFO: Pod "pod-exec-websocket-adfe49f0-7614-4ca0-9ba3-9ad121803a48" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 26 12:05:35.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7626" for this suite. 11/26/22 12:05:35.595
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:35.612
Nov 26 12:05:35.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:05:35.613
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:35.642
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:35.65
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-84 11/26/22 12:05:35.655
STEP: creating service affinity-nodeport in namespace services-84 11/26/22 12:05:35.656
STEP: creating replication controller affinity-nodeport in namespace services-84 11/26/22 12:05:35.682
I1126 12:05:35.716186      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-84, replica count: 3
I1126 12:05:38.767336      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 12:05:38.785: INFO: Creating new exec pod
Nov 26 12:05:38.795: INFO: Waiting up to 5m0s for pod "execpod-affinityjmvjq" in namespace "services-84" to be "running"
Nov 26 12:05:38.801: INFO: Pod "execpod-affinityjmvjq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.106802ms
Nov 26 12:05:40.812: INFO: Pod "execpod-affinityjmvjq": Phase="Running", Reason="", readiness=true. Elapsed: 2.016880231s
Nov 26 12:05:40.812: INFO: Pod "execpod-affinityjmvjq" satisfied condition "running"
Nov 26 12:05:41.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-84 exec execpod-affinityjmvjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Nov 26 12:05:42.028: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Nov 26 12:05:42.028: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:05:42.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-84 exec execpod-affinityjmvjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.250 80'
Nov 26 12:05:42.209: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.250 80\nConnection to 10.152.183.250 80 port [tcp/http] succeeded!\n"
Nov 26 12:05:42.209: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:05:42.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-84 exec execpod-affinityjmvjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 31222'
Nov 26 12:05:42.404: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.29.104 31222\nConnection to 172.31.29.104 31222 port [tcp/*] succeeded!\n"
Nov 26 12:05:42.404: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:05:42.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-84 exec execpod-affinityjmvjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.82 31222'
Nov 26 12:05:42.589: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.43.82 31222\nConnection to 172.31.43.82 31222 port [tcp/*] succeeded!\n"
Nov 26 12:05:42.589: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:05:42.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-84 exec execpod-affinityjmvjq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.249:31222/ ; done'
Nov 26 12:05:42.862: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n"
Nov 26 12:05:42.862: INFO: stdout: "\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd"
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
Nov 26 12:05:42.862: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-84, will wait for the garbage collector to delete the pods 11/26/22 12:05:42.887
Nov 26 12:05:42.956: INFO: Deleting ReplicationController affinity-nodeport took: 10.917184ms
Nov 26 12:05:43.057: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.077673ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:05:45.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-84" for this suite. 11/26/22 12:05:45.214
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":56,"skipped":968,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.615 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:35.612
    Nov 26 12:05:35.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:05:35.613
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:35.642
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:35.65
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-84 11/26/22 12:05:35.655
    STEP: creating service affinity-nodeport in namespace services-84 11/26/22 12:05:35.656
    STEP: creating replication controller affinity-nodeport in namespace services-84 11/26/22 12:05:35.682
    I1126 12:05:35.716186      19 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-84, replica count: 3
    I1126 12:05:38.767336      19 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 12:05:38.785: INFO: Creating new exec pod
    Nov 26 12:05:38.795: INFO: Waiting up to 5m0s for pod "execpod-affinityjmvjq" in namespace "services-84" to be "running"
    Nov 26 12:05:38.801: INFO: Pod "execpod-affinityjmvjq": Phase="Pending", Reason="", readiness=false. Elapsed: 6.106802ms
    Nov 26 12:05:40.812: INFO: Pod "execpod-affinityjmvjq": Phase="Running", Reason="", readiness=true. Elapsed: 2.016880231s
    Nov 26 12:05:40.812: INFO: Pod "execpod-affinityjmvjq" satisfied condition "running"
    Nov 26 12:05:41.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-84 exec execpod-affinityjmvjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Nov 26 12:05:42.028: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Nov 26 12:05:42.028: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:05:42.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-84 exec execpod-affinityjmvjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.250 80'
    Nov 26 12:05:42.209: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.250 80\nConnection to 10.152.183.250 80 port [tcp/http] succeeded!\n"
    Nov 26 12:05:42.209: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:05:42.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-84 exec execpod-affinityjmvjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 31222'
    Nov 26 12:05:42.404: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.29.104 31222\nConnection to 172.31.29.104 31222 port [tcp/*] succeeded!\n"
    Nov 26 12:05:42.404: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:05:42.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-84 exec execpod-affinityjmvjq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.82 31222'
    Nov 26 12:05:42.589: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.43.82 31222\nConnection to 172.31.43.82 31222 port [tcp/*] succeeded!\n"
    Nov 26 12:05:42.589: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:05:42.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-84 exec execpod-affinityjmvjq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.249:31222/ ; done'
    Nov 26 12:05:42.862: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:31222/\n"
    Nov 26 12:05:42.862: INFO: stdout: "\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd\naffinity-nodeport-w7xfd"
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Received response from host: affinity-nodeport-w7xfd
    Nov 26 12:05:42.862: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-84, will wait for the garbage collector to delete the pods 11/26/22 12:05:42.887
    Nov 26 12:05:42.956: INFO: Deleting ReplicationController affinity-nodeport took: 10.917184ms
    Nov 26 12:05:43.057: INFO: Terminating ReplicationController affinity-nodeport pods took: 101.077673ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:05:45.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-84" for this suite. 11/26/22 12:05:45.214
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:45.23
Nov 26 12:05:45.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:05:45.232
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:45.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:45.27
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 11/26/22 12:05:45.276
Nov 26 12:05:45.290: INFO: Waiting up to 5m0s for pod "annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40" in namespace "projected-2944" to be "running and ready"
Nov 26 12:05:45.299: INFO: Pod "annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40": Phase="Pending", Reason="", readiness=false. Elapsed: 8.797575ms
Nov 26 12:05:45.299: INFO: The phase of Pod annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:05:47.306: INFO: Pod "annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40": Phase="Running", Reason="", readiness=true. Elapsed: 2.015234564s
Nov 26 12:05:47.306: INFO: The phase of Pod annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40 is Running (Ready = true)
Nov 26 12:05:47.306: INFO: Pod "annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40" satisfied condition "running and ready"
Nov 26 12:05:47.839: INFO: Successfully updated pod "annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 12:05:49.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2944" for this suite. 11/26/22 12:05:49.864
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":57,"skipped":1011,"failed":0}
------------------------------
â€¢ [4.644 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:45.23
    Nov 26 12:05:45.230: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:05:45.232
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:45.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:45.27
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 11/26/22 12:05:45.276
    Nov 26 12:05:45.290: INFO: Waiting up to 5m0s for pod "annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40" in namespace "projected-2944" to be "running and ready"
    Nov 26 12:05:45.299: INFO: Pod "annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40": Phase="Pending", Reason="", readiness=false. Elapsed: 8.797575ms
    Nov 26 12:05:45.299: INFO: The phase of Pod annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:05:47.306: INFO: Pod "annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40": Phase="Running", Reason="", readiness=true. Elapsed: 2.015234564s
    Nov 26 12:05:47.306: INFO: The phase of Pod annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40 is Running (Ready = true)
    Nov 26 12:05:47.306: INFO: Pod "annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40" satisfied condition "running and ready"
    Nov 26 12:05:47.839: INFO: Successfully updated pod "annotationupdatec934e2fb-ac8c-4d20-bd04-1ea799ff1f40"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 12:05:49.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2944" for this suite. 11/26/22 12:05:49.864
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:05:49.875
Nov 26 12:05:49.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename svc-latency 11/26/22 12:05:49.876
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:49.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:49.909
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Nov 26 12:05:49.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8144 11/26/22 12:05:49.915
I1126 12:05:49.928150      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8144, replica count: 1
I1126 12:05:50.978655      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1126 12:05:51.979419      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 12:05:52.094: INFO: Created: latency-svc-vlk46
Nov 26 12:05:52.110: INFO: Got endpoints: latency-svc-vlk46 [30.496431ms]
Nov 26 12:05:52.144: INFO: Created: latency-svc-pcl8k
Nov 26 12:05:52.152: INFO: Got endpoints: latency-svc-pcl8k [40.990007ms]
Nov 26 12:05:52.158: INFO: Created: latency-svc-rw6b8
Nov 26 12:05:52.172: INFO: Created: latency-svc-dtws9
Nov 26 12:05:52.176: INFO: Got endpoints: latency-svc-rw6b8 [64.208098ms]
Nov 26 12:05:52.178: INFO: Got endpoints: latency-svc-dtws9 [67.647378ms]
Nov 26 12:05:52.197: INFO: Created: latency-svc-hdq87
Nov 26 12:05:52.219: INFO: Got endpoints: latency-svc-hdq87 [106.913325ms]
Nov 26 12:05:52.222: INFO: Created: latency-svc-7f7nw
Nov 26 12:05:52.229: INFO: Created: latency-svc-cklwg
Nov 26 12:05:52.236: INFO: Got endpoints: latency-svc-7f7nw [123.763558ms]
Nov 26 12:05:52.250: INFO: Got endpoints: latency-svc-cklwg [138.42554ms]
Nov 26 12:05:52.253: INFO: Created: latency-svc-7lnxm
Nov 26 12:05:52.270: INFO: Got endpoints: latency-svc-7lnxm [158.329644ms]
Nov 26 12:05:52.276: INFO: Created: latency-svc-mfhf8
Nov 26 12:05:52.284: INFO: Got endpoints: latency-svc-mfhf8 [172.334871ms]
Nov 26 12:05:52.380: INFO: Created: latency-svc-v8pjv
Nov 26 12:05:52.391: INFO: Created: latency-svc-zhc62
Nov 26 12:05:52.402: INFO: Got endpoints: latency-svc-v8pjv [288.86388ms]
Nov 26 12:05:52.407: INFO: Created: latency-svc-j9lst
Nov 26 12:05:52.407: INFO: Created: latency-svc-tztp4
Nov 26 12:05:52.412: INFO: Created: latency-svc-vh2k7
Nov 26 12:05:52.412: INFO: Created: latency-svc-fd7js
Nov 26 12:05:52.412: INFO: Created: latency-svc-9vfnh
Nov 26 12:05:52.413: INFO: Got endpoints: latency-svc-9vfnh [299.498608ms]
Nov 26 12:05:52.412: INFO: Created: latency-svc-lk7vw
Nov 26 12:05:52.412: INFO: Created: latency-svc-794sb
Nov 26 12:05:52.413: INFO: Created: latency-svc-zxlvj
Nov 26 12:05:52.415: INFO: Created: latency-svc-gdzdx
Nov 26 12:05:52.415: INFO: Created: latency-svc-qcdqb
Nov 26 12:05:52.415: INFO: Created: latency-svc-q4xbf
Nov 26 12:05:52.418: INFO: Created: latency-svc-wbzk8
Nov 26 12:05:52.419: INFO: Created: latency-svc-vwtkg
Nov 26 12:05:52.436: INFO: Got endpoints: latency-svc-vh2k7 [323.336535ms]
Nov 26 12:05:52.461: INFO: Created: latency-svc-xm5qx
Nov 26 12:05:52.462: INFO: Got endpoints: latency-svc-qcdqb [349.635408ms]
Nov 26 12:05:52.464: INFO: Got endpoints: latency-svc-tztp4 [350.078039ms]
Nov 26 12:05:52.464: INFO: Got endpoints: latency-svc-zxlvj [180.052661ms]
Nov 26 12:05:52.464: INFO: Got endpoints: latency-svc-j9lst [352.666278ms]
Nov 26 12:05:52.485: INFO: Got endpoints: latency-svc-vwtkg [309.308367ms]
Nov 26 12:05:52.486: INFO: Got endpoints: latency-svc-zhc62 [249.710666ms]
Nov 26 12:05:52.490: INFO: Created: latency-svc-ksptm
Nov 26 12:05:52.498: INFO: Got endpoints: latency-svc-lk7vw [320.057718ms]
Nov 26 12:05:52.499: INFO: Got endpoints: latency-svc-gdzdx [346.73314ms]
Nov 26 12:05:52.499: INFO: Got endpoints: latency-svc-fd7js [279.696266ms]
Nov 26 12:05:52.500: INFO: Got endpoints: latency-svc-794sb [229.525165ms]
Nov 26 12:05:52.513: INFO: Created: latency-svc-tdn68
Nov 26 12:05:52.532: INFO: Got endpoints: latency-svc-wbzk8 [282.329948ms]
Nov 26 12:05:52.533: INFO: Got endpoints: latency-svc-q4xbf [420.787148ms]
Nov 26 12:05:52.534: INFO: Got endpoints: latency-svc-xm5qx [131.509308ms]
Nov 26 12:05:52.534: INFO: Got endpoints: latency-svc-tdn68 [98.213372ms]
Nov 26 12:05:52.538: INFO: Got endpoints: latency-svc-ksptm [125.294384ms]
Nov 26 12:05:52.542: INFO: Created: latency-svc-plbnz
Nov 26 12:05:52.552: INFO: Got endpoints: latency-svc-plbnz [89.888937ms]
Nov 26 12:05:52.561: INFO: Created: latency-svc-4dmz9
Nov 26 12:05:52.568: INFO: Got endpoints: latency-svc-4dmz9 [103.074276ms]
Nov 26 12:05:52.574: INFO: Created: latency-svc-2br78
Nov 26 12:05:52.583: INFO: Got endpoints: latency-svc-2br78 [119.686792ms]
Nov 26 12:05:52.584: INFO: Created: latency-svc-226lq
Nov 26 12:05:52.596: INFO: Created: latency-svc-64l8v
Nov 26 12:05:52.601: INFO: Got endpoints: latency-svc-226lq [137.173351ms]
Nov 26 12:05:52.607: INFO: Got endpoints: latency-svc-64l8v [121.582567ms]
Nov 26 12:05:52.615: INFO: Created: latency-svc-lk86c
Nov 26 12:05:52.626: INFO: Created: latency-svc-b5vhc
Nov 26 12:05:52.629: INFO: Got endpoints: latency-svc-lk86c [143.368496ms]
Nov 26 12:05:52.636: INFO: Got endpoints: latency-svc-b5vhc [137.174691ms]
Nov 26 12:05:52.649: INFO: Created: latency-svc-klzzx
Nov 26 12:05:52.658: INFO: Created: latency-svc-v4nqc
Nov 26 12:05:52.660: INFO: Got endpoints: latency-svc-klzzx [160.662389ms]
Nov 26 12:05:52.667: INFO: Created: latency-svc-js4b6
Nov 26 12:05:52.670: INFO: Got endpoints: latency-svc-v4nqc [170.659263ms]
Nov 26 12:05:52.678: INFO: Got endpoints: latency-svc-js4b6 [178.304691ms]
Nov 26 12:05:52.689: INFO: Created: latency-svc-bp5lg
Nov 26 12:05:52.697: INFO: Got endpoints: latency-svc-bp5lg [165.334217ms]
Nov 26 12:05:52.705: INFO: Created: latency-svc-dr7kq
Nov 26 12:05:52.715: INFO: Created: latency-svc-b9wlg
Nov 26 12:05:52.716: INFO: Got endpoints: latency-svc-dr7kq [183.235056ms]
Nov 26 12:05:52.725: INFO: Got endpoints: latency-svc-b9wlg [190.540606ms]
Nov 26 12:05:52.730: INFO: Created: latency-svc-b75wj
Nov 26 12:05:52.742: INFO: Created: latency-svc-c92lr
Nov 26 12:05:52.747: INFO: Got endpoints: latency-svc-b75wj [208.624917ms]
Nov 26 12:05:52.753: INFO: Got endpoints: latency-svc-c92lr [219.181524ms]
Nov 26 12:05:52.763: INFO: Created: latency-svc-xpsv4
Nov 26 12:05:52.774: INFO: Got endpoints: latency-svc-xpsv4 [221.244732ms]
Nov 26 12:05:52.777: INFO: Created: latency-svc-2xjfh
Nov 26 12:05:52.787: INFO: Created: latency-svc-7fbw6
Nov 26 12:05:52.793: INFO: Created: latency-svc-xx9xh
Nov 26 12:05:52.804: INFO: Created: latency-svc-69j8z
Nov 26 12:05:52.807: INFO: Got endpoints: latency-svc-2xjfh [238.620088ms]
Nov 26 12:05:52.813: INFO: Created: latency-svc-9924s
Nov 26 12:05:52.822: INFO: Created: latency-svc-25rt8
Nov 26 12:05:52.829: INFO: Created: latency-svc-h8h29
Nov 26 12:05:52.839: INFO: Created: latency-svc-7fsdq
Nov 26 12:05:52.851: INFO: Created: latency-svc-4n9sc
Nov 26 12:05:52.858: INFO: Got endpoints: latency-svc-7fbw6 [274.33037ms]
Nov 26 12:05:52.863: INFO: Created: latency-svc-8bqcn
Nov 26 12:05:52.876: INFO: Created: latency-svc-7pzfl
Nov 26 12:05:52.880: INFO: Created: latency-svc-j8plc
Nov 26 12:05:52.889: INFO: Created: latency-svc-8hk7f
Nov 26 12:05:52.902: INFO: Got endpoints: latency-svc-xx9xh [300.485832ms]
Nov 26 12:05:52.910: INFO: Created: latency-svc-5jj7m
Nov 26 12:05:52.911: INFO: Created: latency-svc-4s6l5
Nov 26 12:05:52.922: INFO: Created: latency-svc-fq28m
Nov 26 12:05:52.928: INFO: Created: latency-svc-nl75f
Nov 26 12:05:52.935: INFO: Created: latency-svc-7fjrh
Nov 26 12:05:52.957: INFO: Got endpoints: latency-svc-69j8z [349.174027ms]
Nov 26 12:05:52.973: INFO: Created: latency-svc-p7zdw
Nov 26 12:05:53.005: INFO: Got endpoints: latency-svc-9924s [376.597887ms]
Nov 26 12:05:53.025: INFO: Created: latency-svc-bsb2v
Nov 26 12:05:53.060: INFO: Got endpoints: latency-svc-25rt8 [424.217538ms]
Nov 26 12:05:53.080: INFO: Created: latency-svc-7hmgs
Nov 26 12:05:53.108: INFO: Got endpoints: latency-svc-h8h29 [448.648888ms]
Nov 26 12:05:53.128: INFO: Created: latency-svc-c5lvx
Nov 26 12:05:53.154: INFO: Got endpoints: latency-svc-7fsdq [484.019274ms]
Nov 26 12:05:53.172: INFO: Created: latency-svc-cxr6v
Nov 26 12:05:53.205: INFO: Got endpoints: latency-svc-4n9sc [526.598148ms]
Nov 26 12:05:53.220: INFO: Created: latency-svc-mklhm
Nov 26 12:05:53.254: INFO: Got endpoints: latency-svc-8bqcn [556.129177ms]
Nov 26 12:05:53.270: INFO: Created: latency-svc-l5zqz
Nov 26 12:05:53.303: INFO: Got endpoints: latency-svc-7pzfl [586.338872ms]
Nov 26 12:05:53.319: INFO: Created: latency-svc-jsw7r
Nov 26 12:05:53.355: INFO: Got endpoints: latency-svc-j8plc [629.418158ms]
Nov 26 12:05:53.369: INFO: Created: latency-svc-rjdsd
Nov 26 12:05:53.404: INFO: Got endpoints: latency-svc-8hk7f [657.206577ms]
Nov 26 12:05:53.419: INFO: Created: latency-svc-x9tbw
Nov 26 12:05:53.457: INFO: Got endpoints: latency-svc-5jj7m [703.898686ms]
Nov 26 12:05:53.473: INFO: Created: latency-svc-2tz4w
Nov 26 12:05:53.508: INFO: Got endpoints: latency-svc-4s6l5 [734.423428ms]
Nov 26 12:05:53.530: INFO: Created: latency-svc-tlkz6
Nov 26 12:05:53.554: INFO: Got endpoints: latency-svc-fq28m [747.882753ms]
Nov 26 12:05:53.575: INFO: Created: latency-svc-kbzhq
Nov 26 12:05:53.603: INFO: Got endpoints: latency-svc-nl75f [745.079458ms]
Nov 26 12:05:53.619: INFO: Created: latency-svc-mtddt
Nov 26 12:05:53.659: INFO: Got endpoints: latency-svc-7fjrh [756.642898ms]
Nov 26 12:05:53.673: INFO: Created: latency-svc-nzkq9
Nov 26 12:05:53.705: INFO: Got endpoints: latency-svc-p7zdw [748.322195ms]
Nov 26 12:05:53.721: INFO: Created: latency-svc-rl9n6
Nov 26 12:05:53.756: INFO: Got endpoints: latency-svc-bsb2v [750.420193ms]
Nov 26 12:05:53.771: INFO: Created: latency-svc-hzm2p
Nov 26 12:05:53.807: INFO: Got endpoints: latency-svc-7hmgs [746.976493ms]
Nov 26 12:05:53.822: INFO: Created: latency-svc-m7wgm
Nov 26 12:05:53.855: INFO: Got endpoints: latency-svc-c5lvx [746.982994ms]
Nov 26 12:05:53.871: INFO: Created: latency-svc-lz8js
Nov 26 12:05:53.905: INFO: Got endpoints: latency-svc-cxr6v [751.192571ms]
Nov 26 12:05:53.924: INFO: Created: latency-svc-bmm9b
Nov 26 12:05:53.953: INFO: Got endpoints: latency-svc-mklhm [748.068018ms]
Nov 26 12:05:53.969: INFO: Created: latency-svc-9x7s9
Nov 26 12:05:54.004: INFO: Got endpoints: latency-svc-l5zqz [750.034594ms]
Nov 26 12:05:54.022: INFO: Created: latency-svc-44hzf
Nov 26 12:05:54.056: INFO: Got endpoints: latency-svc-jsw7r [753.207788ms]
Nov 26 12:05:54.073: INFO: Created: latency-svc-dglk2
Nov 26 12:05:54.103: INFO: Got endpoints: latency-svc-rjdsd [747.991566ms]
Nov 26 12:05:54.119: INFO: Created: latency-svc-rfr4d
Nov 26 12:05:54.155: INFO: Got endpoints: latency-svc-x9tbw [750.211108ms]
Nov 26 12:05:54.177: INFO: Created: latency-svc-zzb6x
Nov 26 12:05:54.207: INFO: Got endpoints: latency-svc-2tz4w [749.84214ms]
Nov 26 12:05:54.225: INFO: Created: latency-svc-vvx7l
Nov 26 12:05:54.253: INFO: Got endpoints: latency-svc-tlkz6 [744.540377ms]
Nov 26 12:05:54.268: INFO: Created: latency-svc-57s5c
Nov 26 12:05:54.307: INFO: Got endpoints: latency-svc-kbzhq [751.453019ms]
Nov 26 12:05:54.326: INFO: Created: latency-svc-gc2dd
Nov 26 12:05:54.356: INFO: Got endpoints: latency-svc-mtddt [752.547444ms]
Nov 26 12:05:54.372: INFO: Created: latency-svc-vpbsr
Nov 26 12:05:54.406: INFO: Got endpoints: latency-svc-nzkq9 [747.059916ms]
Nov 26 12:05:54.420: INFO: Created: latency-svc-78qf7
Nov 26 12:05:54.457: INFO: Got endpoints: latency-svc-rl9n6 [751.770237ms]
Nov 26 12:05:54.475: INFO: Created: latency-svc-mmtbm
Nov 26 12:05:54.505: INFO: Got endpoints: latency-svc-hzm2p [748.744096ms]
Nov 26 12:05:54.521: INFO: Created: latency-svc-vcdkx
Nov 26 12:05:54.564: INFO: Got endpoints: latency-svc-m7wgm [756.372255ms]
Nov 26 12:05:54.593: INFO: Created: latency-svc-mg85z
Nov 26 12:05:54.607: INFO: Got endpoints: latency-svc-lz8js [750.502788ms]
Nov 26 12:05:54.632: INFO: Created: latency-svc-6chwf
Nov 26 12:05:54.657: INFO: Got endpoints: latency-svc-bmm9b [751.254327ms]
Nov 26 12:05:54.693: INFO: Created: latency-svc-d8sx9
Nov 26 12:05:54.709: INFO: Got endpoints: latency-svc-9x7s9 [755.576378ms]
Nov 26 12:05:54.730: INFO: Created: latency-svc-tgm46
Nov 26 12:05:54.756: INFO: Got endpoints: latency-svc-44hzf [751.230737ms]
Nov 26 12:05:54.789: INFO: Created: latency-svc-bnbjh
Nov 26 12:05:54.804: INFO: Got endpoints: latency-svc-dglk2 [748.38189ms]
Nov 26 12:05:54.823: INFO: Created: latency-svc-nx5c6
Nov 26 12:05:54.854: INFO: Got endpoints: latency-svc-rfr4d [750.933269ms]
Nov 26 12:05:54.869: INFO: Created: latency-svc-d6htr
Nov 26 12:05:54.915: INFO: Got endpoints: latency-svc-zzb6x [760.37201ms]
Nov 26 12:05:54.935: INFO: Created: latency-svc-vdt4n
Nov 26 12:05:54.956: INFO: Got endpoints: latency-svc-vvx7l [749.20902ms]
Nov 26 12:05:54.990: INFO: Created: latency-svc-nhbrk
Nov 26 12:05:55.005: INFO: Got endpoints: latency-svc-57s5c [751.723698ms]
Nov 26 12:05:55.039: INFO: Created: latency-svc-cfths
Nov 26 12:05:55.056: INFO: Got endpoints: latency-svc-gc2dd [749.747973ms]
Nov 26 12:05:55.071: INFO: Created: latency-svc-q9zgd
Nov 26 12:05:55.111: INFO: Got endpoints: latency-svc-vpbsr [754.615377ms]
Nov 26 12:05:55.133: INFO: Created: latency-svc-zljzl
Nov 26 12:05:55.159: INFO: Got endpoints: latency-svc-78qf7 [752.982119ms]
Nov 26 12:05:55.176: INFO: Created: latency-svc-cpbvk
Nov 26 12:05:55.206: INFO: Got endpoints: latency-svc-mmtbm [748.285729ms]
Nov 26 12:05:55.237: INFO: Created: latency-svc-5ntx5
Nov 26 12:05:55.254: INFO: Got endpoints: latency-svc-vcdkx [748.671819ms]
Nov 26 12:05:55.271: INFO: Created: latency-svc-p7ntc
Nov 26 12:05:55.306: INFO: Got endpoints: latency-svc-mg85z [741.879481ms]
Nov 26 12:05:55.328: INFO: Created: latency-svc-rkvxb
Nov 26 12:05:55.353: INFO: Got endpoints: latency-svc-6chwf [746.1387ms]
Nov 26 12:05:55.371: INFO: Created: latency-svc-bhp5l
Nov 26 12:05:55.405: INFO: Got endpoints: latency-svc-d8sx9 [748.246819ms]
Nov 26 12:05:55.425: INFO: Created: latency-svc-r6pwt
Nov 26 12:05:55.454: INFO: Got endpoints: latency-svc-tgm46 [744.877881ms]
Nov 26 12:05:55.472: INFO: Created: latency-svc-xxjq6
Nov 26 12:05:55.504: INFO: Got endpoints: latency-svc-bnbjh [748.414884ms]
Nov 26 12:05:55.518: INFO: Created: latency-svc-w4sn2
Nov 26 12:05:55.555: INFO: Got endpoints: latency-svc-nx5c6 [750.112994ms]
Nov 26 12:05:55.569: INFO: Created: latency-svc-jskxp
Nov 26 12:05:55.605: INFO: Got endpoints: latency-svc-d6htr [751.272961ms]
Nov 26 12:05:55.621: INFO: Created: latency-svc-k2pjq
Nov 26 12:05:55.658: INFO: Got endpoints: latency-svc-vdt4n [742.870786ms]
Nov 26 12:05:55.674: INFO: Created: latency-svc-gm958
Nov 26 12:05:55.706: INFO: Got endpoints: latency-svc-nhbrk [749.338957ms]
Nov 26 12:05:55.720: INFO: Created: latency-svc-zfx7j
Nov 26 12:05:55.755: INFO: Got endpoints: latency-svc-cfths [750.369281ms]
Nov 26 12:05:55.770: INFO: Created: latency-svc-grjvf
Nov 26 12:05:55.807: INFO: Got endpoints: latency-svc-q9zgd [750.404771ms]
Nov 26 12:05:55.827: INFO: Created: latency-svc-5qxhb
Nov 26 12:05:55.856: INFO: Got endpoints: latency-svc-zljzl [744.997385ms]
Nov 26 12:05:55.869: INFO: Created: latency-svc-2psqd
Nov 26 12:05:56.031: INFO: Got endpoints: latency-svc-cpbvk [871.924189ms]
Nov 26 12:05:56.039: INFO: Got endpoints: latency-svc-p7ntc [785.01091ms]
Nov 26 12:05:56.039: INFO: Got endpoints: latency-svc-5ntx5 [833.397649ms]
Nov 26 12:05:56.052: INFO: Created: latency-svc-9gvq2
Nov 26 12:05:56.053: INFO: Got endpoints: latency-svc-rkvxb [746.704646ms]
Nov 26 12:05:56.065: INFO: Created: latency-svc-gtrtf
Nov 26 12:05:56.071: INFO: Created: latency-svc-q6gf8
Nov 26 12:05:56.080: INFO: Created: latency-svc-dgmr8
Nov 26 12:05:56.110: INFO: Got endpoints: latency-svc-bhp5l [756.806332ms]
Nov 26 12:05:56.128: INFO: Created: latency-svc-vhd5p
Nov 26 12:05:56.158: INFO: Got endpoints: latency-svc-r6pwt [752.766008ms]
Nov 26 12:05:56.180: INFO: Created: latency-svc-hgthx
Nov 26 12:05:56.208: INFO: Got endpoints: latency-svc-xxjq6 [753.709851ms]
Nov 26 12:05:56.225: INFO: Created: latency-svc-qk855
Nov 26 12:05:56.254: INFO: Got endpoints: latency-svc-w4sn2 [749.975824ms]
Nov 26 12:05:56.269: INFO: Created: latency-svc-q656x
Nov 26 12:05:56.304: INFO: Got endpoints: latency-svc-jskxp [749.853561ms]
Nov 26 12:05:56.320: INFO: Created: latency-svc-sbjlb
Nov 26 12:05:56.356: INFO: Got endpoints: latency-svc-k2pjq [750.928296ms]
Nov 26 12:05:56.372: INFO: Created: latency-svc-b7mdq
Nov 26 12:05:56.405: INFO: Got endpoints: latency-svc-gm958 [747.27422ms]
Nov 26 12:05:56.423: INFO: Created: latency-svc-rb8np
Nov 26 12:05:56.454: INFO: Got endpoints: latency-svc-zfx7j [748.642193ms]
Nov 26 12:05:56.472: INFO: Created: latency-svc-pzcbb
Nov 26 12:05:56.504: INFO: Got endpoints: latency-svc-grjvf [747.915836ms]
Nov 26 12:05:56.519: INFO: Created: latency-svc-5mbck
Nov 26 12:05:56.554: INFO: Got endpoints: latency-svc-5qxhb [746.730509ms]
Nov 26 12:05:56.571: INFO: Created: latency-svc-4755v
Nov 26 12:05:56.603: INFO: Got endpoints: latency-svc-2psqd [746.633137ms]
Nov 26 12:05:56.619: INFO: Created: latency-svc-mn5m7
Nov 26 12:05:56.654: INFO: Got endpoints: latency-svc-9gvq2 [622.892258ms]
Nov 26 12:05:56.673: INFO: Created: latency-svc-ns8rc
Nov 26 12:05:56.703: INFO: Got endpoints: latency-svc-gtrtf [663.823534ms]
Nov 26 12:05:56.721: INFO: Created: latency-svc-n2fth
Nov 26 12:05:56.755: INFO: Got endpoints: latency-svc-q6gf8 [716.199278ms]
Nov 26 12:05:56.770: INFO: Created: latency-svc-4wwtw
Nov 26 12:05:56.807: INFO: Got endpoints: latency-svc-dgmr8 [754.804569ms]
Nov 26 12:05:56.820: INFO: Created: latency-svc-4v7mp
Nov 26 12:05:56.855: INFO: Got endpoints: latency-svc-vhd5p [744.372775ms]
Nov 26 12:05:56.871: INFO: Created: latency-svc-kqbmb
Nov 26 12:05:56.904: INFO: Got endpoints: latency-svc-hgthx [745.476581ms]
Nov 26 12:05:56.918: INFO: Created: latency-svc-72k2s
Nov 26 12:05:56.954: INFO: Got endpoints: latency-svc-qk855 [745.710626ms]
Nov 26 12:05:56.973: INFO: Created: latency-svc-7j58r
Nov 26 12:05:57.005: INFO: Got endpoints: latency-svc-q656x [750.428466ms]
Nov 26 12:05:57.021: INFO: Created: latency-svc-c7sjj
Nov 26 12:05:57.055: INFO: Got endpoints: latency-svc-sbjlb [750.797455ms]
Nov 26 12:05:57.070: INFO: Created: latency-svc-mm9vt
Nov 26 12:05:57.106: INFO: Got endpoints: latency-svc-b7mdq [749.29479ms]
Nov 26 12:05:57.126: INFO: Created: latency-svc-5k68z
Nov 26 12:05:57.156: INFO: Got endpoints: latency-svc-rb8np [750.809156ms]
Nov 26 12:05:57.173: INFO: Created: latency-svc-snrth
Nov 26 12:05:57.206: INFO: Got endpoints: latency-svc-pzcbb [750.987031ms]
Nov 26 12:05:57.223: INFO: Created: latency-svc-p67tr
Nov 26 12:05:57.257: INFO: Got endpoints: latency-svc-5mbck [753.434288ms]
Nov 26 12:05:57.274: INFO: Created: latency-svc-m8hgx
Nov 26 12:05:57.308: INFO: Got endpoints: latency-svc-4755v [754.178505ms]
Nov 26 12:05:57.321: INFO: Created: latency-svc-5jghj
Nov 26 12:05:57.354: INFO: Got endpoints: latency-svc-mn5m7 [751.727859ms]
Nov 26 12:05:57.371: INFO: Created: latency-svc-56t9v
Nov 26 12:05:57.403: INFO: Got endpoints: latency-svc-ns8rc [748.641757ms]
Nov 26 12:05:57.421: INFO: Created: latency-svc-h6sw4
Nov 26 12:05:57.453: INFO: Got endpoints: latency-svc-n2fth [750.116022ms]
Nov 26 12:05:57.467: INFO: Created: latency-svc-xb7fd
Nov 26 12:05:57.506: INFO: Got endpoints: latency-svc-4wwtw [750.785567ms]
Nov 26 12:05:57.527: INFO: Created: latency-svc-wpv49
Nov 26 12:05:57.559: INFO: Got endpoints: latency-svc-4v7mp [751.455664ms]
Nov 26 12:05:57.583: INFO: Created: latency-svc-fh4hf
Nov 26 12:05:57.607: INFO: Got endpoints: latency-svc-kqbmb [751.580756ms]
Nov 26 12:05:57.624: INFO: Created: latency-svc-z296v
Nov 26 12:05:57.657: INFO: Got endpoints: latency-svc-72k2s [752.920539ms]
Nov 26 12:05:57.672: INFO: Created: latency-svc-xln7r
Nov 26 12:05:57.710: INFO: Got endpoints: latency-svc-7j58r [756.612435ms]
Nov 26 12:05:57.728: INFO: Created: latency-svc-q5tps
Nov 26 12:05:57.753: INFO: Got endpoints: latency-svc-c7sjj [747.923942ms]
Nov 26 12:05:57.771: INFO: Created: latency-svc-8894c
Nov 26 12:05:57.804: INFO: Got endpoints: latency-svc-mm9vt [748.610529ms]
Nov 26 12:05:57.821: INFO: Created: latency-svc-4dxnh
Nov 26 12:05:57.863: INFO: Got endpoints: latency-svc-5k68z [757.24071ms]
Nov 26 12:05:57.877: INFO: Created: latency-svc-2pmts
Nov 26 12:05:57.906: INFO: Got endpoints: latency-svc-snrth [749.513089ms]
Nov 26 12:05:57.919: INFO: Created: latency-svc-mb4m8
Nov 26 12:05:57.954: INFO: Got endpoints: latency-svc-p67tr [748.139038ms]
Nov 26 12:05:57.970: INFO: Created: latency-svc-k6z8j
Nov 26 12:05:58.005: INFO: Got endpoints: latency-svc-m8hgx [747.524043ms]
Nov 26 12:05:58.023: INFO: Created: latency-svc-zm47p
Nov 26 12:05:58.056: INFO: Got endpoints: latency-svc-5jghj [747.986724ms]
Nov 26 12:05:58.071: INFO: Created: latency-svc-4hj4k
Nov 26 12:05:58.111: INFO: Got endpoints: latency-svc-56t9v [756.236187ms]
Nov 26 12:05:58.131: INFO: Created: latency-svc-qznd6
Nov 26 12:05:58.154: INFO: Got endpoints: latency-svc-h6sw4 [750.240068ms]
Nov 26 12:05:58.171: INFO: Created: latency-svc-jdfpx
Nov 26 12:05:58.206: INFO: Got endpoints: latency-svc-xb7fd [752.386367ms]
Nov 26 12:05:58.227: INFO: Created: latency-svc-7jfc2
Nov 26 12:05:58.256: INFO: Got endpoints: latency-svc-wpv49 [749.48984ms]
Nov 26 12:05:58.270: INFO: Created: latency-svc-62tct
Nov 26 12:05:58.306: INFO: Got endpoints: latency-svc-fh4hf [746.549842ms]
Nov 26 12:05:58.322: INFO: Created: latency-svc-7twwz
Nov 26 12:05:58.354: INFO: Got endpoints: latency-svc-z296v [746.848679ms]
Nov 26 12:05:58.366: INFO: Created: latency-svc-2mzfr
Nov 26 12:05:58.408: INFO: Got endpoints: latency-svc-xln7r [750.870813ms]
Nov 26 12:05:58.424: INFO: Created: latency-svc-rccs6
Nov 26 12:05:58.453: INFO: Got endpoints: latency-svc-q5tps [742.005687ms]
Nov 26 12:05:58.472: INFO: Created: latency-svc-rjrm8
Nov 26 12:05:58.504: INFO: Got endpoints: latency-svc-8894c [751.541949ms]
Nov 26 12:05:58.518: INFO: Created: latency-svc-8kw62
Nov 26 12:05:58.557: INFO: Got endpoints: latency-svc-4dxnh [752.489042ms]
Nov 26 12:05:58.573: INFO: Created: latency-svc-vxc69
Nov 26 12:05:58.606: INFO: Got endpoints: latency-svc-2pmts [742.921499ms]
Nov 26 12:05:58.623: INFO: Created: latency-svc-mvh96
Nov 26 12:05:58.655: INFO: Got endpoints: latency-svc-mb4m8 [748.882079ms]
Nov 26 12:05:58.674: INFO: Created: latency-svc-c42dt
Nov 26 12:05:58.705: INFO: Got endpoints: latency-svc-k6z8j [750.635369ms]
Nov 26 12:05:58.723: INFO: Created: latency-svc-9b95m
Nov 26 12:05:58.759: INFO: Got endpoints: latency-svc-zm47p [753.259741ms]
Nov 26 12:05:58.774: INFO: Created: latency-svc-dftrp
Nov 26 12:05:58.803: INFO: Got endpoints: latency-svc-4hj4k [747.471646ms]
Nov 26 12:05:58.816: INFO: Created: latency-svc-c7thd
Nov 26 12:05:58.856: INFO: Got endpoints: latency-svc-qznd6 [745.405977ms]
Nov 26 12:05:58.873: INFO: Created: latency-svc-ppp8w
Nov 26 12:05:58.904: INFO: Got endpoints: latency-svc-jdfpx [750.175929ms]
Nov 26 12:05:58.920: INFO: Created: latency-svc-9lnwb
Nov 26 12:05:58.954: INFO: Got endpoints: latency-svc-7jfc2 [747.731222ms]
Nov 26 12:05:58.970: INFO: Created: latency-svc-zg78c
Nov 26 12:05:59.004: INFO: Got endpoints: latency-svc-62tct [748.173263ms]
Nov 26 12:05:59.020: INFO: Created: latency-svc-gq749
Nov 26 12:05:59.055: INFO: Got endpoints: latency-svc-7twwz [748.973232ms]
Nov 26 12:05:59.068: INFO: Created: latency-svc-99tqj
Nov 26 12:05:59.107: INFO: Got endpoints: latency-svc-2mzfr [752.636178ms]
Nov 26 12:05:59.122: INFO: Created: latency-svc-tg25d
Nov 26 12:05:59.155: INFO: Got endpoints: latency-svc-rccs6 [746.473563ms]
Nov 26 12:05:59.180: INFO: Created: latency-svc-kr7tw
Nov 26 12:05:59.204: INFO: Got endpoints: latency-svc-rjrm8 [751.244385ms]
Nov 26 12:05:59.223: INFO: Created: latency-svc-l7sg2
Nov 26 12:05:59.255: INFO: Got endpoints: latency-svc-8kw62 [750.15514ms]
Nov 26 12:05:59.268: INFO: Created: latency-svc-hstkt
Nov 26 12:05:59.308: INFO: Got endpoints: latency-svc-vxc69 [750.509359ms]
Nov 26 12:05:59.325: INFO: Created: latency-svc-6khtj
Nov 26 12:05:59.356: INFO: Got endpoints: latency-svc-mvh96 [750.171001ms]
Nov 26 12:05:59.373: INFO: Created: latency-svc-zb2xb
Nov 26 12:05:59.403: INFO: Got endpoints: latency-svc-c42dt [747.454027ms]
Nov 26 12:05:59.419: INFO: Created: latency-svc-vz9f9
Nov 26 12:05:59.453: INFO: Got endpoints: latency-svc-9b95m [747.879338ms]
Nov 26 12:05:59.473: INFO: Created: latency-svc-znsr6
Nov 26 12:05:59.507: INFO: Got endpoints: latency-svc-dftrp [747.369816ms]
Nov 26 12:05:59.524: INFO: Created: latency-svc-9wbkf
Nov 26 12:05:59.558: INFO: Got endpoints: latency-svc-c7thd [754.544184ms]
Nov 26 12:05:59.571: INFO: Created: latency-svc-wrbrm
Nov 26 12:05:59.603: INFO: Got endpoints: latency-svc-ppp8w [746.23168ms]
Nov 26 12:05:59.621: INFO: Created: latency-svc-bt6gx
Nov 26 12:05:59.655: INFO: Got endpoints: latency-svc-9lnwb [750.327527ms]
Nov 26 12:05:59.672: INFO: Created: latency-svc-pv8q4
Nov 26 12:05:59.703: INFO: Got endpoints: latency-svc-zg78c [748.956735ms]
Nov 26 12:05:59.717: INFO: Created: latency-svc-dqxh2
Nov 26 12:05:59.757: INFO: Got endpoints: latency-svc-gq749 [752.846606ms]
Nov 26 12:05:59.774: INFO: Created: latency-svc-578sq
Nov 26 12:05:59.807: INFO: Got endpoints: latency-svc-99tqj [752.407396ms]
Nov 26 12:05:59.822: INFO: Created: latency-svc-mxjfx
Nov 26 12:05:59.856: INFO: Got endpoints: latency-svc-tg25d [749.15601ms]
Nov 26 12:05:59.869: INFO: Created: latency-svc-5hf2x
Nov 26 12:05:59.903: INFO: Got endpoints: latency-svc-kr7tw [747.723316ms]
Nov 26 12:05:59.922: INFO: Created: latency-svc-xb662
Nov 26 12:05:59.954: INFO: Got endpoints: latency-svc-l7sg2 [749.215971ms]
Nov 26 12:06:00.007: INFO: Got endpoints: latency-svc-hstkt [751.860273ms]
Nov 26 12:06:00.055: INFO: Got endpoints: latency-svc-6khtj [747.060991ms]
Nov 26 12:06:00.107: INFO: Got endpoints: latency-svc-zb2xb [751.006814ms]
Nov 26 12:06:00.160: INFO: Got endpoints: latency-svc-vz9f9 [757.167768ms]
Nov 26 12:06:00.207: INFO: Got endpoints: latency-svc-znsr6 [754.848914ms]
Nov 26 12:06:00.254: INFO: Got endpoints: latency-svc-9wbkf [747.345139ms]
Nov 26 12:06:00.306: INFO: Got endpoints: latency-svc-wrbrm [747.949433ms]
Nov 26 12:06:00.353: INFO: Got endpoints: latency-svc-bt6gx [750.599696ms]
Nov 26 12:06:00.404: INFO: Got endpoints: latency-svc-pv8q4 [748.980148ms]
Nov 26 12:06:00.459: INFO: Got endpoints: latency-svc-dqxh2 [755.845378ms]
Nov 26 12:06:00.504: INFO: Got endpoints: latency-svc-578sq [747.515184ms]
Nov 26 12:06:00.557: INFO: Got endpoints: latency-svc-mxjfx [749.988452ms]
Nov 26 12:06:00.603: INFO: Got endpoints: latency-svc-5hf2x [747.126096ms]
Nov 26 12:06:00.657: INFO: Got endpoints: latency-svc-xb662 [753.898844ms]
Nov 26 12:06:00.657: INFO: Latencies: [40.990007ms 64.208098ms 67.647378ms 89.888937ms 98.213372ms 103.074276ms 106.913325ms 119.686792ms 121.582567ms 123.763558ms 125.294384ms 131.509308ms 137.173351ms 137.174691ms 138.42554ms 143.368496ms 158.329644ms 160.662389ms 165.334217ms 170.659263ms 172.334871ms 178.304691ms 180.052661ms 183.235056ms 190.540606ms 208.624917ms 219.181524ms 221.244732ms 229.525165ms 238.620088ms 249.710666ms 274.33037ms 279.696266ms 282.329948ms 288.86388ms 299.498608ms 300.485832ms 309.308367ms 320.057718ms 323.336535ms 346.73314ms 349.174027ms 349.635408ms 350.078039ms 352.666278ms 376.597887ms 420.787148ms 424.217538ms 448.648888ms 484.019274ms 526.598148ms 556.129177ms 586.338872ms 622.892258ms 629.418158ms 657.206577ms 663.823534ms 703.898686ms 716.199278ms 734.423428ms 741.879481ms 742.005687ms 742.870786ms 742.921499ms 744.372775ms 744.540377ms 744.877881ms 744.997385ms 745.079458ms 745.405977ms 745.476581ms 745.710626ms 746.1387ms 746.23168ms 746.473563ms 746.549842ms 746.633137ms 746.704646ms 746.730509ms 746.848679ms 746.976493ms 746.982994ms 747.059916ms 747.060991ms 747.126096ms 747.27422ms 747.345139ms 747.369816ms 747.454027ms 747.471646ms 747.515184ms 747.524043ms 747.723316ms 747.731222ms 747.879338ms 747.882753ms 747.915836ms 747.923942ms 747.949433ms 747.986724ms 747.991566ms 748.068018ms 748.139038ms 748.173263ms 748.246819ms 748.285729ms 748.322195ms 748.38189ms 748.414884ms 748.610529ms 748.641757ms 748.642193ms 748.671819ms 748.744096ms 748.882079ms 748.956735ms 748.973232ms 748.980148ms 749.15601ms 749.20902ms 749.215971ms 749.29479ms 749.338957ms 749.48984ms 749.513089ms 749.747973ms 749.84214ms 749.853561ms 749.975824ms 749.988452ms 750.034594ms 750.112994ms 750.116022ms 750.15514ms 750.171001ms 750.175929ms 750.211108ms 750.240068ms 750.327527ms 750.369281ms 750.404771ms 750.420193ms 750.428466ms 750.502788ms 750.509359ms 750.599696ms 750.635369ms 750.785567ms 750.797455ms 750.809156ms 750.870813ms 750.928296ms 750.933269ms 750.987031ms 751.006814ms 751.192571ms 751.230737ms 751.244385ms 751.254327ms 751.272961ms 751.453019ms 751.455664ms 751.541949ms 751.580756ms 751.723698ms 751.727859ms 751.770237ms 751.860273ms 752.386367ms 752.407396ms 752.489042ms 752.547444ms 752.636178ms 752.766008ms 752.846606ms 752.920539ms 752.982119ms 753.207788ms 753.259741ms 753.434288ms 753.709851ms 753.898844ms 754.178505ms 754.544184ms 754.615377ms 754.804569ms 754.848914ms 755.576378ms 755.845378ms 756.236187ms 756.372255ms 756.612435ms 756.642898ms 756.806332ms 757.167768ms 757.24071ms 760.37201ms 785.01091ms 833.397649ms 871.924189ms]
Nov 26 12:06:00.657: INFO: 50 %ile: 747.991566ms
Nov 26 12:06:00.657: INFO: 90 %ile: 753.709851ms
Nov 26 12:06:00.657: INFO: 99 %ile: 833.397649ms
Nov 26 12:06:00.657: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Nov 26 12:06:00.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8144" for this suite. 11/26/22 12:06:00.665
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":58,"skipped":1011,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.801 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:05:49.875
    Nov 26 12:05:49.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename svc-latency 11/26/22 12:05:49.876
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:05:49.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:05:49.909
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Nov 26 12:05:49.914: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-8144 11/26/22 12:05:49.915
    I1126 12:05:49.928150      19 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8144, replica count: 1
    I1126 12:05:50.978655      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1126 12:05:51.979419      19 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 12:05:52.094: INFO: Created: latency-svc-vlk46
    Nov 26 12:05:52.110: INFO: Got endpoints: latency-svc-vlk46 [30.496431ms]
    Nov 26 12:05:52.144: INFO: Created: latency-svc-pcl8k
    Nov 26 12:05:52.152: INFO: Got endpoints: latency-svc-pcl8k [40.990007ms]
    Nov 26 12:05:52.158: INFO: Created: latency-svc-rw6b8
    Nov 26 12:05:52.172: INFO: Created: latency-svc-dtws9
    Nov 26 12:05:52.176: INFO: Got endpoints: latency-svc-rw6b8 [64.208098ms]
    Nov 26 12:05:52.178: INFO: Got endpoints: latency-svc-dtws9 [67.647378ms]
    Nov 26 12:05:52.197: INFO: Created: latency-svc-hdq87
    Nov 26 12:05:52.219: INFO: Got endpoints: latency-svc-hdq87 [106.913325ms]
    Nov 26 12:05:52.222: INFO: Created: latency-svc-7f7nw
    Nov 26 12:05:52.229: INFO: Created: latency-svc-cklwg
    Nov 26 12:05:52.236: INFO: Got endpoints: latency-svc-7f7nw [123.763558ms]
    Nov 26 12:05:52.250: INFO: Got endpoints: latency-svc-cklwg [138.42554ms]
    Nov 26 12:05:52.253: INFO: Created: latency-svc-7lnxm
    Nov 26 12:05:52.270: INFO: Got endpoints: latency-svc-7lnxm [158.329644ms]
    Nov 26 12:05:52.276: INFO: Created: latency-svc-mfhf8
    Nov 26 12:05:52.284: INFO: Got endpoints: latency-svc-mfhf8 [172.334871ms]
    Nov 26 12:05:52.380: INFO: Created: latency-svc-v8pjv
    Nov 26 12:05:52.391: INFO: Created: latency-svc-zhc62
    Nov 26 12:05:52.402: INFO: Got endpoints: latency-svc-v8pjv [288.86388ms]
    Nov 26 12:05:52.407: INFO: Created: latency-svc-j9lst
    Nov 26 12:05:52.407: INFO: Created: latency-svc-tztp4
    Nov 26 12:05:52.412: INFO: Created: latency-svc-vh2k7
    Nov 26 12:05:52.412: INFO: Created: latency-svc-fd7js
    Nov 26 12:05:52.412: INFO: Created: latency-svc-9vfnh
    Nov 26 12:05:52.413: INFO: Got endpoints: latency-svc-9vfnh [299.498608ms]
    Nov 26 12:05:52.412: INFO: Created: latency-svc-lk7vw
    Nov 26 12:05:52.412: INFO: Created: latency-svc-794sb
    Nov 26 12:05:52.413: INFO: Created: latency-svc-zxlvj
    Nov 26 12:05:52.415: INFO: Created: latency-svc-gdzdx
    Nov 26 12:05:52.415: INFO: Created: latency-svc-qcdqb
    Nov 26 12:05:52.415: INFO: Created: latency-svc-q4xbf
    Nov 26 12:05:52.418: INFO: Created: latency-svc-wbzk8
    Nov 26 12:05:52.419: INFO: Created: latency-svc-vwtkg
    Nov 26 12:05:52.436: INFO: Got endpoints: latency-svc-vh2k7 [323.336535ms]
    Nov 26 12:05:52.461: INFO: Created: latency-svc-xm5qx
    Nov 26 12:05:52.462: INFO: Got endpoints: latency-svc-qcdqb [349.635408ms]
    Nov 26 12:05:52.464: INFO: Got endpoints: latency-svc-tztp4 [350.078039ms]
    Nov 26 12:05:52.464: INFO: Got endpoints: latency-svc-zxlvj [180.052661ms]
    Nov 26 12:05:52.464: INFO: Got endpoints: latency-svc-j9lst [352.666278ms]
    Nov 26 12:05:52.485: INFO: Got endpoints: latency-svc-vwtkg [309.308367ms]
    Nov 26 12:05:52.486: INFO: Got endpoints: latency-svc-zhc62 [249.710666ms]
    Nov 26 12:05:52.490: INFO: Created: latency-svc-ksptm
    Nov 26 12:05:52.498: INFO: Got endpoints: latency-svc-lk7vw [320.057718ms]
    Nov 26 12:05:52.499: INFO: Got endpoints: latency-svc-gdzdx [346.73314ms]
    Nov 26 12:05:52.499: INFO: Got endpoints: latency-svc-fd7js [279.696266ms]
    Nov 26 12:05:52.500: INFO: Got endpoints: latency-svc-794sb [229.525165ms]
    Nov 26 12:05:52.513: INFO: Created: latency-svc-tdn68
    Nov 26 12:05:52.532: INFO: Got endpoints: latency-svc-wbzk8 [282.329948ms]
    Nov 26 12:05:52.533: INFO: Got endpoints: latency-svc-q4xbf [420.787148ms]
    Nov 26 12:05:52.534: INFO: Got endpoints: latency-svc-xm5qx [131.509308ms]
    Nov 26 12:05:52.534: INFO: Got endpoints: latency-svc-tdn68 [98.213372ms]
    Nov 26 12:05:52.538: INFO: Got endpoints: latency-svc-ksptm [125.294384ms]
    Nov 26 12:05:52.542: INFO: Created: latency-svc-plbnz
    Nov 26 12:05:52.552: INFO: Got endpoints: latency-svc-plbnz [89.888937ms]
    Nov 26 12:05:52.561: INFO: Created: latency-svc-4dmz9
    Nov 26 12:05:52.568: INFO: Got endpoints: latency-svc-4dmz9 [103.074276ms]
    Nov 26 12:05:52.574: INFO: Created: latency-svc-2br78
    Nov 26 12:05:52.583: INFO: Got endpoints: latency-svc-2br78 [119.686792ms]
    Nov 26 12:05:52.584: INFO: Created: latency-svc-226lq
    Nov 26 12:05:52.596: INFO: Created: latency-svc-64l8v
    Nov 26 12:05:52.601: INFO: Got endpoints: latency-svc-226lq [137.173351ms]
    Nov 26 12:05:52.607: INFO: Got endpoints: latency-svc-64l8v [121.582567ms]
    Nov 26 12:05:52.615: INFO: Created: latency-svc-lk86c
    Nov 26 12:05:52.626: INFO: Created: latency-svc-b5vhc
    Nov 26 12:05:52.629: INFO: Got endpoints: latency-svc-lk86c [143.368496ms]
    Nov 26 12:05:52.636: INFO: Got endpoints: latency-svc-b5vhc [137.174691ms]
    Nov 26 12:05:52.649: INFO: Created: latency-svc-klzzx
    Nov 26 12:05:52.658: INFO: Created: latency-svc-v4nqc
    Nov 26 12:05:52.660: INFO: Got endpoints: latency-svc-klzzx [160.662389ms]
    Nov 26 12:05:52.667: INFO: Created: latency-svc-js4b6
    Nov 26 12:05:52.670: INFO: Got endpoints: latency-svc-v4nqc [170.659263ms]
    Nov 26 12:05:52.678: INFO: Got endpoints: latency-svc-js4b6 [178.304691ms]
    Nov 26 12:05:52.689: INFO: Created: latency-svc-bp5lg
    Nov 26 12:05:52.697: INFO: Got endpoints: latency-svc-bp5lg [165.334217ms]
    Nov 26 12:05:52.705: INFO: Created: latency-svc-dr7kq
    Nov 26 12:05:52.715: INFO: Created: latency-svc-b9wlg
    Nov 26 12:05:52.716: INFO: Got endpoints: latency-svc-dr7kq [183.235056ms]
    Nov 26 12:05:52.725: INFO: Got endpoints: latency-svc-b9wlg [190.540606ms]
    Nov 26 12:05:52.730: INFO: Created: latency-svc-b75wj
    Nov 26 12:05:52.742: INFO: Created: latency-svc-c92lr
    Nov 26 12:05:52.747: INFO: Got endpoints: latency-svc-b75wj [208.624917ms]
    Nov 26 12:05:52.753: INFO: Got endpoints: latency-svc-c92lr [219.181524ms]
    Nov 26 12:05:52.763: INFO: Created: latency-svc-xpsv4
    Nov 26 12:05:52.774: INFO: Got endpoints: latency-svc-xpsv4 [221.244732ms]
    Nov 26 12:05:52.777: INFO: Created: latency-svc-2xjfh
    Nov 26 12:05:52.787: INFO: Created: latency-svc-7fbw6
    Nov 26 12:05:52.793: INFO: Created: latency-svc-xx9xh
    Nov 26 12:05:52.804: INFO: Created: latency-svc-69j8z
    Nov 26 12:05:52.807: INFO: Got endpoints: latency-svc-2xjfh [238.620088ms]
    Nov 26 12:05:52.813: INFO: Created: latency-svc-9924s
    Nov 26 12:05:52.822: INFO: Created: latency-svc-25rt8
    Nov 26 12:05:52.829: INFO: Created: latency-svc-h8h29
    Nov 26 12:05:52.839: INFO: Created: latency-svc-7fsdq
    Nov 26 12:05:52.851: INFO: Created: latency-svc-4n9sc
    Nov 26 12:05:52.858: INFO: Got endpoints: latency-svc-7fbw6 [274.33037ms]
    Nov 26 12:05:52.863: INFO: Created: latency-svc-8bqcn
    Nov 26 12:05:52.876: INFO: Created: latency-svc-7pzfl
    Nov 26 12:05:52.880: INFO: Created: latency-svc-j8plc
    Nov 26 12:05:52.889: INFO: Created: latency-svc-8hk7f
    Nov 26 12:05:52.902: INFO: Got endpoints: latency-svc-xx9xh [300.485832ms]
    Nov 26 12:05:52.910: INFO: Created: latency-svc-5jj7m
    Nov 26 12:05:52.911: INFO: Created: latency-svc-4s6l5
    Nov 26 12:05:52.922: INFO: Created: latency-svc-fq28m
    Nov 26 12:05:52.928: INFO: Created: latency-svc-nl75f
    Nov 26 12:05:52.935: INFO: Created: latency-svc-7fjrh
    Nov 26 12:05:52.957: INFO: Got endpoints: latency-svc-69j8z [349.174027ms]
    Nov 26 12:05:52.973: INFO: Created: latency-svc-p7zdw
    Nov 26 12:05:53.005: INFO: Got endpoints: latency-svc-9924s [376.597887ms]
    Nov 26 12:05:53.025: INFO: Created: latency-svc-bsb2v
    Nov 26 12:05:53.060: INFO: Got endpoints: latency-svc-25rt8 [424.217538ms]
    Nov 26 12:05:53.080: INFO: Created: latency-svc-7hmgs
    Nov 26 12:05:53.108: INFO: Got endpoints: latency-svc-h8h29 [448.648888ms]
    Nov 26 12:05:53.128: INFO: Created: latency-svc-c5lvx
    Nov 26 12:05:53.154: INFO: Got endpoints: latency-svc-7fsdq [484.019274ms]
    Nov 26 12:05:53.172: INFO: Created: latency-svc-cxr6v
    Nov 26 12:05:53.205: INFO: Got endpoints: latency-svc-4n9sc [526.598148ms]
    Nov 26 12:05:53.220: INFO: Created: latency-svc-mklhm
    Nov 26 12:05:53.254: INFO: Got endpoints: latency-svc-8bqcn [556.129177ms]
    Nov 26 12:05:53.270: INFO: Created: latency-svc-l5zqz
    Nov 26 12:05:53.303: INFO: Got endpoints: latency-svc-7pzfl [586.338872ms]
    Nov 26 12:05:53.319: INFO: Created: latency-svc-jsw7r
    Nov 26 12:05:53.355: INFO: Got endpoints: latency-svc-j8plc [629.418158ms]
    Nov 26 12:05:53.369: INFO: Created: latency-svc-rjdsd
    Nov 26 12:05:53.404: INFO: Got endpoints: latency-svc-8hk7f [657.206577ms]
    Nov 26 12:05:53.419: INFO: Created: latency-svc-x9tbw
    Nov 26 12:05:53.457: INFO: Got endpoints: latency-svc-5jj7m [703.898686ms]
    Nov 26 12:05:53.473: INFO: Created: latency-svc-2tz4w
    Nov 26 12:05:53.508: INFO: Got endpoints: latency-svc-4s6l5 [734.423428ms]
    Nov 26 12:05:53.530: INFO: Created: latency-svc-tlkz6
    Nov 26 12:05:53.554: INFO: Got endpoints: latency-svc-fq28m [747.882753ms]
    Nov 26 12:05:53.575: INFO: Created: latency-svc-kbzhq
    Nov 26 12:05:53.603: INFO: Got endpoints: latency-svc-nl75f [745.079458ms]
    Nov 26 12:05:53.619: INFO: Created: latency-svc-mtddt
    Nov 26 12:05:53.659: INFO: Got endpoints: latency-svc-7fjrh [756.642898ms]
    Nov 26 12:05:53.673: INFO: Created: latency-svc-nzkq9
    Nov 26 12:05:53.705: INFO: Got endpoints: latency-svc-p7zdw [748.322195ms]
    Nov 26 12:05:53.721: INFO: Created: latency-svc-rl9n6
    Nov 26 12:05:53.756: INFO: Got endpoints: latency-svc-bsb2v [750.420193ms]
    Nov 26 12:05:53.771: INFO: Created: latency-svc-hzm2p
    Nov 26 12:05:53.807: INFO: Got endpoints: latency-svc-7hmgs [746.976493ms]
    Nov 26 12:05:53.822: INFO: Created: latency-svc-m7wgm
    Nov 26 12:05:53.855: INFO: Got endpoints: latency-svc-c5lvx [746.982994ms]
    Nov 26 12:05:53.871: INFO: Created: latency-svc-lz8js
    Nov 26 12:05:53.905: INFO: Got endpoints: latency-svc-cxr6v [751.192571ms]
    Nov 26 12:05:53.924: INFO: Created: latency-svc-bmm9b
    Nov 26 12:05:53.953: INFO: Got endpoints: latency-svc-mklhm [748.068018ms]
    Nov 26 12:05:53.969: INFO: Created: latency-svc-9x7s9
    Nov 26 12:05:54.004: INFO: Got endpoints: latency-svc-l5zqz [750.034594ms]
    Nov 26 12:05:54.022: INFO: Created: latency-svc-44hzf
    Nov 26 12:05:54.056: INFO: Got endpoints: latency-svc-jsw7r [753.207788ms]
    Nov 26 12:05:54.073: INFO: Created: latency-svc-dglk2
    Nov 26 12:05:54.103: INFO: Got endpoints: latency-svc-rjdsd [747.991566ms]
    Nov 26 12:05:54.119: INFO: Created: latency-svc-rfr4d
    Nov 26 12:05:54.155: INFO: Got endpoints: latency-svc-x9tbw [750.211108ms]
    Nov 26 12:05:54.177: INFO: Created: latency-svc-zzb6x
    Nov 26 12:05:54.207: INFO: Got endpoints: latency-svc-2tz4w [749.84214ms]
    Nov 26 12:05:54.225: INFO: Created: latency-svc-vvx7l
    Nov 26 12:05:54.253: INFO: Got endpoints: latency-svc-tlkz6 [744.540377ms]
    Nov 26 12:05:54.268: INFO: Created: latency-svc-57s5c
    Nov 26 12:05:54.307: INFO: Got endpoints: latency-svc-kbzhq [751.453019ms]
    Nov 26 12:05:54.326: INFO: Created: latency-svc-gc2dd
    Nov 26 12:05:54.356: INFO: Got endpoints: latency-svc-mtddt [752.547444ms]
    Nov 26 12:05:54.372: INFO: Created: latency-svc-vpbsr
    Nov 26 12:05:54.406: INFO: Got endpoints: latency-svc-nzkq9 [747.059916ms]
    Nov 26 12:05:54.420: INFO: Created: latency-svc-78qf7
    Nov 26 12:05:54.457: INFO: Got endpoints: latency-svc-rl9n6 [751.770237ms]
    Nov 26 12:05:54.475: INFO: Created: latency-svc-mmtbm
    Nov 26 12:05:54.505: INFO: Got endpoints: latency-svc-hzm2p [748.744096ms]
    Nov 26 12:05:54.521: INFO: Created: latency-svc-vcdkx
    Nov 26 12:05:54.564: INFO: Got endpoints: latency-svc-m7wgm [756.372255ms]
    Nov 26 12:05:54.593: INFO: Created: latency-svc-mg85z
    Nov 26 12:05:54.607: INFO: Got endpoints: latency-svc-lz8js [750.502788ms]
    Nov 26 12:05:54.632: INFO: Created: latency-svc-6chwf
    Nov 26 12:05:54.657: INFO: Got endpoints: latency-svc-bmm9b [751.254327ms]
    Nov 26 12:05:54.693: INFO: Created: latency-svc-d8sx9
    Nov 26 12:05:54.709: INFO: Got endpoints: latency-svc-9x7s9 [755.576378ms]
    Nov 26 12:05:54.730: INFO: Created: latency-svc-tgm46
    Nov 26 12:05:54.756: INFO: Got endpoints: latency-svc-44hzf [751.230737ms]
    Nov 26 12:05:54.789: INFO: Created: latency-svc-bnbjh
    Nov 26 12:05:54.804: INFO: Got endpoints: latency-svc-dglk2 [748.38189ms]
    Nov 26 12:05:54.823: INFO: Created: latency-svc-nx5c6
    Nov 26 12:05:54.854: INFO: Got endpoints: latency-svc-rfr4d [750.933269ms]
    Nov 26 12:05:54.869: INFO: Created: latency-svc-d6htr
    Nov 26 12:05:54.915: INFO: Got endpoints: latency-svc-zzb6x [760.37201ms]
    Nov 26 12:05:54.935: INFO: Created: latency-svc-vdt4n
    Nov 26 12:05:54.956: INFO: Got endpoints: latency-svc-vvx7l [749.20902ms]
    Nov 26 12:05:54.990: INFO: Created: latency-svc-nhbrk
    Nov 26 12:05:55.005: INFO: Got endpoints: latency-svc-57s5c [751.723698ms]
    Nov 26 12:05:55.039: INFO: Created: latency-svc-cfths
    Nov 26 12:05:55.056: INFO: Got endpoints: latency-svc-gc2dd [749.747973ms]
    Nov 26 12:05:55.071: INFO: Created: latency-svc-q9zgd
    Nov 26 12:05:55.111: INFO: Got endpoints: latency-svc-vpbsr [754.615377ms]
    Nov 26 12:05:55.133: INFO: Created: latency-svc-zljzl
    Nov 26 12:05:55.159: INFO: Got endpoints: latency-svc-78qf7 [752.982119ms]
    Nov 26 12:05:55.176: INFO: Created: latency-svc-cpbvk
    Nov 26 12:05:55.206: INFO: Got endpoints: latency-svc-mmtbm [748.285729ms]
    Nov 26 12:05:55.237: INFO: Created: latency-svc-5ntx5
    Nov 26 12:05:55.254: INFO: Got endpoints: latency-svc-vcdkx [748.671819ms]
    Nov 26 12:05:55.271: INFO: Created: latency-svc-p7ntc
    Nov 26 12:05:55.306: INFO: Got endpoints: latency-svc-mg85z [741.879481ms]
    Nov 26 12:05:55.328: INFO: Created: latency-svc-rkvxb
    Nov 26 12:05:55.353: INFO: Got endpoints: latency-svc-6chwf [746.1387ms]
    Nov 26 12:05:55.371: INFO: Created: latency-svc-bhp5l
    Nov 26 12:05:55.405: INFO: Got endpoints: latency-svc-d8sx9 [748.246819ms]
    Nov 26 12:05:55.425: INFO: Created: latency-svc-r6pwt
    Nov 26 12:05:55.454: INFO: Got endpoints: latency-svc-tgm46 [744.877881ms]
    Nov 26 12:05:55.472: INFO: Created: latency-svc-xxjq6
    Nov 26 12:05:55.504: INFO: Got endpoints: latency-svc-bnbjh [748.414884ms]
    Nov 26 12:05:55.518: INFO: Created: latency-svc-w4sn2
    Nov 26 12:05:55.555: INFO: Got endpoints: latency-svc-nx5c6 [750.112994ms]
    Nov 26 12:05:55.569: INFO: Created: latency-svc-jskxp
    Nov 26 12:05:55.605: INFO: Got endpoints: latency-svc-d6htr [751.272961ms]
    Nov 26 12:05:55.621: INFO: Created: latency-svc-k2pjq
    Nov 26 12:05:55.658: INFO: Got endpoints: latency-svc-vdt4n [742.870786ms]
    Nov 26 12:05:55.674: INFO: Created: latency-svc-gm958
    Nov 26 12:05:55.706: INFO: Got endpoints: latency-svc-nhbrk [749.338957ms]
    Nov 26 12:05:55.720: INFO: Created: latency-svc-zfx7j
    Nov 26 12:05:55.755: INFO: Got endpoints: latency-svc-cfths [750.369281ms]
    Nov 26 12:05:55.770: INFO: Created: latency-svc-grjvf
    Nov 26 12:05:55.807: INFO: Got endpoints: latency-svc-q9zgd [750.404771ms]
    Nov 26 12:05:55.827: INFO: Created: latency-svc-5qxhb
    Nov 26 12:05:55.856: INFO: Got endpoints: latency-svc-zljzl [744.997385ms]
    Nov 26 12:05:55.869: INFO: Created: latency-svc-2psqd
    Nov 26 12:05:56.031: INFO: Got endpoints: latency-svc-cpbvk [871.924189ms]
    Nov 26 12:05:56.039: INFO: Got endpoints: latency-svc-p7ntc [785.01091ms]
    Nov 26 12:05:56.039: INFO: Got endpoints: latency-svc-5ntx5 [833.397649ms]
    Nov 26 12:05:56.052: INFO: Created: latency-svc-9gvq2
    Nov 26 12:05:56.053: INFO: Got endpoints: latency-svc-rkvxb [746.704646ms]
    Nov 26 12:05:56.065: INFO: Created: latency-svc-gtrtf
    Nov 26 12:05:56.071: INFO: Created: latency-svc-q6gf8
    Nov 26 12:05:56.080: INFO: Created: latency-svc-dgmr8
    Nov 26 12:05:56.110: INFO: Got endpoints: latency-svc-bhp5l [756.806332ms]
    Nov 26 12:05:56.128: INFO: Created: latency-svc-vhd5p
    Nov 26 12:05:56.158: INFO: Got endpoints: latency-svc-r6pwt [752.766008ms]
    Nov 26 12:05:56.180: INFO: Created: latency-svc-hgthx
    Nov 26 12:05:56.208: INFO: Got endpoints: latency-svc-xxjq6 [753.709851ms]
    Nov 26 12:05:56.225: INFO: Created: latency-svc-qk855
    Nov 26 12:05:56.254: INFO: Got endpoints: latency-svc-w4sn2 [749.975824ms]
    Nov 26 12:05:56.269: INFO: Created: latency-svc-q656x
    Nov 26 12:05:56.304: INFO: Got endpoints: latency-svc-jskxp [749.853561ms]
    Nov 26 12:05:56.320: INFO: Created: latency-svc-sbjlb
    Nov 26 12:05:56.356: INFO: Got endpoints: latency-svc-k2pjq [750.928296ms]
    Nov 26 12:05:56.372: INFO: Created: latency-svc-b7mdq
    Nov 26 12:05:56.405: INFO: Got endpoints: latency-svc-gm958 [747.27422ms]
    Nov 26 12:05:56.423: INFO: Created: latency-svc-rb8np
    Nov 26 12:05:56.454: INFO: Got endpoints: latency-svc-zfx7j [748.642193ms]
    Nov 26 12:05:56.472: INFO: Created: latency-svc-pzcbb
    Nov 26 12:05:56.504: INFO: Got endpoints: latency-svc-grjvf [747.915836ms]
    Nov 26 12:05:56.519: INFO: Created: latency-svc-5mbck
    Nov 26 12:05:56.554: INFO: Got endpoints: latency-svc-5qxhb [746.730509ms]
    Nov 26 12:05:56.571: INFO: Created: latency-svc-4755v
    Nov 26 12:05:56.603: INFO: Got endpoints: latency-svc-2psqd [746.633137ms]
    Nov 26 12:05:56.619: INFO: Created: latency-svc-mn5m7
    Nov 26 12:05:56.654: INFO: Got endpoints: latency-svc-9gvq2 [622.892258ms]
    Nov 26 12:05:56.673: INFO: Created: latency-svc-ns8rc
    Nov 26 12:05:56.703: INFO: Got endpoints: latency-svc-gtrtf [663.823534ms]
    Nov 26 12:05:56.721: INFO: Created: latency-svc-n2fth
    Nov 26 12:05:56.755: INFO: Got endpoints: latency-svc-q6gf8 [716.199278ms]
    Nov 26 12:05:56.770: INFO: Created: latency-svc-4wwtw
    Nov 26 12:05:56.807: INFO: Got endpoints: latency-svc-dgmr8 [754.804569ms]
    Nov 26 12:05:56.820: INFO: Created: latency-svc-4v7mp
    Nov 26 12:05:56.855: INFO: Got endpoints: latency-svc-vhd5p [744.372775ms]
    Nov 26 12:05:56.871: INFO: Created: latency-svc-kqbmb
    Nov 26 12:05:56.904: INFO: Got endpoints: latency-svc-hgthx [745.476581ms]
    Nov 26 12:05:56.918: INFO: Created: latency-svc-72k2s
    Nov 26 12:05:56.954: INFO: Got endpoints: latency-svc-qk855 [745.710626ms]
    Nov 26 12:05:56.973: INFO: Created: latency-svc-7j58r
    Nov 26 12:05:57.005: INFO: Got endpoints: latency-svc-q656x [750.428466ms]
    Nov 26 12:05:57.021: INFO: Created: latency-svc-c7sjj
    Nov 26 12:05:57.055: INFO: Got endpoints: latency-svc-sbjlb [750.797455ms]
    Nov 26 12:05:57.070: INFO: Created: latency-svc-mm9vt
    Nov 26 12:05:57.106: INFO: Got endpoints: latency-svc-b7mdq [749.29479ms]
    Nov 26 12:05:57.126: INFO: Created: latency-svc-5k68z
    Nov 26 12:05:57.156: INFO: Got endpoints: latency-svc-rb8np [750.809156ms]
    Nov 26 12:05:57.173: INFO: Created: latency-svc-snrth
    Nov 26 12:05:57.206: INFO: Got endpoints: latency-svc-pzcbb [750.987031ms]
    Nov 26 12:05:57.223: INFO: Created: latency-svc-p67tr
    Nov 26 12:05:57.257: INFO: Got endpoints: latency-svc-5mbck [753.434288ms]
    Nov 26 12:05:57.274: INFO: Created: latency-svc-m8hgx
    Nov 26 12:05:57.308: INFO: Got endpoints: latency-svc-4755v [754.178505ms]
    Nov 26 12:05:57.321: INFO: Created: latency-svc-5jghj
    Nov 26 12:05:57.354: INFO: Got endpoints: latency-svc-mn5m7 [751.727859ms]
    Nov 26 12:05:57.371: INFO: Created: latency-svc-56t9v
    Nov 26 12:05:57.403: INFO: Got endpoints: latency-svc-ns8rc [748.641757ms]
    Nov 26 12:05:57.421: INFO: Created: latency-svc-h6sw4
    Nov 26 12:05:57.453: INFO: Got endpoints: latency-svc-n2fth [750.116022ms]
    Nov 26 12:05:57.467: INFO: Created: latency-svc-xb7fd
    Nov 26 12:05:57.506: INFO: Got endpoints: latency-svc-4wwtw [750.785567ms]
    Nov 26 12:05:57.527: INFO: Created: latency-svc-wpv49
    Nov 26 12:05:57.559: INFO: Got endpoints: latency-svc-4v7mp [751.455664ms]
    Nov 26 12:05:57.583: INFO: Created: latency-svc-fh4hf
    Nov 26 12:05:57.607: INFO: Got endpoints: latency-svc-kqbmb [751.580756ms]
    Nov 26 12:05:57.624: INFO: Created: latency-svc-z296v
    Nov 26 12:05:57.657: INFO: Got endpoints: latency-svc-72k2s [752.920539ms]
    Nov 26 12:05:57.672: INFO: Created: latency-svc-xln7r
    Nov 26 12:05:57.710: INFO: Got endpoints: latency-svc-7j58r [756.612435ms]
    Nov 26 12:05:57.728: INFO: Created: latency-svc-q5tps
    Nov 26 12:05:57.753: INFO: Got endpoints: latency-svc-c7sjj [747.923942ms]
    Nov 26 12:05:57.771: INFO: Created: latency-svc-8894c
    Nov 26 12:05:57.804: INFO: Got endpoints: latency-svc-mm9vt [748.610529ms]
    Nov 26 12:05:57.821: INFO: Created: latency-svc-4dxnh
    Nov 26 12:05:57.863: INFO: Got endpoints: latency-svc-5k68z [757.24071ms]
    Nov 26 12:05:57.877: INFO: Created: latency-svc-2pmts
    Nov 26 12:05:57.906: INFO: Got endpoints: latency-svc-snrth [749.513089ms]
    Nov 26 12:05:57.919: INFO: Created: latency-svc-mb4m8
    Nov 26 12:05:57.954: INFO: Got endpoints: latency-svc-p67tr [748.139038ms]
    Nov 26 12:05:57.970: INFO: Created: latency-svc-k6z8j
    Nov 26 12:05:58.005: INFO: Got endpoints: latency-svc-m8hgx [747.524043ms]
    Nov 26 12:05:58.023: INFO: Created: latency-svc-zm47p
    Nov 26 12:05:58.056: INFO: Got endpoints: latency-svc-5jghj [747.986724ms]
    Nov 26 12:05:58.071: INFO: Created: latency-svc-4hj4k
    Nov 26 12:05:58.111: INFO: Got endpoints: latency-svc-56t9v [756.236187ms]
    Nov 26 12:05:58.131: INFO: Created: latency-svc-qznd6
    Nov 26 12:05:58.154: INFO: Got endpoints: latency-svc-h6sw4 [750.240068ms]
    Nov 26 12:05:58.171: INFO: Created: latency-svc-jdfpx
    Nov 26 12:05:58.206: INFO: Got endpoints: latency-svc-xb7fd [752.386367ms]
    Nov 26 12:05:58.227: INFO: Created: latency-svc-7jfc2
    Nov 26 12:05:58.256: INFO: Got endpoints: latency-svc-wpv49 [749.48984ms]
    Nov 26 12:05:58.270: INFO: Created: latency-svc-62tct
    Nov 26 12:05:58.306: INFO: Got endpoints: latency-svc-fh4hf [746.549842ms]
    Nov 26 12:05:58.322: INFO: Created: latency-svc-7twwz
    Nov 26 12:05:58.354: INFO: Got endpoints: latency-svc-z296v [746.848679ms]
    Nov 26 12:05:58.366: INFO: Created: latency-svc-2mzfr
    Nov 26 12:05:58.408: INFO: Got endpoints: latency-svc-xln7r [750.870813ms]
    Nov 26 12:05:58.424: INFO: Created: latency-svc-rccs6
    Nov 26 12:05:58.453: INFO: Got endpoints: latency-svc-q5tps [742.005687ms]
    Nov 26 12:05:58.472: INFO: Created: latency-svc-rjrm8
    Nov 26 12:05:58.504: INFO: Got endpoints: latency-svc-8894c [751.541949ms]
    Nov 26 12:05:58.518: INFO: Created: latency-svc-8kw62
    Nov 26 12:05:58.557: INFO: Got endpoints: latency-svc-4dxnh [752.489042ms]
    Nov 26 12:05:58.573: INFO: Created: latency-svc-vxc69
    Nov 26 12:05:58.606: INFO: Got endpoints: latency-svc-2pmts [742.921499ms]
    Nov 26 12:05:58.623: INFO: Created: latency-svc-mvh96
    Nov 26 12:05:58.655: INFO: Got endpoints: latency-svc-mb4m8 [748.882079ms]
    Nov 26 12:05:58.674: INFO: Created: latency-svc-c42dt
    Nov 26 12:05:58.705: INFO: Got endpoints: latency-svc-k6z8j [750.635369ms]
    Nov 26 12:05:58.723: INFO: Created: latency-svc-9b95m
    Nov 26 12:05:58.759: INFO: Got endpoints: latency-svc-zm47p [753.259741ms]
    Nov 26 12:05:58.774: INFO: Created: latency-svc-dftrp
    Nov 26 12:05:58.803: INFO: Got endpoints: latency-svc-4hj4k [747.471646ms]
    Nov 26 12:05:58.816: INFO: Created: latency-svc-c7thd
    Nov 26 12:05:58.856: INFO: Got endpoints: latency-svc-qznd6 [745.405977ms]
    Nov 26 12:05:58.873: INFO: Created: latency-svc-ppp8w
    Nov 26 12:05:58.904: INFO: Got endpoints: latency-svc-jdfpx [750.175929ms]
    Nov 26 12:05:58.920: INFO: Created: latency-svc-9lnwb
    Nov 26 12:05:58.954: INFO: Got endpoints: latency-svc-7jfc2 [747.731222ms]
    Nov 26 12:05:58.970: INFO: Created: latency-svc-zg78c
    Nov 26 12:05:59.004: INFO: Got endpoints: latency-svc-62tct [748.173263ms]
    Nov 26 12:05:59.020: INFO: Created: latency-svc-gq749
    Nov 26 12:05:59.055: INFO: Got endpoints: latency-svc-7twwz [748.973232ms]
    Nov 26 12:05:59.068: INFO: Created: latency-svc-99tqj
    Nov 26 12:05:59.107: INFO: Got endpoints: latency-svc-2mzfr [752.636178ms]
    Nov 26 12:05:59.122: INFO: Created: latency-svc-tg25d
    Nov 26 12:05:59.155: INFO: Got endpoints: latency-svc-rccs6 [746.473563ms]
    Nov 26 12:05:59.180: INFO: Created: latency-svc-kr7tw
    Nov 26 12:05:59.204: INFO: Got endpoints: latency-svc-rjrm8 [751.244385ms]
    Nov 26 12:05:59.223: INFO: Created: latency-svc-l7sg2
    Nov 26 12:05:59.255: INFO: Got endpoints: latency-svc-8kw62 [750.15514ms]
    Nov 26 12:05:59.268: INFO: Created: latency-svc-hstkt
    Nov 26 12:05:59.308: INFO: Got endpoints: latency-svc-vxc69 [750.509359ms]
    Nov 26 12:05:59.325: INFO: Created: latency-svc-6khtj
    Nov 26 12:05:59.356: INFO: Got endpoints: latency-svc-mvh96 [750.171001ms]
    Nov 26 12:05:59.373: INFO: Created: latency-svc-zb2xb
    Nov 26 12:05:59.403: INFO: Got endpoints: latency-svc-c42dt [747.454027ms]
    Nov 26 12:05:59.419: INFO: Created: latency-svc-vz9f9
    Nov 26 12:05:59.453: INFO: Got endpoints: latency-svc-9b95m [747.879338ms]
    Nov 26 12:05:59.473: INFO: Created: latency-svc-znsr6
    Nov 26 12:05:59.507: INFO: Got endpoints: latency-svc-dftrp [747.369816ms]
    Nov 26 12:05:59.524: INFO: Created: latency-svc-9wbkf
    Nov 26 12:05:59.558: INFO: Got endpoints: latency-svc-c7thd [754.544184ms]
    Nov 26 12:05:59.571: INFO: Created: latency-svc-wrbrm
    Nov 26 12:05:59.603: INFO: Got endpoints: latency-svc-ppp8w [746.23168ms]
    Nov 26 12:05:59.621: INFO: Created: latency-svc-bt6gx
    Nov 26 12:05:59.655: INFO: Got endpoints: latency-svc-9lnwb [750.327527ms]
    Nov 26 12:05:59.672: INFO: Created: latency-svc-pv8q4
    Nov 26 12:05:59.703: INFO: Got endpoints: latency-svc-zg78c [748.956735ms]
    Nov 26 12:05:59.717: INFO: Created: latency-svc-dqxh2
    Nov 26 12:05:59.757: INFO: Got endpoints: latency-svc-gq749 [752.846606ms]
    Nov 26 12:05:59.774: INFO: Created: latency-svc-578sq
    Nov 26 12:05:59.807: INFO: Got endpoints: latency-svc-99tqj [752.407396ms]
    Nov 26 12:05:59.822: INFO: Created: latency-svc-mxjfx
    Nov 26 12:05:59.856: INFO: Got endpoints: latency-svc-tg25d [749.15601ms]
    Nov 26 12:05:59.869: INFO: Created: latency-svc-5hf2x
    Nov 26 12:05:59.903: INFO: Got endpoints: latency-svc-kr7tw [747.723316ms]
    Nov 26 12:05:59.922: INFO: Created: latency-svc-xb662
    Nov 26 12:05:59.954: INFO: Got endpoints: latency-svc-l7sg2 [749.215971ms]
    Nov 26 12:06:00.007: INFO: Got endpoints: latency-svc-hstkt [751.860273ms]
    Nov 26 12:06:00.055: INFO: Got endpoints: latency-svc-6khtj [747.060991ms]
    Nov 26 12:06:00.107: INFO: Got endpoints: latency-svc-zb2xb [751.006814ms]
    Nov 26 12:06:00.160: INFO: Got endpoints: latency-svc-vz9f9 [757.167768ms]
    Nov 26 12:06:00.207: INFO: Got endpoints: latency-svc-znsr6 [754.848914ms]
    Nov 26 12:06:00.254: INFO: Got endpoints: latency-svc-9wbkf [747.345139ms]
    Nov 26 12:06:00.306: INFO: Got endpoints: latency-svc-wrbrm [747.949433ms]
    Nov 26 12:06:00.353: INFO: Got endpoints: latency-svc-bt6gx [750.599696ms]
    Nov 26 12:06:00.404: INFO: Got endpoints: latency-svc-pv8q4 [748.980148ms]
    Nov 26 12:06:00.459: INFO: Got endpoints: latency-svc-dqxh2 [755.845378ms]
    Nov 26 12:06:00.504: INFO: Got endpoints: latency-svc-578sq [747.515184ms]
    Nov 26 12:06:00.557: INFO: Got endpoints: latency-svc-mxjfx [749.988452ms]
    Nov 26 12:06:00.603: INFO: Got endpoints: latency-svc-5hf2x [747.126096ms]
    Nov 26 12:06:00.657: INFO: Got endpoints: latency-svc-xb662 [753.898844ms]
    Nov 26 12:06:00.657: INFO: Latencies: [40.990007ms 64.208098ms 67.647378ms 89.888937ms 98.213372ms 103.074276ms 106.913325ms 119.686792ms 121.582567ms 123.763558ms 125.294384ms 131.509308ms 137.173351ms 137.174691ms 138.42554ms 143.368496ms 158.329644ms 160.662389ms 165.334217ms 170.659263ms 172.334871ms 178.304691ms 180.052661ms 183.235056ms 190.540606ms 208.624917ms 219.181524ms 221.244732ms 229.525165ms 238.620088ms 249.710666ms 274.33037ms 279.696266ms 282.329948ms 288.86388ms 299.498608ms 300.485832ms 309.308367ms 320.057718ms 323.336535ms 346.73314ms 349.174027ms 349.635408ms 350.078039ms 352.666278ms 376.597887ms 420.787148ms 424.217538ms 448.648888ms 484.019274ms 526.598148ms 556.129177ms 586.338872ms 622.892258ms 629.418158ms 657.206577ms 663.823534ms 703.898686ms 716.199278ms 734.423428ms 741.879481ms 742.005687ms 742.870786ms 742.921499ms 744.372775ms 744.540377ms 744.877881ms 744.997385ms 745.079458ms 745.405977ms 745.476581ms 745.710626ms 746.1387ms 746.23168ms 746.473563ms 746.549842ms 746.633137ms 746.704646ms 746.730509ms 746.848679ms 746.976493ms 746.982994ms 747.059916ms 747.060991ms 747.126096ms 747.27422ms 747.345139ms 747.369816ms 747.454027ms 747.471646ms 747.515184ms 747.524043ms 747.723316ms 747.731222ms 747.879338ms 747.882753ms 747.915836ms 747.923942ms 747.949433ms 747.986724ms 747.991566ms 748.068018ms 748.139038ms 748.173263ms 748.246819ms 748.285729ms 748.322195ms 748.38189ms 748.414884ms 748.610529ms 748.641757ms 748.642193ms 748.671819ms 748.744096ms 748.882079ms 748.956735ms 748.973232ms 748.980148ms 749.15601ms 749.20902ms 749.215971ms 749.29479ms 749.338957ms 749.48984ms 749.513089ms 749.747973ms 749.84214ms 749.853561ms 749.975824ms 749.988452ms 750.034594ms 750.112994ms 750.116022ms 750.15514ms 750.171001ms 750.175929ms 750.211108ms 750.240068ms 750.327527ms 750.369281ms 750.404771ms 750.420193ms 750.428466ms 750.502788ms 750.509359ms 750.599696ms 750.635369ms 750.785567ms 750.797455ms 750.809156ms 750.870813ms 750.928296ms 750.933269ms 750.987031ms 751.006814ms 751.192571ms 751.230737ms 751.244385ms 751.254327ms 751.272961ms 751.453019ms 751.455664ms 751.541949ms 751.580756ms 751.723698ms 751.727859ms 751.770237ms 751.860273ms 752.386367ms 752.407396ms 752.489042ms 752.547444ms 752.636178ms 752.766008ms 752.846606ms 752.920539ms 752.982119ms 753.207788ms 753.259741ms 753.434288ms 753.709851ms 753.898844ms 754.178505ms 754.544184ms 754.615377ms 754.804569ms 754.848914ms 755.576378ms 755.845378ms 756.236187ms 756.372255ms 756.612435ms 756.642898ms 756.806332ms 757.167768ms 757.24071ms 760.37201ms 785.01091ms 833.397649ms 871.924189ms]
    Nov 26 12:06:00.657: INFO: 50 %ile: 747.991566ms
    Nov 26 12:06:00.657: INFO: 90 %ile: 753.709851ms
    Nov 26 12:06:00.657: INFO: 99 %ile: 833.397649ms
    Nov 26 12:06:00.657: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Nov 26 12:06:00.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-8144" for this suite. 11/26/22 12:06:00.665
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:06:00.681
Nov 26 12:06:00.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replication-controller 11/26/22 12:06:00.683
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:06:00.708
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:06:00.714
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Nov 26 12:06:00.720: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 11/26/22 12:06:00.736
STEP: Checking rc "condition-test" has the desired failure condition set 11/26/22 12:06:00.75
STEP: Scaling down rc "condition-test" to satisfy pod quota 11/26/22 12:06:01.762
Nov 26 12:06:01.778: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 11/26/22 12:06:01.778
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 26 12:06:02.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6372" for this suite. 11/26/22 12:06:02.799
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":59,"skipped":1041,"failed":0}
------------------------------
â€¢ [2.131 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:06:00.681
    Nov 26 12:06:00.682: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replication-controller 11/26/22 12:06:00.683
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:06:00.708
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:06:00.714
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Nov 26 12:06:00.720: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 11/26/22 12:06:00.736
    STEP: Checking rc "condition-test" has the desired failure condition set 11/26/22 12:06:00.75
    STEP: Scaling down rc "condition-test" to satisfy pod quota 11/26/22 12:06:01.762
    Nov 26 12:06:01.778: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 11/26/22 12:06:01.778
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 26 12:06:02.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-6372" for this suite. 11/26/22 12:06:02.799
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:06:02.814
Nov 26 12:06:02.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename taint-single-pod 11/26/22 12:06:02.815
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:06:02.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:06:02.845
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Nov 26 12:06:02.851: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 26 12:07:02.884: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Nov 26 12:07:02.891: INFO: Starting informer...
STEP: Starting pod... 11/26/22 12:07:02.891
Nov 26 12:07:03.119: INFO: Pod is running on ip-172-31-43-82. Tainting Node
STEP: Trying to apply a taint on the Node 11/26/22 12:07:03.119
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/26/22 12:07:03.134
STEP: Waiting short time to make sure Pod is queued for deletion 11/26/22 12:07:03.151
Nov 26 12:07:03.151: INFO: Pod wasn't evicted. Proceeding
Nov 26 12:07:03.151: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/26/22 12:07:03.18
STEP: Waiting some time to make sure that toleration time passed. 11/26/22 12:07:03.189
Nov 26 12:08:18.190: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:08:18.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-1286" for this suite. 11/26/22 12:08:18.199
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":60,"skipped":1044,"failed":0}
------------------------------
â€¢ [SLOW TEST] [135.396 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:06:02.814
    Nov 26 12:06:02.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename taint-single-pod 11/26/22 12:06:02.815
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:06:02.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:06:02.845
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Nov 26 12:06:02.851: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 26 12:07:02.884: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Nov 26 12:07:02.891: INFO: Starting informer...
    STEP: Starting pod... 11/26/22 12:07:02.891
    Nov 26 12:07:03.119: INFO: Pod is running on ip-172-31-43-82. Tainting Node
    STEP: Trying to apply a taint on the Node 11/26/22 12:07:03.119
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/26/22 12:07:03.134
    STEP: Waiting short time to make sure Pod is queued for deletion 11/26/22 12:07:03.151
    Nov 26 12:07:03.151: INFO: Pod wasn't evicted. Proceeding
    Nov 26 12:07:03.151: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/26/22 12:07:03.18
    STEP: Waiting some time to make sure that toleration time passed. 11/26/22 12:07:03.189
    Nov 26 12:08:18.190: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:08:18.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-1286" for this suite. 11/26/22 12:08:18.199
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:08:18.211
Nov 26 12:08:18.211: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:08:18.212
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:18.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:18.24
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 11/26/22 12:08:18.245
Nov 26 12:08:18.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7852 api-versions'
Nov 26 12:08:18.324: INFO: stderr: ""
Nov 26 12:08:18.324: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:08:18.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7852" for this suite. 11/26/22 12:08:18.331
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":61,"skipped":1062,"failed":0}
------------------------------
â€¢ [0.134 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:08:18.211
    Nov 26 12:08:18.211: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:08:18.212
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:18.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:18.24
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 11/26/22 12:08:18.245
    Nov 26 12:08:18.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7852 api-versions'
    Nov 26 12:08:18.324: INFO: stderr: ""
    Nov 26 12:08:18.324: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:08:18.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7852" for this suite. 11/26/22 12:08:18.331
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:08:18.345
Nov 26 12:08:18.346: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 12:08:18.347
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:18.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:18.376
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-6941/secret-test-c95f6915-ae48-471a-9666-525318256597 11/26/22 12:08:18.382
STEP: Creating a pod to test consume secrets 11/26/22 12:08:18.391
Nov 26 12:08:18.404: INFO: Waiting up to 5m0s for pod "pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7" in namespace "secrets-6941" to be "Succeeded or Failed"
Nov 26 12:08:18.415: INFO: Pod "pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.554363ms
Nov 26 12:08:20.421: INFO: Pod "pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01650212s
Nov 26 12:08:22.424: INFO: Pod "pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019352045s
STEP: Saw pod success 11/26/22 12:08:22.424
Nov 26 12:08:22.424: INFO: Pod "pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7" satisfied condition "Succeeded or Failed"
Nov 26 12:08:22.430: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7 container env-test: <nil>
STEP: delete the pod 11/26/22 12:08:22.45
Nov 26 12:08:22.471: INFO: Waiting for pod pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7 to disappear
Nov 26 12:08:22.477: INFO: Pod pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 26 12:08:22.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6941" for this suite. 11/26/22 12:08:22.483
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":62,"skipped":1072,"failed":0}
------------------------------
â€¢ [4.149 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:08:18.345
    Nov 26 12:08:18.346: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 12:08:18.347
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:18.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:18.376
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-6941/secret-test-c95f6915-ae48-471a-9666-525318256597 11/26/22 12:08:18.382
    STEP: Creating a pod to test consume secrets 11/26/22 12:08:18.391
    Nov 26 12:08:18.404: INFO: Waiting up to 5m0s for pod "pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7" in namespace "secrets-6941" to be "Succeeded or Failed"
    Nov 26 12:08:18.415: INFO: Pod "pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.554363ms
    Nov 26 12:08:20.421: INFO: Pod "pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01650212s
    Nov 26 12:08:22.424: INFO: Pod "pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019352045s
    STEP: Saw pod success 11/26/22 12:08:22.424
    Nov 26 12:08:22.424: INFO: Pod "pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7" satisfied condition "Succeeded or Failed"
    Nov 26 12:08:22.430: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7 container env-test: <nil>
    STEP: delete the pod 11/26/22 12:08:22.45
    Nov 26 12:08:22.471: INFO: Waiting for pod pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7 to disappear
    Nov 26 12:08:22.477: INFO: Pod pod-configmaps-3d61cc8a-f86f-4667-aa14-3d46813c0ac7 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 12:08:22.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6941" for this suite. 11/26/22 12:08:22.483
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:08:22.5
Nov 26 12:08:22.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename daemonsets 11/26/22 12:08:22.501
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:22.526
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:22.534
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 11/26/22 12:08:22.575
STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 12:08:22.586
Nov 26 12:08:22.595: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:22.595: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:22.600: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:08:22.600: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:23.608: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:23.608: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:23.616: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:08:23.616: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:24.607: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:24.607: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:24.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:08:24.613: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:25.607: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:25.607: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:25.615: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:08:25.615: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:26.608: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:26.608: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:26.614: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:08:26.614: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:27.606: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:27.606: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:27.617: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:08:27.617: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:28.608: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:28.608: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:28.614: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:08:28.614: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:29.607: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:29.607: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:29.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:08:29.613: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:30.607: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:30.607: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:30.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:08:30.613: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:31.608: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:31.608: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:31.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 26 12:08:31.614: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 11/26/22 12:08:31.619
Nov 26 12:08:31.647: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:31.647: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:31.664: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:08:31.664: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:32.671: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:32.671: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:32.678: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:08:32.678: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:08:33.673: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:33.673: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:08:33.680: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 26 12:08:33.680: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 11/26/22 12:08:33.68
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:08:33.693
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7531, will wait for the garbage collector to delete the pods 11/26/22 12:08:33.693
Nov 26 12:08:33.760: INFO: Deleting DaemonSet.extensions daemon-set took: 9.806076ms
Nov 26 12:08:33.861: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.122681ms
Nov 26 12:08:36.069: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:08:36.069: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 26 12:08:36.076: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9012"},"items":null}

Nov 26 12:08:36.084: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9012"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:08:36.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7531" for this suite. 11/26/22 12:08:36.116
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":63,"skipped":1144,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.627 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:08:22.5
    Nov 26 12:08:22.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename daemonsets 11/26/22 12:08:22.501
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:22.526
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:22.534
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 11/26/22 12:08:22.575
    STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 12:08:22.586
    Nov 26 12:08:22.595: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:22.595: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:22.600: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:08:22.600: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:23.608: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:23.608: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:23.616: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:08:23.616: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:24.607: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:24.607: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:24.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:08:24.613: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:25.607: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:25.607: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:25.615: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:08:25.615: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:26.608: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:26.608: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:26.614: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:08:26.614: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:27.606: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:27.606: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:27.617: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:08:27.617: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:28.608: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:28.608: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:28.614: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:08:28.614: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:29.607: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:29.607: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:29.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:08:29.613: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:30.607: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:30.607: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:30.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:08:30.613: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:31.608: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:31.608: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:31.613: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 26 12:08:31.614: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 11/26/22 12:08:31.619
    Nov 26 12:08:31.647: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:31.647: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:31.664: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:08:31.664: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:32.671: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:32.671: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:32.678: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:08:32.678: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:08:33.673: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:33.673: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:08:33.680: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 26 12:08:33.680: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 11/26/22 12:08:33.68
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:08:33.693
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7531, will wait for the garbage collector to delete the pods 11/26/22 12:08:33.693
    Nov 26 12:08:33.760: INFO: Deleting DaemonSet.extensions daemon-set took: 9.806076ms
    Nov 26 12:08:33.861: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.122681ms
    Nov 26 12:08:36.069: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:08:36.069: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 26 12:08:36.076: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"9012"},"items":null}

    Nov 26 12:08:36.084: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"9012"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:08:36.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7531" for this suite. 11/26/22 12:08:36.116
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:08:36.128
Nov 26 12:08:36.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename disruption 11/26/22 12:08:36.13
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:36.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:36.164
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 11/26/22 12:08:36.17
STEP: Waiting for the pdb to be processed 11/26/22 12:08:36.178
STEP: First trying to evict a pod which shouldn't be evictable 11/26/22 12:08:38.214
STEP: Waiting for all pods to be running 11/26/22 12:08:38.214
Nov 26 12:08:38.225: INFO: pods: 1 < 3
Nov 26 12:08:40.232: INFO: running pods: 2 < 3
STEP: locating a running pod 11/26/22 12:08:42.232
STEP: Updating the pdb to allow a pod to be evicted 11/26/22 12:08:42.247
STEP: Waiting for the pdb to be processed 11/26/22 12:08:42.261
STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/26/22 12:08:42.267
STEP: Waiting for all pods to be running 11/26/22 12:08:42.267
STEP: Waiting for the pdb to observed all healthy pods 11/26/22 12:08:42.271
STEP: Patching the pdb to disallow a pod to be evicted 11/26/22 12:08:42.316
STEP: Waiting for the pdb to be processed 11/26/22 12:08:42.346
STEP: Waiting for all pods to be running 11/26/22 12:08:42.363
Nov 26 12:08:42.370: INFO: running pods: 2 < 3
STEP: locating a running pod 11/26/22 12:08:44.377
STEP: Deleting the pdb to allow a pod to be evicted 11/26/22 12:08:44.397
STEP: Waiting for the pdb to be deleted 11/26/22 12:08:44.41
STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/26/22 12:08:44.416
STEP: Waiting for all pods to be running 11/26/22 12:08:44.416
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 26 12:08:44.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9570" for this suite. 11/26/22 12:08:44.478
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":64,"skipped":1145,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.390 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:08:36.128
    Nov 26 12:08:36.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename disruption 11/26/22 12:08:36.13
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:36.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:36.164
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 11/26/22 12:08:36.17
    STEP: Waiting for the pdb to be processed 11/26/22 12:08:36.178
    STEP: First trying to evict a pod which shouldn't be evictable 11/26/22 12:08:38.214
    STEP: Waiting for all pods to be running 11/26/22 12:08:38.214
    Nov 26 12:08:38.225: INFO: pods: 1 < 3
    Nov 26 12:08:40.232: INFO: running pods: 2 < 3
    STEP: locating a running pod 11/26/22 12:08:42.232
    STEP: Updating the pdb to allow a pod to be evicted 11/26/22 12:08:42.247
    STEP: Waiting for the pdb to be processed 11/26/22 12:08:42.261
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/26/22 12:08:42.267
    STEP: Waiting for all pods to be running 11/26/22 12:08:42.267
    STEP: Waiting for the pdb to observed all healthy pods 11/26/22 12:08:42.271
    STEP: Patching the pdb to disallow a pod to be evicted 11/26/22 12:08:42.316
    STEP: Waiting for the pdb to be processed 11/26/22 12:08:42.346
    STEP: Waiting for all pods to be running 11/26/22 12:08:42.363
    Nov 26 12:08:42.370: INFO: running pods: 2 < 3
    STEP: locating a running pod 11/26/22 12:08:44.377
    STEP: Deleting the pdb to allow a pod to be evicted 11/26/22 12:08:44.397
    STEP: Waiting for the pdb to be deleted 11/26/22 12:08:44.41
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/26/22 12:08:44.416
    STEP: Waiting for all pods to be running 11/26/22 12:08:44.416
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 26 12:08:44.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9570" for this suite. 11/26/22 12:08:44.478
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:08:44.526
Nov 26 12:08:44.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 12:08:44.528
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:44.67
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:44.69
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:08:44.696
Nov 26 12:08:44.711: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d" in namespace "downward-api-4273" to be "Succeeded or Failed"
Nov 26 12:08:44.723: INFO: Pod "downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.930053ms
Nov 26 12:08:46.731: INFO: Pod "downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018899215s
Nov 26 12:08:48.731: INFO: Pod "downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019103842s
STEP: Saw pod success 11/26/22 12:08:48.731
Nov 26 12:08:48.731: INFO: Pod "downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d" satisfied condition "Succeeded or Failed"
Nov 26 12:08:48.736: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d container client-container: <nil>
STEP: delete the pod 11/26/22 12:08:48.747
Nov 26 12:08:48.770: INFO: Waiting for pod downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d to disappear
Nov 26 12:08:48.776: INFO: Pod downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 12:08:48.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4273" for this suite. 11/26/22 12:08:48.784
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":65,"skipped":1158,"failed":0}
------------------------------
â€¢ [4.269 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:08:44.526
    Nov 26 12:08:44.526: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 12:08:44.528
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:44.67
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:44.69
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:08:44.696
    Nov 26 12:08:44.711: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d" in namespace "downward-api-4273" to be "Succeeded or Failed"
    Nov 26 12:08:44.723: INFO: Pod "downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.930053ms
    Nov 26 12:08:46.731: INFO: Pod "downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018899215s
    Nov 26 12:08:48.731: INFO: Pod "downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019103842s
    STEP: Saw pod success 11/26/22 12:08:48.731
    Nov 26 12:08:48.731: INFO: Pod "downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d" satisfied condition "Succeeded or Failed"
    Nov 26 12:08:48.736: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d container client-container: <nil>
    STEP: delete the pod 11/26/22 12:08:48.747
    Nov 26 12:08:48.770: INFO: Waiting for pod downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d to disappear
    Nov 26 12:08:48.776: INFO: Pod downwardapi-volume-4bc4ae0c-9ba5-44d4-af82-f13457140a7d no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 12:08:48.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4273" for this suite. 11/26/22 12:08:48.784
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:08:48.795
Nov 26 12:08:48.795: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename svcaccounts 11/26/22 12:08:48.796
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:48.822
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:48.827
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  11/26/22 12:08:48.834
Nov 26 12:08:48.848: INFO: Waiting up to 5m0s for pod "test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345" in namespace "svcaccounts-931" to be "Succeeded or Failed"
Nov 26 12:08:48.860: INFO: Pod "test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345": Phase="Pending", Reason="", readiness=false. Elapsed: 11.077297ms
Nov 26 12:08:50.866: INFO: Pod "test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017014484s
Nov 26 12:08:52.867: INFO: Pod "test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018276201s
STEP: Saw pod success 11/26/22 12:08:52.867
Nov 26 12:08:52.867: INFO: Pod "test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345" satisfied condition "Succeeded or Failed"
Nov 26 12:08:52.872: INFO: Trying to get logs from node ip-172-31-43-82 pod test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345 container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:08:52.884
Nov 26 12:08:52.907: INFO: Waiting for pod test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345 to disappear
Nov 26 12:08:52.912: INFO: Pod test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 26 12:08:52.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-931" for this suite. 11/26/22 12:08:52.918
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":66,"skipped":1160,"failed":0}
------------------------------
â€¢ [4.135 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:08:48.795
    Nov 26 12:08:48.795: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename svcaccounts 11/26/22 12:08:48.796
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:48.822
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:48.827
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  11/26/22 12:08:48.834
    Nov 26 12:08:48.848: INFO: Waiting up to 5m0s for pod "test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345" in namespace "svcaccounts-931" to be "Succeeded or Failed"
    Nov 26 12:08:48.860: INFO: Pod "test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345": Phase="Pending", Reason="", readiness=false. Elapsed: 11.077297ms
    Nov 26 12:08:50.866: INFO: Pod "test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017014484s
    Nov 26 12:08:52.867: INFO: Pod "test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018276201s
    STEP: Saw pod success 11/26/22 12:08:52.867
    Nov 26 12:08:52.867: INFO: Pod "test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345" satisfied condition "Succeeded or Failed"
    Nov 26 12:08:52.872: INFO: Trying to get logs from node ip-172-31-43-82 pod test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345 container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:08:52.884
    Nov 26 12:08:52.907: INFO: Waiting for pod test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345 to disappear
    Nov 26 12:08:52.912: INFO: Pod test-pod-c65bc7cc-7050-4830-8b13-aa153a4ed345 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 26 12:08:52.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-931" for this suite. 11/26/22 12:08:52.918
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:08:52.93
Nov 26 12:08:52.931: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:08:52.932
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:52.954
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:52.959
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 11/26/22 12:08:52.972
STEP: waiting for available Endpoint 11/26/22 12:08:52.981
STEP: listing all Endpoints 11/26/22 12:08:52.984
STEP: updating the Endpoint 11/26/22 12:08:52.99
STEP: fetching the Endpoint 11/26/22 12:08:53
STEP: patching the Endpoint 11/26/22 12:08:53.006
STEP: fetching the Endpoint 11/26/22 12:08:53.02
STEP: deleting the Endpoint by Collection 11/26/22 12:08:53.026
STEP: waiting for Endpoint deletion 11/26/22 12:08:53.042
STEP: fetching the Endpoint 11/26/22 12:08:53.046
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:08:53.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4512" for this suite. 11/26/22 12:08:53.061
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":67,"skipped":1166,"failed":0}
------------------------------
â€¢ [0.140 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:08:52.93
    Nov 26 12:08:52.931: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:08:52.932
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:52.954
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:52.959
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 11/26/22 12:08:52.972
    STEP: waiting for available Endpoint 11/26/22 12:08:52.981
    STEP: listing all Endpoints 11/26/22 12:08:52.984
    STEP: updating the Endpoint 11/26/22 12:08:52.99
    STEP: fetching the Endpoint 11/26/22 12:08:53
    STEP: patching the Endpoint 11/26/22 12:08:53.006
    STEP: fetching the Endpoint 11/26/22 12:08:53.02
    STEP: deleting the Endpoint by Collection 11/26/22 12:08:53.026
    STEP: waiting for Endpoint deletion 11/26/22 12:08:53.042
    STEP: fetching the Endpoint 11/26/22 12:08:53.046
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:08:53.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4512" for this suite. 11/26/22 12:08:53.061
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:08:53.072
Nov 26 12:08:53.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename init-container 11/26/22 12:08:53.073
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:53.096
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:53.101
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 11/26/22 12:08:53.105
Nov 26 12:08:53.106: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 26 12:08:56.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6959" for this suite. 11/26/22 12:08:56.591
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":68,"skipped":1170,"failed":0}
------------------------------
â€¢ [3.529 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:08:53.072
    Nov 26 12:08:53.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename init-container 11/26/22 12:08:53.073
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:53.096
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:53.101
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 11/26/22 12:08:53.105
    Nov 26 12:08:53.106: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 26 12:08:56.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-6959" for this suite. 11/26/22 12:08:56.591
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:08:56.612
Nov 26 12:08:56.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:08:56.613
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:56.634
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:56.64
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-8605 11/26/22 12:08:56.646
STEP: creating replication controller nodeport-test in namespace services-8605 11/26/22 12:08:56.674
I1126 12:08:56.698445      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8605, replica count: 2
I1126 12:08:59.750722      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 12:08:59.750: INFO: Creating new exec pod
Nov 26 12:08:59.761: INFO: Waiting up to 5m0s for pod "execpodtpx4q" in namespace "services-8605" to be "running"
Nov 26 12:08:59.770: INFO: Pod "execpodtpx4q": Phase="Pending", Reason="", readiness=false. Elapsed: 9.54008ms
Nov 26 12:09:01.779: INFO: Pod "execpodtpx4q": Phase="Running", Reason="", readiness=true. Elapsed: 2.017674914s
Nov 26 12:09:01.779: INFO: Pod "execpodtpx4q" satisfied condition "running"
Nov 26 12:09:02.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Nov 26 12:09:02.984: INFO: stderr: "+ + echonc -v hostName\n -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 26 12:09:02.984: INFO: stdout: ""
Nov 26 12:09:03.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Nov 26 12:09:04.165: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 26 12:09:04.165: INFO: stdout: ""
Nov 26 12:09:04.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Nov 26 12:09:05.178: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 26 12:09:05.178: INFO: stdout: "nodeport-test-v2zd9"
Nov 26 12:09:05.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.48 80'
Nov 26 12:09:05.355: INFO: stderr: "+ nc -v -t -w 2 10.152.183.48 80\nConnection to 10.152.183.48 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Nov 26 12:09:05.355: INFO: stdout: "nodeport-test-v2zd9"
Nov 26 12:09:05.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 31699'
Nov 26 12:09:05.535: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.29.104 31699\nConnection to 172.31.29.104 31699 port [tcp/*] succeeded!\n"
Nov 26 12:09:05.535: INFO: stdout: ""
Nov 26 12:09:06.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 31699'
Nov 26 12:09:06.686: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.29.104 31699\nConnection to 172.31.29.104 31699 port [tcp/*] succeeded!\n"
Nov 26 12:09:06.686: INFO: stdout: "nodeport-test-v2zd9"
Nov 26 12:09:06.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.82 31699'
Nov 26 12:09:06.848: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.43.82 31699\nConnection to 172.31.43.82 31699 port [tcp/*] succeeded!\n"
Nov 26 12:09:06.848: INFO: stdout: "nodeport-test-c74s8"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:09:06.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8605" for this suite. 11/26/22 12:09:06.854
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":69,"skipped":1239,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.253 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:08:56.612
    Nov 26 12:08:56.612: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:08:56.613
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:08:56.634
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:08:56.64
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-8605 11/26/22 12:08:56.646
    STEP: creating replication controller nodeport-test in namespace services-8605 11/26/22 12:08:56.674
    I1126 12:08:56.698445      19 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-8605, replica count: 2
    I1126 12:08:59.750722      19 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 12:08:59.750: INFO: Creating new exec pod
    Nov 26 12:08:59.761: INFO: Waiting up to 5m0s for pod "execpodtpx4q" in namespace "services-8605" to be "running"
    Nov 26 12:08:59.770: INFO: Pod "execpodtpx4q": Phase="Pending", Reason="", readiness=false. Elapsed: 9.54008ms
    Nov 26 12:09:01.779: INFO: Pod "execpodtpx4q": Phase="Running", Reason="", readiness=true. Elapsed: 2.017674914s
    Nov 26 12:09:01.779: INFO: Pod "execpodtpx4q" satisfied condition "running"
    Nov 26 12:09:02.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Nov 26 12:09:02.984: INFO: stderr: "+ + echonc -v hostName\n -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Nov 26 12:09:02.984: INFO: stdout: ""
    Nov 26 12:09:03.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Nov 26 12:09:04.165: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Nov 26 12:09:04.165: INFO: stdout: ""
    Nov 26 12:09:04.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Nov 26 12:09:05.178: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Nov 26 12:09:05.178: INFO: stdout: "nodeport-test-v2zd9"
    Nov 26 12:09:05.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.48 80'
    Nov 26 12:09:05.355: INFO: stderr: "+ nc -v -t -w 2 10.152.183.48 80\nConnection to 10.152.183.48 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Nov 26 12:09:05.355: INFO: stdout: "nodeport-test-v2zd9"
    Nov 26 12:09:05.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 31699'
    Nov 26 12:09:05.535: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.29.104 31699\nConnection to 172.31.29.104 31699 port [tcp/*] succeeded!\n"
    Nov 26 12:09:05.535: INFO: stdout: ""
    Nov 26 12:09:06.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 31699'
    Nov 26 12:09:06.686: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.29.104 31699\nConnection to 172.31.29.104 31699 port [tcp/*] succeeded!\n"
    Nov 26 12:09:06.686: INFO: stdout: "nodeport-test-v2zd9"
    Nov 26 12:09:06.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8605 exec execpodtpx4q -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.82 31699'
    Nov 26 12:09:06.848: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.43.82 31699\nConnection to 172.31.43.82 31699 port [tcp/*] succeeded!\n"
    Nov 26 12:09:06.848: INFO: stdout: "nodeport-test-c74s8"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:09:06.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8605" for this suite. 11/26/22 12:09:06.854
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:09:06.867
Nov 26 12:09:06.867: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:09:06.868
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:06.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:06.898
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-20269358-8a5a-4475-b044-0d3c97fbf19b 11/26/22 12:09:06.906
STEP: Creating a pod to test consume secrets 11/26/22 12:09:06.916
Nov 26 12:09:06.930: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1" in namespace "projected-3801" to be "Succeeded or Failed"
Nov 26 12:09:06.938: INFO: Pod "pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.735113ms
Nov 26 12:09:08.945: INFO: Pod "pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013898545s
Nov 26 12:09:10.944: INFO: Pod "pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013447034s
STEP: Saw pod success 11/26/22 12:09:10.944
Nov 26 12:09:10.944: INFO: Pod "pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1" satisfied condition "Succeeded or Failed"
Nov 26 12:09:10.949: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/26/22 12:09:10.959
Nov 26 12:09:10.978: INFO: Waiting for pod pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1 to disappear
Nov 26 12:09:10.983: INFO: Pod pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 26 12:09:10.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3801" for this suite. 11/26/22 12:09:10.987
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":70,"skipped":1259,"failed":0}
------------------------------
â€¢ [4.137 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:09:06.867
    Nov 26 12:09:06.867: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:09:06.868
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:06.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:06.898
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-20269358-8a5a-4475-b044-0d3c97fbf19b 11/26/22 12:09:06.906
    STEP: Creating a pod to test consume secrets 11/26/22 12:09:06.916
    Nov 26 12:09:06.930: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1" in namespace "projected-3801" to be "Succeeded or Failed"
    Nov 26 12:09:06.938: INFO: Pod "pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.735113ms
    Nov 26 12:09:08.945: INFO: Pod "pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013898545s
    Nov 26 12:09:10.944: INFO: Pod "pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013447034s
    STEP: Saw pod success 11/26/22 12:09:10.944
    Nov 26 12:09:10.944: INFO: Pod "pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1" satisfied condition "Succeeded or Failed"
    Nov 26 12:09:10.949: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:09:10.959
    Nov 26 12:09:10.978: INFO: Waiting for pod pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1 to disappear
    Nov 26 12:09:10.983: INFO: Pod pod-projected-secrets-7b83e0c8-c4a5-449f-a553-7ebf9f6fd6d1 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 26 12:09:10.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3801" for this suite. 11/26/22 12:09:10.987
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:09:11.014
Nov 26 12:09:11.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:09:11.015
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:11.033
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:11.038
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 11/26/22 12:09:11.043
Nov 26 12:09:11.056: INFO: Waiting up to 5m0s for pod "pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7" in namespace "emptydir-6170" to be "Succeeded or Failed"
Nov 26 12:09:11.065: INFO: Pod "pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.51356ms
Nov 26 12:09:13.073: INFO: Pod "pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01697338s
Nov 26 12:09:15.070: INFO: Pod "pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014709026s
STEP: Saw pod success 11/26/22 12:09:15.071
Nov 26 12:09:15.071: INFO: Pod "pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7" satisfied condition "Succeeded or Failed"
Nov 26 12:09:15.076: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7 container test-container: <nil>
STEP: delete the pod 11/26/22 12:09:15.085
Nov 26 12:09:15.116: INFO: Waiting for pod pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7 to disappear
Nov 26 12:09:15.121: INFO: Pod pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:09:15.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6170" for this suite. 11/26/22 12:09:15.127
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":71,"skipped":1339,"failed":0}
------------------------------
â€¢ [4.123 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:09:11.014
    Nov 26 12:09:11.014: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:09:11.015
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:11.033
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:11.038
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 11/26/22 12:09:11.043
    Nov 26 12:09:11.056: INFO: Waiting up to 5m0s for pod "pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7" in namespace "emptydir-6170" to be "Succeeded or Failed"
    Nov 26 12:09:11.065: INFO: Pod "pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.51356ms
    Nov 26 12:09:13.073: INFO: Pod "pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01697338s
    Nov 26 12:09:15.070: INFO: Pod "pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014709026s
    STEP: Saw pod success 11/26/22 12:09:15.071
    Nov 26 12:09:15.071: INFO: Pod "pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7" satisfied condition "Succeeded or Failed"
    Nov 26 12:09:15.076: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7 container test-container: <nil>
    STEP: delete the pod 11/26/22 12:09:15.085
    Nov 26 12:09:15.116: INFO: Waiting for pod pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7 to disappear
    Nov 26 12:09:15.121: INFO: Pod pod-d5bb1c51-336e-4df1-b7f2-debdc7eb93a7 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:09:15.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6170" for this suite. 11/26/22 12:09:15.127
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:09:15.138
Nov 26 12:09:15.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:09:15.139
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:15.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:15.223
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 11/26/22 12:09:15.228
Nov 26 12:09:15.284: INFO: Waiting up to 5m0s for pod "pod-c4141ced-5e30-4013-888b-c830f1597c9f" in namespace "emptydir-6567" to be "Succeeded or Failed"
Nov 26 12:09:15.290: INFO: Pod "pod-c4141ced-5e30-4013-888b-c830f1597c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.582164ms
Nov 26 12:09:17.296: INFO: Pod "pod-c4141ced-5e30-4013-888b-c830f1597c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011149582s
Nov 26 12:09:19.296: INFO: Pod "pod-c4141ced-5e30-4013-888b-c830f1597c9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011947514s
STEP: Saw pod success 11/26/22 12:09:19.296
Nov 26 12:09:19.297: INFO: Pod "pod-c4141ced-5e30-4013-888b-c830f1597c9f" satisfied condition "Succeeded or Failed"
Nov 26 12:09:19.306: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-c4141ced-5e30-4013-888b-c830f1597c9f container test-container: <nil>
STEP: delete the pod 11/26/22 12:09:19.315
Nov 26 12:09:19.350: INFO: Waiting for pod pod-c4141ced-5e30-4013-888b-c830f1597c9f to disappear
Nov 26 12:09:19.520: INFO: Pod pod-c4141ced-5e30-4013-888b-c830f1597c9f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:09:19.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6567" for this suite. 11/26/22 12:09:19.527
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":72,"skipped":1358,"failed":0}
------------------------------
â€¢ [4.448 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:09:15.138
    Nov 26 12:09:15.138: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:09:15.139
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:15.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:15.223
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 11/26/22 12:09:15.228
    Nov 26 12:09:15.284: INFO: Waiting up to 5m0s for pod "pod-c4141ced-5e30-4013-888b-c830f1597c9f" in namespace "emptydir-6567" to be "Succeeded or Failed"
    Nov 26 12:09:15.290: INFO: Pod "pod-c4141ced-5e30-4013-888b-c830f1597c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.582164ms
    Nov 26 12:09:17.296: INFO: Pod "pod-c4141ced-5e30-4013-888b-c830f1597c9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011149582s
    Nov 26 12:09:19.296: INFO: Pod "pod-c4141ced-5e30-4013-888b-c830f1597c9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011947514s
    STEP: Saw pod success 11/26/22 12:09:19.296
    Nov 26 12:09:19.297: INFO: Pod "pod-c4141ced-5e30-4013-888b-c830f1597c9f" satisfied condition "Succeeded or Failed"
    Nov 26 12:09:19.306: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-c4141ced-5e30-4013-888b-c830f1597c9f container test-container: <nil>
    STEP: delete the pod 11/26/22 12:09:19.315
    Nov 26 12:09:19.350: INFO: Waiting for pod pod-c4141ced-5e30-4013-888b-c830f1597c9f to disappear
    Nov 26 12:09:19.520: INFO: Pod pod-c4141ced-5e30-4013-888b-c830f1597c9f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:09:19.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6567" for this suite. 11/26/22 12:09:19.527
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:09:19.588
Nov 26 12:09:19.588: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replicaset 11/26/22 12:09:19.589
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:19.692
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:19.697
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Nov 26 12:09:19.703: INFO: Creating ReplicaSet my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9
Nov 26 12:09:19.777: INFO: Pod name my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9: Found 0 pods out of 1
Nov 26 12:09:24.784: INFO: Pod name my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9: Found 1 pods out of 1
Nov 26 12:09:24.784: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9" is running
Nov 26 12:09:24.784: INFO: Waiting up to 5m0s for pod "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt" in namespace "replicaset-1779" to be "running"
Nov 26 12:09:24.790: INFO: Pod "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt": Phase="Running", Reason="", readiness=true. Elapsed: 5.737127ms
Nov 26 12:09:24.790: INFO: Pod "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt" satisfied condition "running"
Nov 26 12:09:24.790: INFO: Pod "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 12:09:19 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 12:09:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 12:09:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 12:09:19 +0000 UTC Reason: Message:}])
Nov 26 12:09:24.790: INFO: Trying to dial the pod
Nov 26 12:09:29.808: INFO: Controller my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9: Got expected result from replica 1 [my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt]: "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 26 12:09:29.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1779" for this suite. 11/26/22 12:09:29.815
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":73,"skipped":1362,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.236 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:09:19.588
    Nov 26 12:09:19.588: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replicaset 11/26/22 12:09:19.589
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:19.692
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:19.697
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Nov 26 12:09:19.703: INFO: Creating ReplicaSet my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9
    Nov 26 12:09:19.777: INFO: Pod name my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9: Found 0 pods out of 1
    Nov 26 12:09:24.784: INFO: Pod name my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9: Found 1 pods out of 1
    Nov 26 12:09:24.784: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9" is running
    Nov 26 12:09:24.784: INFO: Waiting up to 5m0s for pod "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt" in namespace "replicaset-1779" to be "running"
    Nov 26 12:09:24.790: INFO: Pod "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt": Phase="Running", Reason="", readiness=true. Elapsed: 5.737127ms
    Nov 26 12:09:24.790: INFO: Pod "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt" satisfied condition "running"
    Nov 26 12:09:24.790: INFO: Pod "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 12:09:19 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 12:09:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 12:09:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 12:09:19 +0000 UTC Reason: Message:}])
    Nov 26 12:09:24.790: INFO: Trying to dial the pod
    Nov 26 12:09:29.808: INFO: Controller my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9: Got expected result from replica 1 [my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt]: "my-hostname-basic-0046fe75-de8b-4d2e-a27a-5e4e93826da9-xlgnt", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 26 12:09:29.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1779" for this suite. 11/26/22 12:09:29.815
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:09:29.827
Nov 26 12:09:29.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pod-network-test 11/26/22 12:09:29.829
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:29.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:29.993
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-1771 11/26/22 12:09:30.026
STEP: creating a selector 11/26/22 12:09:30.026
STEP: Creating the service pods in kubernetes 11/26/22 12:09:30.026
Nov 26 12:09:30.026: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 26 12:09:30.421: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1771" to be "running and ready"
Nov 26 12:09:30.429: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.622404ms
Nov 26 12:09:30.429: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:09:32.437: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.016153867s
Nov 26 12:09:32.437: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:09:34.480: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.059198455s
Nov 26 12:09:34.480: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:09:36.585: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.163993117s
Nov 26 12:09:36.585: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:09:38.436: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.015165473s
Nov 26 12:09:38.436: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:09:40.437: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.016284842s
Nov 26 12:09:40.437: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:09:42.436: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.014994888s
Nov 26 12:09:42.436: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:09:44.436: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.014996703s
Nov 26 12:09:44.436: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:09:46.437: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.016021888s
Nov 26 12:09:46.437: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:09:48.436: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.015082375s
Nov 26 12:09:48.436: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:09:50.435: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.014054594s
Nov 26 12:09:50.435: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:09:52.436: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.014961886s
Nov 26 12:09:52.436: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 26 12:09:52.436: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 26 12:09:52.442: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1771" to be "running and ready"
Nov 26 12:09:52.447: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.946609ms
Nov 26 12:09:52.447: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 26 12:09:52.447: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 26 12:09:52.452: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-1771" to be "running and ready"
Nov 26 12:09:52.459: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.177044ms
Nov 26 12:09:52.459: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 26 12:09:52.459: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/26/22 12:09:52.463
Nov 26 12:09:52.491: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1771" to be "running"
Nov 26 12:09:52.500: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.509824ms
Nov 26 12:09:54.506: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014514933s
Nov 26 12:09:54.506: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 26 12:09:54.512: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1771" to be "running"
Nov 26 12:09:54.518: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.780856ms
Nov 26 12:09:54.518: INFO: Pod "host-test-container-pod" satisfied condition "running"
Nov 26 12:09:54.522: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 26 12:09:54.522: INFO: Going to poll 192.168.150.148 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov 26 12:09:54.528: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.150.148 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1771 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:09:54.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:09:54.529: INFO: ExecWithOptions: Clientset creation
Nov 26 12:09:54.529: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1771/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.150.148+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 26 12:09:55.622: INFO: Found all 1 expected endpoints: [netserver-0]
Nov 26 12:09:55.622: INFO: Going to poll 192.168.46.227 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov 26 12:09:55.628: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.46.227 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1771 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:09:55.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:09:55.629: INFO: ExecWithOptions: Clientset creation
Nov 26 12:09:55.629: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1771/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.46.227+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 26 12:09:56.717: INFO: Found all 1 expected endpoints: [netserver-1]
Nov 26 12:09:56.717: INFO: Going to poll 192.168.34.63 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov 26 12:09:56.725: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.34.63 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1771 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:09:56.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:09:56.725: INFO: ExecWithOptions: Clientset creation
Nov 26 12:09:56.726: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1771/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.34.63+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 26 12:09:57.810: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 26 12:09:57.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1771" for this suite. 11/26/22 12:09:57.816
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":74,"skipped":1380,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.001 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:09:29.827
    Nov 26 12:09:29.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pod-network-test 11/26/22 12:09:29.829
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:29.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:29.993
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-1771 11/26/22 12:09:30.026
    STEP: creating a selector 11/26/22 12:09:30.026
    STEP: Creating the service pods in kubernetes 11/26/22 12:09:30.026
    Nov 26 12:09:30.026: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 26 12:09:30.421: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1771" to be "running and ready"
    Nov 26 12:09:30.429: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.622404ms
    Nov 26 12:09:30.429: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:09:32.437: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.016153867s
    Nov 26 12:09:32.437: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:09:34.480: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.059198455s
    Nov 26 12:09:34.480: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:09:36.585: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.163993117s
    Nov 26 12:09:36.585: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:09:38.436: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.015165473s
    Nov 26 12:09:38.436: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:09:40.437: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.016284842s
    Nov 26 12:09:40.437: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:09:42.436: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.014994888s
    Nov 26 12:09:42.436: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:09:44.436: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.014996703s
    Nov 26 12:09:44.436: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:09:46.437: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.016021888s
    Nov 26 12:09:46.437: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:09:48.436: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.015082375s
    Nov 26 12:09:48.436: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:09:50.435: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.014054594s
    Nov 26 12:09:50.435: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:09:52.436: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.014961886s
    Nov 26 12:09:52.436: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 26 12:09:52.436: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 26 12:09:52.442: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1771" to be "running and ready"
    Nov 26 12:09:52.447: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.946609ms
    Nov 26 12:09:52.447: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 26 12:09:52.447: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 26 12:09:52.452: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-1771" to be "running and ready"
    Nov 26 12:09:52.459: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 6.177044ms
    Nov 26 12:09:52.459: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 26 12:09:52.459: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/26/22 12:09:52.463
    Nov 26 12:09:52.491: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1771" to be "running"
    Nov 26 12:09:52.500: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.509824ms
    Nov 26 12:09:54.506: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014514933s
    Nov 26 12:09:54.506: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 26 12:09:54.512: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1771" to be "running"
    Nov 26 12:09:54.518: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 5.780856ms
    Nov 26 12:09:54.518: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Nov 26 12:09:54.522: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 26 12:09:54.522: INFO: Going to poll 192.168.150.148 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov 26 12:09:54.528: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.150.148 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1771 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:09:54.528: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:09:54.529: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:09:54.529: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1771/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.150.148+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 26 12:09:55.622: INFO: Found all 1 expected endpoints: [netserver-0]
    Nov 26 12:09:55.622: INFO: Going to poll 192.168.46.227 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov 26 12:09:55.628: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.46.227 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1771 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:09:55.628: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:09:55.629: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:09:55.629: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1771/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.46.227+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 26 12:09:56.717: INFO: Found all 1 expected endpoints: [netserver-1]
    Nov 26 12:09:56.717: INFO: Going to poll 192.168.34.63 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov 26 12:09:56.725: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.34.63 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1771 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:09:56.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:09:56.725: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:09:56.726: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1771/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.34.63+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 26 12:09:57.810: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 26 12:09:57.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-1771" for this suite. 11/26/22 12:09:57.816
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:09:57.833
Nov 26 12:09:57.833: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sched-preemption 11/26/22 12:09:57.834
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:57.859
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:57.865
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 26 12:09:57.896: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 26 12:10:57.925: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:10:57.932
Nov 26 12:10:57.932: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sched-preemption-path 11/26/22 12:10:57.934
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:10:57.961
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:10:57.968
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 11/26/22 12:10:57.973
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/26/22 12:10:57.973
Nov 26 12:10:57.986: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-2994" to be "running"
Nov 26 12:10:57.995: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 8.616749ms
Nov 26 12:11:00.002: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.015894118s
Nov 26 12:11:00.002: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/26/22 12:11:00.007
Nov 26 12:11:00.022: INFO: found a healthy node: ip-172-31-43-82
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Nov 26 12:11:14.153: INFO: pods created so far: [1 1 1]
Nov 26 12:11:14.153: INFO: length of pods created so far: 3
Nov 26 12:11:16.171: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Nov 26 12:11:23.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-2994" for this suite. 11/26/22 12:11:23.186
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:11:23.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4369" for this suite. 11/26/22 12:11:23.265
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":75,"skipped":1435,"failed":0}
------------------------------
â€¢ [SLOW TEST] [85.509 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:09:57.833
    Nov 26 12:09:57.833: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sched-preemption 11/26/22 12:09:57.834
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:09:57.859
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:09:57.865
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 26 12:09:57.896: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 26 12:10:57.925: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:10:57.932
    Nov 26 12:10:57.932: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sched-preemption-path 11/26/22 12:10:57.934
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:10:57.961
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:10:57.968
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 11/26/22 12:10:57.973
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/26/22 12:10:57.973
    Nov 26 12:10:57.986: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-2994" to be "running"
    Nov 26 12:10:57.995: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 8.616749ms
    Nov 26 12:11:00.002: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.015894118s
    Nov 26 12:11:00.002: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/26/22 12:11:00.007
    Nov 26 12:11:00.022: INFO: found a healthy node: ip-172-31-43-82
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Nov 26 12:11:14.153: INFO: pods created so far: [1 1 1]
    Nov 26 12:11:14.153: INFO: length of pods created so far: 3
    Nov 26 12:11:16.171: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Nov 26 12:11:23.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-2994" for this suite. 11/26/22 12:11:23.186
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:11:23.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4369" for this suite. 11/26/22 12:11:23.265
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:11:23.346
Nov 26 12:11:23.346: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:11:23.348
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:11:23.422
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:11:23.427
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:11:23.458
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:11:24.207
STEP: Deploying the webhook pod 11/26/22 12:11:24.224
STEP: Wait for the deployment to be ready 11/26/22 12:11:24.242
Nov 26 12:11:24.259: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/26/22 12:11:26.278
STEP: Verifying the service has paired with the endpoint 11/26/22 12:11:26.292
Nov 26 12:11:27.293: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 11/26/22 12:11:27.298
STEP: Registering slow webhook via the AdmissionRegistration API 11/26/22 12:11:27.299
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 11/26/22 12:11:27.323
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 11/26/22 12:11:28.353
STEP: Registering slow webhook via the AdmissionRegistration API 11/26/22 12:11:28.353
STEP: Having no error when timeout is longer than webhook latency 11/26/22 12:11:29.402
STEP: Registering slow webhook via the AdmissionRegistration API 11/26/22 12:11:29.402
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 11/26/22 12:11:34.46
STEP: Registering slow webhook via the AdmissionRegistration API 11/26/22 12:11:34.46
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:11:39.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4696" for this suite. 11/26/22 12:11:39.517
STEP: Destroying namespace "webhook-4696-markers" for this suite. 11/26/22 12:11:39.527
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":76,"skipped":1448,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.259 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:11:23.346
    Nov 26 12:11:23.346: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:11:23.348
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:11:23.422
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:11:23.427
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:11:23.458
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:11:24.207
    STEP: Deploying the webhook pod 11/26/22 12:11:24.224
    STEP: Wait for the deployment to be ready 11/26/22 12:11:24.242
    Nov 26 12:11:24.259: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/26/22 12:11:26.278
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:11:26.292
    Nov 26 12:11:27.293: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 11/26/22 12:11:27.298
    STEP: Registering slow webhook via the AdmissionRegistration API 11/26/22 12:11:27.299
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 11/26/22 12:11:27.323
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 11/26/22 12:11:28.353
    STEP: Registering slow webhook via the AdmissionRegistration API 11/26/22 12:11:28.353
    STEP: Having no error when timeout is longer than webhook latency 11/26/22 12:11:29.402
    STEP: Registering slow webhook via the AdmissionRegistration API 11/26/22 12:11:29.402
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 11/26/22 12:11:34.46
    STEP: Registering slow webhook via the AdmissionRegistration API 11/26/22 12:11:34.46
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:11:39.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4696" for this suite. 11/26/22 12:11:39.517
    STEP: Destroying namespace "webhook-4696-markers" for this suite. 11/26/22 12:11:39.527
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:11:39.606
Nov 26 12:11:39.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 12:11:39.607
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:11:39.644
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:11:39.66
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-da209af5-692b-44e3-902d-e8a061c8949e 11/26/22 12:11:39.671
STEP: Creating the pod 11/26/22 12:11:39.679
Nov 26 12:11:39.701: INFO: Waiting up to 5m0s for pod "pod-configmaps-e50be947-d56c-4b4c-a948-0bb6d334b356" in namespace "configmap-7825" to be "running"
Nov 26 12:11:39.712: INFO: Pod "pod-configmaps-e50be947-d56c-4b4c-a948-0bb6d334b356": Phase="Pending", Reason="", readiness=false. Elapsed: 11.235217ms
Nov 26 12:11:41.719: INFO: Pod "pod-configmaps-e50be947-d56c-4b4c-a948-0bb6d334b356": Phase="Running", Reason="", readiness=false. Elapsed: 2.018489632s
Nov 26 12:11:41.720: INFO: Pod "pod-configmaps-e50be947-d56c-4b4c-a948-0bb6d334b356" satisfied condition "running"
STEP: Waiting for pod with text data 11/26/22 12:11:41.72
STEP: Waiting for pod with binary data 11/26/22 12:11:41.743
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 12:11:41.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7825" for this suite. 11/26/22 12:11:41.777
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":77,"skipped":1451,"failed":0}
------------------------------
â€¢ [2.182 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:11:39.606
    Nov 26 12:11:39.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 12:11:39.607
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:11:39.644
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:11:39.66
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-da209af5-692b-44e3-902d-e8a061c8949e 11/26/22 12:11:39.671
    STEP: Creating the pod 11/26/22 12:11:39.679
    Nov 26 12:11:39.701: INFO: Waiting up to 5m0s for pod "pod-configmaps-e50be947-d56c-4b4c-a948-0bb6d334b356" in namespace "configmap-7825" to be "running"
    Nov 26 12:11:39.712: INFO: Pod "pod-configmaps-e50be947-d56c-4b4c-a948-0bb6d334b356": Phase="Pending", Reason="", readiness=false. Elapsed: 11.235217ms
    Nov 26 12:11:41.719: INFO: Pod "pod-configmaps-e50be947-d56c-4b4c-a948-0bb6d334b356": Phase="Running", Reason="", readiness=false. Elapsed: 2.018489632s
    Nov 26 12:11:41.720: INFO: Pod "pod-configmaps-e50be947-d56c-4b4c-a948-0bb6d334b356" satisfied condition "running"
    STEP: Waiting for pod with text data 11/26/22 12:11:41.72
    STEP: Waiting for pod with binary data 11/26/22 12:11:41.743
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 12:11:41.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7825" for this suite. 11/26/22 12:11:41.777
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:11:41.794
Nov 26 12:11:41.795: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:11:41.796
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:11:41.819
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:11:41.824
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 11/26/22 12:11:41.83
Nov 26 12:11:41.830: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6650 proxy --unix-socket=/tmp/kubectl-proxy-unix825313188/test'
STEP: retrieving proxy /api/ output 11/26/22 12:11:41.931
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:11:41.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6650" for this suite. 11/26/22 12:11:41.938
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":78,"skipped":1455,"failed":0}
------------------------------
â€¢ [0.153 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:11:41.794
    Nov 26 12:11:41.795: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:11:41.796
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:11:41.819
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:11:41.824
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 11/26/22 12:11:41.83
    Nov 26 12:11:41.830: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6650 proxy --unix-socket=/tmp/kubectl-proxy-unix825313188/test'
    STEP: retrieving proxy /api/ output 11/26/22 12:11:41.931
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:11:41.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6650" for this suite. 11/26/22 12:11:41.938
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:11:41.948
Nov 26 12:11:41.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:11:41.949
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:11:41.984
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:11:41.989
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 11/26/22 12:11:41.995
Nov 26 12:11:42.009: INFO: Waiting up to 5m0s for pod "labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47" in namespace "projected-9498" to be "running and ready"
Nov 26 12:11:42.023: INFO: Pod "labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47": Phase="Pending", Reason="", readiness=false. Elapsed: 14.16682ms
Nov 26 12:11:42.023: INFO: The phase of Pod labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:11:44.038: INFO: Pod "labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47": Phase="Running", Reason="", readiness=true. Elapsed: 2.02931726s
Nov 26 12:11:44.038: INFO: The phase of Pod labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47 is Running (Ready = true)
Nov 26 12:11:44.038: INFO: Pod "labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47" satisfied condition "running and ready"
Nov 26 12:11:44.587: INFO: Successfully updated pod "labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 12:11:48.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9498" for this suite. 11/26/22 12:11:48.626
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":79,"skipped":1464,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.688 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:11:41.948
    Nov 26 12:11:41.948: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:11:41.949
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:11:41.984
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:11:41.989
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 11/26/22 12:11:41.995
    Nov 26 12:11:42.009: INFO: Waiting up to 5m0s for pod "labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47" in namespace "projected-9498" to be "running and ready"
    Nov 26 12:11:42.023: INFO: Pod "labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47": Phase="Pending", Reason="", readiness=false. Elapsed: 14.16682ms
    Nov 26 12:11:42.023: INFO: The phase of Pod labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:11:44.038: INFO: Pod "labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47": Phase="Running", Reason="", readiness=true. Elapsed: 2.02931726s
    Nov 26 12:11:44.038: INFO: The phase of Pod labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47 is Running (Ready = true)
    Nov 26 12:11:44.038: INFO: Pod "labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47" satisfied condition "running and ready"
    Nov 26 12:11:44.587: INFO: Successfully updated pod "labelsupdatea61804b2-de9d-4dd3-94a8-7e27e191ff47"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 12:11:48.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9498" for this suite. 11/26/22 12:11:48.626
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:11:48.637
Nov 26 12:11:48.637: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pod-network-test 11/26/22 12:11:48.638
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:11:48.659
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:11:48.666
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-8826 11/26/22 12:11:48.672
STEP: creating a selector 11/26/22 12:11:48.673
STEP: Creating the service pods in kubernetes 11/26/22 12:11:48.674
Nov 26 12:11:48.674: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 26 12:11:48.717: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8826" to be "running and ready"
Nov 26 12:11:48.729: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.266931ms
Nov 26 12:11:48.729: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:11:50.734: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.016390234s
Nov 26 12:11:50.734: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:11:52.735: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017975562s
Nov 26 12:11:52.735: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:11:54.735: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017832197s
Nov 26 12:11:54.735: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:11:56.736: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.018507562s
Nov 26 12:11:56.736: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:11:58.734: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.017028892s
Nov 26 12:11:58.734: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:12:00.737: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.019416164s
Nov 26 12:12:00.737: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 26 12:12:00.737: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 26 12:12:00.742: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8826" to be "running and ready"
Nov 26 12:12:00.748: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 5.155708ms
Nov 26 12:12:00.748: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov 26 12:12:02.755: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.012712374s
Nov 26 12:12:02.756: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov 26 12:12:04.755: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.012652885s
Nov 26 12:12:04.755: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov 26 12:12:06.754: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.011056239s
Nov 26 12:12:06.754: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov 26 12:12:08.755: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.012020503s
Nov 26 12:12:08.755: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov 26 12:12:10.753: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.010464446s
Nov 26 12:12:10.753: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 26 12:12:10.753: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 26 12:12:10.762: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8826" to be "running and ready"
Nov 26 12:12:10.767: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 5.734911ms
Nov 26 12:12:10.767: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 26 12:12:10.767: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/26/22 12:12:10.772
Nov 26 12:12:10.782: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8826" to be "running"
Nov 26 12:12:10.794: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.618611ms
Nov 26 12:12:12.799: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016920056s
Nov 26 12:12:12.799: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 26 12:12:12.805: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 26 12:12:12.806: INFO: Breadth first check of 192.168.150.149 on host 172.31.0.249...
Nov 26 12:12:12.812: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.9:9080/dial?request=hostname&protocol=udp&host=192.168.150.149&port=8081&tries=1'] Namespace:pod-network-test-8826 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:12:12.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:12:12.812: INFO: ExecWithOptions: Clientset creation
Nov 26 12:12:12.812: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8826/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.9%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.150.149%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 26 12:12:12.910: INFO: Waiting for responses: map[]
Nov 26 12:12:12.910: INFO: reached 192.168.150.149 after 0/1 tries
Nov 26 12:12:12.910: INFO: Breadth first check of 192.168.46.229 on host 172.31.29.104...
Nov 26 12:12:12.916: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.9:9080/dial?request=hostname&protocol=udp&host=192.168.46.229&port=8081&tries=1'] Namespace:pod-network-test-8826 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:12:12.916: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:12:12.917: INFO: ExecWithOptions: Clientset creation
Nov 26 12:12:12.917: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8826/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.9%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.46.229%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 26 12:12:13.006: INFO: Waiting for responses: map[]
Nov 26 12:12:13.006: INFO: reached 192.168.46.229 after 0/1 tries
Nov 26 12:12:13.006: INFO: Breadth first check of 192.168.34.10 on host 172.31.43.82...
Nov 26 12:12:13.013: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.9:9080/dial?request=hostname&protocol=udp&host=192.168.34.10&port=8081&tries=1'] Namespace:pod-network-test-8826 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:12:13.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:12:13.015: INFO: ExecWithOptions: Clientset creation
Nov 26 12:12:13.015: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8826/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.9%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.34.10%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 26 12:12:13.099: INFO: Waiting for responses: map[]
Nov 26 12:12:13.099: INFO: reached 192.168.34.10 after 0/1 tries
Nov 26 12:12:13.099: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 26 12:12:13.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8826" for this suite. 11/26/22 12:12:13.114
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":80,"skipped":1465,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.487 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:11:48.637
    Nov 26 12:11:48.637: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pod-network-test 11/26/22 12:11:48.638
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:11:48.659
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:11:48.666
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-8826 11/26/22 12:11:48.672
    STEP: creating a selector 11/26/22 12:11:48.673
    STEP: Creating the service pods in kubernetes 11/26/22 12:11:48.674
    Nov 26 12:11:48.674: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 26 12:11:48.717: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-8826" to be "running and ready"
    Nov 26 12:11:48.729: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.266931ms
    Nov 26 12:11:48.729: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:11:50.734: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.016390234s
    Nov 26 12:11:50.734: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:11:52.735: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.017975562s
    Nov 26 12:11:52.735: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:11:54.735: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.017832197s
    Nov 26 12:11:54.735: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:11:56.736: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.018507562s
    Nov 26 12:11:56.736: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:11:58.734: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.017028892s
    Nov 26 12:11:58.734: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:12:00.737: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.019416164s
    Nov 26 12:12:00.737: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 26 12:12:00.737: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 26 12:12:00.742: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-8826" to be "running and ready"
    Nov 26 12:12:00.748: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 5.155708ms
    Nov 26 12:12:00.748: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov 26 12:12:02.755: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.012712374s
    Nov 26 12:12:02.756: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov 26 12:12:04.755: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.012652885s
    Nov 26 12:12:04.755: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov 26 12:12:06.754: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.011056239s
    Nov 26 12:12:06.754: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov 26 12:12:08.755: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.012020503s
    Nov 26 12:12:08.755: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov 26 12:12:10.753: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.010464446s
    Nov 26 12:12:10.753: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 26 12:12:10.753: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 26 12:12:10.762: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-8826" to be "running and ready"
    Nov 26 12:12:10.767: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 5.734911ms
    Nov 26 12:12:10.767: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 26 12:12:10.767: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/26/22 12:12:10.772
    Nov 26 12:12:10.782: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-8826" to be "running"
    Nov 26 12:12:10.794: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 11.618611ms
    Nov 26 12:12:12.799: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016920056s
    Nov 26 12:12:12.799: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 26 12:12:12.805: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 26 12:12:12.806: INFO: Breadth first check of 192.168.150.149 on host 172.31.0.249...
    Nov 26 12:12:12.812: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.9:9080/dial?request=hostname&protocol=udp&host=192.168.150.149&port=8081&tries=1'] Namespace:pod-network-test-8826 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:12:12.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:12:12.812: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:12:12.812: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8826/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.9%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.150.149%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 26 12:12:12.910: INFO: Waiting for responses: map[]
    Nov 26 12:12:12.910: INFO: reached 192.168.150.149 after 0/1 tries
    Nov 26 12:12:12.910: INFO: Breadth first check of 192.168.46.229 on host 172.31.29.104...
    Nov 26 12:12:12.916: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.9:9080/dial?request=hostname&protocol=udp&host=192.168.46.229&port=8081&tries=1'] Namespace:pod-network-test-8826 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:12:12.916: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:12:12.917: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:12:12.917: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8826/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.9%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.46.229%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 26 12:12:13.006: INFO: Waiting for responses: map[]
    Nov 26 12:12:13.006: INFO: reached 192.168.46.229 after 0/1 tries
    Nov 26 12:12:13.006: INFO: Breadth first check of 192.168.34.10 on host 172.31.43.82...
    Nov 26 12:12:13.013: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.9:9080/dial?request=hostname&protocol=udp&host=192.168.34.10&port=8081&tries=1'] Namespace:pod-network-test-8826 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:12:13.013: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:12:13.015: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:12:13.015: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-8826/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.9%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.34.10%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 26 12:12:13.099: INFO: Waiting for responses: map[]
    Nov 26 12:12:13.099: INFO: reached 192.168.34.10 after 0/1 tries
    Nov 26 12:12:13.099: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 26 12:12:13.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-8826" for this suite. 11/26/22 12:12:13.114
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:12:13.128
Nov 26 12:12:13.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename var-expansion 11/26/22 12:12:13.13
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:13.154
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:13.161
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 11/26/22 12:12:13.166
Nov 26 12:12:13.181: INFO: Waiting up to 5m0s for pod "var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38" in namespace "var-expansion-3773" to be "Succeeded or Failed"
Nov 26 12:12:13.193: INFO: Pod "var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38": Phase="Pending", Reason="", readiness=false. Elapsed: 12.246233ms
Nov 26 12:12:15.202: INFO: Pod "var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020551447s
Nov 26 12:12:17.200: INFO: Pod "var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018827713s
STEP: Saw pod success 11/26/22 12:12:17.2
Nov 26 12:12:17.200: INFO: Pod "var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38" satisfied condition "Succeeded or Failed"
Nov 26 12:12:17.206: INFO: Trying to get logs from node ip-172-31-43-82 pod var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38 container dapi-container: <nil>
STEP: delete the pod 11/26/22 12:12:17.216
Nov 26 12:12:17.237: INFO: Waiting for pod var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38 to disappear
Nov 26 12:12:17.242: INFO: Pod var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 26 12:12:17.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3773" for this suite. 11/26/22 12:12:17.249
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":81,"skipped":1491,"failed":0}
------------------------------
â€¢ [4.131 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:12:13.128
    Nov 26 12:12:13.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename var-expansion 11/26/22 12:12:13.13
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:13.154
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:13.161
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 11/26/22 12:12:13.166
    Nov 26 12:12:13.181: INFO: Waiting up to 5m0s for pod "var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38" in namespace "var-expansion-3773" to be "Succeeded or Failed"
    Nov 26 12:12:13.193: INFO: Pod "var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38": Phase="Pending", Reason="", readiness=false. Elapsed: 12.246233ms
    Nov 26 12:12:15.202: INFO: Pod "var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020551447s
    Nov 26 12:12:17.200: INFO: Pod "var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018827713s
    STEP: Saw pod success 11/26/22 12:12:17.2
    Nov 26 12:12:17.200: INFO: Pod "var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38" satisfied condition "Succeeded or Failed"
    Nov 26 12:12:17.206: INFO: Trying to get logs from node ip-172-31-43-82 pod var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38 container dapi-container: <nil>
    STEP: delete the pod 11/26/22 12:12:17.216
    Nov 26 12:12:17.237: INFO: Waiting for pod var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38 to disappear
    Nov 26 12:12:17.242: INFO: Pod var-expansion-a49932c5-a3ae-4bc9-87b5-b08f3127fc38 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 26 12:12:17.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3773" for this suite. 11/26/22 12:12:17.249
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:12:17.263
Nov 26 12:12:17.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:12:17.264
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:17.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:17.29
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 11/26/22 12:12:17.295
Nov 26 12:12:17.296: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:12:20.226: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:12:33.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2138" for this suite. 11/26/22 12:12:33.806
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":82,"skipped":1509,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.554 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:12:17.263
    Nov 26 12:12:17.263: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:12:17.264
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:17.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:17.29
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 11/26/22 12:12:17.295
    Nov 26 12:12:17.296: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:12:20.226: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:12:33.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2138" for this suite. 11/26/22 12:12:33.806
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:12:33.82
Nov 26 12:12:33.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename podtemplate 11/26/22 12:12:33.821
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:33.844
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:33.849
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 11/26/22 12:12:33.854
Nov 26 12:12:33.865: INFO: created test-podtemplate-1
Nov 26 12:12:33.872: INFO: created test-podtemplate-2
Nov 26 12:12:33.880: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 11/26/22 12:12:33.88
STEP: delete collection of pod templates 11/26/22 12:12:33.885
Nov 26 12:12:33.886: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 11/26/22 12:12:33.913
Nov 26 12:12:33.913: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 26 12:12:33.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-1218" for this suite. 11/26/22 12:12:33.924
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":83,"skipped":1539,"failed":0}
------------------------------
â€¢ [0.115 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:12:33.82
    Nov 26 12:12:33.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename podtemplate 11/26/22 12:12:33.821
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:33.844
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:33.849
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 11/26/22 12:12:33.854
    Nov 26 12:12:33.865: INFO: created test-podtemplate-1
    Nov 26 12:12:33.872: INFO: created test-podtemplate-2
    Nov 26 12:12:33.880: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 11/26/22 12:12:33.88
    STEP: delete collection of pod templates 11/26/22 12:12:33.885
    Nov 26 12:12:33.886: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 11/26/22 12:12:33.913
    Nov 26 12:12:33.913: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 26 12:12:33.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-1218" for this suite. 11/26/22 12:12:33.924
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:12:33.937
Nov 26 12:12:33.937: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 12:12:33.938
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:33.96
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:33.965
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:12:33.97
Nov 26 12:12:33.981: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b" in namespace "downward-api-2795" to be "Succeeded or Failed"
Nov 26 12:12:33.991: INFO: Pod "downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.254184ms
Nov 26 12:12:35.997: INFO: Pod "downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01617239s
Nov 26 12:12:37.997: INFO: Pod "downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016126425s
STEP: Saw pod success 11/26/22 12:12:37.997
Nov 26 12:12:37.998: INFO: Pod "downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b" satisfied condition "Succeeded or Failed"
Nov 26 12:12:38.002: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b container client-container: <nil>
STEP: delete the pod 11/26/22 12:12:38.012
Nov 26 12:12:38.042: INFO: Waiting for pod downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b to disappear
Nov 26 12:12:38.049: INFO: Pod downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 12:12:38.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2795" for this suite. 11/26/22 12:12:38.059
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":84,"skipped":1553,"failed":0}
------------------------------
â€¢ [4.133 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:12:33.937
    Nov 26 12:12:33.937: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 12:12:33.938
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:33.96
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:33.965
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:12:33.97
    Nov 26 12:12:33.981: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b" in namespace "downward-api-2795" to be "Succeeded or Failed"
    Nov 26 12:12:33.991: INFO: Pod "downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.254184ms
    Nov 26 12:12:35.997: INFO: Pod "downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01617239s
    Nov 26 12:12:37.997: INFO: Pod "downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016126425s
    STEP: Saw pod success 11/26/22 12:12:37.997
    Nov 26 12:12:37.998: INFO: Pod "downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b" satisfied condition "Succeeded or Failed"
    Nov 26 12:12:38.002: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b container client-container: <nil>
    STEP: delete the pod 11/26/22 12:12:38.012
    Nov 26 12:12:38.042: INFO: Waiting for pod downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b to disappear
    Nov 26 12:12:38.049: INFO: Pod downwardapi-volume-3a7b8e36-7450-45f2-81e1-205984bc8d6b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 12:12:38.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2795" for this suite. 11/26/22 12:12:38.059
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:12:38.072
Nov 26 12:12:38.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:12:38.074
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:38.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:38.107
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:12:38.136
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:12:38.636
STEP: Deploying the webhook pod 11/26/22 12:12:38.648
STEP: Wait for the deployment to be ready 11/26/22 12:12:38.667
Nov 26 12:12:38.678: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/26/22 12:12:40.698
STEP: Verifying the service has paired with the endpoint 11/26/22 12:12:40.715
Nov 26 12:12:41.716: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 11/26/22 12:12:41.827
STEP: Creating a configMap that does not comply to the validation webhook rules 11/26/22 12:12:41.878
STEP: Deleting the collection of validation webhooks 11/26/22 12:12:41.92
STEP: Creating a configMap that does not comply to the validation webhook rules 11/26/22 12:12:41.997
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:12:42.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8166" for this suite. 11/26/22 12:12:42.021
STEP: Destroying namespace "webhook-8166-markers" for this suite. 11/26/22 12:12:42.032
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":85,"skipped":1563,"failed":0}
------------------------------
â€¢ [4.066 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:12:38.072
    Nov 26 12:12:38.072: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:12:38.074
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:38.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:38.107
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:12:38.136
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:12:38.636
    STEP: Deploying the webhook pod 11/26/22 12:12:38.648
    STEP: Wait for the deployment to be ready 11/26/22 12:12:38.667
    Nov 26 12:12:38.678: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/26/22 12:12:40.698
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:12:40.715
    Nov 26 12:12:41.716: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 11/26/22 12:12:41.827
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/26/22 12:12:41.878
    STEP: Deleting the collection of validation webhooks 11/26/22 12:12:41.92
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/26/22 12:12:41.997
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:12:42.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8166" for this suite. 11/26/22 12:12:42.021
    STEP: Destroying namespace "webhook-8166-markers" for this suite. 11/26/22 12:12:42.032
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:12:42.142
Nov 26 12:12:42.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename var-expansion 11/26/22 12:12:42.144
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:42.171
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:42.175
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 11/26/22 12:12:42.182
Nov 26 12:12:42.193: INFO: Waiting up to 5m0s for pod "var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13" in namespace "var-expansion-915" to be "Succeeded or Failed"
Nov 26 12:12:42.198: INFO: Pod "var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13": Phase="Pending", Reason="", readiness=false. Elapsed: 5.030346ms
Nov 26 12:12:44.204: INFO: Pod "var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13": Phase="Running", Reason="", readiness=false. Elapsed: 2.011316277s
Nov 26 12:12:46.204: INFO: Pod "var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010933012s
STEP: Saw pod success 11/26/22 12:12:46.204
Nov 26 12:12:46.204: INFO: Pod "var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13" satisfied condition "Succeeded or Failed"
Nov 26 12:12:46.209: INFO: Trying to get logs from node ip-172-31-43-82 pod var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13 container dapi-container: <nil>
STEP: delete the pod 11/26/22 12:12:46.219
Nov 26 12:12:46.241: INFO: Waiting for pod var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13 to disappear
Nov 26 12:12:46.247: INFO: Pod var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 26 12:12:46.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-915" for this suite. 11/26/22 12:12:46.253
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":86,"skipped":1628,"failed":0}
------------------------------
â€¢ [4.121 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:12:42.142
    Nov 26 12:12:42.143: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename var-expansion 11/26/22 12:12:42.144
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:42.171
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:42.175
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 11/26/22 12:12:42.182
    Nov 26 12:12:42.193: INFO: Waiting up to 5m0s for pod "var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13" in namespace "var-expansion-915" to be "Succeeded or Failed"
    Nov 26 12:12:42.198: INFO: Pod "var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13": Phase="Pending", Reason="", readiness=false. Elapsed: 5.030346ms
    Nov 26 12:12:44.204: INFO: Pod "var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13": Phase="Running", Reason="", readiness=false. Elapsed: 2.011316277s
    Nov 26 12:12:46.204: INFO: Pod "var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010933012s
    STEP: Saw pod success 11/26/22 12:12:46.204
    Nov 26 12:12:46.204: INFO: Pod "var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13" satisfied condition "Succeeded or Failed"
    Nov 26 12:12:46.209: INFO: Trying to get logs from node ip-172-31-43-82 pod var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13 container dapi-container: <nil>
    STEP: delete the pod 11/26/22 12:12:46.219
    Nov 26 12:12:46.241: INFO: Waiting for pod var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13 to disappear
    Nov 26 12:12:46.247: INFO: Pod var-expansion-51004fef-f636-4a89-b4b4-ea1a2053aa13 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 26 12:12:46.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-915" for this suite. 11/26/22 12:12:46.253
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:12:46.264
Nov 26 12:12:46.264: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename statefulset 11/26/22 12:12:46.265
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:46.293
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:46.298
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3433 11/26/22 12:12:46.304
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Nov 26 12:12:46.333: INFO: Found 0 stateful pods, waiting for 1
Nov 26 12:12:56.341: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 11/26/22 12:12:56.351
W1126 12:12:56.367356      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 26 12:12:56.379: INFO: Found 1 stateful pods, waiting for 2
Nov 26 12:13:06.388: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 12:13:06.388: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 11/26/22 12:13:06.399
STEP: Delete all of the StatefulSets 11/26/22 12:13:06.405
STEP: Verify that StatefulSets have been deleted 11/26/22 12:13:06.421
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 26 12:13:06.439: INFO: Deleting all statefulset in ns statefulset-3433
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 26 12:13:06.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3433" for this suite. 11/26/22 12:13:06.481
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":87,"skipped":1628,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.233 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:12:46.264
    Nov 26 12:12:46.264: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename statefulset 11/26/22 12:12:46.265
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:12:46.293
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:12:46.298
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3433 11/26/22 12:12:46.304
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Nov 26 12:12:46.333: INFO: Found 0 stateful pods, waiting for 1
    Nov 26 12:12:56.341: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 11/26/22 12:12:56.351
    W1126 12:12:56.367356      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 26 12:12:56.379: INFO: Found 1 stateful pods, waiting for 2
    Nov 26 12:13:06.388: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 12:13:06.388: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 11/26/22 12:13:06.399
    STEP: Delete all of the StatefulSets 11/26/22 12:13:06.405
    STEP: Verify that StatefulSets have been deleted 11/26/22 12:13:06.421
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 26 12:13:06.439: INFO: Deleting all statefulset in ns statefulset-3433
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 26 12:13:06.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3433" for this suite. 11/26/22 12:13:06.481
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:13:06.499
Nov 26 12:13:06.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sched-preemption 11/26/22 12:13:06.5
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:13:06.522
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:13:06.53
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 26 12:13:06.562: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 26 12:14:06.591: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:14:06.597
Nov 26 12:14:06.597: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sched-preemption-path 11/26/22 12:14:06.598
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:14:06.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:14:06.625
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Nov 26 12:14:06.654: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Nov 26 12:14:06.660: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Nov 26 12:14:06.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-8481" for this suite. 11/26/22 12:14:06.7
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:14:06.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-592" for this suite. 11/26/22 12:14:06.735
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":88,"skipped":1636,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.312 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:13:06.499
    Nov 26 12:13:06.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sched-preemption 11/26/22 12:13:06.5
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:13:06.522
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:13:06.53
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 26 12:13:06.562: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 26 12:14:06.591: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:14:06.597
    Nov 26 12:14:06.597: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sched-preemption-path 11/26/22 12:14:06.598
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:14:06.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:14:06.625
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Nov 26 12:14:06.654: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Nov 26 12:14:06.660: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Nov 26 12:14:06.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-8481" for this suite. 11/26/22 12:14:06.7
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:14:06.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-592" for this suite. 11/26/22 12:14:06.735
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:14:06.813
Nov 26 12:14:06.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-probe 11/26/22 12:14:06.814
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:14:06.835
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:14:06.839
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50 in namespace container-probe-7061 11/26/22 12:14:06.844
Nov 26 12:14:06.863: INFO: Waiting up to 5m0s for pod "liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50" in namespace "container-probe-7061" to be "not pending"
Nov 26 12:14:06.872: INFO: Pod "liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50": Phase="Pending", Reason="", readiness=false. Elapsed: 8.577699ms
Nov 26 12:14:08.880: INFO: Pod "liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50": Phase="Running", Reason="", readiness=true. Elapsed: 2.016648363s
Nov 26 12:14:08.880: INFO: Pod "liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50" satisfied condition "not pending"
Nov 26 12:14:08.880: INFO: Started pod liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50 in namespace container-probe-7061
STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 12:14:08.88
Nov 26 12:14:08.886: INFO: Initial restart count of pod liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50 is 0
Nov 26 12:14:28.970: INFO: Restart count of pod container-probe-7061/liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50 is now 1 (20.083725833s elapsed)
STEP: deleting the pod 11/26/22 12:14:28.97
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 26 12:14:28.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7061" for this suite. 11/26/22 12:14:29.003
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":89,"skipped":1659,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.205 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:14:06.813
    Nov 26 12:14:06.813: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-probe 11/26/22 12:14:06.814
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:14:06.835
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:14:06.839
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50 in namespace container-probe-7061 11/26/22 12:14:06.844
    Nov 26 12:14:06.863: INFO: Waiting up to 5m0s for pod "liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50" in namespace "container-probe-7061" to be "not pending"
    Nov 26 12:14:06.872: INFO: Pod "liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50": Phase="Pending", Reason="", readiness=false. Elapsed: 8.577699ms
    Nov 26 12:14:08.880: INFO: Pod "liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50": Phase="Running", Reason="", readiness=true. Elapsed: 2.016648363s
    Nov 26 12:14:08.880: INFO: Pod "liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50" satisfied condition "not pending"
    Nov 26 12:14:08.880: INFO: Started pod liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50 in namespace container-probe-7061
    STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 12:14:08.88
    Nov 26 12:14:08.886: INFO: Initial restart count of pod liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50 is 0
    Nov 26 12:14:28.970: INFO: Restart count of pod container-probe-7061/liveness-8642e3f0-73bc-4086-8481-c6dcbea98a50 is now 1 (20.083725833s elapsed)
    STEP: deleting the pod 11/26/22 12:14:28.97
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 26 12:14:28.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7061" for this suite. 11/26/22 12:14:29.003
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:14:29.02
Nov 26 12:14:29.020: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:14:29.021
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:14:29.049
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:14:29.058
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-9784 11/26/22 12:14:29.066
Nov 26 12:14:29.077: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-9784" to be "running and ready"
Nov 26 12:14:29.089: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 11.005931ms
Nov 26 12:14:29.089: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:14:31.097: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.019740381s
Nov 26 12:14:31.097: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Nov 26 12:14:31.097: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Nov 26 12:14:31.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Nov 26 12:14:31.309: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Nov 26 12:14:31.309: INFO: stdout: "iptables"
Nov 26 12:14:31.309: INFO: proxyMode: iptables
Nov 26 12:14:31.330: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Nov 26 12:14:31.336: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-9784 11/26/22 12:14:31.336
STEP: creating replication controller affinity-nodeport-timeout in namespace services-9784 11/26/22 12:14:31.362
I1126 12:14:31.389185      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-9784, replica count: 3
I1126 12:14:34.440939      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 12:14:34.469: INFO: Creating new exec pod
Nov 26 12:14:34.499: INFO: Waiting up to 5m0s for pod "execpod-affinity94jdb" in namespace "services-9784" to be "running"
Nov 26 12:14:34.510: INFO: Pod "execpod-affinity94jdb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.099594ms
Nov 26 12:14:36.517: INFO: Pod "execpod-affinity94jdb": Phase="Running", Reason="", readiness=true. Elapsed: 2.018190118s
Nov 26 12:14:36.517: INFO: Pod "execpod-affinity94jdb" satisfied condition "running"
Nov 26 12:14:37.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Nov 26 12:14:37.742: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Nov 26 12:14:37.742: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:14:37.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.26 80'
Nov 26 12:14:37.957: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.26 80\nConnection to 10.152.183.26 80 port [tcp/http] succeeded!\n"
Nov 26 12:14:37.957: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:14:37.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.249 32597'
Nov 26 12:14:38.176: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.0.249 32597\nConnection to 172.31.0.249 32597 port [tcp/*] succeeded!\n"
Nov 26 12:14:38.176: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:14:38.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.82 32597'
Nov 26 12:14:38.375: INFO: stderr: "+ nc -v -t -w 2 172.31.43.82 32597\n+ echo hostName\nConnection to 172.31.43.82 32597 port [tcp/*] succeeded!\n"
Nov 26 12:14:38.375: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:14:38.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.249:32597/ ; done'
Nov 26 12:14:38.697: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n"
Nov 26 12:14:38.697: INFO: stdout: "\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9"
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
Nov 26 12:14:38.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.0.249:32597/'
Nov 26 12:14:38.921: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n"
Nov 26 12:14:38.921: INFO: stdout: "affinity-nodeport-timeout-g4rh9"
Nov 26 12:14:58.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.0.249:32597/'
Nov 26 12:14:59.093: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n"
Nov 26 12:14:59.093: INFO: stdout: "affinity-nodeport-timeout-tj5cw"
Nov 26 12:14:59.093: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-9784, will wait for the garbage collector to delete the pods 11/26/22 12:14:59.114
Nov 26 12:14:59.182: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 11.456904ms
Nov 26 12:14:59.283: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.761437ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:15:01.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9784" for this suite. 11/26/22 12:15:01.644
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":90,"skipped":1673,"failed":0}
------------------------------
â€¢ [SLOW TEST] [32.640 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:14:29.02
    Nov 26 12:14:29.020: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:14:29.021
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:14:29.049
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:14:29.058
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-9784 11/26/22 12:14:29.066
    Nov 26 12:14:29.077: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-9784" to be "running and ready"
    Nov 26 12:14:29.089: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 11.005931ms
    Nov 26 12:14:29.089: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:14:31.097: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.019740381s
    Nov 26 12:14:31.097: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Nov 26 12:14:31.097: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Nov 26 12:14:31.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Nov 26 12:14:31.309: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Nov 26 12:14:31.309: INFO: stdout: "iptables"
    Nov 26 12:14:31.309: INFO: proxyMode: iptables
    Nov 26 12:14:31.330: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Nov 26 12:14:31.336: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-9784 11/26/22 12:14:31.336
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-9784 11/26/22 12:14:31.362
    I1126 12:14:31.389185      19 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-9784, replica count: 3
    I1126 12:14:34.440939      19 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 12:14:34.469: INFO: Creating new exec pod
    Nov 26 12:14:34.499: INFO: Waiting up to 5m0s for pod "execpod-affinity94jdb" in namespace "services-9784" to be "running"
    Nov 26 12:14:34.510: INFO: Pod "execpod-affinity94jdb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.099594ms
    Nov 26 12:14:36.517: INFO: Pod "execpod-affinity94jdb": Phase="Running", Reason="", readiness=true. Elapsed: 2.018190118s
    Nov 26 12:14:36.517: INFO: Pod "execpod-affinity94jdb" satisfied condition "running"
    Nov 26 12:14:37.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Nov 26 12:14:37.742: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Nov 26 12:14:37.742: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:14:37.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.26 80'
    Nov 26 12:14:37.957: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.26 80\nConnection to 10.152.183.26 80 port [tcp/http] succeeded!\n"
    Nov 26 12:14:37.957: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:14:37.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.249 32597'
    Nov 26 12:14:38.176: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.0.249 32597\nConnection to 172.31.0.249 32597 port [tcp/*] succeeded!\n"
    Nov 26 12:14:38.176: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:14:38.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.43.82 32597'
    Nov 26 12:14:38.375: INFO: stderr: "+ nc -v -t -w 2 172.31.43.82 32597\n+ echo hostName\nConnection to 172.31.43.82 32597 port [tcp/*] succeeded!\n"
    Nov 26 12:14:38.375: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:14:38.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.249:32597/ ; done'
    Nov 26 12:14:38.697: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n"
    Nov 26 12:14:38.697: INFO: stdout: "\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9\naffinity-nodeport-timeout-g4rh9"
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Received response from host: affinity-nodeport-timeout-g4rh9
    Nov 26 12:14:38.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.0.249:32597/'
    Nov 26 12:14:38.921: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n"
    Nov 26 12:14:38.921: INFO: stdout: "affinity-nodeport-timeout-g4rh9"
    Nov 26 12:14:58.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-9784 exec execpod-affinity94jdb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.0.249:32597/'
    Nov 26 12:14:59.093: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.0.249:32597/\n"
    Nov 26 12:14:59.093: INFO: stdout: "affinity-nodeport-timeout-tj5cw"
    Nov 26 12:14:59.093: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-9784, will wait for the garbage collector to delete the pods 11/26/22 12:14:59.114
    Nov 26 12:14:59.182: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 11.456904ms
    Nov 26 12:14:59.283: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.761437ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:15:01.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9784" for this suite. 11/26/22 12:15:01.644
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:15:01.662
Nov 26 12:15:01.662: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename deployment 11/26/22 12:15:01.664
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:01.699
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:01.709
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Nov 26 12:15:01.748: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 26 12:15:06.758: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/26/22 12:15:06.758
Nov 26 12:15:06.758: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 26 12:15:08.764: INFO: Creating deployment "test-rollover-deployment"
Nov 26 12:15:08.785: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 26 12:15:10.795: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 26 12:15:10.819: INFO: Ensure that both replica sets have 1 created replica
Nov 26 12:15:10.830: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 26 12:15:10.851: INFO: Updating deployment test-rollover-deployment
Nov 26 12:15:10.851: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 26 12:15:12.869: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 26 12:15:12.882: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 26 12:15:12.895: INFO: all replica sets need to contain the pod-template-hash label
Nov 26 12:15:12.895: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 12:15:14.907: INFO: all replica sets need to contain the pod-template-hash label
Nov 26 12:15:14.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 12:15:16.909: INFO: all replica sets need to contain the pod-template-hash label
Nov 26 12:15:16.909: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 12:15:18.907: INFO: all replica sets need to contain the pod-template-hash label
Nov 26 12:15:18.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 12:15:20.906: INFO: all replica sets need to contain the pod-template-hash label
Nov 26 12:15:20.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 12:15:22.906: INFO: 
Nov 26 12:15:22.906: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 26 12:15:22.925: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-8709  81cf75c3-2f1a-4bdf-8789-b7697f90d81b 11631 2 2022-11-26 12:15:08 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-26 12:15:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:15:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002bbb718 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-26 12:15:08 +0000 UTC,LastTransitionTime:2022-11-26 12:15:08 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-11-26 12:15:22 +0000 UTC,LastTransitionTime:2022-11-26 12:15:08 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 26 12:15:22.932: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-8709  b9e890d9-0c0a-4228-97d7-7e9bef3d5e8d 11621 2 2022-11-26 12:15:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 81cf75c3-2f1a-4bdf-8789-b7697f90d81b 0xc0031df987 0xc0031df988}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:15:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"81cf75c3-2f1a-4bdf-8789-b7697f90d81b\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:15:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0031dfa48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:15:22.932: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 26 12:15:22.932: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8709  4fa3e230-6071-47bb-93d8-0e65a93446b3 11630 2 2022-11-26 12:15:01 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 81cf75c3-2f1a-4bdf-8789-b7697f90d81b 0xc0031df727 0xc0031df728}] [] [{e2e.test Update apps/v1 2022-11-26 12:15:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:15:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"81cf75c3-2f1a-4bdf-8789-b7697f90d81b\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:15:22 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0031df7f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:15:22.932: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-8709  7b203ee3-2dd5-4e91-b5bf-f249f10a3ebf 11585 2 2022-11-26 12:15:08 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 81cf75c3-2f1a-4bdf-8789-b7697f90d81b 0xc0031df867 0xc0031df868}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:15:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"81cf75c3-2f1a-4bdf-8789-b7697f90d81b\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:15:11 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0031df918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:15:22.938: INFO: Pod "test-rollover-deployment-6d45fd857b-c8gcj" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-c8gcj test-rollover-deployment-6d45fd857b- deployment-8709  eb58de46-7953-4fa8-88f8-2725a37d1deb 11599 0 2022-11-26 12:15:11 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b b9e890d9-0c0a-4228-97d7-7e9bef3d5e8d 0xc002bbbaf7 0xc002bbbaf8}] [] [{kube-controller-manager Update v1 2022-11-26 12:15:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b9e890d9-0c0a-4228-97d7-7e9bef3d5e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:15:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kn9vb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kn9vb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:15:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:15:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:15:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:15:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.23,StartTime:2022-11-26 12:15:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:15:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://990ca6c237a61e8369768adf02984b1c24be5248c90cf828cc7a10172103919f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 26 12:15:22.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8709" for this suite. 11/26/22 12:15:22.945
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":91,"skipped":1683,"failed":0}
------------------------------
â€¢ [SLOW TEST] [21.296 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:15:01.662
    Nov 26 12:15:01.662: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename deployment 11/26/22 12:15:01.664
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:01.699
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:01.709
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Nov 26 12:15:01.748: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Nov 26 12:15:06.758: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/26/22 12:15:06.758
    Nov 26 12:15:06.758: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Nov 26 12:15:08.764: INFO: Creating deployment "test-rollover-deployment"
    Nov 26 12:15:08.785: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Nov 26 12:15:10.795: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Nov 26 12:15:10.819: INFO: Ensure that both replica sets have 1 created replica
    Nov 26 12:15:10.830: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Nov 26 12:15:10.851: INFO: Updating deployment test-rollover-deployment
    Nov 26 12:15:10.851: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Nov 26 12:15:12.869: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Nov 26 12:15:12.882: INFO: Make sure deployment "test-rollover-deployment" is complete
    Nov 26 12:15:12.895: INFO: all replica sets need to contain the pod-template-hash label
    Nov 26 12:15:12.895: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 12:15:14.907: INFO: all replica sets need to contain the pod-template-hash label
    Nov 26 12:15:14.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 12:15:16.909: INFO: all replica sets need to contain the pod-template-hash label
    Nov 26 12:15:16.909: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 12:15:18.907: INFO: all replica sets need to contain the pod-template-hash label
    Nov 26 12:15:18.907: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 12:15:20.906: INFO: all replica sets need to contain the pod-template-hash label
    Nov 26 12:15:20.906: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 15, 12, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 15, 8, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 12:15:22.906: INFO: 
    Nov 26 12:15:22.906: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 26 12:15:22.925: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-8709  81cf75c3-2f1a-4bdf-8789-b7697f90d81b 11631 2 2022-11-26 12:15:08 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-26 12:15:10 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:15:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002bbb718 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-26 12:15:08 +0000 UTC,LastTransitionTime:2022-11-26 12:15:08 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-11-26 12:15:22 +0000 UTC,LastTransitionTime:2022-11-26 12:15:08 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 26 12:15:22.932: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-8709  b9e890d9-0c0a-4228-97d7-7e9bef3d5e8d 11621 2 2022-11-26 12:15:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 81cf75c3-2f1a-4bdf-8789-b7697f90d81b 0xc0031df987 0xc0031df988}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:15:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"81cf75c3-2f1a-4bdf-8789-b7697f90d81b\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:15:22 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0031dfa48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:15:22.932: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Nov 26 12:15:22.932: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8709  4fa3e230-6071-47bb-93d8-0e65a93446b3 11630 2 2022-11-26 12:15:01 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 81cf75c3-2f1a-4bdf-8789-b7697f90d81b 0xc0031df727 0xc0031df728}] [] [{e2e.test Update apps/v1 2022-11-26 12:15:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:15:22 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"81cf75c3-2f1a-4bdf-8789-b7697f90d81b\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:15:22 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0031df7f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:15:22.932: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-8709  7b203ee3-2dd5-4e91-b5bf-f249f10a3ebf 11585 2 2022-11-26 12:15:08 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 81cf75c3-2f1a-4bdf-8789-b7697f90d81b 0xc0031df867 0xc0031df868}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:15:10 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"81cf75c3-2f1a-4bdf-8789-b7697f90d81b\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:15:11 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0031df918 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:15:22.938: INFO: Pod "test-rollover-deployment-6d45fd857b-c8gcj" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-c8gcj test-rollover-deployment-6d45fd857b- deployment-8709  eb58de46-7953-4fa8-88f8-2725a37d1deb 11599 0 2022-11-26 12:15:11 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b b9e890d9-0c0a-4228-97d7-7e9bef3d5e8d 0xc002bbbaf7 0xc002bbbaf8}] [] [{kube-controller-manager Update v1 2022-11-26 12:15:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b9e890d9-0c0a-4228-97d7-7e9bef3d5e8d\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:15:12 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.23\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kn9vb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kn9vb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:15:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:15:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:15:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:15:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.23,StartTime:2022-11-26 12:15:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:15:12 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://990ca6c237a61e8369768adf02984b1c24be5248c90cf828cc7a10172103919f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 26 12:15:22.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8709" for this suite. 11/26/22 12:15:22.945
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:15:22.959
Nov 26 12:15:22.959: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replicaset 11/26/22 12:15:22.964
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:22.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:22.998
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 11/26/22 12:15:23.004
Nov 26 12:15:23.021: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 26 12:15:28.033: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/26/22 12:15:28.033
STEP: getting scale subresource 11/26/22 12:15:28.033
STEP: updating a scale subresource 11/26/22 12:15:28.042
STEP: verifying the replicaset Spec.Replicas was modified 11/26/22 12:15:28.052
STEP: Patch a scale subresource 11/26/22 12:15:28.058
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 26 12:15:28.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7935" for this suite. 11/26/22 12:15:28.115
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":92,"skipped":1685,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.173 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:15:22.959
    Nov 26 12:15:22.959: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replicaset 11/26/22 12:15:22.964
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:22.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:22.998
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 11/26/22 12:15:23.004
    Nov 26 12:15:23.021: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 26 12:15:28.033: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/26/22 12:15:28.033
    STEP: getting scale subresource 11/26/22 12:15:28.033
    STEP: updating a scale subresource 11/26/22 12:15:28.042
    STEP: verifying the replicaset Spec.Replicas was modified 11/26/22 12:15:28.052
    STEP: Patch a scale subresource 11/26/22 12:15:28.058
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 26 12:15:28.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7935" for this suite. 11/26/22 12:15:28.115
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:15:28.134
Nov 26 12:15:28.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:15:28.135
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:28.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:28.19
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 11/26/22 12:15:28.196
Nov 26 12:15:28.214: INFO: Waiting up to 5m0s for pod "pod-f37b75ef-a1cc-42dc-906c-eab95a2af286" in namespace "emptydir-8531" to be "Succeeded or Failed"
Nov 26 12:15:28.228: INFO: Pod "pod-f37b75ef-a1cc-42dc-906c-eab95a2af286": Phase="Pending", Reason="", readiness=false. Elapsed: 14.767941ms
Nov 26 12:15:30.235: INFO: Pod "pod-f37b75ef-a1cc-42dc-906c-eab95a2af286": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02174301s
Nov 26 12:15:32.237: INFO: Pod "pod-f37b75ef-a1cc-42dc-906c-eab95a2af286": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022843595s
STEP: Saw pod success 11/26/22 12:15:32.237
Nov 26 12:15:32.237: INFO: Pod "pod-f37b75ef-a1cc-42dc-906c-eab95a2af286" satisfied condition "Succeeded or Failed"
Nov 26 12:15:32.254: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-f37b75ef-a1cc-42dc-906c-eab95a2af286 container test-container: <nil>
STEP: delete the pod 11/26/22 12:15:32.272
Nov 26 12:15:32.292: INFO: Waiting for pod pod-f37b75ef-a1cc-42dc-906c-eab95a2af286 to disappear
Nov 26 12:15:32.297: INFO: Pod pod-f37b75ef-a1cc-42dc-906c-eab95a2af286 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:15:32.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8531" for this suite. 11/26/22 12:15:32.306
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":93,"skipped":1694,"failed":0}
------------------------------
â€¢ [4.183 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:15:28.134
    Nov 26 12:15:28.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:15:28.135
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:28.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:28.19
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 11/26/22 12:15:28.196
    Nov 26 12:15:28.214: INFO: Waiting up to 5m0s for pod "pod-f37b75ef-a1cc-42dc-906c-eab95a2af286" in namespace "emptydir-8531" to be "Succeeded or Failed"
    Nov 26 12:15:28.228: INFO: Pod "pod-f37b75ef-a1cc-42dc-906c-eab95a2af286": Phase="Pending", Reason="", readiness=false. Elapsed: 14.767941ms
    Nov 26 12:15:30.235: INFO: Pod "pod-f37b75ef-a1cc-42dc-906c-eab95a2af286": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02174301s
    Nov 26 12:15:32.237: INFO: Pod "pod-f37b75ef-a1cc-42dc-906c-eab95a2af286": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022843595s
    STEP: Saw pod success 11/26/22 12:15:32.237
    Nov 26 12:15:32.237: INFO: Pod "pod-f37b75ef-a1cc-42dc-906c-eab95a2af286" satisfied condition "Succeeded or Failed"
    Nov 26 12:15:32.254: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-f37b75ef-a1cc-42dc-906c-eab95a2af286 container test-container: <nil>
    STEP: delete the pod 11/26/22 12:15:32.272
    Nov 26 12:15:32.292: INFO: Waiting for pod pod-f37b75ef-a1cc-42dc-906c-eab95a2af286 to disappear
    Nov 26 12:15:32.297: INFO: Pod pod-f37b75ef-a1cc-42dc-906c-eab95a2af286 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:15:32.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8531" for this suite. 11/26/22 12:15:32.306
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:15:32.319
Nov 26 12:15:32.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sysctl 11/26/22 12:15:32.32
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:32.339
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:32.347
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 11/26/22 12:15:32.352
STEP: Watching for error events or started pod 11/26/22 12:15:32.372
STEP: Waiting for pod completion 11/26/22 12:15:34.379
Nov 26 12:15:34.379: INFO: Waiting up to 3m0s for pod "sysctl-80d3f806-d74e-429d-a349-535f0e6a0153" in namespace "sysctl-6427" to be "completed"
Nov 26 12:15:34.386: INFO: Pod "sysctl-80d3f806-d74e-429d-a349-535f0e6a0153": Phase="Pending", Reason="", readiness=false. Elapsed: 6.218501ms
Nov 26 12:15:36.392: INFO: Pod "sysctl-80d3f806-d74e-429d-a349-535f0e6a0153": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013005818s
Nov 26 12:15:36.393: INFO: Pod "sysctl-80d3f806-d74e-429d-a349-535f0e6a0153" satisfied condition "completed"
STEP: Checking that the pod succeeded 11/26/22 12:15:36.398
STEP: Getting logs from the pod 11/26/22 12:15:36.399
STEP: Checking that the sysctl is actually updated 11/26/22 12:15:36.411
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 26 12:15:36.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-6427" for this suite. 11/26/22 12:15:36.417
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":94,"skipped":1717,"failed":0}
------------------------------
â€¢ [4.109 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:15:32.319
    Nov 26 12:15:32.319: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sysctl 11/26/22 12:15:32.32
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:32.339
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:32.347
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 11/26/22 12:15:32.352
    STEP: Watching for error events or started pod 11/26/22 12:15:32.372
    STEP: Waiting for pod completion 11/26/22 12:15:34.379
    Nov 26 12:15:34.379: INFO: Waiting up to 3m0s for pod "sysctl-80d3f806-d74e-429d-a349-535f0e6a0153" in namespace "sysctl-6427" to be "completed"
    Nov 26 12:15:34.386: INFO: Pod "sysctl-80d3f806-d74e-429d-a349-535f0e6a0153": Phase="Pending", Reason="", readiness=false. Elapsed: 6.218501ms
    Nov 26 12:15:36.392: INFO: Pod "sysctl-80d3f806-d74e-429d-a349-535f0e6a0153": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013005818s
    Nov 26 12:15:36.393: INFO: Pod "sysctl-80d3f806-d74e-429d-a349-535f0e6a0153" satisfied condition "completed"
    STEP: Checking that the pod succeeded 11/26/22 12:15:36.398
    STEP: Getting logs from the pod 11/26/22 12:15:36.399
    STEP: Checking that the sysctl is actually updated 11/26/22 12:15:36.411
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 26 12:15:36.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-6427" for this suite. 11/26/22 12:15:36.417
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:15:36.439
Nov 26 12:15:36.439: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename daemonsets 11/26/22 12:15:36.44
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:36.465
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:36.47
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Nov 26 12:15:36.504: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 12:15:36.514
Nov 26 12:15:36.525: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:36.526: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:36.531: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:15:36.531: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:15:37.545: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:37.545: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:37.553: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:15:37.553: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:15:38.538: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:38.538: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:38.544: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 26 12:15:38.544: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 11/26/22 12:15:38.566
STEP: Check that daemon pods images are updated. 11/26/22 12:15:38.59
Nov 26 12:15:38.596: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:38.596: INFO: Wrong image for pod: daemon-set-pnwcd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:38.596: INFO: Wrong image for pod: daemon-set-x9z2g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:38.604: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:38.604: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:39.610: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:39.610: INFO: Wrong image for pod: daemon-set-x9z2g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:39.616: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:39.616: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:40.609: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:40.609: INFO: Wrong image for pod: daemon-set-x9z2g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:40.617: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:40.617: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:41.610: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:41.610: INFO: Pod daemon-set-wwbqk is not available
Nov 26 12:15:41.610: INFO: Wrong image for pod: daemon-set-x9z2g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:41.618: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:41.618: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:42.609: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:42.609: INFO: Pod daemon-set-wwbqk is not available
Nov 26 12:15:42.609: INFO: Wrong image for pod: daemon-set-x9z2g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:42.615: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:42.615: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:43.610: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:43.620: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:43.620: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:44.611: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:44.611: INFO: Pod daemon-set-tzzjx is not available
Nov 26 12:15:44.621: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:44.621: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:45.612: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov 26 12:15:45.612: INFO: Pod daemon-set-tzzjx is not available
Nov 26 12:15:45.617: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:45.617: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:46.616: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:46.617: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:47.617: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:47.617: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:48.611: INFO: Pod daemon-set-wmv6w is not available
Nov 26 12:15:48.617: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:48.617: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster. 11/26/22 12:15:48.617
Nov 26 12:15:48.623: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:48.623: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:48.629: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:15:48.629: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:15:49.635: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:49.635: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:49.640: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:15:49.640: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:15:50.635: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:50.636: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:15:50.641: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 26 12:15:50.641: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:15:50.679
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9553, will wait for the garbage collector to delete the pods 11/26/22 12:15:50.679
Nov 26 12:15:50.750: INFO: Deleting DaemonSet.extensions daemon-set took: 14.189943ms
Nov 26 12:15:50.850: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.138677ms
Nov 26 12:15:52.759: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:15:52.759: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 26 12:15:52.764: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"12004"},"items":null}

Nov 26 12:15:52.770: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"12004"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:15:52.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9553" for this suite. 11/26/22 12:15:52.806
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":95,"skipped":1788,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.379 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:15:36.439
    Nov 26 12:15:36.439: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename daemonsets 11/26/22 12:15:36.44
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:36.465
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:36.47
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Nov 26 12:15:36.504: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 12:15:36.514
    Nov 26 12:15:36.525: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:36.526: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:36.531: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:15:36.531: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:15:37.545: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:37.545: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:37.553: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:15:37.553: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:15:38.538: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:38.538: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:38.544: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 26 12:15:38.544: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 11/26/22 12:15:38.566
    STEP: Check that daemon pods images are updated. 11/26/22 12:15:38.59
    Nov 26 12:15:38.596: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:38.596: INFO: Wrong image for pod: daemon-set-pnwcd. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:38.596: INFO: Wrong image for pod: daemon-set-x9z2g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:38.604: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:38.604: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:39.610: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:39.610: INFO: Wrong image for pod: daemon-set-x9z2g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:39.616: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:39.616: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:40.609: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:40.609: INFO: Wrong image for pod: daemon-set-x9z2g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:40.617: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:40.617: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:41.610: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:41.610: INFO: Pod daemon-set-wwbqk is not available
    Nov 26 12:15:41.610: INFO: Wrong image for pod: daemon-set-x9z2g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:41.618: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:41.618: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:42.609: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:42.609: INFO: Pod daemon-set-wwbqk is not available
    Nov 26 12:15:42.609: INFO: Wrong image for pod: daemon-set-x9z2g. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:42.615: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:42.615: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:43.610: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:43.620: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:43.620: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:44.611: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:44.611: INFO: Pod daemon-set-tzzjx is not available
    Nov 26 12:15:44.621: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:44.621: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:45.612: INFO: Wrong image for pod: daemon-set-lkfx9. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov 26 12:15:45.612: INFO: Pod daemon-set-tzzjx is not available
    Nov 26 12:15:45.617: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:45.617: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:46.616: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:46.617: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:47.617: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:47.617: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:48.611: INFO: Pod daemon-set-wmv6w is not available
    Nov 26 12:15:48.617: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:48.617: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    STEP: Check that daemon pods are still running on every node of the cluster. 11/26/22 12:15:48.617
    Nov 26 12:15:48.623: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:48.623: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:48.629: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:15:48.629: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:15:49.635: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:49.635: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:49.640: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:15:49.640: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:15:50.635: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:50.636: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:15:50.641: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 26 12:15:50.641: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:15:50.679
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9553, will wait for the garbage collector to delete the pods 11/26/22 12:15:50.679
    Nov 26 12:15:50.750: INFO: Deleting DaemonSet.extensions daemon-set took: 14.189943ms
    Nov 26 12:15:50.850: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.138677ms
    Nov 26 12:15:52.759: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:15:52.759: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 26 12:15:52.764: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"12004"},"items":null}

    Nov 26 12:15:52.770: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"12004"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:15:52.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-9553" for this suite. 11/26/22 12:15:52.806
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:15:52.823
Nov 26 12:15:52.824: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:15:52.825
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:52.843
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:52.852
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-bb13e3a9-e5e7-46e4-8f21-325c845dd2e5 11/26/22 12:15:52.857
STEP: Creating a pod to test consume configMaps 11/26/22 12:15:52.865
Nov 26 12:15:52.878: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61" in namespace "projected-5075" to be "Succeeded or Failed"
Nov 26 12:15:52.889: INFO: Pod "pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61": Phase="Pending", Reason="", readiness=false. Elapsed: 11.064226ms
Nov 26 12:15:54.896: INFO: Pod "pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01780415s
Nov 26 12:15:56.897: INFO: Pod "pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018862043s
STEP: Saw pod success 11/26/22 12:15:56.898
Nov 26 12:15:56.898: INFO: Pod "pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61" satisfied condition "Succeeded or Failed"
Nov 26 12:15:56.904: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61 container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:15:56.917
Nov 26 12:15:56.947: INFO: Waiting for pod pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61 to disappear
Nov 26 12:15:56.952: INFO: Pod pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 26 12:15:56.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5075" for this suite. 11/26/22 12:15:56.965
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":96,"skipped":1801,"failed":0}
------------------------------
â€¢ [4.157 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:15:52.823
    Nov 26 12:15:52.824: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:15:52.825
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:52.843
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:52.852
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-bb13e3a9-e5e7-46e4-8f21-325c845dd2e5 11/26/22 12:15:52.857
    STEP: Creating a pod to test consume configMaps 11/26/22 12:15:52.865
    Nov 26 12:15:52.878: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61" in namespace "projected-5075" to be "Succeeded or Failed"
    Nov 26 12:15:52.889: INFO: Pod "pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61": Phase="Pending", Reason="", readiness=false. Elapsed: 11.064226ms
    Nov 26 12:15:54.896: INFO: Pod "pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01780415s
    Nov 26 12:15:56.897: INFO: Pod "pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018862043s
    STEP: Saw pod success 11/26/22 12:15:56.898
    Nov 26 12:15:56.898: INFO: Pod "pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61" satisfied condition "Succeeded or Failed"
    Nov 26 12:15:56.904: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61 container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:15:56.917
    Nov 26 12:15:56.947: INFO: Waiting for pod pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61 to disappear
    Nov 26 12:15:56.952: INFO: Pod pod-projected-configmaps-d903f4c0-909c-4e2d-b067-45ea86c92e61 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 26 12:15:56.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5075" for this suite. 11/26/22 12:15:56.965
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:15:56.981
Nov 26 12:15:56.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename job 11/26/22 12:15:56.982
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:57.009
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:57.015
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 11/26/22 12:15:57.03
STEP: Patching the Job 11/26/22 12:15:57.041
STEP: Watching for Job to be patched 11/26/22 12:15:57.076
Nov 26 12:15:57.080: INFO: Event ADDED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking:]
Nov 26 12:15:57.080: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking:]
Nov 26 12:15:57.080: INFO: Event MODIFIED found for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 11/26/22 12:15:57.08
STEP: Watching for Job to be updated 11/26/22 12:15:57.099
Nov 26 12:15:57.102: INFO: Event MODIFIED found for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 26 12:15:57.102: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 11/26/22 12:15:57.102
Nov 26 12:15:57.110: INFO: Job: e2e-c548j as labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j]
STEP: Waiting for job to complete 11/26/22 12:15:57.11
STEP: Delete a job collection with a labelselector 11/26/22 12:16:07.117
STEP: Watching for Job to be deleted 11/26/22 12:16:07.131
Nov 26 12:16:07.144: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 26 12:16:07.144: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 26 12:16:07.145: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 26 12:16:07.145: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 26 12:16:07.145: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov 26 12:16:07.145: INFO: Event DELETED found for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 11/26/22 12:16:07.145
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 26 12:16:07.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1498" for this suite. 11/26/22 12:16:07.163
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":97,"skipped":1803,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.199 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:15:56.981
    Nov 26 12:15:56.981: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename job 11/26/22 12:15:56.982
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:15:57.009
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:15:57.015
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 11/26/22 12:15:57.03
    STEP: Patching the Job 11/26/22 12:15:57.041
    STEP: Watching for Job to be patched 11/26/22 12:15:57.076
    Nov 26 12:15:57.080: INFO: Event ADDED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking:]
    Nov 26 12:15:57.080: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking:]
    Nov 26 12:15:57.080: INFO: Event MODIFIED found for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 11/26/22 12:15:57.08
    STEP: Watching for Job to be updated 11/26/22 12:15:57.099
    Nov 26 12:15:57.102: INFO: Event MODIFIED found for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 26 12:15:57.102: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 11/26/22 12:15:57.102
    Nov 26 12:15:57.110: INFO: Job: e2e-c548j as labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j]
    STEP: Waiting for job to complete 11/26/22 12:15:57.11
    STEP: Delete a job collection with a labelselector 11/26/22 12:16:07.117
    STEP: Watching for Job to be deleted 11/26/22 12:16:07.131
    Nov 26 12:16:07.144: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 26 12:16:07.144: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 26 12:16:07.145: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 26 12:16:07.145: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 26 12:16:07.145: INFO: Event MODIFIED observed for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov 26 12:16:07.145: INFO: Event DELETED found for Job e2e-c548j in namespace job-1498 with labels: map[e2e-c548j:patched e2e-job-label:e2e-c548j] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 11/26/22 12:16:07.145
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 26 12:16:07.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-1498" for this suite. 11/26/22 12:16:07.163
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:16:07.182
Nov 26 12:16:07.182: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-webhook 11/26/22 12:16:07.183
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:16:07.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:16:07.215
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 11/26/22 12:16:07.223
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/26/22 12:16:07.859
STEP: Deploying the custom resource conversion webhook pod 11/26/22 12:16:07.871
STEP: Wait for the deployment to be ready 11/26/22 12:16:07.892
Nov 26 12:16:07.919: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/26/22 12:16:09.939
STEP: Verifying the service has paired with the endpoint 11/26/22 12:16:09.959
Nov 26 12:16:10.959: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Nov 26 12:16:10.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Creating a v1 custom resource 11/26/22 12:16:13.616
STEP: v2 custom resource should be converted 11/26/22 12:16:13.624
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:16:14.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7359" for this suite. 11/26/22 12:16:14.163
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":98,"skipped":1813,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.086 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:16:07.182
    Nov 26 12:16:07.182: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-webhook 11/26/22 12:16:07.183
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:16:07.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:16:07.215
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 11/26/22 12:16:07.223
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/26/22 12:16:07.859
    STEP: Deploying the custom resource conversion webhook pod 11/26/22 12:16:07.871
    STEP: Wait for the deployment to be ready 11/26/22 12:16:07.892
    Nov 26 12:16:07.919: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/26/22 12:16:09.939
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:16:09.959
    Nov 26 12:16:10.959: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Nov 26 12:16:10.965: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Creating a v1 custom resource 11/26/22 12:16:13.616
    STEP: v2 custom resource should be converted 11/26/22 12:16:13.624
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:16:14.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-7359" for this suite. 11/26/22 12:16:14.163
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:16:14.268
Nov 26 12:16:14.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:16:14.269
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:16:14.296
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:16:14.302
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 11/26/22 12:16:14.308
Nov 26 12:16:14.309: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-576 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 11/26/22 12:16:14.381
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:16:14.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-576" for this suite. 11/26/22 12:16:14.407
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":99,"skipped":1820,"failed":0}
------------------------------
â€¢ [0.149 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:16:14.268
    Nov 26 12:16:14.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:16:14.269
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:16:14.296
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:16:14.302
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 11/26/22 12:16:14.308
    Nov 26 12:16:14.309: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-576 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 11/26/22 12:16:14.381
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:16:14.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-576" for this suite. 11/26/22 12:16:14.407
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:16:14.418
Nov 26 12:16:14.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:16:14.42
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:16:14.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:16:14.46
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-1cc4bafa-102d-4592-a120-f64d29d65212 11/26/22 12:16:14.474
STEP: Creating configMap with name cm-test-opt-upd-2a6f95a3-7a3f-451a-b1bd-1fc8de2ba7ef 11/26/22 12:16:14.481
STEP: Creating the pod 11/26/22 12:16:14.489
Nov 26 12:16:14.502: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc" in namespace "projected-5384" to be "running and ready"
Nov 26 12:16:14.512: INFO: Pod "pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.468957ms
Nov 26 12:16:14.512: INFO: The phase of Pod pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:16:16.520: INFO: Pod "pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017310324s
Nov 26 12:16:16.520: INFO: The phase of Pod pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:16:18.519: INFO: Pod "pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc": Phase="Running", Reason="", readiness=true. Elapsed: 4.016631387s
Nov 26 12:16:18.519: INFO: The phase of Pod pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc is Running (Ready = true)
Nov 26 12:16:18.519: INFO: Pod "pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-1cc4bafa-102d-4592-a120-f64d29d65212 11/26/22 12:16:18.555
STEP: Updating configmap cm-test-opt-upd-2a6f95a3-7a3f-451a-b1bd-1fc8de2ba7ef 11/26/22 12:16:18.566
STEP: Creating configMap with name cm-test-opt-create-95e73c29-5e0e-4324-9f9c-4d8decfc294e 11/26/22 12:16:18.575
STEP: waiting to observe update in volume 11/26/22 12:16:18.582
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 26 12:17:25.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5384" for this suite. 11/26/22 12:17:25.015
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":100,"skipped":1826,"failed":0}
------------------------------
â€¢ [SLOW TEST] [70.608 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:16:14.418
    Nov 26 12:16:14.418: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:16:14.42
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:16:14.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:16:14.46
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-1cc4bafa-102d-4592-a120-f64d29d65212 11/26/22 12:16:14.474
    STEP: Creating configMap with name cm-test-opt-upd-2a6f95a3-7a3f-451a-b1bd-1fc8de2ba7ef 11/26/22 12:16:14.481
    STEP: Creating the pod 11/26/22 12:16:14.489
    Nov 26 12:16:14.502: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc" in namespace "projected-5384" to be "running and ready"
    Nov 26 12:16:14.512: INFO: Pod "pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.468957ms
    Nov 26 12:16:14.512: INFO: The phase of Pod pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:16:16.520: INFO: Pod "pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017310324s
    Nov 26 12:16:16.520: INFO: The phase of Pod pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:16:18.519: INFO: Pod "pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc": Phase="Running", Reason="", readiness=true. Elapsed: 4.016631387s
    Nov 26 12:16:18.519: INFO: The phase of Pod pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc is Running (Ready = true)
    Nov 26 12:16:18.519: INFO: Pod "pod-projected-configmaps-155c5582-35af-4d04-ab70-bf0a0fbaf0dc" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-1cc4bafa-102d-4592-a120-f64d29d65212 11/26/22 12:16:18.555
    STEP: Updating configmap cm-test-opt-upd-2a6f95a3-7a3f-451a-b1bd-1fc8de2ba7ef 11/26/22 12:16:18.566
    STEP: Creating configMap with name cm-test-opt-create-95e73c29-5e0e-4324-9f9c-4d8decfc294e 11/26/22 12:16:18.575
    STEP: waiting to observe update in volume 11/26/22 12:16:18.582
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 26 12:17:25.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5384" for this suite. 11/26/22 12:17:25.015
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:17:25.032
Nov 26 12:17:25.032: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename endpointslice 11/26/22 12:17:25.035
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:17:25.062
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:17:25.068
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Nov 26 12:17:25.089: INFO: Endpoints addresses: [172.31.39.222 172.31.88.138] , ports: [6443]
Nov 26 12:17:25.089: INFO: EndpointSlices addresses: [172.31.39.222 172.31.88.138] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 26 12:17:25.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4093" for this suite. 11/26/22 12:17:25.095
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":101,"skipped":1880,"failed":0}
------------------------------
â€¢ [0.073 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:17:25.032
    Nov 26 12:17:25.032: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename endpointslice 11/26/22 12:17:25.035
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:17:25.062
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:17:25.068
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Nov 26 12:17:25.089: INFO: Endpoints addresses: [172.31.39.222 172.31.88.138] , ports: [6443]
    Nov 26 12:17:25.089: INFO: EndpointSlices addresses: [172.31.39.222 172.31.88.138] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 26 12:17:25.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-4093" for this suite. 11/26/22 12:17:25.095
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:17:25.109
Nov 26 12:17:25.109: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubelet-test 11/26/22 12:17:25.11
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:17:25.132
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:17:25.138
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Nov 26 12:17:25.163: INFO: Waiting up to 5m0s for pod "busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f" in namespace "kubelet-test-7716" to be "running and ready"
Nov 26 12:17:25.171: INFO: Pod "busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.31491ms
Nov 26 12:17:25.171: INFO: The phase of Pod busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:17:27.180: INFO: Pod "busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01752246s
Nov 26 12:17:27.180: INFO: The phase of Pod busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f is Running (Ready = true)
Nov 26 12:17:27.180: INFO: Pod "busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 26 12:17:27.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7716" for this suite. 11/26/22 12:17:27.225
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":102,"skipped":1925,"failed":0}
------------------------------
â€¢ [2.126 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:17:25.109
    Nov 26 12:17:25.109: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubelet-test 11/26/22 12:17:25.11
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:17:25.132
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:17:25.138
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Nov 26 12:17:25.163: INFO: Waiting up to 5m0s for pod "busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f" in namespace "kubelet-test-7716" to be "running and ready"
    Nov 26 12:17:25.171: INFO: Pod "busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.31491ms
    Nov 26 12:17:25.171: INFO: The phase of Pod busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:17:27.180: INFO: Pod "busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01752246s
    Nov 26 12:17:27.180: INFO: The phase of Pod busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f is Running (Ready = true)
    Nov 26 12:17:27.180: INFO: Pod "busybox-scheduling-3e3d59fa-9f36-48f3-bb25-ed1b46c36c3f" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 26 12:17:27.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-7716" for this suite. 11/26/22 12:17:27.225
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:17:27.236
Nov 26 12:17:27.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename security-context-test 11/26/22 12:17:27.238
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:17:27.261
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:17:27.267
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Nov 26 12:17:27.287: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91" in namespace "security-context-test-6043" to be "Succeeded or Failed"
Nov 26 12:17:27.293: INFO: Pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91": Phase="Pending", Reason="", readiness=false. Elapsed: 6.158747ms
Nov 26 12:17:29.301: INFO: Pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013792726s
Nov 26 12:17:31.301: INFO: Pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013532892s
Nov 26 12:17:31.301: INFO: Pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91" satisfied condition "Succeeded or Failed"
Nov 26 12:17:31.310: INFO: Got logs for pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 26 12:17:31.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6043" for this suite. 11/26/22 12:17:31.316
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":103,"skipped":1938,"failed":0}
------------------------------
â€¢ [4.089 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:17:27.236
    Nov 26 12:17:27.236: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename security-context-test 11/26/22 12:17:27.238
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:17:27.261
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:17:27.267
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Nov 26 12:17:27.287: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91" in namespace "security-context-test-6043" to be "Succeeded or Failed"
    Nov 26 12:17:27.293: INFO: Pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91": Phase="Pending", Reason="", readiness=false. Elapsed: 6.158747ms
    Nov 26 12:17:29.301: INFO: Pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013792726s
    Nov 26 12:17:31.301: INFO: Pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013532892s
    Nov 26 12:17:31.301: INFO: Pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91" satisfied condition "Succeeded or Failed"
    Nov 26 12:17:31.310: INFO: Got logs for pod "busybox-privileged-false-cc6408cf-9c7c-406c-9659-eca87c9c3a91": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 26 12:17:31.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-6043" for this suite. 11/26/22 12:17:31.316
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:17:31.327
Nov 26 12:17:31.328: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-probe 11/26/22 12:17:31.329
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:17:31.357
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:17:31.362
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab in namespace container-probe-7373 11/26/22 12:17:31.367
Nov 26 12:17:31.383: INFO: Waiting up to 5m0s for pod "test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab" in namespace "container-probe-7373" to be "not pending"
Nov 26 12:17:31.389: INFO: Pod "test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab": Phase="Pending", Reason="", readiness=false. Elapsed: 6.514522ms
Nov 26 12:17:33.396: INFO: Pod "test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab": Phase="Running", Reason="", readiness=true. Elapsed: 2.013355593s
Nov 26 12:17:33.396: INFO: Pod "test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab" satisfied condition "not pending"
Nov 26 12:17:33.396: INFO: Started pod test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab in namespace container-probe-7373
STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 12:17:33.396
Nov 26 12:17:33.402: INFO: Initial restart count of pod test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab is 0
STEP: deleting the pod 11/26/22 12:21:34.249
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 26 12:21:34.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7373" for this suite. 11/26/22 12:21:34.276
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":104,"skipped":1952,"failed":0}
------------------------------
â€¢ [SLOW TEST] [242.961 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:17:31.327
    Nov 26 12:17:31.328: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-probe 11/26/22 12:17:31.329
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:17:31.357
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:17:31.362
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab in namespace container-probe-7373 11/26/22 12:17:31.367
    Nov 26 12:17:31.383: INFO: Waiting up to 5m0s for pod "test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab" in namespace "container-probe-7373" to be "not pending"
    Nov 26 12:17:31.389: INFO: Pod "test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab": Phase="Pending", Reason="", readiness=false. Elapsed: 6.514522ms
    Nov 26 12:17:33.396: INFO: Pod "test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab": Phase="Running", Reason="", readiness=true. Elapsed: 2.013355593s
    Nov 26 12:17:33.396: INFO: Pod "test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab" satisfied condition "not pending"
    Nov 26 12:17:33.396: INFO: Started pod test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab in namespace container-probe-7373
    STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 12:17:33.396
    Nov 26 12:17:33.402: INFO: Initial restart count of pod test-webserver-c9f806c4-8d31-44fc-b5e8-dd238b92cfab is 0
    STEP: deleting the pod 11/26/22 12:21:34.249
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 26 12:21:34.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7373" for this suite. 11/26/22 12:21:34.276
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:21:34.288
Nov 26 12:21:34.288: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename svcaccounts 11/26/22 12:21:34.289
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:21:34.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:21:34.327
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 11/26/22 12:21:34.333
STEP: watching for the ServiceAccount to be added 11/26/22 12:21:34.35
STEP: patching the ServiceAccount 11/26/22 12:21:34.353
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 11/26/22 12:21:34.363
STEP: deleting the ServiceAccount 11/26/22 12:21:34.37
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 26 12:21:34.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8910" for this suite. 11/26/22 12:21:34.409
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":105,"skipped":1957,"failed":0}
------------------------------
â€¢ [0.134 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:21:34.288
    Nov 26 12:21:34.288: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename svcaccounts 11/26/22 12:21:34.289
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:21:34.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:21:34.327
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 11/26/22 12:21:34.333
    STEP: watching for the ServiceAccount to be added 11/26/22 12:21:34.35
    STEP: patching the ServiceAccount 11/26/22 12:21:34.353
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 11/26/22 12:21:34.363
    STEP: deleting the ServiceAccount 11/26/22 12:21:34.37
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 26 12:21:34.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8910" for this suite. 11/26/22 12:21:34.409
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:21:34.424
Nov 26 12:21:34.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:21:34.425
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:21:34.448
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:21:34.454
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:21:34.461
Nov 26 12:21:34.473: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac" in namespace "projected-2999" to be "Succeeded or Failed"
Nov 26 12:21:34.480: INFO: Pod "downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02711ms
Nov 26 12:21:36.486: INFO: Pod "downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01240598s
Nov 26 12:21:38.485: INFO: Pod "downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011899797s
STEP: Saw pod success 11/26/22 12:21:38.485
Nov 26 12:21:38.486: INFO: Pod "downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac" satisfied condition "Succeeded or Failed"
Nov 26 12:21:38.491: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac container client-container: <nil>
STEP: delete the pod 11/26/22 12:21:38.507
Nov 26 12:21:38.525: INFO: Waiting for pod downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac to disappear
Nov 26 12:21:38.529: INFO: Pod downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 12:21:38.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2999" for this suite. 11/26/22 12:21:38.535
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":106,"skipped":1959,"failed":0}
------------------------------
â€¢ [4.121 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:21:34.424
    Nov 26 12:21:34.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:21:34.425
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:21:34.448
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:21:34.454
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:21:34.461
    Nov 26 12:21:34.473: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac" in namespace "projected-2999" to be "Succeeded or Failed"
    Nov 26 12:21:34.480: INFO: Pod "downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac": Phase="Pending", Reason="", readiness=false. Elapsed: 6.02711ms
    Nov 26 12:21:36.486: INFO: Pod "downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01240598s
    Nov 26 12:21:38.485: INFO: Pod "downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011899797s
    STEP: Saw pod success 11/26/22 12:21:38.485
    Nov 26 12:21:38.486: INFO: Pod "downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac" satisfied condition "Succeeded or Failed"
    Nov 26 12:21:38.491: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac container client-container: <nil>
    STEP: delete the pod 11/26/22 12:21:38.507
    Nov 26 12:21:38.525: INFO: Waiting for pod downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac to disappear
    Nov 26 12:21:38.529: INFO: Pod downwardapi-volume-a2c2576b-89dd-449d-9a03-409970403cac no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 12:21:38.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2999" for this suite. 11/26/22 12:21:38.535
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:21:38.546
Nov 26 12:21:38.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-probe 11/26/22 12:21:38.547
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:21:38.568
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:21:38.578
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Nov 26 12:21:38.600: INFO: Waiting up to 5m0s for pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051" in namespace "container-probe-7893" to be "running and ready"
Nov 26 12:21:38.607: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Pending", Reason="", readiness=false. Elapsed: 6.957834ms
Nov 26 12:21:38.607: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:21:40.613: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 2.01349354s
Nov 26 12:21:40.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
Nov 26 12:21:42.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 4.014047967s
Nov 26 12:21:42.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
Nov 26 12:21:44.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 6.014085416s
Nov 26 12:21:44.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
Nov 26 12:21:46.615: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 8.015188001s
Nov 26 12:21:46.615: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
Nov 26 12:21:48.616: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 10.015759428s
Nov 26 12:21:48.616: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
Nov 26 12:21:50.613: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 12.013036245s
Nov 26 12:21:50.613: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
Nov 26 12:21:52.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 14.01354207s
Nov 26 12:21:52.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
Nov 26 12:21:54.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 16.01382656s
Nov 26 12:21:54.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
Nov 26 12:21:56.613: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 18.012742099s
Nov 26 12:21:56.613: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
Nov 26 12:21:58.617: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 20.016777205s
Nov 26 12:21:58.617: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
Nov 26 12:22:00.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=true. Elapsed: 22.0143552s
Nov 26 12:22:00.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = true)
Nov 26 12:22:00.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051" satisfied condition "running and ready"
Nov 26 12:22:00.621: INFO: Container started at 2022-11-26 12:21:39 +0000 UTC, pod became ready at 2022-11-26 12:21:58 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 26 12:22:00.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7893" for this suite. 11/26/22 12:22:00.628
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":107,"skipped":1960,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.092 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:21:38.546
    Nov 26 12:21:38.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-probe 11/26/22 12:21:38.547
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:21:38.568
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:21:38.578
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Nov 26 12:21:38.600: INFO: Waiting up to 5m0s for pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051" in namespace "container-probe-7893" to be "running and ready"
    Nov 26 12:21:38.607: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Pending", Reason="", readiness=false. Elapsed: 6.957834ms
    Nov 26 12:21:38.607: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:21:40.613: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 2.01349354s
    Nov 26 12:21:40.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
    Nov 26 12:21:42.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 4.014047967s
    Nov 26 12:21:42.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
    Nov 26 12:21:44.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 6.014085416s
    Nov 26 12:21:44.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
    Nov 26 12:21:46.615: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 8.015188001s
    Nov 26 12:21:46.615: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
    Nov 26 12:21:48.616: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 10.015759428s
    Nov 26 12:21:48.616: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
    Nov 26 12:21:50.613: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 12.013036245s
    Nov 26 12:21:50.613: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
    Nov 26 12:21:52.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 14.01354207s
    Nov 26 12:21:52.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
    Nov 26 12:21:54.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 16.01382656s
    Nov 26 12:21:54.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
    Nov 26 12:21:56.613: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 18.012742099s
    Nov 26 12:21:56.613: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
    Nov 26 12:21:58.617: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=false. Elapsed: 20.016777205s
    Nov 26 12:21:58.617: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = false)
    Nov 26 12:22:00.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051": Phase="Running", Reason="", readiness=true. Elapsed: 22.0143552s
    Nov 26 12:22:00.614: INFO: The phase of Pod test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051 is Running (Ready = true)
    Nov 26 12:22:00.614: INFO: Pod "test-webserver-0e4adda4-1397-416c-bc94-00c50c88a051" satisfied condition "running and ready"
    Nov 26 12:22:00.621: INFO: Container started at 2022-11-26 12:21:39 +0000 UTC, pod became ready at 2022-11-26 12:21:58 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 26 12:22:00.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7893" for this suite. 11/26/22 12:22:00.628
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:22:00.64
Nov 26 12:22:00.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename subpath 11/26/22 12:22:00.641
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:00.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:00.672
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/26/22 12:22:00.676
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-zgjg 11/26/22 12:22:00.693
STEP: Creating a pod to test atomic-volume-subpath 11/26/22 12:22:00.694
Nov 26 12:22:00.706: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-zgjg" in namespace "subpath-7745" to be "Succeeded or Failed"
Nov 26 12:22:00.713: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.064183ms
Nov 26 12:22:02.719: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 2.012283081s
Nov 26 12:22:04.719: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 4.012513796s
Nov 26 12:22:06.721: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 6.013965018s
Nov 26 12:22:08.721: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 8.014695717s
Nov 26 12:22:10.719: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 10.012860674s
Nov 26 12:22:12.720: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 12.013557778s
Nov 26 12:22:14.718: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 14.011810771s
Nov 26 12:22:16.721: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 16.014179164s
Nov 26 12:22:18.721: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 18.014294201s
Nov 26 12:22:20.720: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 20.013798163s
Nov 26 12:22:22.720: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=false. Elapsed: 22.013659508s
Nov 26 12:22:24.719: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012213269s
STEP: Saw pod success 11/26/22 12:22:24.719
Nov 26 12:22:24.719: INFO: Pod "pod-subpath-test-secret-zgjg" satisfied condition "Succeeded or Failed"
Nov 26 12:22:24.725: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-subpath-test-secret-zgjg container test-container-subpath-secret-zgjg: <nil>
STEP: delete the pod 11/26/22 12:22:24.741
Nov 26 12:22:24.758: INFO: Waiting for pod pod-subpath-test-secret-zgjg to disappear
Nov 26 12:22:24.764: INFO: Pod pod-subpath-test-secret-zgjg no longer exists
STEP: Deleting pod pod-subpath-test-secret-zgjg 11/26/22 12:22:24.764
Nov 26 12:22:24.765: INFO: Deleting pod "pod-subpath-test-secret-zgjg" in namespace "subpath-7745"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 26 12:22:24.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7745" for this suite. 11/26/22 12:22:24.778
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":108,"skipped":1965,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.149 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:22:00.64
    Nov 26 12:22:00.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename subpath 11/26/22 12:22:00.641
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:00.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:00.672
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/26/22 12:22:00.676
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-zgjg 11/26/22 12:22:00.693
    STEP: Creating a pod to test atomic-volume-subpath 11/26/22 12:22:00.694
    Nov 26 12:22:00.706: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-zgjg" in namespace "subpath-7745" to be "Succeeded or Failed"
    Nov 26 12:22:00.713: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.064183ms
    Nov 26 12:22:02.719: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 2.012283081s
    Nov 26 12:22:04.719: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 4.012513796s
    Nov 26 12:22:06.721: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 6.013965018s
    Nov 26 12:22:08.721: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 8.014695717s
    Nov 26 12:22:10.719: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 10.012860674s
    Nov 26 12:22:12.720: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 12.013557778s
    Nov 26 12:22:14.718: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 14.011810771s
    Nov 26 12:22:16.721: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 16.014179164s
    Nov 26 12:22:18.721: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 18.014294201s
    Nov 26 12:22:20.720: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=true. Elapsed: 20.013798163s
    Nov 26 12:22:22.720: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Running", Reason="", readiness=false. Elapsed: 22.013659508s
    Nov 26 12:22:24.719: INFO: Pod "pod-subpath-test-secret-zgjg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012213269s
    STEP: Saw pod success 11/26/22 12:22:24.719
    Nov 26 12:22:24.719: INFO: Pod "pod-subpath-test-secret-zgjg" satisfied condition "Succeeded or Failed"
    Nov 26 12:22:24.725: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-subpath-test-secret-zgjg container test-container-subpath-secret-zgjg: <nil>
    STEP: delete the pod 11/26/22 12:22:24.741
    Nov 26 12:22:24.758: INFO: Waiting for pod pod-subpath-test-secret-zgjg to disappear
    Nov 26 12:22:24.764: INFO: Pod pod-subpath-test-secret-zgjg no longer exists
    STEP: Deleting pod pod-subpath-test-secret-zgjg 11/26/22 12:22:24.764
    Nov 26 12:22:24.765: INFO: Deleting pod "pod-subpath-test-secret-zgjg" in namespace "subpath-7745"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 26 12:22:24.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7745" for this suite. 11/26/22 12:22:24.778
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:22:24.792
Nov 26 12:22:24.793: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:22:24.794
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:24.813
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:24.822
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Nov 26 12:22:24.829: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/26/22 12:22:27.727
Nov 26 12:22:27.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-446 --namespace=crd-publish-openapi-446 create -f -'
Nov 26 12:22:28.957: INFO: stderr: ""
Nov 26 12:22:28.957: INFO: stdout: "e2e-test-crd-publish-openapi-9377-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 26 12:22:28.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-446 --namespace=crd-publish-openapi-446 delete e2e-test-crd-publish-openapi-9377-crds test-cr'
Nov 26 12:22:29.053: INFO: stderr: ""
Nov 26 12:22:29.053: INFO: stdout: "e2e-test-crd-publish-openapi-9377-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov 26 12:22:29.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-446 --namespace=crd-publish-openapi-446 apply -f -'
Nov 26 12:22:29.920: INFO: stderr: ""
Nov 26 12:22:29.920: INFO: stdout: "e2e-test-crd-publish-openapi-9377-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 26 12:22:29.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-446 --namespace=crd-publish-openapi-446 delete e2e-test-crd-publish-openapi-9377-crds test-cr'
Nov 26 12:22:30.021: INFO: stderr: ""
Nov 26 12:22:30.021: INFO: stdout: "e2e-test-crd-publish-openapi-9377-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 11/26/22 12:22:30.021
Nov 26 12:22:30.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-446 explain e2e-test-crd-publish-openapi-9377-crds'
Nov 26 12:22:30.240: INFO: stderr: ""
Nov 26 12:22:30.240: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9377-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:22:33.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-446" for this suite. 11/26/22 12:22:33.281
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":109,"skipped":1977,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.498 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:22:24.792
    Nov 26 12:22:24.793: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:22:24.794
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:24.813
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:24.822
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Nov 26 12:22:24.829: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/26/22 12:22:27.727
    Nov 26 12:22:27.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-446 --namespace=crd-publish-openapi-446 create -f -'
    Nov 26 12:22:28.957: INFO: stderr: ""
    Nov 26 12:22:28.957: INFO: stdout: "e2e-test-crd-publish-openapi-9377-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Nov 26 12:22:28.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-446 --namespace=crd-publish-openapi-446 delete e2e-test-crd-publish-openapi-9377-crds test-cr'
    Nov 26 12:22:29.053: INFO: stderr: ""
    Nov 26 12:22:29.053: INFO: stdout: "e2e-test-crd-publish-openapi-9377-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Nov 26 12:22:29.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-446 --namespace=crd-publish-openapi-446 apply -f -'
    Nov 26 12:22:29.920: INFO: stderr: ""
    Nov 26 12:22:29.920: INFO: stdout: "e2e-test-crd-publish-openapi-9377-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Nov 26 12:22:29.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-446 --namespace=crd-publish-openapi-446 delete e2e-test-crd-publish-openapi-9377-crds test-cr'
    Nov 26 12:22:30.021: INFO: stderr: ""
    Nov 26 12:22:30.021: INFO: stdout: "e2e-test-crd-publish-openapi-9377-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 11/26/22 12:22:30.021
    Nov 26 12:22:30.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-446 explain e2e-test-crd-publish-openapi-9377-crds'
    Nov 26 12:22:30.240: INFO: stderr: ""
    Nov 26 12:22:30.240: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9377-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:22:33.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-446" for this suite. 11/26/22 12:22:33.281
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:22:33.292
Nov 26 12:22:33.292: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename proxy 11/26/22 12:22:33.293
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:33.321
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:33.328
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Nov 26 12:22:33.333: INFO: Creating pod...
Nov 26 12:22:33.347: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-4968" to be "running"
Nov 26 12:22:33.353: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 5.559646ms
Nov 26 12:22:35.358: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.010197236s
Nov 26 12:22:35.358: INFO: Pod "agnhost" satisfied condition "running"
Nov 26 12:22:35.358: INFO: Creating service...
Nov 26 12:22:35.373: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/DELETE
Nov 26 12:22:35.382: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 26 12:22:35.382: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/GET
Nov 26 12:22:35.391: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Nov 26 12:22:35.391: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/HEAD
Nov 26 12:22:35.400: INFO: http.Client request:HEAD | StatusCode:200
Nov 26 12:22:35.400: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/OPTIONS
Nov 26 12:22:35.407: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 26 12:22:35.407: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/PATCH
Nov 26 12:22:35.414: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 26 12:22:35.414: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/POST
Nov 26 12:22:35.420: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 26 12:22:35.420: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/PUT
Nov 26 12:22:35.427: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 26 12:22:35.427: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/DELETE
Nov 26 12:22:35.439: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 26 12:22:35.439: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/GET
Nov 26 12:22:35.447: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Nov 26 12:22:35.447: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/HEAD
Nov 26 12:22:35.459: INFO: http.Client request:HEAD | StatusCode:200
Nov 26 12:22:35.459: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/OPTIONS
Nov 26 12:22:35.479: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 26 12:22:35.479: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/PATCH
Nov 26 12:22:35.488: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 26 12:22:35.488: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/POST
Nov 26 12:22:35.497: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 26 12:22:35.497: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/PUT
Nov 26 12:22:35.506: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 26 12:22:35.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4968" for this suite. 11/26/22 12:22:35.511
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":110,"skipped":1986,"failed":0}
------------------------------
â€¢ [2.229 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:22:33.292
    Nov 26 12:22:33.292: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename proxy 11/26/22 12:22:33.293
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:33.321
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:33.328
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Nov 26 12:22:33.333: INFO: Creating pod...
    Nov 26 12:22:33.347: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-4968" to be "running"
    Nov 26 12:22:33.353: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 5.559646ms
    Nov 26 12:22:35.358: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.010197236s
    Nov 26 12:22:35.358: INFO: Pod "agnhost" satisfied condition "running"
    Nov 26 12:22:35.358: INFO: Creating service...
    Nov 26 12:22:35.373: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/DELETE
    Nov 26 12:22:35.382: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 26 12:22:35.382: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/GET
    Nov 26 12:22:35.391: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Nov 26 12:22:35.391: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/HEAD
    Nov 26 12:22:35.400: INFO: http.Client request:HEAD | StatusCode:200
    Nov 26 12:22:35.400: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/OPTIONS
    Nov 26 12:22:35.407: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 26 12:22:35.407: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/PATCH
    Nov 26 12:22:35.414: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 26 12:22:35.414: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/POST
    Nov 26 12:22:35.420: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 26 12:22:35.420: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/pods/agnhost/proxy/some/path/with/PUT
    Nov 26 12:22:35.427: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 26 12:22:35.427: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/DELETE
    Nov 26 12:22:35.439: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 26 12:22:35.439: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/GET
    Nov 26 12:22:35.447: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Nov 26 12:22:35.447: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/HEAD
    Nov 26 12:22:35.459: INFO: http.Client request:HEAD | StatusCode:200
    Nov 26 12:22:35.459: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/OPTIONS
    Nov 26 12:22:35.479: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 26 12:22:35.479: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/PATCH
    Nov 26 12:22:35.488: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 26 12:22:35.488: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/POST
    Nov 26 12:22:35.497: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 26 12:22:35.497: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-4968/services/test-service/proxy/some/path/with/PUT
    Nov 26 12:22:35.506: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 26 12:22:35.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-4968" for this suite. 11/26/22 12:22:35.511
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:22:35.523
Nov 26 12:22:35.523: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:22:35.524
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:35.552
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:35.569
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Nov 26 12:22:35.574: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/26/22 12:22:39.762
Nov 26 12:22:39.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-1034 --namespace=crd-publish-openapi-1034 create -f -'
Nov 26 12:22:40.603: INFO: stderr: ""
Nov 26 12:22:40.603: INFO: stdout: "e2e-test-crd-publish-openapi-4931-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 26 12:22:40.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-1034 --namespace=crd-publish-openapi-1034 delete e2e-test-crd-publish-openapi-4931-crds test-cr'
Nov 26 12:22:40.700: INFO: stderr: ""
Nov 26 12:22:40.700: INFO: stdout: "e2e-test-crd-publish-openapi-4931-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov 26 12:22:40.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-1034 --namespace=crd-publish-openapi-1034 apply -f -'
Nov 26 12:22:41.406: INFO: stderr: ""
Nov 26 12:22:41.406: INFO: stdout: "e2e-test-crd-publish-openapi-4931-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 26 12:22:41.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-1034 --namespace=crd-publish-openapi-1034 delete e2e-test-crd-publish-openapi-4931-crds test-cr'
Nov 26 12:22:41.504: INFO: stderr: ""
Nov 26 12:22:41.504: INFO: stdout: "e2e-test-crd-publish-openapi-4931-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 11/26/22 12:22:41.504
Nov 26 12:22:41.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-1034 explain e2e-test-crd-publish-openapi-4931-crds'
Nov 26 12:22:41.795: INFO: stderr: ""
Nov 26 12:22:41.795: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4931-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:22:44.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1034" for this suite. 11/26/22 12:22:44.85
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":111,"skipped":2011,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.336 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:22:35.523
    Nov 26 12:22:35.523: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:22:35.524
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:35.552
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:35.569
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Nov 26 12:22:35.574: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/26/22 12:22:39.762
    Nov 26 12:22:39.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-1034 --namespace=crd-publish-openapi-1034 create -f -'
    Nov 26 12:22:40.603: INFO: stderr: ""
    Nov 26 12:22:40.603: INFO: stdout: "e2e-test-crd-publish-openapi-4931-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Nov 26 12:22:40.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-1034 --namespace=crd-publish-openapi-1034 delete e2e-test-crd-publish-openapi-4931-crds test-cr'
    Nov 26 12:22:40.700: INFO: stderr: ""
    Nov 26 12:22:40.700: INFO: stdout: "e2e-test-crd-publish-openapi-4931-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Nov 26 12:22:40.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-1034 --namespace=crd-publish-openapi-1034 apply -f -'
    Nov 26 12:22:41.406: INFO: stderr: ""
    Nov 26 12:22:41.406: INFO: stdout: "e2e-test-crd-publish-openapi-4931-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Nov 26 12:22:41.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-1034 --namespace=crd-publish-openapi-1034 delete e2e-test-crd-publish-openapi-4931-crds test-cr'
    Nov 26 12:22:41.504: INFO: stderr: ""
    Nov 26 12:22:41.504: INFO: stdout: "e2e-test-crd-publish-openapi-4931-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 11/26/22 12:22:41.504
    Nov 26 12:22:41.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-1034 explain e2e-test-crd-publish-openapi-4931-crds'
    Nov 26 12:22:41.795: INFO: stderr: ""
    Nov 26 12:22:41.795: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4931-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:22:44.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1034" for this suite. 11/26/22 12:22:44.85
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:22:44.871
Nov 26 12:22:44.871: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 12:22:44.872
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:44.901
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:44.907
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-7724dde7-a359-4ac3-948c-eea28b409dcd 11/26/22 12:22:44.915
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 12:22:44.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3230" for this suite. 11/26/22 12:22:44.925
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":112,"skipped":2130,"failed":0}
------------------------------
â€¢ [0.063 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:22:44.871
    Nov 26 12:22:44.871: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 12:22:44.872
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:44.901
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:44.907
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-7724dde7-a359-4ac3-948c-eea28b409dcd 11/26/22 12:22:44.915
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 12:22:44.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3230" for this suite. 11/26/22 12:22:44.925
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:22:44.935
Nov 26 12:22:44.935: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename watch 11/26/22 12:22:44.936
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:44.963
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:44.969
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 11/26/22 12:22:44.974
STEP: creating a new configmap 11/26/22 12:22:44.977
STEP: modifying the configmap once 11/26/22 12:22:44.985
STEP: changing the label value of the configmap 11/26/22 12:22:44.997
STEP: Expecting to observe a delete notification for the watched object 11/26/22 12:22:45.011
Nov 26 12:22:45.011: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13440 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 12:22:45.011: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13441 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 12:22:45.012: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13442 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 11/26/22 12:22:45.012
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 11/26/22 12:22:45.025
STEP: changing the label value of the configmap back 11/26/22 12:22:55.026
STEP: modifying the configmap a third time 11/26/22 12:22:55.102
STEP: deleting the configmap 11/26/22 12:22:55.114
STEP: Expecting to observe an add notification for the watched object when the label value was restored 11/26/22 12:22:55.177
Nov 26 12:22:55.177: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13478 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 12:22:55.177: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13479 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 12:22:55.177: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13480 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 26 12:22:55.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2357" for this suite. 11/26/22 12:22:55.182
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":113,"skipped":2136,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.319 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:22:44.935
    Nov 26 12:22:44.935: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename watch 11/26/22 12:22:44.936
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:44.963
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:44.969
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 11/26/22 12:22:44.974
    STEP: creating a new configmap 11/26/22 12:22:44.977
    STEP: modifying the configmap once 11/26/22 12:22:44.985
    STEP: changing the label value of the configmap 11/26/22 12:22:44.997
    STEP: Expecting to observe a delete notification for the watched object 11/26/22 12:22:45.011
    Nov 26 12:22:45.011: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13440 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:44 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 12:22:45.011: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13441 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 12:22:45.012: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13442 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:45 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 11/26/22 12:22:45.012
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 11/26/22 12:22:45.025
    STEP: changing the label value of the configmap back 11/26/22 12:22:55.026
    STEP: modifying the configmap a third time 11/26/22 12:22:55.102
    STEP: deleting the configmap 11/26/22 12:22:55.114
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 11/26/22 12:22:55.177
    Nov 26 12:22:55.177: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13478 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 12:22:55.177: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13479 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 12:22:55.177: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2357  091b37b3-475b-48b0-bb58-5413d2daa9e1 13480 0 2022-11-26 12:22:44 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-26 12:22:55 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 26 12:22:55.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2357" for this suite. 11/26/22 12:22:55.182
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:22:55.259
Nov 26 12:22:55.259: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:22:55.26
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:55.434
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:55.44
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 11/26/22 12:22:55.444
Nov 26 12:22:55.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:22:57.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:23:10.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9508" for this suite. 11/26/22 12:23:10.474
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":114,"skipped":2161,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.227 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:22:55.259
    Nov 26 12:22:55.259: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:22:55.26
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:22:55.434
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:22:55.44
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 11/26/22 12:22:55.444
    Nov 26 12:22:55.445: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:22:57.989: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:23:10.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9508" for this suite. 11/26/22 12:23:10.474
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:23:10.489
Nov 26 12:23:10.489: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 12:23:10.49
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:23:10.516
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:23:10.537
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 11/26/22 12:23:10.542
Nov 26 12:23:10.562: INFO: Waiting up to 5m0s for pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5" in namespace "downward-api-5280" to be "Succeeded or Failed"
Nov 26 12:23:10.570: INFO: Pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.488586ms
Nov 26 12:23:12.576: INFO: Pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014627724s
Nov 26 12:23:14.578: INFO: Pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015734653s
Nov 26 12:23:16.577: INFO: Pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015397162s
STEP: Saw pod success 11/26/22 12:23:16.577
Nov 26 12:23:16.578: INFO: Pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5" satisfied condition "Succeeded or Failed"
Nov 26 12:23:16.584: INFO: Trying to get logs from node ip-172-31-43-82 pod downward-api-03202057-0b93-4d3d-af61-5873375411d5 container dapi-container: <nil>
STEP: delete the pod 11/26/22 12:23:16.592
Nov 26 12:23:16.612: INFO: Waiting for pod downward-api-03202057-0b93-4d3d-af61-5873375411d5 to disappear
Nov 26 12:23:16.620: INFO: Pod downward-api-03202057-0b93-4d3d-af61-5873375411d5 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 26 12:23:16.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5280" for this suite. 11/26/22 12:23:16.627
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":115,"skipped":2184,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.150 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:23:10.489
    Nov 26 12:23:10.489: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 12:23:10.49
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:23:10.516
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:23:10.537
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 11/26/22 12:23:10.542
    Nov 26 12:23:10.562: INFO: Waiting up to 5m0s for pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5" in namespace "downward-api-5280" to be "Succeeded or Failed"
    Nov 26 12:23:10.570: INFO: Pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.488586ms
    Nov 26 12:23:12.576: INFO: Pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014627724s
    Nov 26 12:23:14.578: INFO: Pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015734653s
    Nov 26 12:23:16.577: INFO: Pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015397162s
    STEP: Saw pod success 11/26/22 12:23:16.577
    Nov 26 12:23:16.578: INFO: Pod "downward-api-03202057-0b93-4d3d-af61-5873375411d5" satisfied condition "Succeeded or Failed"
    Nov 26 12:23:16.584: INFO: Trying to get logs from node ip-172-31-43-82 pod downward-api-03202057-0b93-4d3d-af61-5873375411d5 container dapi-container: <nil>
    STEP: delete the pod 11/26/22 12:23:16.592
    Nov 26 12:23:16.612: INFO: Waiting for pod downward-api-03202057-0b93-4d3d-af61-5873375411d5 to disappear
    Nov 26 12:23:16.620: INFO: Pod downward-api-03202057-0b93-4d3d-af61-5873375411d5 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 26 12:23:16.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5280" for this suite. 11/26/22 12:23:16.627
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:23:16.646
Nov 26 12:23:16.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename endpointslice 11/26/22 12:23:16.647
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:23:16.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:23:16.687
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 11/26/22 12:23:21.894
STEP: referencing matching pods with named port 11/26/22 12:23:26.915
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 11/26/22 12:23:31.928
STEP: recreating EndpointSlices after they've been deleted 11/26/22 12:23:36.941
Nov 26 12:23:36.991: INFO: EndpointSlice for Service endpointslice-1281/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 26 12:23:47.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-1281" for this suite. 11/26/22 12:23:47.021
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":116,"skipped":2227,"failed":0}
------------------------------
â€¢ [SLOW TEST] [30.385 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:23:16.646
    Nov 26 12:23:16.646: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename endpointslice 11/26/22 12:23:16.647
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:23:16.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:23:16.687
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 11/26/22 12:23:21.894
    STEP: referencing matching pods with named port 11/26/22 12:23:26.915
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 11/26/22 12:23:31.928
    STEP: recreating EndpointSlices after they've been deleted 11/26/22 12:23:36.941
    Nov 26 12:23:36.991: INFO: EndpointSlice for Service endpointslice-1281/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 26 12:23:47.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-1281" for this suite. 11/26/22 12:23:47.021
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:23:47.032
Nov 26 12:23:47.032: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:23:47.033
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:23:47.06
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:23:47.066
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:23:47.074
Nov 26 12:23:47.087: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5" in namespace "projected-6762" to be "Succeeded or Failed"
Nov 26 12:23:47.098: INFO: Pod "downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.278169ms
Nov 26 12:23:49.105: INFO: Pod "downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017491419s
Nov 26 12:23:51.104: INFO: Pod "downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016320881s
STEP: Saw pod success 11/26/22 12:23:51.104
Nov 26 12:23:51.104: INFO: Pod "downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5" satisfied condition "Succeeded or Failed"
Nov 26 12:23:51.109: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5 container client-container: <nil>
STEP: delete the pod 11/26/22 12:23:51.12
Nov 26 12:23:51.137: INFO: Waiting for pod downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5 to disappear
Nov 26 12:23:51.145: INFO: Pod downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 12:23:51.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6762" for this suite. 11/26/22 12:23:51.153
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":117,"skipped":2230,"failed":0}
------------------------------
â€¢ [4.133 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:23:47.032
    Nov 26 12:23:47.032: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:23:47.033
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:23:47.06
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:23:47.066
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:23:47.074
    Nov 26 12:23:47.087: INFO: Waiting up to 5m0s for pod "downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5" in namespace "projected-6762" to be "Succeeded or Failed"
    Nov 26 12:23:47.098: INFO: Pod "downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.278169ms
    Nov 26 12:23:49.105: INFO: Pod "downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017491419s
    Nov 26 12:23:51.104: INFO: Pod "downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016320881s
    STEP: Saw pod success 11/26/22 12:23:51.104
    Nov 26 12:23:51.104: INFO: Pod "downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5" satisfied condition "Succeeded or Failed"
    Nov 26 12:23:51.109: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5 container client-container: <nil>
    STEP: delete the pod 11/26/22 12:23:51.12
    Nov 26 12:23:51.137: INFO: Waiting for pod downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5 to disappear
    Nov 26 12:23:51.145: INFO: Pod downwardapi-volume-db4c5644-c2b6-4509-ab4a-c54342fdfac5 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 12:23:51.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6762" for this suite. 11/26/22 12:23:51.153
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:23:51.167
Nov 26 12:23:51.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename limitrange 11/26/22 12:23:51.168
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:23:51.192
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:23:51.198
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 11/26/22 12:23:51.205
STEP: Setting up watch 11/26/22 12:23:51.205
STEP: Submitting a LimitRange 11/26/22 12:23:51.313
STEP: Verifying LimitRange creation was observed 11/26/22 12:23:51.324
STEP: Fetching the LimitRange to ensure it has proper values 11/26/22 12:23:51.324
Nov 26 12:23:51.329: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov 26 12:23:51.330: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 11/26/22 12:23:51.33
STEP: Ensuring Pod has resource requirements applied from LimitRange 11/26/22 12:23:51.342
Nov 26 12:23:51.347: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov 26 12:23:51.347: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 11/26/22 12:23:51.347
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 11/26/22 12:23:51.356
Nov 26 12:23:51.371: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Nov 26 12:23:51.371: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 11/26/22 12:23:51.371
STEP: Failing to create a Pod with more than max resources 11/26/22 12:23:51.378
STEP: Updating a LimitRange 11/26/22 12:23:51.382
STEP: Verifying LimitRange updating is effective 11/26/22 12:23:51.393
STEP: Creating a Pod with less than former min resources 11/26/22 12:23:53.4
STEP: Failing to create a Pod with more than max resources 11/26/22 12:23:53.407
STEP: Deleting a LimitRange 11/26/22 12:23:53.413
STEP: Verifying the LimitRange was deleted 11/26/22 12:23:53.427
Nov 26 12:23:58.441: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 11/26/22 12:23:58.441
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Nov 26 12:23:58.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-2734" for this suite. 11/26/22 12:23:58.463
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":118,"skipped":2244,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.395 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:23:51.167
    Nov 26 12:23:51.167: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename limitrange 11/26/22 12:23:51.168
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:23:51.192
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:23:51.198
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 11/26/22 12:23:51.205
    STEP: Setting up watch 11/26/22 12:23:51.205
    STEP: Submitting a LimitRange 11/26/22 12:23:51.313
    STEP: Verifying LimitRange creation was observed 11/26/22 12:23:51.324
    STEP: Fetching the LimitRange to ensure it has proper values 11/26/22 12:23:51.324
    Nov 26 12:23:51.329: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Nov 26 12:23:51.330: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 11/26/22 12:23:51.33
    STEP: Ensuring Pod has resource requirements applied from LimitRange 11/26/22 12:23:51.342
    Nov 26 12:23:51.347: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Nov 26 12:23:51.347: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 11/26/22 12:23:51.347
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 11/26/22 12:23:51.356
    Nov 26 12:23:51.371: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Nov 26 12:23:51.371: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 11/26/22 12:23:51.371
    STEP: Failing to create a Pod with more than max resources 11/26/22 12:23:51.378
    STEP: Updating a LimitRange 11/26/22 12:23:51.382
    STEP: Verifying LimitRange updating is effective 11/26/22 12:23:51.393
    STEP: Creating a Pod with less than former min resources 11/26/22 12:23:53.4
    STEP: Failing to create a Pod with more than max resources 11/26/22 12:23:53.407
    STEP: Deleting a LimitRange 11/26/22 12:23:53.413
    STEP: Verifying the LimitRange was deleted 11/26/22 12:23:53.427
    Nov 26 12:23:58.441: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 11/26/22 12:23:58.441
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Nov 26 12:23:58.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-2734" for this suite. 11/26/22 12:23:58.463
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:23:58.581
Nov 26 12:23:58.581: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename statefulset 11/26/22 12:23:58.584
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:23:58.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:23:58.686
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3523 11/26/22 12:23:58.724
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 11/26/22 12:23:58.74
Nov 26 12:23:58.758: INFO: Found 0 stateful pods, waiting for 3
Nov 26 12:24:08.769: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 12:24:08.769: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 12:24:08.769: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 12:24:08.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-3523 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 26 12:24:09.122: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 26 12:24:09.123: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 26 12:24:09.123: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/26/22 12:24:19.149
Nov 26 12:24:19.177: INFO: Updating stateful set ss2
STEP: Creating a new revision 11/26/22 12:24:19.177
STEP: Updating Pods in reverse ordinal order 11/26/22 12:24:29.203
Nov 26 12:24:29.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-3523 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 26 12:24:29.412: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 26 12:24:29.412: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 26 12:24:29.412: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 26 12:24:39.454: INFO: Waiting for StatefulSet statefulset-3523/ss2 to complete update
Nov 26 12:24:39.454: INFO: Waiting for Pod statefulset-3523/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Nov 26 12:24:39.454: INFO: Waiting for Pod statefulset-3523/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Nov 26 12:24:49.468: INFO: Waiting for StatefulSet statefulset-3523/ss2 to complete update
Nov 26 12:24:49.468: INFO: Waiting for Pod statefulset-3523/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Rolling back to a previous revision 11/26/22 12:24:59.467
Nov 26 12:24:59.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-3523 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 26 12:24:59.799: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 26 12:24:59.799: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 26 12:24:59.799: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 26 12:25:09.848: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 11/26/22 12:25:19.872
Nov 26 12:25:19.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-3523 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 26 12:25:20.085: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 26 12:25:20.085: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 26 12:25:20.085: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 26 12:25:30.122: INFO: Deleting all statefulset in ns statefulset-3523
Nov 26 12:25:30.127: INFO: Scaling statefulset ss2 to 0
Nov 26 12:25:40.155: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 12:25:40.160: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 26 12:25:40.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3523" for this suite. 11/26/22 12:25:40.211
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":119,"skipped":2267,"failed":0}
------------------------------
â€¢ [SLOW TEST] [101.643 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:23:58.581
    Nov 26 12:23:58.581: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename statefulset 11/26/22 12:23:58.584
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:23:58.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:23:58.686
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3523 11/26/22 12:23:58.724
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 11/26/22 12:23:58.74
    Nov 26 12:23:58.758: INFO: Found 0 stateful pods, waiting for 3
    Nov 26 12:24:08.769: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 12:24:08.769: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 12:24:08.769: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 12:24:08.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-3523 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 26 12:24:09.122: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 26 12:24:09.123: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 26 12:24:09.123: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/26/22 12:24:19.149
    Nov 26 12:24:19.177: INFO: Updating stateful set ss2
    STEP: Creating a new revision 11/26/22 12:24:19.177
    STEP: Updating Pods in reverse ordinal order 11/26/22 12:24:29.203
    Nov 26 12:24:29.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-3523 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 26 12:24:29.412: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 26 12:24:29.412: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 26 12:24:29.412: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 26 12:24:39.454: INFO: Waiting for StatefulSet statefulset-3523/ss2 to complete update
    Nov 26 12:24:39.454: INFO: Waiting for Pod statefulset-3523/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Nov 26 12:24:39.454: INFO: Waiting for Pod statefulset-3523/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Nov 26 12:24:49.468: INFO: Waiting for StatefulSet statefulset-3523/ss2 to complete update
    Nov 26 12:24:49.468: INFO: Waiting for Pod statefulset-3523/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Rolling back to a previous revision 11/26/22 12:24:59.467
    Nov 26 12:24:59.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-3523 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 26 12:24:59.799: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 26 12:24:59.799: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 26 12:24:59.799: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 26 12:25:09.848: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 11/26/22 12:25:19.872
    Nov 26 12:25:19.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-3523 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 26 12:25:20.085: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 26 12:25:20.085: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 26 12:25:20.085: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 26 12:25:30.122: INFO: Deleting all statefulset in ns statefulset-3523
    Nov 26 12:25:30.127: INFO: Scaling statefulset ss2 to 0
    Nov 26 12:25:40.155: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 12:25:40.160: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 26 12:25:40.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3523" for this suite. 11/26/22 12:25:40.211
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:25:40.228
Nov 26 12:25:40.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:25:40.229
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:25:40.254
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:25:40.263
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 11/26/22 12:25:40.269
Nov 26 12:25:40.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 create -f -'
Nov 26 12:25:41.122: INFO: stderr: ""
Nov 26 12:25:41.122: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/26/22 12:25:41.122
Nov 26 12:25:41.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 26 12:25:41.255: INFO: stderr: ""
Nov 26 12:25:41.255: INFO: stdout: "update-demo-nautilus-2qz82 update-demo-nautilus-h2sdk "
Nov 26 12:25:41.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-2qz82 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 12:25:41.358: INFO: stderr: ""
Nov 26 12:25:41.358: INFO: stdout: ""
Nov 26 12:25:41.358: INFO: update-demo-nautilus-2qz82 is created but not running
Nov 26 12:25:46.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 26 12:25:46.441: INFO: stderr: ""
Nov 26 12:25:46.441: INFO: stdout: "update-demo-nautilus-2qz82 update-demo-nautilus-h2sdk "
Nov 26 12:25:46.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-2qz82 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 12:25:46.521: INFO: stderr: ""
Nov 26 12:25:46.521: INFO: stdout: ""
Nov 26 12:25:46.521: INFO: update-demo-nautilus-2qz82 is created but not running
Nov 26 12:25:51.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 26 12:25:51.620: INFO: stderr: ""
Nov 26 12:25:51.620: INFO: stdout: "update-demo-nautilus-2qz82 update-demo-nautilus-h2sdk "
Nov 26 12:25:51.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-2qz82 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 12:25:51.721: INFO: stderr: ""
Nov 26 12:25:51.721: INFO: stdout: "true"
Nov 26 12:25:51.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-2qz82 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 26 12:25:51.840: INFO: stderr: ""
Nov 26 12:25:51.840: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 26 12:25:51.840: INFO: validating pod update-demo-nautilus-2qz82
Nov 26 12:25:51.847: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 26 12:25:51.848: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 26 12:25:51.848: INFO: update-demo-nautilus-2qz82 is verified up and running
Nov 26 12:25:51.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-h2sdk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 12:25:52.017: INFO: stderr: ""
Nov 26 12:25:52.017: INFO: stdout: "true"
Nov 26 12:25:52.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-h2sdk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 26 12:25:52.189: INFO: stderr: ""
Nov 26 12:25:52.189: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 26 12:25:52.189: INFO: validating pod update-demo-nautilus-h2sdk
Nov 26 12:25:52.197: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 26 12:25:52.197: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 26 12:25:52.197: INFO: update-demo-nautilus-h2sdk is verified up and running
STEP: using delete to clean up resources 11/26/22 12:25:52.197
Nov 26 12:25:52.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 delete --grace-period=0 --force -f -'
Nov 26 12:25:52.304: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 26 12:25:52.304: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 26 12:25:52.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get rc,svc -l name=update-demo --no-headers'
Nov 26 12:25:52.484: INFO: stderr: "No resources found in kubectl-7009 namespace.\n"
Nov 26 12:25:52.484: INFO: stdout: ""
Nov 26 12:25:52.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 26 12:25:52.656: INFO: stderr: ""
Nov 26 12:25:52.656: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:25:52.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7009" for this suite. 11/26/22 12:25:52.663
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":120,"skipped":2279,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.451 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:25:40.228
    Nov 26 12:25:40.229: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:25:40.229
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:25:40.254
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:25:40.263
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 11/26/22 12:25:40.269
    Nov 26 12:25:40.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 create -f -'
    Nov 26 12:25:41.122: INFO: stderr: ""
    Nov 26 12:25:41.122: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/26/22 12:25:41.122
    Nov 26 12:25:41.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 26 12:25:41.255: INFO: stderr: ""
    Nov 26 12:25:41.255: INFO: stdout: "update-demo-nautilus-2qz82 update-demo-nautilus-h2sdk "
    Nov 26 12:25:41.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-2qz82 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 12:25:41.358: INFO: stderr: ""
    Nov 26 12:25:41.358: INFO: stdout: ""
    Nov 26 12:25:41.358: INFO: update-demo-nautilus-2qz82 is created but not running
    Nov 26 12:25:46.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 26 12:25:46.441: INFO: stderr: ""
    Nov 26 12:25:46.441: INFO: stdout: "update-demo-nautilus-2qz82 update-demo-nautilus-h2sdk "
    Nov 26 12:25:46.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-2qz82 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 12:25:46.521: INFO: stderr: ""
    Nov 26 12:25:46.521: INFO: stdout: ""
    Nov 26 12:25:46.521: INFO: update-demo-nautilus-2qz82 is created but not running
    Nov 26 12:25:51.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 26 12:25:51.620: INFO: stderr: ""
    Nov 26 12:25:51.620: INFO: stdout: "update-demo-nautilus-2qz82 update-demo-nautilus-h2sdk "
    Nov 26 12:25:51.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-2qz82 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 12:25:51.721: INFO: stderr: ""
    Nov 26 12:25:51.721: INFO: stdout: "true"
    Nov 26 12:25:51.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-2qz82 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 26 12:25:51.840: INFO: stderr: ""
    Nov 26 12:25:51.840: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 26 12:25:51.840: INFO: validating pod update-demo-nautilus-2qz82
    Nov 26 12:25:51.847: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 26 12:25:51.848: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 26 12:25:51.848: INFO: update-demo-nautilus-2qz82 is verified up and running
    Nov 26 12:25:51.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-h2sdk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 12:25:52.017: INFO: stderr: ""
    Nov 26 12:25:52.017: INFO: stdout: "true"
    Nov 26 12:25:52.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods update-demo-nautilus-h2sdk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 26 12:25:52.189: INFO: stderr: ""
    Nov 26 12:25:52.189: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 26 12:25:52.189: INFO: validating pod update-demo-nautilus-h2sdk
    Nov 26 12:25:52.197: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 26 12:25:52.197: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 26 12:25:52.197: INFO: update-demo-nautilus-h2sdk is verified up and running
    STEP: using delete to clean up resources 11/26/22 12:25:52.197
    Nov 26 12:25:52.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 delete --grace-period=0 --force -f -'
    Nov 26 12:25:52.304: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 26 12:25:52.304: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Nov 26 12:25:52.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get rc,svc -l name=update-demo --no-headers'
    Nov 26 12:25:52.484: INFO: stderr: "No resources found in kubectl-7009 namespace.\n"
    Nov 26 12:25:52.484: INFO: stdout: ""
    Nov 26 12:25:52.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7009 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 26 12:25:52.656: INFO: stderr: ""
    Nov 26 12:25:52.656: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:25:52.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7009" for this suite. 11/26/22 12:25:52.663
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:25:52.68
Nov 26 12:25:52.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:25:52.681
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:25:52.721
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:25:52.729
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 11/26/22 12:25:52.745
STEP: watching for the Service to be added 11/26/22 12:25:52.763
Nov 26 12:25:52.766: INFO: Found Service test-service-n6fkf in namespace services-1850 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Nov 26 12:25:52.766: INFO: Service test-service-n6fkf created
STEP: Getting /status 11/26/22 12:25:52.767
Nov 26 12:25:52.776: INFO: Service test-service-n6fkf has LoadBalancer: {[]}
STEP: patching the ServiceStatus 11/26/22 12:25:52.776
STEP: watching for the Service to be patched 11/26/22 12:25:52.787
Nov 26 12:25:52.790: INFO: observed Service test-service-n6fkf in namespace services-1850 with annotations: map[] & LoadBalancer: {[]}
Nov 26 12:25:52.791: INFO: Found Service test-service-n6fkf in namespace services-1850 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Nov 26 12:25:52.791: INFO: Service test-service-n6fkf has service status patched
STEP: updating the ServiceStatus 11/26/22 12:25:52.791
Nov 26 12:25:52.817: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 11/26/22 12:25:52.817
Nov 26 12:25:52.821: INFO: Observed Service test-service-n6fkf in namespace services-1850 with annotations: map[] & Conditions: {[]}
Nov 26 12:25:52.821: INFO: Observed event: &Service{ObjectMeta:{test-service-n6fkf  services-1850  1983e89d-9b95-44cb-840f-67a38ab6e2f6 14558 0 2022-11-26 12:25:52 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-11-26 12:25:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-11-26 12:25:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.184,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.184],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Nov 26 12:25:52.821: INFO: Found Service test-service-n6fkf in namespace services-1850 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 26 12:25:52.821: INFO: Service test-service-n6fkf has service status updated
STEP: patching the service 11/26/22 12:25:52.821
STEP: watching for the Service to be patched 11/26/22 12:25:52.843
Nov 26 12:25:52.849: INFO: observed Service test-service-n6fkf in namespace services-1850 with labels: map[test-service-static:true]
Nov 26 12:25:52.850: INFO: observed Service test-service-n6fkf in namespace services-1850 with labels: map[test-service-static:true]
Nov 26 12:25:52.850: INFO: observed Service test-service-n6fkf in namespace services-1850 with labels: map[test-service-static:true]
Nov 26 12:25:52.850: INFO: Found Service test-service-n6fkf in namespace services-1850 with labels: map[test-service:patched test-service-static:true]
Nov 26 12:25:52.850: INFO: Service test-service-n6fkf patched
STEP: deleting the service 11/26/22 12:25:52.85
STEP: watching for the Service to be deleted 11/26/22 12:25:52.883
Nov 26 12:25:52.887: INFO: Observed event: ADDED
Nov 26 12:25:52.887: INFO: Observed event: MODIFIED
Nov 26 12:25:52.887: INFO: Observed event: MODIFIED
Nov 26 12:25:52.887: INFO: Observed event: MODIFIED
Nov 26 12:25:52.887: INFO: Found Service test-service-n6fkf in namespace services-1850 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Nov 26 12:25:52.887: INFO: Service test-service-n6fkf deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:25:52.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1850" for this suite. 11/26/22 12:25:52.895
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":121,"skipped":2279,"failed":0}
------------------------------
â€¢ [0.230 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:25:52.68
    Nov 26 12:25:52.680: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:25:52.681
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:25:52.721
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:25:52.729
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 11/26/22 12:25:52.745
    STEP: watching for the Service to be added 11/26/22 12:25:52.763
    Nov 26 12:25:52.766: INFO: Found Service test-service-n6fkf in namespace services-1850 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Nov 26 12:25:52.766: INFO: Service test-service-n6fkf created
    STEP: Getting /status 11/26/22 12:25:52.767
    Nov 26 12:25:52.776: INFO: Service test-service-n6fkf has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 11/26/22 12:25:52.776
    STEP: watching for the Service to be patched 11/26/22 12:25:52.787
    Nov 26 12:25:52.790: INFO: observed Service test-service-n6fkf in namespace services-1850 with annotations: map[] & LoadBalancer: {[]}
    Nov 26 12:25:52.791: INFO: Found Service test-service-n6fkf in namespace services-1850 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Nov 26 12:25:52.791: INFO: Service test-service-n6fkf has service status patched
    STEP: updating the ServiceStatus 11/26/22 12:25:52.791
    Nov 26 12:25:52.817: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 11/26/22 12:25:52.817
    Nov 26 12:25:52.821: INFO: Observed Service test-service-n6fkf in namespace services-1850 with annotations: map[] & Conditions: {[]}
    Nov 26 12:25:52.821: INFO: Observed event: &Service{ObjectMeta:{test-service-n6fkf  services-1850  1983e89d-9b95-44cb-840f-67a38ab6e2f6 14558 0 2022-11-26 12:25:52 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-11-26 12:25:52 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-11-26 12:25:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.184,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.184],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Nov 26 12:25:52.821: INFO: Found Service test-service-n6fkf in namespace services-1850 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 26 12:25:52.821: INFO: Service test-service-n6fkf has service status updated
    STEP: patching the service 11/26/22 12:25:52.821
    STEP: watching for the Service to be patched 11/26/22 12:25:52.843
    Nov 26 12:25:52.849: INFO: observed Service test-service-n6fkf in namespace services-1850 with labels: map[test-service-static:true]
    Nov 26 12:25:52.850: INFO: observed Service test-service-n6fkf in namespace services-1850 with labels: map[test-service-static:true]
    Nov 26 12:25:52.850: INFO: observed Service test-service-n6fkf in namespace services-1850 with labels: map[test-service-static:true]
    Nov 26 12:25:52.850: INFO: Found Service test-service-n6fkf in namespace services-1850 with labels: map[test-service:patched test-service-static:true]
    Nov 26 12:25:52.850: INFO: Service test-service-n6fkf patched
    STEP: deleting the service 11/26/22 12:25:52.85
    STEP: watching for the Service to be deleted 11/26/22 12:25:52.883
    Nov 26 12:25:52.887: INFO: Observed event: ADDED
    Nov 26 12:25:52.887: INFO: Observed event: MODIFIED
    Nov 26 12:25:52.887: INFO: Observed event: MODIFIED
    Nov 26 12:25:52.887: INFO: Observed event: MODIFIED
    Nov 26 12:25:52.887: INFO: Found Service test-service-n6fkf in namespace services-1850 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Nov 26 12:25:52.887: INFO: Service test-service-n6fkf deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:25:52.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1850" for this suite. 11/26/22 12:25:52.895
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:25:52.911
Nov 26 12:25:52.911: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 12:25:52.912
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:25:52.944
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:25:52.951
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 11/26/22 12:25:52.957
STEP: Getting a ResourceQuota 11/26/22 12:25:52.964
STEP: Updating a ResourceQuota 11/26/22 12:25:52.973
STEP: Verifying a ResourceQuota was modified 11/26/22 12:25:52.982
STEP: Deleting a ResourceQuota 11/26/22 12:25:52.988
STEP: Verifying the deleted ResourceQuota 11/26/22 12:25:52.996
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 12:25:53.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7407" for this suite. 11/26/22 12:25:53.009
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":122,"skipped":2281,"failed":0}
------------------------------
â€¢ [0.111 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:25:52.911
    Nov 26 12:25:52.911: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 12:25:52.912
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:25:52.944
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:25:52.951
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 11/26/22 12:25:52.957
    STEP: Getting a ResourceQuota 11/26/22 12:25:52.964
    STEP: Updating a ResourceQuota 11/26/22 12:25:52.973
    STEP: Verifying a ResourceQuota was modified 11/26/22 12:25:52.982
    STEP: Deleting a ResourceQuota 11/26/22 12:25:52.988
    STEP: Verifying the deleted ResourceQuota 11/26/22 12:25:52.996
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 12:25:53.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7407" for this suite. 11/26/22 12:25:53.009
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:25:53.027
Nov 26 12:25:53.027: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename statefulset 11/26/22 12:25:53.028
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:25:53.063
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:25:53.077
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5139 11/26/22 12:25:53.082
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-5139 11/26/22 12:25:53.091
Nov 26 12:25:53.182: INFO: Found 0 stateful pods, waiting for 1
Nov 26 12:26:03.190: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 11/26/22 12:26:03.202
STEP: updating a scale subresource 11/26/22 12:26:03.209
STEP: verifying the statefulset Spec.Replicas was modified 11/26/22 12:26:03.221
STEP: Patch a scale subresource 11/26/22 12:26:03.228
STEP: verifying the statefulset Spec.Replicas was modified 11/26/22 12:26:03.263
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 26 12:26:03.271: INFO: Deleting all statefulset in ns statefulset-5139
Nov 26 12:26:03.280: INFO: Scaling statefulset ss to 0
Nov 26 12:26:13.347: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 12:26:13.353: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 26 12:26:13.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5139" for this suite. 11/26/22 12:26:13.404
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":123,"skipped":2326,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.397 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:25:53.027
    Nov 26 12:25:53.027: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename statefulset 11/26/22 12:25:53.028
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:25:53.063
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:25:53.077
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5139 11/26/22 12:25:53.082
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-5139 11/26/22 12:25:53.091
    Nov 26 12:25:53.182: INFO: Found 0 stateful pods, waiting for 1
    Nov 26 12:26:03.190: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 11/26/22 12:26:03.202
    STEP: updating a scale subresource 11/26/22 12:26:03.209
    STEP: verifying the statefulset Spec.Replicas was modified 11/26/22 12:26:03.221
    STEP: Patch a scale subresource 11/26/22 12:26:03.228
    STEP: verifying the statefulset Spec.Replicas was modified 11/26/22 12:26:03.263
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 26 12:26:03.271: INFO: Deleting all statefulset in ns statefulset-5139
    Nov 26 12:26:03.280: INFO: Scaling statefulset ss to 0
    Nov 26 12:26:13.347: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 12:26:13.353: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 26 12:26:13.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5139" for this suite. 11/26/22 12:26:13.404
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:13.424
Nov 26 12:26:13.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename var-expansion 11/26/22 12:26:13.425
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:13.454
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:13.461
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 11/26/22 12:26:13.467
Nov 26 12:26:13.482: INFO: Waiting up to 5m0s for pod "var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada" in namespace "var-expansion-840" to be "Succeeded or Failed"
Nov 26 12:26:13.488: INFO: Pod "var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada": Phase="Pending", Reason="", readiness=false. Elapsed: 5.744302ms
Nov 26 12:26:15.494: INFO: Pod "var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011489092s
Nov 26 12:26:17.495: INFO: Pod "var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012873945s
STEP: Saw pod success 11/26/22 12:26:17.495
Nov 26 12:26:17.495: INFO: Pod "var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada" satisfied condition "Succeeded or Failed"
Nov 26 12:26:17.505: INFO: Trying to get logs from node ip-172-31-43-82 pod var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada container dapi-container: <nil>
STEP: delete the pod 11/26/22 12:26:17.527
Nov 26 12:26:17.543: INFO: Waiting for pod var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada to disappear
Nov 26 12:26:17.549: INFO: Pod var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 26 12:26:17.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-840" for this suite. 11/26/22 12:26:17.554
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":124,"skipped":2333,"failed":0}
------------------------------
â€¢ [4.141 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:13.424
    Nov 26 12:26:13.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename var-expansion 11/26/22 12:26:13.425
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:13.454
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:13.461
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 11/26/22 12:26:13.467
    Nov 26 12:26:13.482: INFO: Waiting up to 5m0s for pod "var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada" in namespace "var-expansion-840" to be "Succeeded or Failed"
    Nov 26 12:26:13.488: INFO: Pod "var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada": Phase="Pending", Reason="", readiness=false. Elapsed: 5.744302ms
    Nov 26 12:26:15.494: INFO: Pod "var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011489092s
    Nov 26 12:26:17.495: INFO: Pod "var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012873945s
    STEP: Saw pod success 11/26/22 12:26:17.495
    Nov 26 12:26:17.495: INFO: Pod "var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada" satisfied condition "Succeeded or Failed"
    Nov 26 12:26:17.505: INFO: Trying to get logs from node ip-172-31-43-82 pod var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada container dapi-container: <nil>
    STEP: delete the pod 11/26/22 12:26:17.527
    Nov 26 12:26:17.543: INFO: Waiting for pod var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada to disappear
    Nov 26 12:26:17.549: INFO: Pod var-expansion-d35e8d3a-0155-4bcb-b8fb-470551490ada no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 26 12:26:17.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-840" for this suite. 11/26/22 12:26:17.554
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:17.568
Nov 26 12:26:17.569: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:26:17.569
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:17.59
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:17.598
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Nov 26 12:26:17.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/26/22 12:26:22.18
Nov 26 12:26:22.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-2374 --namespace=crd-publish-openapi-2374 create -f -'
Nov 26 12:26:23.056: INFO: stderr: ""
Nov 26 12:26:23.056: INFO: stdout: "e2e-test-crd-publish-openapi-4822-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 26 12:26:23.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-2374 --namespace=crd-publish-openapi-2374 delete e2e-test-crd-publish-openapi-4822-crds test-cr'
Nov 26 12:26:23.148: INFO: stderr: ""
Nov 26 12:26:23.148: INFO: stdout: "e2e-test-crd-publish-openapi-4822-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov 26 12:26:23.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-2374 --namespace=crd-publish-openapi-2374 apply -f -'
Nov 26 12:26:23.883: INFO: stderr: ""
Nov 26 12:26:23.883: INFO: stdout: "e2e-test-crd-publish-openapi-4822-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 26 12:26:23.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-2374 --namespace=crd-publish-openapi-2374 delete e2e-test-crd-publish-openapi-4822-crds test-cr'
Nov 26 12:26:23.973: INFO: stderr: ""
Nov 26 12:26:23.973: INFO: stdout: "e2e-test-crd-publish-openapi-4822-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 11/26/22 12:26:23.973
Nov 26 12:26:23.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-2374 explain e2e-test-crd-publish-openapi-4822-crds'
Nov 26 12:26:24.323: INFO: stderr: ""
Nov 26 12:26:24.323: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4822-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:26:27.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2374" for this suite. 11/26/22 12:26:27.115
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":125,"skipped":2344,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.558 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:17.568
    Nov 26 12:26:17.569: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 12:26:17.569
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:17.59
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:17.598
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Nov 26 12:26:17.603: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/26/22 12:26:22.18
    Nov 26 12:26:22.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-2374 --namespace=crd-publish-openapi-2374 create -f -'
    Nov 26 12:26:23.056: INFO: stderr: ""
    Nov 26 12:26:23.056: INFO: stdout: "e2e-test-crd-publish-openapi-4822-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Nov 26 12:26:23.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-2374 --namespace=crd-publish-openapi-2374 delete e2e-test-crd-publish-openapi-4822-crds test-cr'
    Nov 26 12:26:23.148: INFO: stderr: ""
    Nov 26 12:26:23.148: INFO: stdout: "e2e-test-crd-publish-openapi-4822-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Nov 26 12:26:23.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-2374 --namespace=crd-publish-openapi-2374 apply -f -'
    Nov 26 12:26:23.883: INFO: stderr: ""
    Nov 26 12:26:23.883: INFO: stdout: "e2e-test-crd-publish-openapi-4822-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Nov 26 12:26:23.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-2374 --namespace=crd-publish-openapi-2374 delete e2e-test-crd-publish-openapi-4822-crds test-cr'
    Nov 26 12:26:23.973: INFO: stderr: ""
    Nov 26 12:26:23.973: INFO: stdout: "e2e-test-crd-publish-openapi-4822-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 11/26/22 12:26:23.973
    Nov 26 12:26:23.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-2374 explain e2e-test-crd-publish-openapi-4822-crds'
    Nov 26 12:26:24.323: INFO: stderr: ""
    Nov 26 12:26:24.323: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-4822-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:26:27.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2374" for this suite. 11/26/22 12:26:27.115
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:27.129
Nov 26 12:26:27.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replicaset 11/26/22 12:26:27.13
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:27.157
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:27.166
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 11/26/22 12:26:27.186
STEP: Verify that the required pods have come up. 11/26/22 12:26:27.196
Nov 26 12:26:27.203: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 26 12:26:32.210: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/26/22 12:26:32.21
STEP: Getting /status 11/26/22 12:26:32.21
Nov 26 12:26:32.218: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 11/26/22 12:26:32.218
Nov 26 12:26:32.235: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 11/26/22 12:26:32.235
Nov 26 12:26:32.242: INFO: Observed &ReplicaSet event: ADDED
Nov 26 12:26:32.242: INFO: Observed &ReplicaSet event: MODIFIED
Nov 26 12:26:32.242: INFO: Observed &ReplicaSet event: MODIFIED
Nov 26 12:26:32.243: INFO: Observed &ReplicaSet event: MODIFIED
Nov 26 12:26:32.243: INFO: Found replicaset test-rs in namespace replicaset-9898 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 26 12:26:32.243: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 11/26/22 12:26:32.243
Nov 26 12:26:32.243: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 26 12:26:32.256: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 11/26/22 12:26:32.256
Nov 26 12:26:32.259: INFO: Observed &ReplicaSet event: ADDED
Nov 26 12:26:32.260: INFO: Observed &ReplicaSet event: MODIFIED
Nov 26 12:26:32.260: INFO: Observed &ReplicaSet event: MODIFIED
Nov 26 12:26:32.260: INFO: Observed &ReplicaSet event: MODIFIED
Nov 26 12:26:32.260: INFO: Observed replicaset test-rs in namespace replicaset-9898 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 26 12:26:32.260: INFO: Observed &ReplicaSet event: MODIFIED
Nov 26 12:26:32.260: INFO: Found replicaset test-rs in namespace replicaset-9898 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Nov 26 12:26:32.260: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 26 12:26:32.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9898" for this suite. 11/26/22 12:26:32.268
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":126,"skipped":2367,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.153 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:27.129
    Nov 26 12:26:27.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replicaset 11/26/22 12:26:27.13
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:27.157
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:27.166
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 11/26/22 12:26:27.186
    STEP: Verify that the required pods have come up. 11/26/22 12:26:27.196
    Nov 26 12:26:27.203: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 26 12:26:32.210: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/26/22 12:26:32.21
    STEP: Getting /status 11/26/22 12:26:32.21
    Nov 26 12:26:32.218: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 11/26/22 12:26:32.218
    Nov 26 12:26:32.235: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 11/26/22 12:26:32.235
    Nov 26 12:26:32.242: INFO: Observed &ReplicaSet event: ADDED
    Nov 26 12:26:32.242: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 26 12:26:32.242: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 26 12:26:32.243: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 26 12:26:32.243: INFO: Found replicaset test-rs in namespace replicaset-9898 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 26 12:26:32.243: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 11/26/22 12:26:32.243
    Nov 26 12:26:32.243: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 26 12:26:32.256: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 11/26/22 12:26:32.256
    Nov 26 12:26:32.259: INFO: Observed &ReplicaSet event: ADDED
    Nov 26 12:26:32.260: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 26 12:26:32.260: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 26 12:26:32.260: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 26 12:26:32.260: INFO: Observed replicaset test-rs in namespace replicaset-9898 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 26 12:26:32.260: INFO: Observed &ReplicaSet event: MODIFIED
    Nov 26 12:26:32.260: INFO: Found replicaset test-rs in namespace replicaset-9898 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Nov 26 12:26:32.260: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 26 12:26:32.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-9898" for this suite. 11/26/22 12:26:32.268
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:32.282
Nov 26 12:26:32.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:26:32.284
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:32.316
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:32.321
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1205 11/26/22 12:26:32.327
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/26/22 12:26:32.366
STEP: creating service externalsvc in namespace services-1205 11/26/22 12:26:32.366
STEP: creating replication controller externalsvc in namespace services-1205 11/26/22 12:26:32.4
I1126 12:26:32.411946      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1205, replica count: 2
I1126 12:26:35.462614      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1126 12:26:38.464342      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 11/26/22 12:26:38.47
Nov 26 12:26:38.507: INFO: Creating new exec pod
Nov 26 12:26:38.520: INFO: Waiting up to 5m0s for pod "execpod68b2m" in namespace "services-1205" to be "running"
Nov 26 12:26:38.527: INFO: Pod "execpod68b2m": Phase="Pending", Reason="", readiness=false. Elapsed: 7.010184ms
Nov 26 12:26:40.534: INFO: Pod "execpod68b2m": Phase="Running", Reason="", readiness=true. Elapsed: 2.014013468s
Nov 26 12:26:40.535: INFO: Pod "execpod68b2m" satisfied condition "running"
Nov 26 12:26:40.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-1205 exec execpod68b2m -- /bin/sh -x -c nslookup nodeport-service.services-1205.svc.cluster.local'
Nov 26 12:26:40.729: INFO: stderr: "+ nslookup nodeport-service.services-1205.svc.cluster.local\n"
Nov 26 12:26:40.729: INFO: stdout: "Server:\t\t10.152.183.246\nAddress:\t10.152.183.246#53\n\nnodeport-service.services-1205.svc.cluster.local\tcanonical name = externalsvc.services-1205.svc.cluster.local.\nName:\texternalsvc.services-1205.svc.cluster.local\nAddress: 10.152.183.222\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1205, will wait for the garbage collector to delete the pods 11/26/22 12:26:40.729
Nov 26 12:26:40.797: INFO: Deleting ReplicationController externalsvc took: 11.20936ms
Nov 26 12:26:40.898: INFO: Terminating ReplicationController externalsvc pods took: 100.646815ms
Nov 26 12:26:43.328: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:26:43.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1205" for this suite. 11/26/22 12:26:43.359
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":127,"skipped":2371,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.093 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:32.282
    Nov 26 12:26:32.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:26:32.284
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:32.316
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:32.321
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-1205 11/26/22 12:26:32.327
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/26/22 12:26:32.366
    STEP: creating service externalsvc in namespace services-1205 11/26/22 12:26:32.366
    STEP: creating replication controller externalsvc in namespace services-1205 11/26/22 12:26:32.4
    I1126 12:26:32.411946      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-1205, replica count: 2
    I1126 12:26:35.462614      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1126 12:26:38.464342      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 11/26/22 12:26:38.47
    Nov 26 12:26:38.507: INFO: Creating new exec pod
    Nov 26 12:26:38.520: INFO: Waiting up to 5m0s for pod "execpod68b2m" in namespace "services-1205" to be "running"
    Nov 26 12:26:38.527: INFO: Pod "execpod68b2m": Phase="Pending", Reason="", readiness=false. Elapsed: 7.010184ms
    Nov 26 12:26:40.534: INFO: Pod "execpod68b2m": Phase="Running", Reason="", readiness=true. Elapsed: 2.014013468s
    Nov 26 12:26:40.535: INFO: Pod "execpod68b2m" satisfied condition "running"
    Nov 26 12:26:40.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-1205 exec execpod68b2m -- /bin/sh -x -c nslookup nodeport-service.services-1205.svc.cluster.local'
    Nov 26 12:26:40.729: INFO: stderr: "+ nslookup nodeport-service.services-1205.svc.cluster.local\n"
    Nov 26 12:26:40.729: INFO: stdout: "Server:\t\t10.152.183.246\nAddress:\t10.152.183.246#53\n\nnodeport-service.services-1205.svc.cluster.local\tcanonical name = externalsvc.services-1205.svc.cluster.local.\nName:\texternalsvc.services-1205.svc.cluster.local\nAddress: 10.152.183.222\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-1205, will wait for the garbage collector to delete the pods 11/26/22 12:26:40.729
    Nov 26 12:26:40.797: INFO: Deleting ReplicationController externalsvc took: 11.20936ms
    Nov 26 12:26:40.898: INFO: Terminating ReplicationController externalsvc pods took: 100.646815ms
    Nov 26 12:26:43.328: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:26:43.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1205" for this suite. 11/26/22 12:26:43.359
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:43.376
Nov 26 12:26:43.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename containers 11/26/22 12:26:43.377
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:43.401
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:43.406
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 11/26/22 12:26:43.412
Nov 26 12:26:43.427: INFO: Waiting up to 5m0s for pod "client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a" in namespace "containers-3598" to be "Succeeded or Failed"
Nov 26 12:26:43.434: INFO: Pod "client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.550547ms
Nov 26 12:26:45.440: INFO: Pod "client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012760365s
Nov 26 12:26:47.441: INFO: Pod "client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01392344s
STEP: Saw pod success 11/26/22 12:26:47.441
Nov 26 12:26:47.441: INFO: Pod "client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a" satisfied condition "Succeeded or Failed"
Nov 26 12:26:47.446: INFO: Trying to get logs from node ip-172-31-43-82 pod client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:26:47.455
Nov 26 12:26:47.475: INFO: Waiting for pod client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a to disappear
Nov 26 12:26:47.480: INFO: Pod client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 26 12:26:47.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3598" for this suite. 11/26/22 12:26:47.486
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":128,"skipped":2378,"failed":0}
------------------------------
â€¢ [4.121 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:43.376
    Nov 26 12:26:43.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename containers 11/26/22 12:26:43.377
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:43.401
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:43.406
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 11/26/22 12:26:43.412
    Nov 26 12:26:43.427: INFO: Waiting up to 5m0s for pod "client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a" in namespace "containers-3598" to be "Succeeded or Failed"
    Nov 26 12:26:43.434: INFO: Pod "client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.550547ms
    Nov 26 12:26:45.440: INFO: Pod "client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012760365s
    Nov 26 12:26:47.441: INFO: Pod "client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01392344s
    STEP: Saw pod success 11/26/22 12:26:47.441
    Nov 26 12:26:47.441: INFO: Pod "client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a" satisfied condition "Succeeded or Failed"
    Nov 26 12:26:47.446: INFO: Trying to get logs from node ip-172-31-43-82 pod client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:26:47.455
    Nov 26 12:26:47.475: INFO: Waiting for pod client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a to disappear
    Nov 26 12:26:47.480: INFO: Pod client-containers-b3e36d22-aaf5-4f62-9c36-796ffbb5735a no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 26 12:26:47.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-3598" for this suite. 11/26/22 12:26:47.486
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:47.499
Nov 26 12:26:47.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename svcaccounts 11/26/22 12:26:47.5
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:47.523
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:47.529
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Nov 26 12:26:47.540: INFO: Got root ca configmap in namespace "svcaccounts-5443"
Nov 26 12:26:47.552: INFO: Deleted root ca configmap in namespace "svcaccounts-5443"
STEP: waiting for a new root ca configmap created 11/26/22 12:26:48.053
Nov 26 12:26:48.059: INFO: Recreated root ca configmap in namespace "svcaccounts-5443"
Nov 26 12:26:48.072: INFO: Updated root ca configmap in namespace "svcaccounts-5443"
STEP: waiting for the root ca configmap reconciled 11/26/22 12:26:48.573
Nov 26 12:26:48.579: INFO: Reconciled root ca configmap in namespace "svcaccounts-5443"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 26 12:26:48.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5443" for this suite. 11/26/22 12:26:48.602
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":129,"skipped":2384,"failed":0}
------------------------------
â€¢ [1.113 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:47.499
    Nov 26 12:26:47.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename svcaccounts 11/26/22 12:26:47.5
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:47.523
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:47.529
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Nov 26 12:26:47.540: INFO: Got root ca configmap in namespace "svcaccounts-5443"
    Nov 26 12:26:47.552: INFO: Deleted root ca configmap in namespace "svcaccounts-5443"
    STEP: waiting for a new root ca configmap created 11/26/22 12:26:48.053
    Nov 26 12:26:48.059: INFO: Recreated root ca configmap in namespace "svcaccounts-5443"
    Nov 26 12:26:48.072: INFO: Updated root ca configmap in namespace "svcaccounts-5443"
    STEP: waiting for the root ca configmap reconciled 11/26/22 12:26:48.573
    Nov 26 12:26:48.579: INFO: Reconciled root ca configmap in namespace "svcaccounts-5443"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 26 12:26:48.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-5443" for this suite. 11/26/22 12:26:48.602
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:48.617
Nov 26 12:26:48.617: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 12:26:48.618
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:48.643
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:48.65
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 11/26/22 12:26:48.657
STEP: fetching the ConfigMap 11/26/22 12:26:48.665
STEP: patching the ConfigMap 11/26/22 12:26:48.672
STEP: listing all ConfigMaps in all namespaces with a label selector 11/26/22 12:26:48.691
STEP: deleting the ConfigMap by collection with a label selector 11/26/22 12:26:48.762
STEP: listing all ConfigMaps in test namespace 11/26/22 12:26:48.781
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 12:26:48.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2791" for this suite. 11/26/22 12:26:48.793
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":130,"skipped":2416,"failed":0}
------------------------------
â€¢ [0.189 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:48.617
    Nov 26 12:26:48.617: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 12:26:48.618
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:48.643
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:48.65
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 11/26/22 12:26:48.657
    STEP: fetching the ConfigMap 11/26/22 12:26:48.665
    STEP: patching the ConfigMap 11/26/22 12:26:48.672
    STEP: listing all ConfigMaps in all namespaces with a label selector 11/26/22 12:26:48.691
    STEP: deleting the ConfigMap by collection with a label selector 11/26/22 12:26:48.762
    STEP: listing all ConfigMaps in test namespace 11/26/22 12:26:48.781
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 12:26:48.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2791" for this suite. 11/26/22 12:26:48.793
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:48.812
Nov 26 12:26:48.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:26:48.813
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:48.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:48.846
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:26:48.887
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:26:49.537
STEP: Deploying the webhook pod 11/26/22 12:26:49.547
STEP: Wait for the deployment to be ready 11/26/22 12:26:49.567
Nov 26 12:26:49.586: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/26/22 12:26:51.605
STEP: Verifying the service has paired with the endpoint 11/26/22 12:26:51.623
Nov 26 12:26:52.624: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 11/26/22 12:26:52.629
STEP: create a configmap that should be updated by the webhook 11/26/22 12:26:52.651
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:26:52.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4870" for this suite. 11/26/22 12:26:52.691
STEP: Destroying namespace "webhook-4870-markers" for this suite. 11/26/22 12:26:52.702
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":131,"skipped":2460,"failed":0}
------------------------------
â€¢ [3.997 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:48.812
    Nov 26 12:26:48.812: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:26:48.813
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:48.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:48.846
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:26:48.887
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:26:49.537
    STEP: Deploying the webhook pod 11/26/22 12:26:49.547
    STEP: Wait for the deployment to be ready 11/26/22 12:26:49.567
    Nov 26 12:26:49.586: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/26/22 12:26:51.605
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:26:51.623
    Nov 26 12:26:52.624: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 11/26/22 12:26:52.629
    STEP: create a configmap that should be updated by the webhook 11/26/22 12:26:52.651
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:26:52.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4870" for this suite. 11/26/22 12:26:52.691
    STEP: Destroying namespace "webhook-4870-markers" for this suite. 11/26/22 12:26:52.702
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:52.813
Nov 26 12:26:52.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:26:52.815
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:52.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:52.855
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-f7017277-3f99-40c3-bbcc-4c576e12cfed 11/26/22 12:26:52.862
STEP: Creating a pod to test consume secrets 11/26/22 12:26:52.87
Nov 26 12:26:52.889: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915" in namespace "projected-3815" to be "Succeeded or Failed"
Nov 26 12:26:52.898: INFO: Pod "pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915": Phase="Pending", Reason="", readiness=false. Elapsed: 8.844018ms
Nov 26 12:26:54.903: INFO: Pod "pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0140566s
Nov 26 12:26:56.904: INFO: Pod "pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014995741s
STEP: Saw pod success 11/26/22 12:26:56.904
Nov 26 12:26:56.904: INFO: Pod "pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915" satisfied condition "Succeeded or Failed"
Nov 26 12:26:56.910: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915 container secret-volume-test: <nil>
STEP: delete the pod 11/26/22 12:26:56.92
Nov 26 12:26:56.937: INFO: Waiting for pod pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915 to disappear
Nov 26 12:26:56.944: INFO: Pod pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 26 12:26:56.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3815" for this suite. 11/26/22 12:26:56.96
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":132,"skipped":2478,"failed":0}
------------------------------
â€¢ [4.158 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:52.813
    Nov 26 12:26:52.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:26:52.815
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:52.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:52.855
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-f7017277-3f99-40c3-bbcc-4c576e12cfed 11/26/22 12:26:52.862
    STEP: Creating a pod to test consume secrets 11/26/22 12:26:52.87
    Nov 26 12:26:52.889: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915" in namespace "projected-3815" to be "Succeeded or Failed"
    Nov 26 12:26:52.898: INFO: Pod "pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915": Phase="Pending", Reason="", readiness=false. Elapsed: 8.844018ms
    Nov 26 12:26:54.903: INFO: Pod "pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0140566s
    Nov 26 12:26:56.904: INFO: Pod "pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014995741s
    STEP: Saw pod success 11/26/22 12:26:56.904
    Nov 26 12:26:56.904: INFO: Pod "pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915" satisfied condition "Succeeded or Failed"
    Nov 26 12:26:56.910: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915 container secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:26:56.92
    Nov 26 12:26:56.937: INFO: Waiting for pod pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915 to disappear
    Nov 26 12:26:56.944: INFO: Pod pod-projected-secrets-462eca4a-b17f-4d6f-b46a-6dceb1b79915 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 26 12:26:56.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3815" for this suite. 11/26/22 12:26:56.96
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:56.972
Nov 26 12:26:56.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename runtimeclass 11/26/22 12:26:56.973
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:56.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:57.001
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-3093-delete-me 11/26/22 12:26:57.022
STEP: Waiting for the RuntimeClass to disappear 11/26/22 12:26:57.032
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 26 12:26:57.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-3093" for this suite. 11/26/22 12:26:57.064
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":133,"skipped":2479,"failed":0}
------------------------------
â€¢ [0.110 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:56.972
    Nov 26 12:26:56.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename runtimeclass 11/26/22 12:26:56.973
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:56.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:57.001
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-3093-delete-me 11/26/22 12:26:57.022
    STEP: Waiting for the RuntimeClass to disappear 11/26/22 12:26:57.032
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 26 12:26:57.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-3093" for this suite. 11/26/22 12:26:57.064
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:26:57.083
Nov 26 12:26:57.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename namespaces 11/26/22 12:26:57.084
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:57.106
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:57.119
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 11/26/22 12:26:57.125
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:57.149
STEP: Creating a pod in the namespace 11/26/22 12:26:57.155
STEP: Waiting for the pod to have running status 11/26/22 12:26:57.172
Nov 26 12:26:57.172: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-4111" to be "running"
Nov 26 12:26:57.186: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.212675ms
Nov 26 12:26:59.194: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021325549s
Nov 26 12:27:01.193: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.021111318s
Nov 26 12:27:01.193: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 11/26/22 12:27:01.193
STEP: Waiting for the namespace to be removed. 11/26/22 12:27:01.206
STEP: Recreating the namespace 11/26/22 12:27:12.214
STEP: Verifying there are no pods in the namespace 11/26/22 12:27:12.234
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:27:12.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-179" for this suite. 11/26/22 12:27:12.25
STEP: Destroying namespace "nsdeletetest-4111" for this suite. 11/26/22 12:27:12.261
Nov 26 12:27:12.266: INFO: Namespace nsdeletetest-4111 was already deleted
STEP: Destroying namespace "nsdeletetest-433" for this suite. 11/26/22 12:27:12.266
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":134,"skipped":2480,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.195 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:26:57.083
    Nov 26 12:26:57.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename namespaces 11/26/22 12:26:57.084
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:57.106
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:26:57.119
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 11/26/22 12:26:57.125
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:26:57.149
    STEP: Creating a pod in the namespace 11/26/22 12:26:57.155
    STEP: Waiting for the pod to have running status 11/26/22 12:26:57.172
    Nov 26 12:26:57.172: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-4111" to be "running"
    Nov 26 12:26:57.186: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 14.212675ms
    Nov 26 12:26:59.194: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021325549s
    Nov 26 12:27:01.193: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.021111318s
    Nov 26 12:27:01.193: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 11/26/22 12:27:01.193
    STEP: Waiting for the namespace to be removed. 11/26/22 12:27:01.206
    STEP: Recreating the namespace 11/26/22 12:27:12.214
    STEP: Verifying there are no pods in the namespace 11/26/22 12:27:12.234
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:27:12.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-179" for this suite. 11/26/22 12:27:12.25
    STEP: Destroying namespace "nsdeletetest-4111" for this suite. 11/26/22 12:27:12.261
    Nov 26 12:27:12.266: INFO: Namespace nsdeletetest-4111 was already deleted
    STEP: Destroying namespace "nsdeletetest-433" for this suite. 11/26/22 12:27:12.266
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:27:12.279
Nov 26 12:27:12.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename gc 11/26/22 12:27:12.281
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:27:12.305
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:27:12.311
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 11/26/22 12:27:12.322
STEP: create the rc2 11/26/22 12:27:12.335
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 11/26/22 12:27:17.354
STEP: delete the rc simpletest-rc-to-be-deleted 11/26/22 12:27:18.101
STEP: wait for the rc to be deleted 11/26/22 12:27:18.112
Nov 26 12:27:23.143: INFO: 66 pods remaining
Nov 26 12:27:23.143: INFO: 66 pods has nil DeletionTimestamp
Nov 26 12:27:23.143: INFO: 
STEP: Gathering metrics 11/26/22 12:27:28.138
W1126 12:27:28.145531      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 26 12:27:28.145: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Nov 26 12:27:28.145: INFO: Deleting pod "simpletest-rc-to-be-deleted-29xm4" in namespace "gc-2725"
Nov 26 12:27:28.161: INFO: Deleting pod "simpletest-rc-to-be-deleted-2b5kg" in namespace "gc-2725"
Nov 26 12:27:28.183: INFO: Deleting pod "simpletest-rc-to-be-deleted-2qml6" in namespace "gc-2725"
Nov 26 12:27:28.205: INFO: Deleting pod "simpletest-rc-to-be-deleted-44pbg" in namespace "gc-2725"
Nov 26 12:27:28.228: INFO: Deleting pod "simpletest-rc-to-be-deleted-44qj7" in namespace "gc-2725"
Nov 26 12:27:28.249: INFO: Deleting pod "simpletest-rc-to-be-deleted-44qtm" in namespace "gc-2725"
Nov 26 12:27:28.266: INFO: Deleting pod "simpletest-rc-to-be-deleted-4cxg6" in namespace "gc-2725"
Nov 26 12:27:28.283: INFO: Deleting pod "simpletest-rc-to-be-deleted-4fsjw" in namespace "gc-2725"
Nov 26 12:27:28.312: INFO: Deleting pod "simpletest-rc-to-be-deleted-4l6ch" in namespace "gc-2725"
Nov 26 12:27:28.332: INFO: Deleting pod "simpletest-rc-to-be-deleted-4t7p4" in namespace "gc-2725"
Nov 26 12:27:28.354: INFO: Deleting pod "simpletest-rc-to-be-deleted-4wxzw" in namespace "gc-2725"
Nov 26 12:27:28.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-64rjw" in namespace "gc-2725"
Nov 26 12:27:28.395: INFO: Deleting pod "simpletest-rc-to-be-deleted-68btz" in namespace "gc-2725"
Nov 26 12:27:28.420: INFO: Deleting pod "simpletest-rc-to-be-deleted-6xrmx" in namespace "gc-2725"
Nov 26 12:27:28.438: INFO: Deleting pod "simpletest-rc-to-be-deleted-777nm" in namespace "gc-2725"
Nov 26 12:27:28.455: INFO: Deleting pod "simpletest-rc-to-be-deleted-7b7j8" in namespace "gc-2725"
Nov 26 12:27:28.474: INFO: Deleting pod "simpletest-rc-to-be-deleted-7crb9" in namespace "gc-2725"
Nov 26 12:27:28.492: INFO: Deleting pod "simpletest-rc-to-be-deleted-88ldl" in namespace "gc-2725"
Nov 26 12:27:28.512: INFO: Deleting pod "simpletest-rc-to-be-deleted-8j792" in namespace "gc-2725"
Nov 26 12:27:28.535: INFO: Deleting pod "simpletest-rc-to-be-deleted-8ktpn" in namespace "gc-2725"
Nov 26 12:27:28.549: INFO: Deleting pod "simpletest-rc-to-be-deleted-9t6f9" in namespace "gc-2725"
Nov 26 12:27:28.568: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xcj5" in namespace "gc-2725"
Nov 26 12:27:28.590: INFO: Deleting pod "simpletest-rc-to-be-deleted-b2nw8" in namespace "gc-2725"
Nov 26 12:27:28.610: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqdh9" in namespace "gc-2725"
Nov 26 12:27:28.628: INFO: Deleting pod "simpletest-rc-to-be-deleted-bwdz8" in namespace "gc-2725"
Nov 26 12:27:28.648: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjrnf" in namespace "gc-2725"
Nov 26 12:27:28.670: INFO: Deleting pod "simpletest-rc-to-be-deleted-cqtl2" in namespace "gc-2725"
Nov 26 12:27:28.685: INFO: Deleting pod "simpletest-rc-to-be-deleted-dbsjl" in namespace "gc-2725"
Nov 26 12:27:28.703: INFO: Deleting pod "simpletest-rc-to-be-deleted-dlqh6" in namespace "gc-2725"
Nov 26 12:27:28.724: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnnth" in namespace "gc-2725"
Nov 26 12:27:28.743: INFO: Deleting pod "simpletest-rc-to-be-deleted-dswgj" in namespace "gc-2725"
Nov 26 12:27:28.763: INFO: Deleting pod "simpletest-rc-to-be-deleted-dtk2v" in namespace "gc-2725"
Nov 26 12:27:28.783: INFO: Deleting pod "simpletest-rc-to-be-deleted-f6gp2" in namespace "gc-2725"
Nov 26 12:27:28.806: INFO: Deleting pod "simpletest-rc-to-be-deleted-f8hwp" in namespace "gc-2725"
Nov 26 12:27:28.826: INFO: Deleting pod "simpletest-rc-to-be-deleted-fgq7w" in namespace "gc-2725"
Nov 26 12:27:28.846: INFO: Deleting pod "simpletest-rc-to-be-deleted-fhjvx" in namespace "gc-2725"
Nov 26 12:27:28.866: INFO: Deleting pod "simpletest-rc-to-be-deleted-fmjn6" in namespace "gc-2725"
Nov 26 12:27:28.884: INFO: Deleting pod "simpletest-rc-to-be-deleted-fz9vq" in namespace "gc-2725"
Nov 26 12:27:28.907: INFO: Deleting pod "simpletest-rc-to-be-deleted-gf2lv" in namespace "gc-2725"
Nov 26 12:27:28.928: INFO: Deleting pod "simpletest-rc-to-be-deleted-ghc2j" in namespace "gc-2725"
Nov 26 12:27:28.946: INFO: Deleting pod "simpletest-rc-to-be-deleted-gqgzd" in namespace "gc-2725"
Nov 26 12:27:28.964: INFO: Deleting pod "simpletest-rc-to-be-deleted-grbfd" in namespace "gc-2725"
Nov 26 12:27:28.985: INFO: Deleting pod "simpletest-rc-to-be-deleted-grw7n" in namespace "gc-2725"
Nov 26 12:27:29.003: INFO: Deleting pod "simpletest-rc-to-be-deleted-gzmkl" in namespace "gc-2725"
Nov 26 12:27:29.022: INFO: Deleting pod "simpletest-rc-to-be-deleted-hc9nr" in namespace "gc-2725"
Nov 26 12:27:29.042: INFO: Deleting pod "simpletest-rc-to-be-deleted-hxk4s" in namespace "gc-2725"
Nov 26 12:27:29.061: INFO: Deleting pod "simpletest-rc-to-be-deleted-j4z56" in namespace "gc-2725"
Nov 26 12:27:29.078: INFO: Deleting pod "simpletest-rc-to-be-deleted-j6tpv" in namespace "gc-2725"
Nov 26 12:27:29.101: INFO: Deleting pod "simpletest-rc-to-be-deleted-jk2gx" in namespace "gc-2725"
Nov 26 12:27:29.116: INFO: Deleting pod "simpletest-rc-to-be-deleted-jkxzp" in namespace "gc-2725"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 26 12:27:29.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2725" for this suite. 11/26/22 12:27:29.149
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":135,"skipped":2501,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.879 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:27:12.279
    Nov 26 12:27:12.280: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename gc 11/26/22 12:27:12.281
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:27:12.305
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:27:12.311
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 11/26/22 12:27:12.322
    STEP: create the rc2 11/26/22 12:27:12.335
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 11/26/22 12:27:17.354
    STEP: delete the rc simpletest-rc-to-be-deleted 11/26/22 12:27:18.101
    STEP: wait for the rc to be deleted 11/26/22 12:27:18.112
    Nov 26 12:27:23.143: INFO: 66 pods remaining
    Nov 26 12:27:23.143: INFO: 66 pods has nil DeletionTimestamp
    Nov 26 12:27:23.143: INFO: 
    STEP: Gathering metrics 11/26/22 12:27:28.138
    W1126 12:27:28.145531      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 26 12:27:28.145: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Nov 26 12:27:28.145: INFO: Deleting pod "simpletest-rc-to-be-deleted-29xm4" in namespace "gc-2725"
    Nov 26 12:27:28.161: INFO: Deleting pod "simpletest-rc-to-be-deleted-2b5kg" in namespace "gc-2725"
    Nov 26 12:27:28.183: INFO: Deleting pod "simpletest-rc-to-be-deleted-2qml6" in namespace "gc-2725"
    Nov 26 12:27:28.205: INFO: Deleting pod "simpletest-rc-to-be-deleted-44pbg" in namespace "gc-2725"
    Nov 26 12:27:28.228: INFO: Deleting pod "simpletest-rc-to-be-deleted-44qj7" in namespace "gc-2725"
    Nov 26 12:27:28.249: INFO: Deleting pod "simpletest-rc-to-be-deleted-44qtm" in namespace "gc-2725"
    Nov 26 12:27:28.266: INFO: Deleting pod "simpletest-rc-to-be-deleted-4cxg6" in namespace "gc-2725"
    Nov 26 12:27:28.283: INFO: Deleting pod "simpletest-rc-to-be-deleted-4fsjw" in namespace "gc-2725"
    Nov 26 12:27:28.312: INFO: Deleting pod "simpletest-rc-to-be-deleted-4l6ch" in namespace "gc-2725"
    Nov 26 12:27:28.332: INFO: Deleting pod "simpletest-rc-to-be-deleted-4t7p4" in namespace "gc-2725"
    Nov 26 12:27:28.354: INFO: Deleting pod "simpletest-rc-to-be-deleted-4wxzw" in namespace "gc-2725"
    Nov 26 12:27:28.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-64rjw" in namespace "gc-2725"
    Nov 26 12:27:28.395: INFO: Deleting pod "simpletest-rc-to-be-deleted-68btz" in namespace "gc-2725"
    Nov 26 12:27:28.420: INFO: Deleting pod "simpletest-rc-to-be-deleted-6xrmx" in namespace "gc-2725"
    Nov 26 12:27:28.438: INFO: Deleting pod "simpletest-rc-to-be-deleted-777nm" in namespace "gc-2725"
    Nov 26 12:27:28.455: INFO: Deleting pod "simpletest-rc-to-be-deleted-7b7j8" in namespace "gc-2725"
    Nov 26 12:27:28.474: INFO: Deleting pod "simpletest-rc-to-be-deleted-7crb9" in namespace "gc-2725"
    Nov 26 12:27:28.492: INFO: Deleting pod "simpletest-rc-to-be-deleted-88ldl" in namespace "gc-2725"
    Nov 26 12:27:28.512: INFO: Deleting pod "simpletest-rc-to-be-deleted-8j792" in namespace "gc-2725"
    Nov 26 12:27:28.535: INFO: Deleting pod "simpletest-rc-to-be-deleted-8ktpn" in namespace "gc-2725"
    Nov 26 12:27:28.549: INFO: Deleting pod "simpletest-rc-to-be-deleted-9t6f9" in namespace "gc-2725"
    Nov 26 12:27:28.568: INFO: Deleting pod "simpletest-rc-to-be-deleted-9xcj5" in namespace "gc-2725"
    Nov 26 12:27:28.590: INFO: Deleting pod "simpletest-rc-to-be-deleted-b2nw8" in namespace "gc-2725"
    Nov 26 12:27:28.610: INFO: Deleting pod "simpletest-rc-to-be-deleted-bqdh9" in namespace "gc-2725"
    Nov 26 12:27:28.628: INFO: Deleting pod "simpletest-rc-to-be-deleted-bwdz8" in namespace "gc-2725"
    Nov 26 12:27:28.648: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjrnf" in namespace "gc-2725"
    Nov 26 12:27:28.670: INFO: Deleting pod "simpletest-rc-to-be-deleted-cqtl2" in namespace "gc-2725"
    Nov 26 12:27:28.685: INFO: Deleting pod "simpletest-rc-to-be-deleted-dbsjl" in namespace "gc-2725"
    Nov 26 12:27:28.703: INFO: Deleting pod "simpletest-rc-to-be-deleted-dlqh6" in namespace "gc-2725"
    Nov 26 12:27:28.724: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnnth" in namespace "gc-2725"
    Nov 26 12:27:28.743: INFO: Deleting pod "simpletest-rc-to-be-deleted-dswgj" in namespace "gc-2725"
    Nov 26 12:27:28.763: INFO: Deleting pod "simpletest-rc-to-be-deleted-dtk2v" in namespace "gc-2725"
    Nov 26 12:27:28.783: INFO: Deleting pod "simpletest-rc-to-be-deleted-f6gp2" in namespace "gc-2725"
    Nov 26 12:27:28.806: INFO: Deleting pod "simpletest-rc-to-be-deleted-f8hwp" in namespace "gc-2725"
    Nov 26 12:27:28.826: INFO: Deleting pod "simpletest-rc-to-be-deleted-fgq7w" in namespace "gc-2725"
    Nov 26 12:27:28.846: INFO: Deleting pod "simpletest-rc-to-be-deleted-fhjvx" in namespace "gc-2725"
    Nov 26 12:27:28.866: INFO: Deleting pod "simpletest-rc-to-be-deleted-fmjn6" in namespace "gc-2725"
    Nov 26 12:27:28.884: INFO: Deleting pod "simpletest-rc-to-be-deleted-fz9vq" in namespace "gc-2725"
    Nov 26 12:27:28.907: INFO: Deleting pod "simpletest-rc-to-be-deleted-gf2lv" in namespace "gc-2725"
    Nov 26 12:27:28.928: INFO: Deleting pod "simpletest-rc-to-be-deleted-ghc2j" in namespace "gc-2725"
    Nov 26 12:27:28.946: INFO: Deleting pod "simpletest-rc-to-be-deleted-gqgzd" in namespace "gc-2725"
    Nov 26 12:27:28.964: INFO: Deleting pod "simpletest-rc-to-be-deleted-grbfd" in namespace "gc-2725"
    Nov 26 12:27:28.985: INFO: Deleting pod "simpletest-rc-to-be-deleted-grw7n" in namespace "gc-2725"
    Nov 26 12:27:29.003: INFO: Deleting pod "simpletest-rc-to-be-deleted-gzmkl" in namespace "gc-2725"
    Nov 26 12:27:29.022: INFO: Deleting pod "simpletest-rc-to-be-deleted-hc9nr" in namespace "gc-2725"
    Nov 26 12:27:29.042: INFO: Deleting pod "simpletest-rc-to-be-deleted-hxk4s" in namespace "gc-2725"
    Nov 26 12:27:29.061: INFO: Deleting pod "simpletest-rc-to-be-deleted-j4z56" in namespace "gc-2725"
    Nov 26 12:27:29.078: INFO: Deleting pod "simpletest-rc-to-be-deleted-j6tpv" in namespace "gc-2725"
    Nov 26 12:27:29.101: INFO: Deleting pod "simpletest-rc-to-be-deleted-jk2gx" in namespace "gc-2725"
    Nov 26 12:27:29.116: INFO: Deleting pod "simpletest-rc-to-be-deleted-jkxzp" in namespace "gc-2725"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 26 12:27:29.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2725" for this suite. 11/26/22 12:27:29.149
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:27:29.161
Nov 26 12:27:29.161: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename ingressclass 11/26/22 12:27:29.162
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:27:29.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:27:29.191
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 11/26/22 12:27:29.196
STEP: getting /apis/networking.k8s.io 11/26/22 12:27:29.201
STEP: getting /apis/networking.k8s.iov1 11/26/22 12:27:29.208
STEP: creating 11/26/22 12:27:29.21
STEP: getting 11/26/22 12:27:29.234
STEP: listing 11/26/22 12:27:29.239
STEP: watching 11/26/22 12:27:29.245
Nov 26 12:27:29.245: INFO: starting watch
STEP: patching 11/26/22 12:27:29.247
STEP: updating 11/26/22 12:27:29.259
Nov 26 12:27:29.267: INFO: waiting for watch events with expected annotations
Nov 26 12:27:29.267: INFO: saw patched and updated annotations
STEP: deleting 11/26/22 12:27:29.267
STEP: deleting a collection 11/26/22 12:27:29.286
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Nov 26 12:27:29.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-8877" for this suite. 11/26/22 12:27:29.316
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":136,"skipped":2516,"failed":0}
------------------------------
â€¢ [0.173 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:27:29.161
    Nov 26 12:27:29.161: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename ingressclass 11/26/22 12:27:29.162
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:27:29.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:27:29.191
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 11/26/22 12:27:29.196
    STEP: getting /apis/networking.k8s.io 11/26/22 12:27:29.201
    STEP: getting /apis/networking.k8s.iov1 11/26/22 12:27:29.208
    STEP: creating 11/26/22 12:27:29.21
    STEP: getting 11/26/22 12:27:29.234
    STEP: listing 11/26/22 12:27:29.239
    STEP: watching 11/26/22 12:27:29.245
    Nov 26 12:27:29.245: INFO: starting watch
    STEP: patching 11/26/22 12:27:29.247
    STEP: updating 11/26/22 12:27:29.259
    Nov 26 12:27:29.267: INFO: waiting for watch events with expected annotations
    Nov 26 12:27:29.267: INFO: saw patched and updated annotations
    STEP: deleting 11/26/22 12:27:29.267
    STEP: deleting a collection 11/26/22 12:27:29.286
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Nov 26 12:27:29.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-8877" for this suite. 11/26/22 12:27:29.316
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:27:29.337
Nov 26 12:27:29.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:27:29.338
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:27:29.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:27:29.362
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:27:29.406
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:27:30.172
STEP: Deploying the webhook pod 11/26/22 12:27:30.183
STEP: Wait for the deployment to be ready 11/26/22 12:27:30.202
Nov 26 12:27:30.219: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 26 12:27:32.239: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 12:27:34.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 12:27:36.247: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 12:27:38.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/26/22 12:27:40.249
STEP: Verifying the service has paired with the endpoint 11/26/22 12:27:40.267
Nov 26 12:27:41.267: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 11/26/22 12:27:41.274
STEP: Creating a custom resource definition that should be denied by the webhook 11/26/22 12:27:41.294
Nov 26 12:27:41.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:27:41.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8262" for this suite. 11/26/22 12:27:41.323
STEP: Destroying namespace "webhook-8262-markers" for this suite. 11/26/22 12:27:41.333
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":137,"skipped":2524,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.097 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:27:29.337
    Nov 26 12:27:29.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:27:29.338
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:27:29.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:27:29.362
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:27:29.406
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:27:30.172
    STEP: Deploying the webhook pod 11/26/22 12:27:30.183
    STEP: Wait for the deployment to be ready 11/26/22 12:27:30.202
    Nov 26 12:27:30.219: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 26 12:27:32.239: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 12:27:34.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 12:27:36.247: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 12:27:38.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 27, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/26/22 12:27:40.249
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:27:40.267
    Nov 26 12:27:41.267: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 11/26/22 12:27:41.274
    STEP: Creating a custom resource definition that should be denied by the webhook 11/26/22 12:27:41.294
    Nov 26 12:27:41.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:27:41.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8262" for this suite. 11/26/22 12:27:41.323
    STEP: Destroying namespace "webhook-8262-markers" for this suite. 11/26/22 12:27:41.333
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:27:41.434
Nov 26 12:27:41.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename dns 11/26/22 12:27:41.435
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:27:41.474
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:27:41.483
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 11/26/22 12:27:41.489
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5401.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5401.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_udp@PTR;check="$$(dig +tcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_tcp@PTR;sleep 1; done
 11/26/22 12:27:41.515
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5401.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5401.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_udp@PTR;check="$$(dig +tcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_tcp@PTR;sleep 1; done
 11/26/22 12:27:41.515
STEP: creating a pod to probe DNS 11/26/22 12:27:41.516
STEP: submitting the pod to kubernetes 11/26/22 12:27:41.516
Nov 26 12:27:41.533: INFO: Waiting up to 15m0s for pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45" in namespace "dns-5401" to be "running"
Nov 26 12:27:41.540: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 6.164903ms
Nov 26 12:27:43.548: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013962295s
Nov 26 12:27:45.547: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013345039s
Nov 26 12:27:47.547: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013407179s
Nov 26 12:27:49.546: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012424855s
Nov 26 12:27:51.548: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014017033s
Nov 26 12:27:53.548: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Running", Reason="", readiness=true. Elapsed: 12.014142197s
Nov 26 12:27:53.548: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45" satisfied condition "running"
STEP: retrieving the pod 11/26/22 12:27:53.548
STEP: looking for the results for each expected name from probers 11/26/22 12:27:53.553
Nov 26 12:27:53.560: INFO: Unable to read wheezy_udp@dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
Nov 26 12:27:53.566: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
Nov 26 12:27:53.574: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
Nov 26 12:27:53.580: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
Nov 26 12:27:53.613: INFO: Unable to read jessie_udp@dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
Nov 26 12:27:53.619: INFO: Unable to read jessie_tcp@dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
Nov 26 12:27:53.625: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
Nov 26 12:27:53.632: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
Nov 26 12:27:53.656: INFO: Lookups using dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45 failed for: [wheezy_udp@dns-test-service.dns-5401.svc.cluster.local wheezy_tcp@dns-test-service.dns-5401.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local jessie_udp@dns-test-service.dns-5401.svc.cluster.local jessie_tcp@dns-test-service.dns-5401.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local]

Nov 26 12:27:58.766: INFO: DNS probes using dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45 succeeded

STEP: deleting the pod 11/26/22 12:27:58.766
STEP: deleting the test service 11/26/22 12:27:58.807
STEP: deleting the test headless service 11/26/22 12:27:58.866
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 26 12:27:58.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5401" for this suite. 11/26/22 12:27:58.91
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":138,"skipped":2526,"failed":0}
------------------------------
â€¢ [SLOW TEST] [17.489 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:27:41.434
    Nov 26 12:27:41.435: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename dns 11/26/22 12:27:41.435
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:27:41.474
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:27:41.483
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 11/26/22 12:27:41.489
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5401.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5401.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_udp@PTR;check="$$(dig +tcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_tcp@PTR;sleep 1; done
     11/26/22 12:27:41.515
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5401.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5401.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5401.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5401.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5401.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_udp@PTR;check="$$(dig +tcp +noall +answer +search 19.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.19_tcp@PTR;sleep 1; done
     11/26/22 12:27:41.515
    STEP: creating a pod to probe DNS 11/26/22 12:27:41.516
    STEP: submitting the pod to kubernetes 11/26/22 12:27:41.516
    Nov 26 12:27:41.533: INFO: Waiting up to 15m0s for pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45" in namespace "dns-5401" to be "running"
    Nov 26 12:27:41.540: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 6.164903ms
    Nov 26 12:27:43.548: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013962295s
    Nov 26 12:27:45.547: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013345039s
    Nov 26 12:27:47.547: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013407179s
    Nov 26 12:27:49.546: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012424855s
    Nov 26 12:27:51.548: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014017033s
    Nov 26 12:27:53.548: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45": Phase="Running", Reason="", readiness=true. Elapsed: 12.014142197s
    Nov 26 12:27:53.548: INFO: Pod "dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45" satisfied condition "running"
    STEP: retrieving the pod 11/26/22 12:27:53.548
    STEP: looking for the results for each expected name from probers 11/26/22 12:27:53.553
    Nov 26 12:27:53.560: INFO: Unable to read wheezy_udp@dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
    Nov 26 12:27:53.566: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
    Nov 26 12:27:53.574: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
    Nov 26 12:27:53.580: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
    Nov 26 12:27:53.613: INFO: Unable to read jessie_udp@dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
    Nov 26 12:27:53.619: INFO: Unable to read jessie_tcp@dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
    Nov 26 12:27:53.625: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
    Nov 26 12:27:53.632: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local from pod dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45: the server could not find the requested resource (get pods dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45)
    Nov 26 12:27:53.656: INFO: Lookups using dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45 failed for: [wheezy_udp@dns-test-service.dns-5401.svc.cluster.local wheezy_tcp@dns-test-service.dns-5401.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local jessie_udp@dns-test-service.dns-5401.svc.cluster.local jessie_tcp@dns-test-service.dns-5401.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5401.svc.cluster.local]

    Nov 26 12:27:58.766: INFO: DNS probes using dns-5401/dns-test-29c7f6e0-fb54-41e8-a68e-c13934082d45 succeeded

    STEP: deleting the pod 11/26/22 12:27:58.766
    STEP: deleting the test service 11/26/22 12:27:58.807
    STEP: deleting the test headless service 11/26/22 12:27:58.866
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 26 12:27:58.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-5401" for this suite. 11/26/22 12:27:58.91
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:27:58.925
Nov 26 12:27:58.925: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename containers 11/26/22 12:27:58.926
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:27:58.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:27:58.974
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Nov 26 12:27:58.999: INFO: Waiting up to 5m0s for pod "client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5" in namespace "containers-9715" to be "running"
Nov 26 12:27:59.009: INFO: Pod "client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.181576ms
Nov 26 12:28:01.016: INFO: Pod "client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5": Phase="Running", Reason="", readiness=true. Elapsed: 2.017028945s
Nov 26 12:28:01.016: INFO: Pod "client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov 26 12:28:01.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9715" for this suite. 11/26/22 12:28:01.037
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":139,"skipped":2527,"failed":0}
------------------------------
â€¢ [2.128 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:27:58.925
    Nov 26 12:27:58.925: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename containers 11/26/22 12:27:58.926
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:27:58.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:27:58.974
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Nov 26 12:27:58.999: INFO: Waiting up to 5m0s for pod "client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5" in namespace "containers-9715" to be "running"
    Nov 26 12:27:59.009: INFO: Pod "client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.181576ms
    Nov 26 12:28:01.016: INFO: Pod "client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5": Phase="Running", Reason="", readiness=true. Elapsed: 2.017028945s
    Nov 26 12:28:01.016: INFO: Pod "client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov 26 12:28:01.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-9715" for this suite. 11/26/22 12:28:01.037
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:28:01.058
Nov 26 12:28:01.058: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sched-pred 11/26/22 12:28:01.06
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:01.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:01.09
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 26 12:28:01.097: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 26 12:28:01.110: INFO: Waiting for terminating namespaces to be deleted...
Nov 26 12:28:01.115: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-0-249 before test
Nov 26 12:28:01.126: INFO: default-http-backend-kubernetes-worker-6546b9855c-4rkhh from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:36 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.126: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov 26 12:28:01.126: INFO: nginx-ingress-controller-kubernetes-worker-m2kb4 from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:35 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.126: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
Nov 26 12:28:01.127: INFO: coredns-6bcf44f4cc-q68zx from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.127: INFO: 	Container coredns ready: true, restart count 0
Nov 26 12:28:01.127: INFO: kube-state-metrics-74f5d549cc-2xtpf from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.127: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov 26 12:28:01.127: INFO: metrics-server-v0.5.2-6b48dc6f97-nfgfh from kube-system started at 2022-11-26 11:51:35 +0000 UTC (2 container statuses recorded)
Nov 26 12:28:01.127: INFO: 	Container metrics-server ready: true, restart count 0
Nov 26 12:28:01.127: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 26 12:28:01.127: INFO: dashboard-metrics-scraper-85d45476c6-h2vdw from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.128: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 26 12:28:01.128: INFO: kubernetes-dashboard-7fb574cb-nwk47 from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.128: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 26 12:28:01.128: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4 from sonobuoy started at 2022-11-26 11:58:40 +0000 UTC (2 container statuses recorded)
Nov 26 12:28:01.128: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 12:28:01.128: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 26 12:28:01.128: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-29-104 before test
Nov 26 12:28:01.143: INFO: nginx-ingress-controller-kubernetes-worker-97spf from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:56 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.144: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 26 12:28:01.144: INFO: sonobuoy from sonobuoy started at 2022-11-26 11:58:19 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.144: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 26 12:28:01.145: INFO: sonobuoy-e2e-job-1d4a77a11cb24dc4 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 12:28:01.145: INFO: 	Container e2e ready: true, restart count 0
Nov 26 12:28:01.145: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 12:28:01.145: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hq4v9 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 12:28:01.146: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 12:28:01.146: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 26 12:28:01.146: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-43-82 before test
Nov 26 12:28:01.160: INFO: client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5 from containers-9715 started at 2022-11-26 12:27:58 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.160: INFO: 	Container agnhost-container ready: true, restart count 0
Nov 26 12:28:01.160: INFO: nginx-ingress-controller-kubernetes-worker-2dckl from ingress-nginx-kubernetes-worker started at 2022-11-26 12:07:15 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.160: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 26 12:28:01.160: INFO: calico-kube-controllers-75648888c-27qdc from kube-system started at 2022-11-26 12:07:03 +0000 UTC (1 container statuses recorded)
Nov 26 12:28:01.160: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 26 12:28:01.160: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hbpwv from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 12:28:01.160: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 12:28:01.160: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node ip-172-31-0-249 11/26/22 12:28:01.199
STEP: verifying the node has the label node ip-172-31-29-104 11/26/22 12:28:01.224
STEP: verifying the node has the label node ip-172-31-43-82 11/26/22 12:28:01.251
Nov 26 12:28:01.272: INFO: Pod client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5 requesting resource cpu=0m on Node ip-172-31-43-82
Nov 26 12:28:01.272: INFO: Pod default-http-backend-kubernetes-worker-6546b9855c-4rkhh requesting resource cpu=10m on Node ip-172-31-0-249
Nov 26 12:28:01.272: INFO: Pod nginx-ingress-controller-kubernetes-worker-2dckl requesting resource cpu=0m on Node ip-172-31-43-82
Nov 26 12:28:01.272: INFO: Pod nginx-ingress-controller-kubernetes-worker-97spf requesting resource cpu=0m on Node ip-172-31-29-104
Nov 26 12:28:01.272: INFO: Pod nginx-ingress-controller-kubernetes-worker-m2kb4 requesting resource cpu=0m on Node ip-172-31-0-249
Nov 26 12:28:01.272: INFO: Pod calico-kube-controllers-75648888c-27qdc requesting resource cpu=0m on Node ip-172-31-43-82
Nov 26 12:28:01.272: INFO: Pod coredns-6bcf44f4cc-q68zx requesting resource cpu=100m on Node ip-172-31-0-249
Nov 26 12:28:01.272: INFO: Pod kube-state-metrics-74f5d549cc-2xtpf requesting resource cpu=0m on Node ip-172-31-0-249
Nov 26 12:28:01.272: INFO: Pod metrics-server-v0.5.2-6b48dc6f97-nfgfh requesting resource cpu=5m on Node ip-172-31-0-249
Nov 26 12:28:01.273: INFO: Pod dashboard-metrics-scraper-85d45476c6-h2vdw requesting resource cpu=0m on Node ip-172-31-0-249
Nov 26 12:28:01.273: INFO: Pod kubernetes-dashboard-7fb574cb-nwk47 requesting resource cpu=0m on Node ip-172-31-0-249
Nov 26 12:28:01.273: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-29-104
Nov 26 12:28:01.273: INFO: Pod sonobuoy-e2e-job-1d4a77a11cb24dc4 requesting resource cpu=0m on Node ip-172-31-29-104
Nov 26 12:28:01.273: INFO: Pod sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4 requesting resource cpu=0m on Node ip-172-31-0-249
Nov 26 12:28:01.273: INFO: Pod sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hbpwv requesting resource cpu=0m on Node ip-172-31-43-82
Nov 26 12:28:01.273: INFO: Pod sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hq4v9 requesting resource cpu=0m on Node ip-172-31-29-104
STEP: Starting Pods to consume most of the cluster CPU. 11/26/22 12:28:01.273
Nov 26 12:28:01.273: INFO: Creating a pod which consumes cpu=1319m on Node ip-172-31-0-249
Nov 26 12:28:01.288: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-29-104
Nov 26 12:28:01.302: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-43-82
Nov 26 12:28:01.318: INFO: Waiting up to 5m0s for pod "filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818" in namespace "sched-pred-2400" to be "running"
Nov 26 12:28:01.325: INFO: Pod "filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818": Phase="Pending", Reason="", readiness=false. Elapsed: 6.652602ms
Nov 26 12:28:03.333: INFO: Pod "filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818": Phase="Running", Reason="", readiness=true. Elapsed: 2.014335104s
Nov 26 12:28:03.333: INFO: Pod "filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818" satisfied condition "running"
Nov 26 12:28:03.333: INFO: Waiting up to 5m0s for pod "filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd" in namespace "sched-pred-2400" to be "running"
Nov 26 12:28:03.338: INFO: Pod "filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd": Phase="Running", Reason="", readiness=true. Elapsed: 5.341098ms
Nov 26 12:28:03.338: INFO: Pod "filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd" satisfied condition "running"
Nov 26 12:28:03.338: INFO: Waiting up to 5m0s for pod "filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944" in namespace "sched-pred-2400" to be "running"
Nov 26 12:28:03.344: INFO: Pod "filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944": Phase="Running", Reason="", readiness=true. Elapsed: 6.023331ms
Nov 26 12:28:03.345: INFO: Pod "filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 11/26/22 12:28:03.345
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd.172b223122597193], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2400/filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd to ip-172-31-29-104] 11/26/22 12:28:03.353
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd.172b22315ccc4458], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/26/22 12:28:03.354
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd.172b223160b6ec0f], Reason = [Created], Message = [Created container filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd] 11/26/22 12:28:03.354
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd.172b22316731f2e8], Reason = [Started], Message = [Started container filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd] 11/26/22 12:28:03.354
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944.172b2231232fd934], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2400/filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944 to ip-172-31-43-82] 11/26/22 12:28:03.354
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944.172b223151acd78c], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/26/22 12:28:03.354
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944.172b2231551d27af], Reason = [Created], Message = [Created container filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944] 11/26/22 12:28:03.354
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944.172b22315bdad839], Reason = [Started], Message = [Started container filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944] 11/26/22 12:28:03.355
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818.172b223121aa93a5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2400/filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818 to ip-172-31-0-249] 11/26/22 12:28:03.355
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818.172b22315544e08f], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/26/22 12:28:03.356
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818.172b223157f74712], Reason = [Created], Message = [Created container filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818] 11/26/22 12:28:03.356
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818.172b22315e6876d4], Reason = [Started], Message = [Started container filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818] 11/26/22 12:28:03.357
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.172b22319cbc1cfa], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] 11/26/22 12:28:03.373
STEP: removing the label node off the node ip-172-31-0-249 11/26/22 12:28:04.373
STEP: verifying the node doesn't have the label node 11/26/22 12:28:04.392
STEP: removing the label node off the node ip-172-31-29-104 11/26/22 12:28:04.404
STEP: verifying the node doesn't have the label node 11/26/22 12:28:04.422
STEP: removing the label node off the node ip-172-31-43-82 11/26/22 12:28:04.431
STEP: verifying the node doesn't have the label node 11/26/22 12:28:04.453
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:28:04.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2400" for this suite. 11/26/22 12:28:04.469
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":140,"skipped":2565,"failed":0}
------------------------------
â€¢ [3.424 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:28:01.058
    Nov 26 12:28:01.058: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sched-pred 11/26/22 12:28:01.06
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:01.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:01.09
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 26 12:28:01.097: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 26 12:28:01.110: INFO: Waiting for terminating namespaces to be deleted...
    Nov 26 12:28:01.115: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-0-249 before test
    Nov 26 12:28:01.126: INFO: default-http-backend-kubernetes-worker-6546b9855c-4rkhh from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:36 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.126: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov 26 12:28:01.126: INFO: nginx-ingress-controller-kubernetes-worker-m2kb4 from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:35 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.126: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
    Nov 26 12:28:01.127: INFO: coredns-6bcf44f4cc-q68zx from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.127: INFO: 	Container coredns ready: true, restart count 0
    Nov 26 12:28:01.127: INFO: kube-state-metrics-74f5d549cc-2xtpf from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.127: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov 26 12:28:01.127: INFO: metrics-server-v0.5.2-6b48dc6f97-nfgfh from kube-system started at 2022-11-26 11:51:35 +0000 UTC (2 container statuses recorded)
    Nov 26 12:28:01.127: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 26 12:28:01.127: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 26 12:28:01.127: INFO: dashboard-metrics-scraper-85d45476c6-h2vdw from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.128: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 26 12:28:01.128: INFO: kubernetes-dashboard-7fb574cb-nwk47 from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.128: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 26 12:28:01.128: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4 from sonobuoy started at 2022-11-26 11:58:40 +0000 UTC (2 container statuses recorded)
    Nov 26 12:28:01.128: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 12:28:01.128: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 26 12:28:01.128: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-29-104 before test
    Nov 26 12:28:01.143: INFO: nginx-ingress-controller-kubernetes-worker-97spf from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:56 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.144: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 26 12:28:01.144: INFO: sonobuoy from sonobuoy started at 2022-11-26 11:58:19 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.144: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 26 12:28:01.145: INFO: sonobuoy-e2e-job-1d4a77a11cb24dc4 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 12:28:01.145: INFO: 	Container e2e ready: true, restart count 0
    Nov 26 12:28:01.145: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 12:28:01.145: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hq4v9 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 12:28:01.146: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 12:28:01.146: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 26 12:28:01.146: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-43-82 before test
    Nov 26 12:28:01.160: INFO: client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5 from containers-9715 started at 2022-11-26 12:27:58 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.160: INFO: 	Container agnhost-container ready: true, restart count 0
    Nov 26 12:28:01.160: INFO: nginx-ingress-controller-kubernetes-worker-2dckl from ingress-nginx-kubernetes-worker started at 2022-11-26 12:07:15 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.160: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 26 12:28:01.160: INFO: calico-kube-controllers-75648888c-27qdc from kube-system started at 2022-11-26 12:07:03 +0000 UTC (1 container statuses recorded)
    Nov 26 12:28:01.160: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 26 12:28:01.160: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hbpwv from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 12:28:01.160: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 12:28:01.160: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node ip-172-31-0-249 11/26/22 12:28:01.199
    STEP: verifying the node has the label node ip-172-31-29-104 11/26/22 12:28:01.224
    STEP: verifying the node has the label node ip-172-31-43-82 11/26/22 12:28:01.251
    Nov 26 12:28:01.272: INFO: Pod client-containers-b5163335-fa07-451a-85f6-0fec72ffdac5 requesting resource cpu=0m on Node ip-172-31-43-82
    Nov 26 12:28:01.272: INFO: Pod default-http-backend-kubernetes-worker-6546b9855c-4rkhh requesting resource cpu=10m on Node ip-172-31-0-249
    Nov 26 12:28:01.272: INFO: Pod nginx-ingress-controller-kubernetes-worker-2dckl requesting resource cpu=0m on Node ip-172-31-43-82
    Nov 26 12:28:01.272: INFO: Pod nginx-ingress-controller-kubernetes-worker-97spf requesting resource cpu=0m on Node ip-172-31-29-104
    Nov 26 12:28:01.272: INFO: Pod nginx-ingress-controller-kubernetes-worker-m2kb4 requesting resource cpu=0m on Node ip-172-31-0-249
    Nov 26 12:28:01.272: INFO: Pod calico-kube-controllers-75648888c-27qdc requesting resource cpu=0m on Node ip-172-31-43-82
    Nov 26 12:28:01.272: INFO: Pod coredns-6bcf44f4cc-q68zx requesting resource cpu=100m on Node ip-172-31-0-249
    Nov 26 12:28:01.272: INFO: Pod kube-state-metrics-74f5d549cc-2xtpf requesting resource cpu=0m on Node ip-172-31-0-249
    Nov 26 12:28:01.272: INFO: Pod metrics-server-v0.5.2-6b48dc6f97-nfgfh requesting resource cpu=5m on Node ip-172-31-0-249
    Nov 26 12:28:01.273: INFO: Pod dashboard-metrics-scraper-85d45476c6-h2vdw requesting resource cpu=0m on Node ip-172-31-0-249
    Nov 26 12:28:01.273: INFO: Pod kubernetes-dashboard-7fb574cb-nwk47 requesting resource cpu=0m on Node ip-172-31-0-249
    Nov 26 12:28:01.273: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-29-104
    Nov 26 12:28:01.273: INFO: Pod sonobuoy-e2e-job-1d4a77a11cb24dc4 requesting resource cpu=0m on Node ip-172-31-29-104
    Nov 26 12:28:01.273: INFO: Pod sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4 requesting resource cpu=0m on Node ip-172-31-0-249
    Nov 26 12:28:01.273: INFO: Pod sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hbpwv requesting resource cpu=0m on Node ip-172-31-43-82
    Nov 26 12:28:01.273: INFO: Pod sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hq4v9 requesting resource cpu=0m on Node ip-172-31-29-104
    STEP: Starting Pods to consume most of the cluster CPU. 11/26/22 12:28:01.273
    Nov 26 12:28:01.273: INFO: Creating a pod which consumes cpu=1319m on Node ip-172-31-0-249
    Nov 26 12:28:01.288: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-29-104
    Nov 26 12:28:01.302: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-43-82
    Nov 26 12:28:01.318: INFO: Waiting up to 5m0s for pod "filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818" in namespace "sched-pred-2400" to be "running"
    Nov 26 12:28:01.325: INFO: Pod "filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818": Phase="Pending", Reason="", readiness=false. Elapsed: 6.652602ms
    Nov 26 12:28:03.333: INFO: Pod "filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818": Phase="Running", Reason="", readiness=true. Elapsed: 2.014335104s
    Nov 26 12:28:03.333: INFO: Pod "filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818" satisfied condition "running"
    Nov 26 12:28:03.333: INFO: Waiting up to 5m0s for pod "filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd" in namespace "sched-pred-2400" to be "running"
    Nov 26 12:28:03.338: INFO: Pod "filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd": Phase="Running", Reason="", readiness=true. Elapsed: 5.341098ms
    Nov 26 12:28:03.338: INFO: Pod "filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd" satisfied condition "running"
    Nov 26 12:28:03.338: INFO: Waiting up to 5m0s for pod "filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944" in namespace "sched-pred-2400" to be "running"
    Nov 26 12:28:03.344: INFO: Pod "filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944": Phase="Running", Reason="", readiness=true. Elapsed: 6.023331ms
    Nov 26 12:28:03.345: INFO: Pod "filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 11/26/22 12:28:03.345
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd.172b223122597193], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2400/filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd to ip-172-31-29-104] 11/26/22 12:28:03.353
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd.172b22315ccc4458], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/26/22 12:28:03.354
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd.172b223160b6ec0f], Reason = [Created], Message = [Created container filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd] 11/26/22 12:28:03.354
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd.172b22316731f2e8], Reason = [Started], Message = [Started container filler-pod-05d52bb1-fa9c-45ee-80eb-41f8b15c84cd] 11/26/22 12:28:03.354
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944.172b2231232fd934], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2400/filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944 to ip-172-31-43-82] 11/26/22 12:28:03.354
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944.172b223151acd78c], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/26/22 12:28:03.354
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944.172b2231551d27af], Reason = [Created], Message = [Created container filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944] 11/26/22 12:28:03.354
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944.172b22315bdad839], Reason = [Started], Message = [Started container filler-pod-60fc5dc8-bf36-43f8-b9e1-bb1016964944] 11/26/22 12:28:03.355
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818.172b223121aa93a5], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2400/filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818 to ip-172-31-0-249] 11/26/22 12:28:03.355
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818.172b22315544e08f], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/26/22 12:28:03.356
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818.172b223157f74712], Reason = [Created], Message = [Created container filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818] 11/26/22 12:28:03.356
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818.172b22315e6876d4], Reason = [Started], Message = [Started container filler-pod-ecf5f868-9507-47fc-9a14-f76ae142a818] 11/26/22 12:28:03.357
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.172b22319cbc1cfa], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] 11/26/22 12:28:03.373
    STEP: removing the label node off the node ip-172-31-0-249 11/26/22 12:28:04.373
    STEP: verifying the node doesn't have the label node 11/26/22 12:28:04.392
    STEP: removing the label node off the node ip-172-31-29-104 11/26/22 12:28:04.404
    STEP: verifying the node doesn't have the label node 11/26/22 12:28:04.422
    STEP: removing the label node off the node ip-172-31-43-82 11/26/22 12:28:04.431
    STEP: verifying the node doesn't have the label node 11/26/22 12:28:04.453
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:28:04.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2400" for this suite. 11/26/22 12:28:04.469
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:28:04.487
Nov 26 12:28:04.488: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 12:28:04.489
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:04.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:04.518
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 11/26/22 12:28:04.523
Nov 26 12:28:04.537: INFO: Waiting up to 5m0s for pod "annotationupdatef516ac57-9dc0-46f9-8967-077013feca59" in namespace "downward-api-6522" to be "running and ready"
Nov 26 12:28:04.548: INFO: Pod "annotationupdatef516ac57-9dc0-46f9-8967-077013feca59": Phase="Pending", Reason="", readiness=false. Elapsed: 11.42808ms
Nov 26 12:28:04.548: INFO: The phase of Pod annotationupdatef516ac57-9dc0-46f9-8967-077013feca59 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:28:06.558: INFO: Pod "annotationupdatef516ac57-9dc0-46f9-8967-077013feca59": Phase="Running", Reason="", readiness=true. Elapsed: 2.021119468s
Nov 26 12:28:06.558: INFO: The phase of Pod annotationupdatef516ac57-9dc0-46f9-8967-077013feca59 is Running (Ready = true)
Nov 26 12:28:06.558: INFO: Pod "annotationupdatef516ac57-9dc0-46f9-8967-077013feca59" satisfied condition "running and ready"
Nov 26 12:28:07.102: INFO: Successfully updated pod "annotationupdatef516ac57-9dc0-46f9-8967-077013feca59"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 12:28:09.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6522" for this suite. 11/26/22 12:28:09.141
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":141,"skipped":2603,"failed":0}
------------------------------
â€¢ [4.667 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:28:04.487
    Nov 26 12:28:04.488: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 12:28:04.489
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:04.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:04.518
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 11/26/22 12:28:04.523
    Nov 26 12:28:04.537: INFO: Waiting up to 5m0s for pod "annotationupdatef516ac57-9dc0-46f9-8967-077013feca59" in namespace "downward-api-6522" to be "running and ready"
    Nov 26 12:28:04.548: INFO: Pod "annotationupdatef516ac57-9dc0-46f9-8967-077013feca59": Phase="Pending", Reason="", readiness=false. Elapsed: 11.42808ms
    Nov 26 12:28:04.548: INFO: The phase of Pod annotationupdatef516ac57-9dc0-46f9-8967-077013feca59 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:28:06.558: INFO: Pod "annotationupdatef516ac57-9dc0-46f9-8967-077013feca59": Phase="Running", Reason="", readiness=true. Elapsed: 2.021119468s
    Nov 26 12:28:06.558: INFO: The phase of Pod annotationupdatef516ac57-9dc0-46f9-8967-077013feca59 is Running (Ready = true)
    Nov 26 12:28:06.558: INFO: Pod "annotationupdatef516ac57-9dc0-46f9-8967-077013feca59" satisfied condition "running and ready"
    Nov 26 12:28:07.102: INFO: Successfully updated pod "annotationupdatef516ac57-9dc0-46f9-8967-077013feca59"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 12:28:09.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6522" for this suite. 11/26/22 12:28:09.141
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:28:09.156
Nov 26 12:28:09.156: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename job 11/26/22 12:28:09.157
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:09.187
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:09.195
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 11/26/22 12:28:09.203
STEP: Ensuring job reaches completions 11/26/22 12:28:09.219
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 26 12:28:23.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4461" for this suite. 11/26/22 12:28:23.239
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":142,"skipped":2617,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.097 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:28:09.156
    Nov 26 12:28:09.156: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename job 11/26/22 12:28:09.157
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:09.187
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:09.195
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 11/26/22 12:28:09.203
    STEP: Ensuring job reaches completions 11/26/22 12:28:09.219
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 26 12:28:23.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4461" for this suite. 11/26/22 12:28:23.239
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:28:23.255
Nov 26 12:28:23.255: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replication-controller 11/26/22 12:28:23.256
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:23.282
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:23.294
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 11/26/22 12:28:23.302
Nov 26 12:28:23.321: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-1699" to be "running and ready"
Nov 26 12:28:23.333: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 12.472021ms
Nov 26 12:28:23.334: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:28:25.341: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.020557809s
Nov 26 12:28:25.342: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Nov 26 12:28:25.342: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 11/26/22 12:28:25.348
STEP: Then the orphan pod is adopted 11/26/22 12:28:25.358
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 26 12:28:26.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1699" for this suite. 11/26/22 12:28:26.381
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":143,"skipped":2632,"failed":0}
------------------------------
â€¢ [3.140 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:28:23.255
    Nov 26 12:28:23.255: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replication-controller 11/26/22 12:28:23.256
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:23.282
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:23.294
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 11/26/22 12:28:23.302
    Nov 26 12:28:23.321: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-1699" to be "running and ready"
    Nov 26 12:28:23.333: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 12.472021ms
    Nov 26 12:28:23.334: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:28:25.341: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.020557809s
    Nov 26 12:28:25.342: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Nov 26 12:28:25.342: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 11/26/22 12:28:25.348
    STEP: Then the orphan pod is adopted 11/26/22 12:28:25.358
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 26 12:28:26.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1699" for this suite. 11/26/22 12:28:26.381
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:28:26.396
Nov 26 12:28:26.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:28:26.397
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:26.422
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:26.438
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 11/26/22 12:28:26.451
Nov 26 12:28:26.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-3569 create -f -'
Nov 26 12:28:27.418: INFO: stderr: ""
Nov 26 12:28:27.418: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 11/26/22 12:28:27.418
Nov 26 12:28:27.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-3569 diff -f -'
Nov 26 12:28:27.769: INFO: rc: 1
Nov 26 12:28:27.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-3569 delete -f -'
Nov 26 12:28:27.869: INFO: stderr: ""
Nov 26 12:28:27.869: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:28:27.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3569" for this suite. 11/26/22 12:28:27.876
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":144,"skipped":2641,"failed":0}
------------------------------
â€¢ [1.504 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:28:26.396
    Nov 26 12:28:26.396: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:28:26.397
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:26.422
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:26.438
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 11/26/22 12:28:26.451
    Nov 26 12:28:26.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-3569 create -f -'
    Nov 26 12:28:27.418: INFO: stderr: ""
    Nov 26 12:28:27.418: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 11/26/22 12:28:27.418
    Nov 26 12:28:27.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-3569 diff -f -'
    Nov 26 12:28:27.769: INFO: rc: 1
    Nov 26 12:28:27.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-3569 delete -f -'
    Nov 26 12:28:27.869: INFO: stderr: ""
    Nov 26 12:28:27.869: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:28:27.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3569" for this suite. 11/26/22 12:28:27.876
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:28:27.901
Nov 26 12:28:27.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:28:27.902
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:27.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:27.929
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:28:27.936
Nov 26 12:28:27.949: INFO: Waiting up to 5m0s for pod "downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7" in namespace "projected-3408" to be "Succeeded or Failed"
Nov 26 12:28:27.958: INFO: Pod "downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.674381ms
Nov 26 12:28:29.965: INFO: Pod "downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01508402s
Nov 26 12:28:31.963: INFO: Pod "downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013714157s
STEP: Saw pod success 11/26/22 12:28:31.963
Nov 26 12:28:31.964: INFO: Pod "downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7" satisfied condition "Succeeded or Failed"
Nov 26 12:28:31.969: INFO: Trying to get logs from node ip-172-31-29-104 pod downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7 container client-container: <nil>
STEP: delete the pod 11/26/22 12:28:31.993
Nov 26 12:28:32.015: INFO: Waiting for pod downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7 to disappear
Nov 26 12:28:32.021: INFO: Pod downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 12:28:32.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3408" for this suite. 11/26/22 12:28:32.031
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":145,"skipped":2649,"failed":0}
------------------------------
â€¢ [4.140 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:28:27.901
    Nov 26 12:28:27.901: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:28:27.902
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:27.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:27.929
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:28:27.936
    Nov 26 12:28:27.949: INFO: Waiting up to 5m0s for pod "downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7" in namespace "projected-3408" to be "Succeeded or Failed"
    Nov 26 12:28:27.958: INFO: Pod "downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.674381ms
    Nov 26 12:28:29.965: INFO: Pod "downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01508402s
    Nov 26 12:28:31.963: INFO: Pod "downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013714157s
    STEP: Saw pod success 11/26/22 12:28:31.963
    Nov 26 12:28:31.964: INFO: Pod "downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7" satisfied condition "Succeeded or Failed"
    Nov 26 12:28:31.969: INFO: Trying to get logs from node ip-172-31-29-104 pod downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7 container client-container: <nil>
    STEP: delete the pod 11/26/22 12:28:31.993
    Nov 26 12:28:32.015: INFO: Waiting for pod downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7 to disappear
    Nov 26 12:28:32.021: INFO: Pod downwardapi-volume-938c187a-4447-4b60-a9e0-2dedb42b81f7 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 12:28:32.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3408" for this suite. 11/26/22 12:28:32.031
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:28:32.043
Nov 26 12:28:32.043: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename deployment 11/26/22 12:28:32.044
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:32.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:32.08
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 11/26/22 12:28:32.094
Nov 26 12:28:32.094: INFO: Creating simple deployment test-deployment-d7h2m
Nov 26 12:28:32.117: INFO: deployment "test-deployment-d7h2m" doesn't have the required revision set
STEP: Getting /status 11/26/22 12:28:34.147
Nov 26 12:28:34.154: INFO: Deployment test-deployment-d7h2m has Conditions: [{Available True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d7h2m-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 11/26/22 12:28:34.154
Nov 26 12:28:34.169: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 28, 33, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 28, 33, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 28, 33, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 28, 32, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-d7h2m-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 11/26/22 12:28:34.169
Nov 26 12:28:34.173: INFO: Observed &Deployment event: ADDED
Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d7h2m-777898ffcc"}
Nov 26 12:28:34.173: INFO: Observed &Deployment event: MODIFIED
Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d7h2m-777898ffcc"}
Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 26 12:28:34.173: INFO: Observed &Deployment event: MODIFIED
Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-d7h2m-777898ffcc" is progressing.}
Nov 26 12:28:34.173: INFO: Observed &Deployment event: MODIFIED
Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d7h2m-777898ffcc" has successfully progressed.}
Nov 26 12:28:34.174: INFO: Observed &Deployment event: MODIFIED
Nov 26 12:28:34.174: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 26 12:28:34.174: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d7h2m-777898ffcc" has successfully progressed.}
Nov 26 12:28:34.174: INFO: Found Deployment test-deployment-d7h2m in namespace deployment-3340 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 26 12:28:34.174: INFO: Deployment test-deployment-d7h2m has an updated status
STEP: patching the Statefulset Status 11/26/22 12:28:34.174
Nov 26 12:28:34.174: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 26 12:28:34.184: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 11/26/22 12:28:34.185
Nov 26 12:28:34.188: INFO: Observed &Deployment event: ADDED
Nov 26 12:28:34.188: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d7h2m-777898ffcc"}
Nov 26 12:28:34.188: INFO: Observed &Deployment event: MODIFIED
Nov 26 12:28:34.189: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d7h2m-777898ffcc"}
Nov 26 12:28:34.189: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 26 12:28:34.189: INFO: Observed &Deployment event: MODIFIED
Nov 26 12:28:34.189: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov 26 12:28:34.189: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-d7h2m-777898ffcc" is progressing.}
Nov 26 12:28:34.190: INFO: Observed &Deployment event: MODIFIED
Nov 26 12:28:34.190: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 26 12:28:34.190: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d7h2m-777898ffcc" has successfully progressed.}
Nov 26 12:28:34.190: INFO: Observed &Deployment event: MODIFIED
Nov 26 12:28:34.190: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov 26 12:28:34.191: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d7h2m-777898ffcc" has successfully progressed.}
Nov 26 12:28:34.191: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 26 12:28:34.191: INFO: Observed &Deployment event: MODIFIED
Nov 26 12:28:34.191: INFO: Found deployment test-deployment-d7h2m in namespace deployment-3340 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Nov 26 12:28:34.191: INFO: Deployment test-deployment-d7h2m has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 26 12:28:34.197: INFO: Deployment "test-deployment-d7h2m":
&Deployment{ObjectMeta:{test-deployment-d7h2m  deployment-3340  65470fc6-789d-4293-9850-fde01aab392a 17939 1 2022-11-26 12:28:32 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-26 12:28:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-11-26 12:28:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-11-26 12:28:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00436a5b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-d7h2m-777898ffcc",LastUpdateTime:2022-11-26 12:28:34 +0000 UTC,LastTransitionTime:2022-11-26 12:28:34 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 26 12:28:34.209: INFO: New ReplicaSet "test-deployment-d7h2m-777898ffcc" of Deployment "test-deployment-d7h2m":
&ReplicaSet{ObjectMeta:{test-deployment-d7h2m-777898ffcc  deployment-3340  4c746fc6-c394-45a4-973e-067f7531e0a5 17935 1 2022-11-26 12:28:32 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-d7h2m 65470fc6-789d-4293-9850-fde01aab392a 0xc00436a9c0 0xc00436a9c1}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:28:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"65470fc6-789d-4293-9850-fde01aab392a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:28:33 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00436aa78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:28:34.217: INFO: Pod "test-deployment-d7h2m-777898ffcc-rfpcp" is available:
&Pod{ObjectMeta:{test-deployment-d7h2m-777898ffcc-rfpcp test-deployment-d7h2m-777898ffcc- deployment-3340  20d808d5-79f3-4266-9b71-270f4d3fd3e7 17934 0 2022-11-26 12:28:32 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-d7h2m-777898ffcc 4c746fc6-c394-45a4-973e-067f7531e0a5 0xc00436ae40 0xc00436ae41}] [] [{kube-controller-manager Update v1 2022-11-26 12:28:32 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4c746fc6-c394-45a4-973e-067f7531e0a5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:28:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.37\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cstc4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cstc4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:28:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:28:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:28:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:28:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.37,StartTime:2022-11-26 12:28:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:28:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c20ccf715fcdf2e3b9f6fe3f6f17ecb6486a994c735b9608f6e859658d1663d5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 26 12:28:34.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3340" for this suite. 11/26/22 12:28:34.223
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":146,"skipped":2661,"failed":0}
------------------------------
â€¢ [2.192 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:28:32.043
    Nov 26 12:28:32.043: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename deployment 11/26/22 12:28:32.044
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:32.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:32.08
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 11/26/22 12:28:32.094
    Nov 26 12:28:32.094: INFO: Creating simple deployment test-deployment-d7h2m
    Nov 26 12:28:32.117: INFO: deployment "test-deployment-d7h2m" doesn't have the required revision set
    STEP: Getting /status 11/26/22 12:28:34.147
    Nov 26 12:28:34.154: INFO: Deployment test-deployment-d7h2m has Conditions: [{Available True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d7h2m-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 11/26/22 12:28:34.154
    Nov 26 12:28:34.169: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 28, 33, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 28, 33, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 28, 33, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 28, 32, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-d7h2m-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 11/26/22 12:28:34.169
    Nov 26 12:28:34.173: INFO: Observed &Deployment event: ADDED
    Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d7h2m-777898ffcc"}
    Nov 26 12:28:34.173: INFO: Observed &Deployment event: MODIFIED
    Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d7h2m-777898ffcc"}
    Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 26 12:28:34.173: INFO: Observed &Deployment event: MODIFIED
    Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-d7h2m-777898ffcc" is progressing.}
    Nov 26 12:28:34.173: INFO: Observed &Deployment event: MODIFIED
    Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 26 12:28:34.173: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d7h2m-777898ffcc" has successfully progressed.}
    Nov 26 12:28:34.174: INFO: Observed &Deployment event: MODIFIED
    Nov 26 12:28:34.174: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 26 12:28:34.174: INFO: Observed Deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d7h2m-777898ffcc" has successfully progressed.}
    Nov 26 12:28:34.174: INFO: Found Deployment test-deployment-d7h2m in namespace deployment-3340 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 26 12:28:34.174: INFO: Deployment test-deployment-d7h2m has an updated status
    STEP: patching the Statefulset Status 11/26/22 12:28:34.174
    Nov 26 12:28:34.174: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 26 12:28:34.184: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 11/26/22 12:28:34.185
    Nov 26 12:28:34.188: INFO: Observed &Deployment event: ADDED
    Nov 26 12:28:34.188: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d7h2m-777898ffcc"}
    Nov 26 12:28:34.188: INFO: Observed &Deployment event: MODIFIED
    Nov 26 12:28:34.189: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-d7h2m-777898ffcc"}
    Nov 26 12:28:34.189: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 26 12:28:34.189: INFO: Observed &Deployment event: MODIFIED
    Nov 26 12:28:34.189: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov 26 12:28:34.189: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:32 +0000 UTC 2022-11-26 12:28:32 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-d7h2m-777898ffcc" is progressing.}
    Nov 26 12:28:34.190: INFO: Observed &Deployment event: MODIFIED
    Nov 26 12:28:34.190: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 26 12:28:34.190: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d7h2m-777898ffcc" has successfully progressed.}
    Nov 26 12:28:34.190: INFO: Observed &Deployment event: MODIFIED
    Nov 26 12:28:34.190: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:33 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov 26 12:28:34.191: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-26 12:28:33 +0000 UTC 2022-11-26 12:28:32 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-d7h2m-777898ffcc" has successfully progressed.}
    Nov 26 12:28:34.191: INFO: Observed deployment test-deployment-d7h2m in namespace deployment-3340 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 26 12:28:34.191: INFO: Observed &Deployment event: MODIFIED
    Nov 26 12:28:34.191: INFO: Found deployment test-deployment-d7h2m in namespace deployment-3340 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Nov 26 12:28:34.191: INFO: Deployment test-deployment-d7h2m has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 26 12:28:34.197: INFO: Deployment "test-deployment-d7h2m":
    &Deployment{ObjectMeta:{test-deployment-d7h2m  deployment-3340  65470fc6-789d-4293-9850-fde01aab392a 17939 1 2022-11-26 12:28:32 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-26 12:28:32 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-11-26 12:28:34 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-11-26 12:28:34 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00436a5b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-d7h2m-777898ffcc",LastUpdateTime:2022-11-26 12:28:34 +0000 UTC,LastTransitionTime:2022-11-26 12:28:34 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 26 12:28:34.209: INFO: New ReplicaSet "test-deployment-d7h2m-777898ffcc" of Deployment "test-deployment-d7h2m":
    &ReplicaSet{ObjectMeta:{test-deployment-d7h2m-777898ffcc  deployment-3340  4c746fc6-c394-45a4-973e-067f7531e0a5 17935 1 2022-11-26 12:28:32 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-d7h2m 65470fc6-789d-4293-9850-fde01aab392a 0xc00436a9c0 0xc00436a9c1}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:28:32 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"65470fc6-789d-4293-9850-fde01aab392a\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:28:33 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00436aa78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:28:34.217: INFO: Pod "test-deployment-d7h2m-777898ffcc-rfpcp" is available:
    &Pod{ObjectMeta:{test-deployment-d7h2m-777898ffcc-rfpcp test-deployment-d7h2m-777898ffcc- deployment-3340  20d808d5-79f3-4266-9b71-270f4d3fd3e7 17934 0 2022-11-26 12:28:32 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-d7h2m-777898ffcc 4c746fc6-c394-45a4-973e-067f7531e0a5 0xc00436ae40 0xc00436ae41}] [] [{kube-controller-manager Update v1 2022-11-26 12:28:32 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4c746fc6-c394-45a4-973e-067f7531e0a5\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:28:33 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.37\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cstc4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cstc4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:28:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:28:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:28:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:28:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.37,StartTime:2022-11-26 12:28:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:28:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c20ccf715fcdf2e3b9f6fe3f6f17ecb6486a994c735b9608f6e859658d1663d5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 26 12:28:34.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3340" for this suite. 11/26/22 12:28:34.223
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:28:34.237
Nov 26 12:28:34.238: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename custom-resource-definition 11/26/22 12:28:34.239
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:34.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:34.271
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 11/26/22 12:28:34.276
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 11/26/22 12:28:34.278
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 11/26/22 12:28:34.278
STEP: fetching the /apis/apiextensions.k8s.io discovery document 11/26/22 12:28:34.278
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 11/26/22 12:28:34.28
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 11/26/22 12:28:34.28
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 11/26/22 12:28:34.283
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:28:34.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5993" for this suite. 11/26/22 12:28:34.29
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":147,"skipped":2664,"failed":0}
------------------------------
â€¢ [0.062 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:28:34.237
    Nov 26 12:28:34.238: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename custom-resource-definition 11/26/22 12:28:34.239
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:34.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:34.271
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 11/26/22 12:28:34.276
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 11/26/22 12:28:34.278
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 11/26/22 12:28:34.278
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 11/26/22 12:28:34.278
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 11/26/22 12:28:34.28
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 11/26/22 12:28:34.28
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 11/26/22 12:28:34.283
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:28:34.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-5993" for this suite. 11/26/22 12:28:34.29
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:28:34.3
Nov 26 12:28:34.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename statefulset 11/26/22 12:28:34.302
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:34.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:34.332
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8942 11/26/22 12:28:34.339
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 11/26/22 12:28:34.361
Nov 26 12:28:34.378: INFO: Found 0 stateful pods, waiting for 3
Nov 26 12:28:44.386: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 12:28:44.387: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 12:28:44.387: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/26/22 12:28:44.408
Nov 26 12:28:44.439: INFO: Updating stateful set ss2
STEP: Creating a new revision 11/26/22 12:28:44.439
STEP: Not applying an update when the partition is greater than the number of replicas 11/26/22 12:28:54.479
STEP: Performing a canary update 11/26/22 12:28:54.479
Nov 26 12:28:54.506: INFO: Updating stateful set ss2
Nov 26 12:28:54.524: INFO: Waiting for Pod statefulset-8942/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 11/26/22 12:29:04.538
Nov 26 12:29:04.606: INFO: Found 2 stateful pods, waiting for 3
Nov 26 12:29:14.613: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 12:29:14.614: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 12:29:14.614: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 11/26/22 12:29:14.625
Nov 26 12:29:14.652: INFO: Updating stateful set ss2
Nov 26 12:29:14.677: INFO: Waiting for Pod statefulset-8942/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Nov 26 12:29:24.720: INFO: Updating stateful set ss2
Nov 26 12:29:24.738: INFO: Waiting for StatefulSet statefulset-8942/ss2 to complete update
Nov 26 12:29:24.738: INFO: Waiting for Pod statefulset-8942/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 26 12:29:34.752: INFO: Deleting all statefulset in ns statefulset-8942
Nov 26 12:29:34.757: INFO: Scaling statefulset ss2 to 0
Nov 26 12:29:44.788: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 12:29:44.793: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 26 12:29:44.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8942" for this suite. 11/26/22 12:29:44.837
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":148,"skipped":2665,"failed":0}
------------------------------
â€¢ [SLOW TEST] [70.560 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:28:34.3
    Nov 26 12:28:34.301: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename statefulset 11/26/22 12:28:34.302
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:28:34.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:28:34.332
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-8942 11/26/22 12:28:34.339
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 11/26/22 12:28:34.361
    Nov 26 12:28:34.378: INFO: Found 0 stateful pods, waiting for 3
    Nov 26 12:28:44.386: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 12:28:44.387: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 12:28:44.387: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/26/22 12:28:44.408
    Nov 26 12:28:44.439: INFO: Updating stateful set ss2
    STEP: Creating a new revision 11/26/22 12:28:44.439
    STEP: Not applying an update when the partition is greater than the number of replicas 11/26/22 12:28:54.479
    STEP: Performing a canary update 11/26/22 12:28:54.479
    Nov 26 12:28:54.506: INFO: Updating stateful set ss2
    Nov 26 12:28:54.524: INFO: Waiting for Pod statefulset-8942/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 11/26/22 12:29:04.538
    Nov 26 12:29:04.606: INFO: Found 2 stateful pods, waiting for 3
    Nov 26 12:29:14.613: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 12:29:14.614: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 12:29:14.614: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 11/26/22 12:29:14.625
    Nov 26 12:29:14.652: INFO: Updating stateful set ss2
    Nov 26 12:29:14.677: INFO: Waiting for Pod statefulset-8942/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Nov 26 12:29:24.720: INFO: Updating stateful set ss2
    Nov 26 12:29:24.738: INFO: Waiting for StatefulSet statefulset-8942/ss2 to complete update
    Nov 26 12:29:24.738: INFO: Waiting for Pod statefulset-8942/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 26 12:29:34.752: INFO: Deleting all statefulset in ns statefulset-8942
    Nov 26 12:29:34.757: INFO: Scaling statefulset ss2 to 0
    Nov 26 12:29:44.788: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 12:29:44.793: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 26 12:29:44.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-8942" for this suite. 11/26/22 12:29:44.837
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:29:44.862
Nov 26 12:29:44.862: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 12:29:44.864
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:29:44.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:29:44.896
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-ea7795ff-bbf2-452d-b96a-34befc7c8911 11/26/22 12:29:44.902
STEP: Creating a pod to test consume configMaps 11/26/22 12:29:44.911
Nov 26 12:29:44.926: INFO: Waiting up to 5m0s for pod "pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4" in namespace "configmap-1710" to be "Succeeded or Failed"
Nov 26 12:29:44.934: INFO: Pod "pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.150025ms
Nov 26 12:29:46.941: INFO: Pod "pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014488853s
Nov 26 12:29:48.939: INFO: Pod "pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012704629s
STEP: Saw pod success 11/26/22 12:29:48.939
Nov 26 12:29:48.939: INFO: Pod "pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4" satisfied condition "Succeeded or Failed"
Nov 26 12:29:48.945: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4 container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:29:48.979
Nov 26 12:29:49.012: INFO: Waiting for pod pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4 to disappear
Nov 26 12:29:49.024: INFO: Pod pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 12:29:49.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1710" for this suite. 11/26/22 12:29:49.039
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":149,"skipped":2678,"failed":0}
------------------------------
â€¢ [4.194 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:29:44.862
    Nov 26 12:29:44.862: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 12:29:44.864
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:29:44.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:29:44.896
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-ea7795ff-bbf2-452d-b96a-34befc7c8911 11/26/22 12:29:44.902
    STEP: Creating a pod to test consume configMaps 11/26/22 12:29:44.911
    Nov 26 12:29:44.926: INFO: Waiting up to 5m0s for pod "pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4" in namespace "configmap-1710" to be "Succeeded or Failed"
    Nov 26 12:29:44.934: INFO: Pod "pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.150025ms
    Nov 26 12:29:46.941: INFO: Pod "pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014488853s
    Nov 26 12:29:48.939: INFO: Pod "pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012704629s
    STEP: Saw pod success 11/26/22 12:29:48.939
    Nov 26 12:29:48.939: INFO: Pod "pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4" satisfied condition "Succeeded or Failed"
    Nov 26 12:29:48.945: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4 container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:29:48.979
    Nov 26 12:29:49.012: INFO: Waiting for pod pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4 to disappear
    Nov 26 12:29:49.024: INFO: Pod pod-configmaps-09c92f67-2a96-481a-900d-3e09932ef2d4 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 12:29:49.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1710" for this suite. 11/26/22 12:29:49.039
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:29:49.058
Nov 26 12:29:49.058: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:29:49.059
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:29:49.095
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:29:49.109
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:29:49.15
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:29:49.749
STEP: Deploying the webhook pod 11/26/22 12:29:49.767
STEP: Wait for the deployment to be ready 11/26/22 12:29:49.852
Nov 26 12:29:49.868: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 26 12:29:51.886: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 29, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 29, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 29, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 29, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/26/22 12:29:53.893
STEP: Verifying the service has paired with the endpoint 11/26/22 12:29:53.909
Nov 26 12:29:54.910: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Nov 26 12:29:54.917: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4666-crds.webhook.example.com via the AdmissionRegistration API 11/26/22 12:29:55.433
STEP: Creating a custom resource while v1 is storage version 11/26/22 12:29:55.454
STEP: Patching Custom Resource Definition to set v2 as storage 11/26/22 12:29:57.543
STEP: Patching the custom resource while v2 is storage version 11/26/22 12:29:57.587
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:29:58.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2114" for this suite. 11/26/22 12:29:58.184
STEP: Destroying namespace "webhook-2114-markers" for this suite. 11/26/22 12:29:58.193
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":150,"skipped":2688,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.217 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:29:49.058
    Nov 26 12:29:49.058: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:29:49.059
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:29:49.095
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:29:49.109
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:29:49.15
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:29:49.749
    STEP: Deploying the webhook pod 11/26/22 12:29:49.767
    STEP: Wait for the deployment to be ready 11/26/22 12:29:49.852
    Nov 26 12:29:49.868: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 26 12:29:51.886: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 29, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 29, 49, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 29, 49, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 29, 49, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/26/22 12:29:53.893
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:29:53.909
    Nov 26 12:29:54.910: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Nov 26 12:29:54.917: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4666-crds.webhook.example.com via the AdmissionRegistration API 11/26/22 12:29:55.433
    STEP: Creating a custom resource while v1 is storage version 11/26/22 12:29:55.454
    STEP: Patching Custom Resource Definition to set v2 as storage 11/26/22 12:29:57.543
    STEP: Patching the custom resource while v2 is storage version 11/26/22 12:29:57.587
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:29:58.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2114" for this suite. 11/26/22 12:29:58.184
    STEP: Destroying namespace "webhook-2114-markers" for this suite. 11/26/22 12:29:58.193
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:29:58.277
Nov 26 12:29:58.277: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-lifecycle-hook 11/26/22 12:29:58.278
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:29:58.362
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:29:58.367
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/26/22 12:29:58.379
Nov 26 12:29:58.393: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4964" to be "running and ready"
Nov 26 12:29:58.399: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 5.832701ms
Nov 26 12:29:58.399: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:30:00.405: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.012555398s
Nov 26 12:30:00.405: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 26 12:30:00.405: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 11/26/22 12:30:00.412
Nov 26 12:30:00.423: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-4964" to be "running and ready"
Nov 26 12:30:00.428: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.308291ms
Nov 26 12:30:00.428: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:30:02.443: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.020176052s
Nov 26 12:30:02.443: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Nov 26 12:30:02.443: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 11/26/22 12:30:02.455
Nov 26 12:30:02.477: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 26 12:30:02.491: INFO: Pod pod-with-prestop-http-hook still exists
Nov 26 12:30:04.493: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 26 12:30:04.500: INFO: Pod pod-with-prestop-http-hook still exists
Nov 26 12:30:06.493: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 26 12:30:06.500: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 11/26/22 12:30:06.5
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 26 12:30:06.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4964" for this suite. 11/26/22 12:30:06.518
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":151,"skipped":2704,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.254 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:29:58.277
    Nov 26 12:29:58.277: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/26/22 12:29:58.278
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:29:58.362
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:29:58.367
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/26/22 12:29:58.379
    Nov 26 12:29:58.393: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4964" to be "running and ready"
    Nov 26 12:29:58.399: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 5.832701ms
    Nov 26 12:29:58.399: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:30:00.405: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.012555398s
    Nov 26 12:30:00.405: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 26 12:30:00.405: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 11/26/22 12:30:00.412
    Nov 26 12:30:00.423: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-4964" to be "running and ready"
    Nov 26 12:30:00.428: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.308291ms
    Nov 26 12:30:00.428: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:30:02.443: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.020176052s
    Nov 26 12:30:02.443: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Nov 26 12:30:02.443: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 11/26/22 12:30:02.455
    Nov 26 12:30:02.477: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 26 12:30:02.491: INFO: Pod pod-with-prestop-http-hook still exists
    Nov 26 12:30:04.493: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 26 12:30:04.500: INFO: Pod pod-with-prestop-http-hook still exists
    Nov 26 12:30:06.493: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov 26 12:30:06.500: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 11/26/22 12:30:06.5
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 26 12:30:06.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4964" for this suite. 11/26/22 12:30:06.518
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:30:06.533
Nov 26 12:30:06.533: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:30:06.535
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:06.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:06.569
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-4566 11/26/22 12:30:06.577
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4566 to expose endpoints map[] 11/26/22 12:30:06.592
Nov 26 12:30:06.603: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
Nov 26 12:30:07.617: INFO: successfully validated that service endpoint-test2 in namespace services-4566 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-4566 11/26/22 12:30:07.617
Nov 26 12:30:07.629: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4566" to be "running and ready"
Nov 26 12:30:07.635: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.342641ms
Nov 26 12:30:07.635: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:30:09.642: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.013271s
Nov 26 12:30:09.642: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 26 12:30:09.643: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4566 to expose endpoints map[pod1:[80]] 11/26/22 12:30:09.649
Nov 26 12:30:09.669: INFO: successfully validated that service endpoint-test2 in namespace services-4566 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 11/26/22 12:30:09.669
Nov 26 12:30:09.670: INFO: Creating new exec pod
Nov 26 12:30:09.680: INFO: Waiting up to 5m0s for pod "execpodh8twp" in namespace "services-4566" to be "running"
Nov 26 12:30:09.685: INFO: Pod "execpodh8twp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.948054ms
Nov 26 12:30:11.692: INFO: Pod "execpodh8twp": Phase="Running", Reason="", readiness=true. Elapsed: 2.011794261s
Nov 26 12:30:11.692: INFO: Pod "execpodh8twp" satisfied condition "running"
Nov 26 12:30:12.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 26 12:30:13.020: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 26 12:30:13.020: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:30:13.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
Nov 26 12:30:13.391: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
Nov 26 12:30:13.391: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-4566 11/26/22 12:30:13.391
Nov 26 12:30:13.410: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4566" to be "running and ready"
Nov 26 12:30:13.415: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.27715ms
Nov 26 12:30:13.415: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:30:15.422: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012383845s
Nov 26 12:30:15.422: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 26 12:30:15.423: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4566 to expose endpoints map[pod1:[80] pod2:[80]] 11/26/22 12:30:15.429
Nov 26 12:30:15.453: INFO: successfully validated that service endpoint-test2 in namespace services-4566 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 11/26/22 12:30:15.453
Nov 26 12:30:16.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 26 12:30:16.684: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 26 12:30:16.684: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:30:16.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
Nov 26 12:30:16.853: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
Nov 26 12:30:16.853: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-4566 11/26/22 12:30:16.853
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4566 to expose endpoints map[pod2:[80]] 11/26/22 12:30:16.878
Nov 26 12:30:16.906: INFO: successfully validated that service endpoint-test2 in namespace services-4566 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 11/26/22 12:30:16.906
Nov 26 12:30:17.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov 26 12:30:18.096: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov 26 12:30:18.096: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:30:18.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
Nov 26 12:30:18.286: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
Nov 26 12:30:18.286: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-4566 11/26/22 12:30:18.286
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4566 to expose endpoints map[] 11/26/22 12:30:18.309
Nov 26 12:30:19.354: INFO: successfully validated that service endpoint-test2 in namespace services-4566 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:30:19.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4566" for this suite. 11/26/22 12:30:19.414
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":152,"skipped":2726,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.894 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:30:06.533
    Nov 26 12:30:06.533: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:30:06.535
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:06.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:06.569
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-4566 11/26/22 12:30:06.577
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4566 to expose endpoints map[] 11/26/22 12:30:06.592
    Nov 26 12:30:06.603: INFO: Failed go get Endpoints object: endpoints "endpoint-test2" not found
    Nov 26 12:30:07.617: INFO: successfully validated that service endpoint-test2 in namespace services-4566 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-4566 11/26/22 12:30:07.617
    Nov 26 12:30:07.629: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-4566" to be "running and ready"
    Nov 26 12:30:07.635: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.342641ms
    Nov 26 12:30:07.635: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:30:09.642: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.013271s
    Nov 26 12:30:09.642: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 26 12:30:09.643: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4566 to expose endpoints map[pod1:[80]] 11/26/22 12:30:09.649
    Nov 26 12:30:09.669: INFO: successfully validated that service endpoint-test2 in namespace services-4566 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 11/26/22 12:30:09.669
    Nov 26 12:30:09.670: INFO: Creating new exec pod
    Nov 26 12:30:09.680: INFO: Waiting up to 5m0s for pod "execpodh8twp" in namespace "services-4566" to be "running"
    Nov 26 12:30:09.685: INFO: Pod "execpodh8twp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.948054ms
    Nov 26 12:30:11.692: INFO: Pod "execpodh8twp": Phase="Running", Reason="", readiness=true. Elapsed: 2.011794261s
    Nov 26 12:30:11.692: INFO: Pod "execpodh8twp" satisfied condition "running"
    Nov 26 12:30:12.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 26 12:30:13.020: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 26 12:30:13.020: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:30:13.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
    Nov 26 12:30:13.391: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
    Nov 26 12:30:13.391: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-4566 11/26/22 12:30:13.391
    Nov 26 12:30:13.410: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-4566" to be "running and ready"
    Nov 26 12:30:13.415: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.27715ms
    Nov 26 12:30:13.415: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:30:15.422: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012383845s
    Nov 26 12:30:15.422: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 26 12:30:15.423: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4566 to expose endpoints map[pod1:[80] pod2:[80]] 11/26/22 12:30:15.429
    Nov 26 12:30:15.453: INFO: successfully validated that service endpoint-test2 in namespace services-4566 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 11/26/22 12:30:15.453
    Nov 26 12:30:16.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 26 12:30:16.684: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 26 12:30:16.684: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:30:16.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
    Nov 26 12:30:16.853: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
    Nov 26 12:30:16.853: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-4566 11/26/22 12:30:16.853
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4566 to expose endpoints map[pod2:[80]] 11/26/22 12:30:16.878
    Nov 26 12:30:16.906: INFO: successfully validated that service endpoint-test2 in namespace services-4566 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 11/26/22 12:30:16.906
    Nov 26 12:30:17.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov 26 12:30:18.096: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov 26 12:30:18.096: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:30:18.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-4566 exec execpodh8twp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.142 80'
    Nov 26 12:30:18.286: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.142 80\nConnection to 10.152.183.142 80 port [tcp/http] succeeded!\n"
    Nov 26 12:30:18.286: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-4566 11/26/22 12:30:18.286
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4566 to expose endpoints map[] 11/26/22 12:30:18.309
    Nov 26 12:30:19.354: INFO: successfully validated that service endpoint-test2 in namespace services-4566 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:30:19.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4566" for this suite. 11/26/22 12:30:19.414
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:30:19.431
Nov 26 12:30:19.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename svcaccounts 11/26/22 12:30:19.435
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:19.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:19.466
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Nov 26 12:30:19.510: INFO: created pod pod-service-account-defaultsa
Nov 26 12:30:19.510: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 26 12:30:19.523: INFO: created pod pod-service-account-mountsa
Nov 26 12:30:19.523: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 26 12:30:19.532: INFO: created pod pod-service-account-nomountsa
Nov 26 12:30:19.532: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 26 12:30:19.548: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 26 12:30:19.548: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 26 12:30:19.563: INFO: created pod pod-service-account-mountsa-mountspec
Nov 26 12:30:19.564: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 26 12:30:19.576: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 26 12:30:19.576: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 26 12:30:19.595: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 26 12:30:19.595: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 26 12:30:19.611: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 26 12:30:19.611: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 26 12:30:19.619: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 26 12:30:19.619: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 26 12:30:19.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9387" for this suite. 11/26/22 12:30:19.638
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":153,"skipped":2777,"failed":0}
------------------------------
â€¢ [0.223 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:30:19.431
    Nov 26 12:30:19.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename svcaccounts 11/26/22 12:30:19.435
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:19.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:19.466
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Nov 26 12:30:19.510: INFO: created pod pod-service-account-defaultsa
    Nov 26 12:30:19.510: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Nov 26 12:30:19.523: INFO: created pod pod-service-account-mountsa
    Nov 26 12:30:19.523: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Nov 26 12:30:19.532: INFO: created pod pod-service-account-nomountsa
    Nov 26 12:30:19.532: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Nov 26 12:30:19.548: INFO: created pod pod-service-account-defaultsa-mountspec
    Nov 26 12:30:19.548: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Nov 26 12:30:19.563: INFO: created pod pod-service-account-mountsa-mountspec
    Nov 26 12:30:19.564: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Nov 26 12:30:19.576: INFO: created pod pod-service-account-nomountsa-mountspec
    Nov 26 12:30:19.576: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Nov 26 12:30:19.595: INFO: created pod pod-service-account-defaultsa-nomountspec
    Nov 26 12:30:19.595: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Nov 26 12:30:19.611: INFO: created pod pod-service-account-mountsa-nomountspec
    Nov 26 12:30:19.611: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Nov 26 12:30:19.619: INFO: created pod pod-service-account-nomountsa-nomountspec
    Nov 26 12:30:19.619: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 26 12:30:19.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9387" for this suite. 11/26/22 12:30:19.638
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:30:19.655
Nov 26 12:30:19.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename daemonsets 11/26/22 12:30:19.656
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:19.681
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:19.686
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 11/26/22 12:30:19.723
STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 12:30:19.747
Nov 26 12:30:19.766: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:19.766: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:19.780: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:30:19.780: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:30:20.787: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:20.787: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:20.792: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:30:20.793: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:30:21.787: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:21.787: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:21.794: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:30:21.794: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:30:22.788: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:22.788: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:22.795: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:30:22.795: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:30:23.786: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:23.786: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:23.792: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:30:23.792: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:30:24.789: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:24.789: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:24.796: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 26 12:30:24.796: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 11/26/22 12:30:24.806
Nov 26 12:30:24.863: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:24.864: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:24.877: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:30:24.877: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:30:25.884: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:25.885: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:25.891: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:30:25.891: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:30:26.885: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:26.885: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:26.891: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:30:26.891: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:30:27.884: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:27.884: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:27.893: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:30:27.893: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:30:28.884: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:28.884: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:28.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:30:28.890: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:30:29.884: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:29.885: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:29.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:30:29.890: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:30:30.883: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:30.883: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:30.889: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 26 12:30:30.889: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:30:30.895
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6779, will wait for the garbage collector to delete the pods 11/26/22 12:30:30.895
Nov 26 12:30:30.971: INFO: Deleting DaemonSet.extensions daemon-set took: 20.400251ms
Nov 26 12:30:31.071: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.189807ms
Nov 26 12:30:32.377: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:30:32.377: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 26 12:30:32.382: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19041"},"items":null}

Nov 26 12:30:32.388: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19041"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:30:32.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6779" for this suite. 11/26/22 12:30:32.416
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":154,"skipped":2795,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.773 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:30:19.655
    Nov 26 12:30:19.655: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename daemonsets 11/26/22 12:30:19.656
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:19.681
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:19.686
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 11/26/22 12:30:19.723
    STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 12:30:19.747
    Nov 26 12:30:19.766: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:19.766: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:19.780: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:30:19.780: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:30:20.787: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:20.787: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:20.792: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:30:20.793: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:30:21.787: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:21.787: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:21.794: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:30:21.794: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:30:22.788: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:22.788: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:22.795: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:30:22.795: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:30:23.786: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:23.786: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:23.792: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:30:23.792: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:30:24.789: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:24.789: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:24.796: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 26 12:30:24.796: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 11/26/22 12:30:24.806
    Nov 26 12:30:24.863: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:24.864: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:24.877: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:30:24.877: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:30:25.884: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:25.885: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:25.891: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:30:25.891: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:30:26.885: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:26.885: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:26.891: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:30:26.891: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:30:27.884: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:27.884: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:27.893: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:30:27.893: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:30:28.884: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:28.884: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:28.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:30:28.890: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:30:29.884: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:29.885: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:29.890: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:30:29.890: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:30:30.883: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:30.883: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:30.889: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 26 12:30:30.889: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:30:30.895
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6779, will wait for the garbage collector to delete the pods 11/26/22 12:30:30.895
    Nov 26 12:30:30.971: INFO: Deleting DaemonSet.extensions daemon-set took: 20.400251ms
    Nov 26 12:30:31.071: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.189807ms
    Nov 26 12:30:32.377: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:30:32.377: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 26 12:30:32.382: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19041"},"items":null}

    Nov 26 12:30:32.388: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19041"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:30:32.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6779" for this suite. 11/26/22 12:30:32.416
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:30:32.431
Nov 26 12:30:32.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 12:30:32.432
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:32.453
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:32.462
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-0dbfee73-a145-4b27-bd28-bae81bb4e919 11/26/22 12:30:32.469
STEP: Creating a pod to test consume secrets 11/26/22 12:30:32.477
Nov 26 12:30:32.490: INFO: Waiting up to 5m0s for pod "pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1" in namespace "secrets-2653" to be "Succeeded or Failed"
Nov 26 12:30:32.501: INFO: Pod "pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.723515ms
Nov 26 12:30:34.508: INFO: Pod "pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017341054s
Nov 26 12:30:36.507: INFO: Pod "pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016773571s
STEP: Saw pod success 11/26/22 12:30:36.507
Nov 26 12:30:36.507: INFO: Pod "pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1" satisfied condition "Succeeded or Failed"
Nov 26 12:30:36.513: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1 container secret-volume-test: <nil>
STEP: delete the pod 11/26/22 12:30:36.524
Nov 26 12:30:36.539: INFO: Waiting for pod pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1 to disappear
Nov 26 12:30:36.544: INFO: Pod pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 26 12:30:36.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2653" for this suite. 11/26/22 12:30:36.55
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":155,"skipped":2819,"failed":0}
------------------------------
â€¢ [4.128 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:30:32.431
    Nov 26 12:30:32.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 12:30:32.432
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:32.453
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:32.462
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-0dbfee73-a145-4b27-bd28-bae81bb4e919 11/26/22 12:30:32.469
    STEP: Creating a pod to test consume secrets 11/26/22 12:30:32.477
    Nov 26 12:30:32.490: INFO: Waiting up to 5m0s for pod "pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1" in namespace "secrets-2653" to be "Succeeded or Failed"
    Nov 26 12:30:32.501: INFO: Pod "pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.723515ms
    Nov 26 12:30:34.508: INFO: Pod "pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017341054s
    Nov 26 12:30:36.507: INFO: Pod "pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016773571s
    STEP: Saw pod success 11/26/22 12:30:36.507
    Nov 26 12:30:36.507: INFO: Pod "pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1" satisfied condition "Succeeded or Failed"
    Nov 26 12:30:36.513: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1 container secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:30:36.524
    Nov 26 12:30:36.539: INFO: Waiting for pod pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1 to disappear
    Nov 26 12:30:36.544: INFO: Pod pod-secrets-4122f0e8-4685-4ed2-a0ad-dddbfe2875c1 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 12:30:36.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2653" for this suite. 11/26/22 12:30:36.55
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:30:36.563
Nov 26 12:30:36.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename var-expansion 11/26/22 12:30:36.564
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:36.585
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:36.591
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 11/26/22 12:30:36.596
Nov 26 12:30:36.609: INFO: Waiting up to 5m0s for pod "var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb" in namespace "var-expansion-4457" to be "Succeeded or Failed"
Nov 26 12:30:36.618: INFO: Pod "var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.922131ms
Nov 26 12:30:38.625: INFO: Pod "var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015377993s
Nov 26 12:30:40.624: INFO: Pod "var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015125794s
STEP: Saw pod success 11/26/22 12:30:40.624
Nov 26 12:30:40.624: INFO: Pod "var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb" satisfied condition "Succeeded or Failed"
Nov 26 12:30:40.630: INFO: Trying to get logs from node ip-172-31-43-82 pod var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb container dapi-container: <nil>
STEP: delete the pod 11/26/22 12:30:40.64
Nov 26 12:30:40.657: INFO: Waiting for pod var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb to disappear
Nov 26 12:30:40.662: INFO: Pod var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 26 12:30:40.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4457" for this suite. 11/26/22 12:30:40.669
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":156,"skipped":2842,"failed":0}
------------------------------
â€¢ [4.118 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:30:36.563
    Nov 26 12:30:36.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename var-expansion 11/26/22 12:30:36.564
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:36.585
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:36.591
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 11/26/22 12:30:36.596
    Nov 26 12:30:36.609: INFO: Waiting up to 5m0s for pod "var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb" in namespace "var-expansion-4457" to be "Succeeded or Failed"
    Nov 26 12:30:36.618: INFO: Pod "var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.922131ms
    Nov 26 12:30:38.625: INFO: Pod "var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015377993s
    Nov 26 12:30:40.624: INFO: Pod "var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015125794s
    STEP: Saw pod success 11/26/22 12:30:40.624
    Nov 26 12:30:40.624: INFO: Pod "var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb" satisfied condition "Succeeded or Failed"
    Nov 26 12:30:40.630: INFO: Trying to get logs from node ip-172-31-43-82 pod var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb container dapi-container: <nil>
    STEP: delete the pod 11/26/22 12:30:40.64
    Nov 26 12:30:40.657: INFO: Waiting for pod var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb to disappear
    Nov 26 12:30:40.662: INFO: Pod var-expansion-ed8be398-0f4d-46c1-b00a-eaf440ee82eb no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 26 12:30:40.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4457" for this suite. 11/26/22 12:30:40.669
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:30:40.682
Nov 26 12:30:40.683: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-runtime 11/26/22 12:30:40.686
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:40.711
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:40.717
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 11/26/22 12:30:40.724
STEP: wait for the container to reach Failed 11/26/22 12:30:40.743
STEP: get the container status 11/26/22 12:30:44.78
STEP: the container should be terminated 11/26/22 12:30:44.787
STEP: the termination message should be set 11/26/22 12:30:44.787
Nov 26 12:30:44.787: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 11/26/22 12:30:44.787
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 26 12:30:44.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1013" for this suite. 11/26/22 12:30:44.821
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":157,"skipped":2856,"failed":0}
------------------------------
â€¢ [4.151 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:30:40.682
    Nov 26 12:30:40.683: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-runtime 11/26/22 12:30:40.686
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:40.711
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:40.717
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 11/26/22 12:30:40.724
    STEP: wait for the container to reach Failed 11/26/22 12:30:40.743
    STEP: get the container status 11/26/22 12:30:44.78
    STEP: the container should be terminated 11/26/22 12:30:44.787
    STEP: the termination message should be set 11/26/22 12:30:44.787
    Nov 26 12:30:44.787: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 11/26/22 12:30:44.787
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 26 12:30:44.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1013" for this suite. 11/26/22 12:30:44.821
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:30:44.837
Nov 26 12:30:44.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 12:30:44.838
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:44.871
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:44.878
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-5be12dbe-cb55-4cdb-bd77-354ad2ccf6ad 11/26/22 12:30:44.884
STEP: Creating a pod to test consume configMaps 11/26/22 12:30:44.893
Nov 26 12:30:44.908: INFO: Waiting up to 5m0s for pod "pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade" in namespace "configmap-4273" to be "Succeeded or Failed"
Nov 26 12:30:44.914: INFO: Pod "pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade": Phase="Pending", Reason="", readiness=false. Elapsed: 5.788931ms
Nov 26 12:30:46.920: INFO: Pod "pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011878218s
Nov 26 12:30:48.921: INFO: Pod "pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012747194s
STEP: Saw pod success 11/26/22 12:30:48.921
Nov 26 12:30:48.921: INFO: Pod "pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade" satisfied condition "Succeeded or Failed"
Nov 26 12:30:48.931: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:30:48.942
Nov 26 12:30:48.964: INFO: Waiting for pod pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade to disappear
Nov 26 12:30:48.971: INFO: Pod pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 12:30:48.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4273" for this suite. 11/26/22 12:30:48.978
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":158,"skipped":2858,"failed":0}
------------------------------
â€¢ [4.152 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:30:44.837
    Nov 26 12:30:44.837: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 12:30:44.838
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:44.871
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:44.878
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-5be12dbe-cb55-4cdb-bd77-354ad2ccf6ad 11/26/22 12:30:44.884
    STEP: Creating a pod to test consume configMaps 11/26/22 12:30:44.893
    Nov 26 12:30:44.908: INFO: Waiting up to 5m0s for pod "pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade" in namespace "configmap-4273" to be "Succeeded or Failed"
    Nov 26 12:30:44.914: INFO: Pod "pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade": Phase="Pending", Reason="", readiness=false. Elapsed: 5.788931ms
    Nov 26 12:30:46.920: INFO: Pod "pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011878218s
    Nov 26 12:30:48.921: INFO: Pod "pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012747194s
    STEP: Saw pod success 11/26/22 12:30:48.921
    Nov 26 12:30:48.921: INFO: Pod "pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade" satisfied condition "Succeeded or Failed"
    Nov 26 12:30:48.931: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:30:48.942
    Nov 26 12:30:48.964: INFO: Waiting for pod pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade to disappear
    Nov 26 12:30:48.971: INFO: Pod pod-configmaps-e209b39d-0975-48cf-83b3-d830be1edade no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 12:30:48.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4273" for this suite. 11/26/22 12:30:48.978
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:30:49.001
Nov 26 12:30:49.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 12:30:49.005
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:49.033
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:49.042
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:30:49.052
Nov 26 12:30:49.076: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820" in namespace "downward-api-3601" to be "Succeeded or Failed"
Nov 26 12:30:49.087: INFO: Pod "downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820": Phase="Pending", Reason="", readiness=false. Elapsed: 10.475872ms
Nov 26 12:30:51.093: INFO: Pod "downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016510365s
Nov 26 12:30:53.094: INFO: Pod "downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017541529s
STEP: Saw pod success 11/26/22 12:30:53.094
Nov 26 12:30:53.094: INFO: Pod "downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820" satisfied condition "Succeeded or Failed"
Nov 26 12:30:53.099: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820 container client-container: <nil>
STEP: delete the pod 11/26/22 12:30:53.11
Nov 26 12:30:53.127: INFO: Waiting for pod downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820 to disappear
Nov 26 12:30:53.132: INFO: Pod downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 12:30:53.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3601" for this suite. 11/26/22 12:30:53.141
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":159,"skipped":2904,"failed":0}
------------------------------
â€¢ [4.151 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:30:49.001
    Nov 26 12:30:49.001: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 12:30:49.005
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:49.033
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:49.042
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:30:49.052
    Nov 26 12:30:49.076: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820" in namespace "downward-api-3601" to be "Succeeded or Failed"
    Nov 26 12:30:49.087: INFO: Pod "downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820": Phase="Pending", Reason="", readiness=false. Elapsed: 10.475872ms
    Nov 26 12:30:51.093: INFO: Pod "downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016510365s
    Nov 26 12:30:53.094: INFO: Pod "downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017541529s
    STEP: Saw pod success 11/26/22 12:30:53.094
    Nov 26 12:30:53.094: INFO: Pod "downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820" satisfied condition "Succeeded or Failed"
    Nov 26 12:30:53.099: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820 container client-container: <nil>
    STEP: delete the pod 11/26/22 12:30:53.11
    Nov 26 12:30:53.127: INFO: Waiting for pod downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820 to disappear
    Nov 26 12:30:53.132: INFO: Pod downwardapi-volume-2ba66c71-5982-4000-9971-5e93dfd88820 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 12:30:53.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3601" for this suite. 11/26/22 12:30:53.141
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:30:53.153
Nov 26 12:30:53.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename daemonsets 11/26/22 12:30:53.154
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:53.182
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:53.189
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Nov 26 12:30:53.233: INFO: Create a RollingUpdate DaemonSet
Nov 26 12:30:53.244: INFO: Check that daemon pods launch on every node of the cluster
Nov 26 12:30:53.253: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:53.253: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:53.260: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:30:53.260: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:30:54.267: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:54.267: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:54.272: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:30:54.273: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:30:55.267: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:55.267: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:55.273: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:30:55.273: INFO: Node ip-172-31-29-104 is running 0 daemon pod, expected 1
Nov 26 12:30:56.273: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:56.273: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:56.281: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 26 12:30:56.281: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Nov 26 12:30:56.281: INFO: Update the DaemonSet to trigger a rollout
Nov 26 12:30:56.296: INFO: Updating DaemonSet daemon-set
Nov 26 12:30:58.329: INFO: Roll back the DaemonSet before rollout is complete
Nov 26 12:30:58.344: INFO: Updating DaemonSet daemon-set
Nov 26 12:30:58.345: INFO: Make sure DaemonSet rollback is complete
Nov 26 12:30:58.356: INFO: Wrong image for pod: daemon-set-8tr5q. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Nov 26 12:30:58.356: INFO: Pod daemon-set-8tr5q is not available
Nov 26 12:30:58.361: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:58.361: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:59.379: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:30:59.379: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:31:00.368: INFO: Pod daemon-set-dv84l is not available
Nov 26 12:31:00.376: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:31:00.376: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:31:00.388
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1278, will wait for the garbage collector to delete the pods 11/26/22 12:31:00.388
Nov 26 12:31:00.472: INFO: Deleting DaemonSet.extensions daemon-set took: 27.945049ms
Nov 26 12:31:00.573: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.504136ms
Nov 26 12:31:01.980: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:31:01.980: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 26 12:31:01.985: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19422"},"items":null}

Nov 26 12:31:01.990: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19422"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:31:02.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1278" for this suite. 11/26/22 12:31:02.02
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":160,"skipped":2908,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.877 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:30:53.153
    Nov 26 12:30:53.153: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename daemonsets 11/26/22 12:30:53.154
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:30:53.182
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:30:53.189
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Nov 26 12:30:53.233: INFO: Create a RollingUpdate DaemonSet
    Nov 26 12:30:53.244: INFO: Check that daemon pods launch on every node of the cluster
    Nov 26 12:30:53.253: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:53.253: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:53.260: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:30:53.260: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:30:54.267: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:54.267: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:54.272: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:30:54.273: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:30:55.267: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:55.267: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:55.273: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:30:55.273: INFO: Node ip-172-31-29-104 is running 0 daemon pod, expected 1
    Nov 26 12:30:56.273: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:56.273: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:56.281: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 26 12:30:56.281: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Nov 26 12:30:56.281: INFO: Update the DaemonSet to trigger a rollout
    Nov 26 12:30:56.296: INFO: Updating DaemonSet daemon-set
    Nov 26 12:30:58.329: INFO: Roll back the DaemonSet before rollout is complete
    Nov 26 12:30:58.344: INFO: Updating DaemonSet daemon-set
    Nov 26 12:30:58.345: INFO: Make sure DaemonSet rollback is complete
    Nov 26 12:30:58.356: INFO: Wrong image for pod: daemon-set-8tr5q. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Nov 26 12:30:58.356: INFO: Pod daemon-set-8tr5q is not available
    Nov 26 12:30:58.361: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:58.361: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:59.379: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:30:59.379: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:31:00.368: INFO: Pod daemon-set-dv84l is not available
    Nov 26 12:31:00.376: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:31:00.376: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:31:00.388
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1278, will wait for the garbage collector to delete the pods 11/26/22 12:31:00.388
    Nov 26 12:31:00.472: INFO: Deleting DaemonSet.extensions daemon-set took: 27.945049ms
    Nov 26 12:31:00.573: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.504136ms
    Nov 26 12:31:01.980: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:31:01.980: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 26 12:31:01.985: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"19422"},"items":null}

    Nov 26 12:31:01.990: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"19422"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:31:02.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1278" for this suite. 11/26/22 12:31:02.02
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:31:02.031
Nov 26 12:31:02.031: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:31:02.032
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:31:02.055
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:31:02.064
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 11/26/22 12:31:02.07
Nov 26 12:31:02.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov 26 12:31:02.191: INFO: stderr: ""
Nov 26 12:31:02.191: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 11/26/22 12:31:02.192
Nov 26 12:31:02.192: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov 26 12:31:02.192: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1709" to be "running and ready, or succeeded"
Nov 26 12:31:02.198: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.79574ms
Nov 26 12:31:02.199: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'ip-172-31-43-82' to be 'Running' but was 'Pending'
Nov 26 12:31:04.205: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.012953228s
Nov 26 12:31:04.205: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov 26 12:31:04.205: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 11/26/22 12:31:04.205
Nov 26 12:31:04.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator'
Nov 26 12:31:04.353: INFO: stderr: ""
Nov 26 12:31:04.353: INFO: stdout: "I1126 12:31:03.134095       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/q6nt 293\nI1126 12:31:03.334446       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/2pj 525\nI1126 12:31:03.534856       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/s26t 355\nI1126 12:31:03.734195       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/p28 323\nI1126 12:31:03.934533       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/xzt 478\nI1126 12:31:04.134854       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/wmk 287\n"
STEP: limiting log lines 11/26/22 12:31:04.354
Nov 26 12:31:04.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator --tail=1'
Nov 26 12:31:04.495: INFO: stderr: ""
Nov 26 12:31:04.495: INFO: stdout: "I1126 12:31:04.335187       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/76lm 328\n"
Nov 26 12:31:04.495: INFO: got output "I1126 12:31:04.335187       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/76lm 328\n"
STEP: limiting log bytes 11/26/22 12:31:04.495
Nov 26 12:31:04.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator --limit-bytes=1'
Nov 26 12:31:04.668: INFO: stderr: ""
Nov 26 12:31:04.668: INFO: stdout: "I"
Nov 26 12:31:04.668: INFO: got output "I"
STEP: exposing timestamps 11/26/22 12:31:04.668
Nov 26 12:31:04.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator --tail=1 --timestamps'
Nov 26 12:31:04.845: INFO: stderr: ""
Nov 26 12:31:04.845: INFO: stdout: "2022-11-26T12:31:04.735025807Z I1126 12:31:04.734791       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/h4n 285\n"
Nov 26 12:31:04.845: INFO: got output "2022-11-26T12:31:04.735025807Z I1126 12:31:04.734791       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/h4n 285\n"
STEP: restricting to a time range 11/26/22 12:31:04.845
Nov 26 12:31:07.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator --since=1s'
Nov 26 12:31:07.492: INFO: stderr: ""
Nov 26 12:31:07.492: INFO: stdout: "I1126 12:31:06.534191       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/cnt 579\nI1126 12:31:06.734487       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/5slz 509\nI1126 12:31:06.934860       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/7cvv 430\nI1126 12:31:07.134163       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/f5t 497\nI1126 12:31:07.334470       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/882 279\n"
Nov 26 12:31:07.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator --since=24h'
Nov 26 12:31:07.614: INFO: stderr: ""
Nov 26 12:31:07.614: INFO: stdout: "I1126 12:31:03.134095       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/q6nt 293\nI1126 12:31:03.334446       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/2pj 525\nI1126 12:31:03.534856       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/s26t 355\nI1126 12:31:03.734195       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/p28 323\nI1126 12:31:03.934533       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/xzt 478\nI1126 12:31:04.134854       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/wmk 287\nI1126 12:31:04.335187       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/76lm 328\nI1126 12:31:04.534555       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/zvr 495\nI1126 12:31:04.734791       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/h4n 285\nI1126 12:31:04.934216       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/grw 539\nI1126 12:31:05.134572       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/5cxw 257\nI1126 12:31:05.335003       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/b9mn 492\nI1126 12:31:05.534210       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/hwn5 576\nI1126 12:31:05.734793       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/795d 310\nI1126 12:31:05.935171       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/hnfb 523\nI1126 12:31:06.134472       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/kkp8 511\nI1126 12:31:06.334869       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/s2s 405\nI1126 12:31:06.534191       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/cnt 579\nI1126 12:31:06.734487       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/5slz 509\nI1126 12:31:06.934860       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/7cvv 430\nI1126 12:31:07.134163       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/f5t 497\nI1126 12:31:07.334470       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/882 279\nI1126 12:31:07.534816       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/bb8 377\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Nov 26 12:31:07.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 delete pod logs-generator'
Nov 26 12:31:08.989: INFO: stderr: ""
Nov 26 12:31:08.989: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:31:08.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1709" for this suite. 11/26/22 12:31:08.995
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":161,"skipped":2912,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.976 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:31:02.031
    Nov 26 12:31:02.031: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:31:02.032
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:31:02.055
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:31:02.064
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 11/26/22 12:31:02.07
    Nov 26 12:31:02.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Nov 26 12:31:02.191: INFO: stderr: ""
    Nov 26 12:31:02.191: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 11/26/22 12:31:02.192
    Nov 26 12:31:02.192: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Nov 26 12:31:02.192: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1709" to be "running and ready, or succeeded"
    Nov 26 12:31:02.198: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.79574ms
    Nov 26 12:31:02.199: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'ip-172-31-43-82' to be 'Running' but was 'Pending'
    Nov 26 12:31:04.205: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.012953228s
    Nov 26 12:31:04.205: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Nov 26 12:31:04.205: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 11/26/22 12:31:04.205
    Nov 26 12:31:04.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator'
    Nov 26 12:31:04.353: INFO: stderr: ""
    Nov 26 12:31:04.353: INFO: stdout: "I1126 12:31:03.134095       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/q6nt 293\nI1126 12:31:03.334446       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/2pj 525\nI1126 12:31:03.534856       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/s26t 355\nI1126 12:31:03.734195       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/p28 323\nI1126 12:31:03.934533       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/xzt 478\nI1126 12:31:04.134854       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/wmk 287\n"
    STEP: limiting log lines 11/26/22 12:31:04.354
    Nov 26 12:31:04.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator --tail=1'
    Nov 26 12:31:04.495: INFO: stderr: ""
    Nov 26 12:31:04.495: INFO: stdout: "I1126 12:31:04.335187       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/76lm 328\n"
    Nov 26 12:31:04.495: INFO: got output "I1126 12:31:04.335187       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/76lm 328\n"
    STEP: limiting log bytes 11/26/22 12:31:04.495
    Nov 26 12:31:04.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator --limit-bytes=1'
    Nov 26 12:31:04.668: INFO: stderr: ""
    Nov 26 12:31:04.668: INFO: stdout: "I"
    Nov 26 12:31:04.668: INFO: got output "I"
    STEP: exposing timestamps 11/26/22 12:31:04.668
    Nov 26 12:31:04.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator --tail=1 --timestamps'
    Nov 26 12:31:04.845: INFO: stderr: ""
    Nov 26 12:31:04.845: INFO: stdout: "2022-11-26T12:31:04.735025807Z I1126 12:31:04.734791       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/h4n 285\n"
    Nov 26 12:31:04.845: INFO: got output "2022-11-26T12:31:04.735025807Z I1126 12:31:04.734791       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/h4n 285\n"
    STEP: restricting to a time range 11/26/22 12:31:04.845
    Nov 26 12:31:07.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator --since=1s'
    Nov 26 12:31:07.492: INFO: stderr: ""
    Nov 26 12:31:07.492: INFO: stdout: "I1126 12:31:06.534191       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/cnt 579\nI1126 12:31:06.734487       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/5slz 509\nI1126 12:31:06.934860       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/7cvv 430\nI1126 12:31:07.134163       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/f5t 497\nI1126 12:31:07.334470       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/882 279\n"
    Nov 26 12:31:07.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 logs logs-generator logs-generator --since=24h'
    Nov 26 12:31:07.614: INFO: stderr: ""
    Nov 26 12:31:07.614: INFO: stdout: "I1126 12:31:03.134095       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/q6nt 293\nI1126 12:31:03.334446       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/2pj 525\nI1126 12:31:03.534856       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/s26t 355\nI1126 12:31:03.734195       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/p28 323\nI1126 12:31:03.934533       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/xzt 478\nI1126 12:31:04.134854       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/wmk 287\nI1126 12:31:04.335187       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/76lm 328\nI1126 12:31:04.534555       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/zvr 495\nI1126 12:31:04.734791       1 logs_generator.go:76] 8 POST /api/v1/namespaces/ns/pods/h4n 285\nI1126 12:31:04.934216       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/grw 539\nI1126 12:31:05.134572       1 logs_generator.go:76] 10 GET /api/v1/namespaces/ns/pods/5cxw 257\nI1126 12:31:05.335003       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/b9mn 492\nI1126 12:31:05.534210       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/hwn5 576\nI1126 12:31:05.734793       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/795d 310\nI1126 12:31:05.935171       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/hnfb 523\nI1126 12:31:06.134472       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/kkp8 511\nI1126 12:31:06.334869       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/s2s 405\nI1126 12:31:06.534191       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/cnt 579\nI1126 12:31:06.734487       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/5slz 509\nI1126 12:31:06.934860       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/7cvv 430\nI1126 12:31:07.134163       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/f5t 497\nI1126 12:31:07.334470       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/882 279\nI1126 12:31:07.534816       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/bb8 377\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Nov 26 12:31:07.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1709 delete pod logs-generator'
    Nov 26 12:31:08.989: INFO: stderr: ""
    Nov 26 12:31:08.989: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:31:08.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1709" for this suite. 11/26/22 12:31:08.995
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:31:09.007
Nov 26 12:31:09.007: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sysctl 11/26/22 12:31:09.01
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:31:09.046
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:31:09.052
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 11/26/22 12:31:09.063
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 26 12:31:09.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-1632" for this suite. 11/26/22 12:31:09.082
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":162,"skipped":2916,"failed":0}
------------------------------
â€¢ [0.086 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:31:09.007
    Nov 26 12:31:09.007: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sysctl 11/26/22 12:31:09.01
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:31:09.046
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:31:09.052
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 11/26/22 12:31:09.063
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 26 12:31:09.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-1632" for this suite. 11/26/22 12:31:09.082
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:31:09.094
Nov 26 12:31:09.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename runtimeclass 11/26/22 12:31:09.095
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:31:09.124
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:31:09.137
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Nov 26 12:31:09.165: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4869 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 26 12:31:09.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-4869" for this suite. 11/26/22 12:31:09.201
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":163,"skipped":2949,"failed":0}
------------------------------
â€¢ [0.119 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:31:09.094
    Nov 26 12:31:09.094: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename runtimeclass 11/26/22 12:31:09.095
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:31:09.124
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:31:09.137
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Nov 26 12:31:09.165: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-4869 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 26 12:31:09.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-4869" for this suite. 11/26/22 12:31:09.201
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:31:09.216
Nov 26 12:31:09.216: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 12:31:09.218
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:31:09.241
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:31:09.252
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 11/26/22 12:31:09.26
Nov 26 12:31:09.276: INFO: Waiting up to 5m0s for pod "downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87" in namespace "downward-api-8046" to be "Succeeded or Failed"
Nov 26 12:31:09.284: INFO: Pod "downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87": Phase="Pending", Reason="", readiness=false. Elapsed: 8.133177ms
Nov 26 12:31:11.291: INFO: Pod "downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014744632s
Nov 26 12:31:13.291: INFO: Pod "downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015149713s
STEP: Saw pod success 11/26/22 12:31:13.291
Nov 26 12:31:13.291: INFO: Pod "downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87" satisfied condition "Succeeded or Failed"
Nov 26 12:31:13.296: INFO: Trying to get logs from node ip-172-31-43-82 pod downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87 container dapi-container: <nil>
STEP: delete the pod 11/26/22 12:31:13.306
Nov 26 12:31:13.327: INFO: Waiting for pod downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87 to disappear
Nov 26 12:31:13.332: INFO: Pod downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 26 12:31:13.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8046" for this suite. 11/26/22 12:31:13.339
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":164,"skipped":2964,"failed":0}
------------------------------
â€¢ [4.134 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:31:09.216
    Nov 26 12:31:09.216: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 12:31:09.218
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:31:09.241
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:31:09.252
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 11/26/22 12:31:09.26
    Nov 26 12:31:09.276: INFO: Waiting up to 5m0s for pod "downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87" in namespace "downward-api-8046" to be "Succeeded or Failed"
    Nov 26 12:31:09.284: INFO: Pod "downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87": Phase="Pending", Reason="", readiness=false. Elapsed: 8.133177ms
    Nov 26 12:31:11.291: INFO: Pod "downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014744632s
    Nov 26 12:31:13.291: INFO: Pod "downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015149713s
    STEP: Saw pod success 11/26/22 12:31:13.291
    Nov 26 12:31:13.291: INFO: Pod "downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87" satisfied condition "Succeeded or Failed"
    Nov 26 12:31:13.296: INFO: Trying to get logs from node ip-172-31-43-82 pod downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87 container dapi-container: <nil>
    STEP: delete the pod 11/26/22 12:31:13.306
    Nov 26 12:31:13.327: INFO: Waiting for pod downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87 to disappear
    Nov 26 12:31:13.332: INFO: Pod downward-api-9d0d825d-fd22-446d-a00a-8e96cc0bbd87 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 26 12:31:13.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8046" for this suite. 11/26/22 12:31:13.339
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:31:13.355
Nov 26 12:31:13.355: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename statefulset 11/26/22 12:31:13.357
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:31:13.391
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:31:13.403
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1678 11/26/22 12:31:13.419
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 11/26/22 12:31:13.438
STEP: Creating stateful set ss in namespace statefulset-1678 11/26/22 12:31:13.471
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1678 11/26/22 12:31:13.5
Nov 26 12:31:13.555: INFO: Found 0 stateful pods, waiting for 1
Nov 26 12:31:23.565: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 11/26/22 12:31:23.565
Nov 26 12:31:23.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 26 12:31:23.836: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 26 12:31:23.836: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 26 12:31:23.836: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 26 12:31:23.842: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 26 12:31:33.849: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 26 12:31:33.849: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 12:31:33.880: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999963s
Nov 26 12:31:34.887: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988093768s
Nov 26 12:31:35.898: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.980534867s
Nov 26 12:31:36.904: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.970648817s
Nov 26 12:31:37.912: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.963865062s
Nov 26 12:31:38.918: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.956503613s
Nov 26 12:31:39.926: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.949254851s
Nov 26 12:31:40.933: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.942614048s
Nov 26 12:31:41.940: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.9349245s
Nov 26 12:31:42.947: INFO: Verifying statefulset ss doesn't scale past 1 for another 927.915441ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1678 11/26/22 12:31:43.947
Nov 26 12:31:43.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 26 12:31:44.156: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 26 12:31:44.156: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 26 12:31:44.156: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 26 12:31:44.163: INFO: Found 1 stateful pods, waiting for 3
Nov 26 12:31:54.171: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 12:31:54.171: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 12:31:54.171: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 11/26/22 12:31:54.171
STEP: Scale down will halt with unhealthy stateful pod 11/26/22 12:31:54.171
Nov 26 12:31:54.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 26 12:31:54.398: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 26 12:31:54.399: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 26 12:31:54.399: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 26 12:31:54.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 26 12:31:54.596: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 26 12:31:54.596: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 26 12:31:54.597: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 26 12:31:54.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 26 12:31:54.796: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 26 12:31:54.796: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 26 12:31:54.796: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 26 12:31:54.796: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 12:31:54.802: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov 26 12:32:04.816: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 26 12:32:04.816: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 26 12:32:04.816: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 26 12:32:04.850: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999969s
Nov 26 12:32:05.857: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.984267954s
Nov 26 12:32:06.864: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978500898s
Nov 26 12:32:07.871: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.970792571s
Nov 26 12:32:08.878: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.963529129s
Nov 26 12:32:09.885: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.957693991s
Nov 26 12:32:10.892: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.949282209s
Nov 26 12:32:11.898: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.942914723s
Nov 26 12:32:12.907: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.936215397s
Nov 26 12:32:13.914: INFO: Verifying statefulset ss doesn't scale past 3 for another 928.573788ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1678 11/26/22 12:32:14.915
Nov 26 12:32:14.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 26 12:32:15.164: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 26 12:32:15.164: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 26 12:32:15.164: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 26 12:32:15.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 26 12:32:15.353: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 26 12:32:15.353: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 26 12:32:15.353: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 26 12:32:15.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 26 12:32:15.531: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 26 12:32:15.531: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 26 12:32:15.531: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 26 12:32:15.531: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 11/26/22 12:32:25.555
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 26 12:32:25.556: INFO: Deleting all statefulset in ns statefulset-1678
Nov 26 12:32:25.562: INFO: Scaling statefulset ss to 0
Nov 26 12:32:25.581: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 12:32:25.587: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 26 12:32:25.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1678" for this suite. 11/26/22 12:32:25.64
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":165,"skipped":2982,"failed":0}
------------------------------
â€¢ [SLOW TEST] [72.311 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:31:13.355
    Nov 26 12:31:13.355: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename statefulset 11/26/22 12:31:13.357
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:31:13.391
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:31:13.403
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1678 11/26/22 12:31:13.419
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 11/26/22 12:31:13.438
    STEP: Creating stateful set ss in namespace statefulset-1678 11/26/22 12:31:13.471
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1678 11/26/22 12:31:13.5
    Nov 26 12:31:13.555: INFO: Found 0 stateful pods, waiting for 1
    Nov 26 12:31:23.565: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 11/26/22 12:31:23.565
    Nov 26 12:31:23.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 26 12:31:23.836: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 26 12:31:23.836: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 26 12:31:23.836: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 26 12:31:23.842: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Nov 26 12:31:33.849: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 26 12:31:33.849: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 12:31:33.880: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999963s
    Nov 26 12:31:34.887: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.988093768s
    Nov 26 12:31:35.898: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.980534867s
    Nov 26 12:31:36.904: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.970648817s
    Nov 26 12:31:37.912: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.963865062s
    Nov 26 12:31:38.918: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.956503613s
    Nov 26 12:31:39.926: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.949254851s
    Nov 26 12:31:40.933: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.942614048s
    Nov 26 12:31:41.940: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.9349245s
    Nov 26 12:31:42.947: INFO: Verifying statefulset ss doesn't scale past 1 for another 927.915441ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1678 11/26/22 12:31:43.947
    Nov 26 12:31:43.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 26 12:31:44.156: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 26 12:31:44.156: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 26 12:31:44.156: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 26 12:31:44.163: INFO: Found 1 stateful pods, waiting for 3
    Nov 26 12:31:54.171: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 12:31:54.171: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 12:31:54.171: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 11/26/22 12:31:54.171
    STEP: Scale down will halt with unhealthy stateful pod 11/26/22 12:31:54.171
    Nov 26 12:31:54.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 26 12:31:54.398: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 26 12:31:54.399: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 26 12:31:54.399: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 26 12:31:54.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 26 12:31:54.596: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 26 12:31:54.596: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 26 12:31:54.597: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 26 12:31:54.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 26 12:31:54.796: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 26 12:31:54.796: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 26 12:31:54.796: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 26 12:31:54.796: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 12:31:54.802: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Nov 26 12:32:04.816: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 26 12:32:04.816: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Nov 26 12:32:04.816: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Nov 26 12:32:04.850: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999969s
    Nov 26 12:32:05.857: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.984267954s
    Nov 26 12:32:06.864: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978500898s
    Nov 26 12:32:07.871: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.970792571s
    Nov 26 12:32:08.878: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.963529129s
    Nov 26 12:32:09.885: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.957693991s
    Nov 26 12:32:10.892: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.949282209s
    Nov 26 12:32:11.898: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.942914723s
    Nov 26 12:32:12.907: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.936215397s
    Nov 26 12:32:13.914: INFO: Verifying statefulset ss doesn't scale past 3 for another 928.573788ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1678 11/26/22 12:32:14.915
    Nov 26 12:32:14.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 26 12:32:15.164: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 26 12:32:15.164: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 26 12:32:15.164: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 26 12:32:15.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 26 12:32:15.353: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 26 12:32:15.353: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 26 12:32:15.353: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 26 12:32:15.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-1678 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 26 12:32:15.531: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 26 12:32:15.531: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 26 12:32:15.531: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 26 12:32:15.531: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 11/26/22 12:32:25.555
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 26 12:32:25.556: INFO: Deleting all statefulset in ns statefulset-1678
    Nov 26 12:32:25.562: INFO: Scaling statefulset ss to 0
    Nov 26 12:32:25.581: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 12:32:25.587: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 26 12:32:25.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1678" for this suite. 11/26/22 12:32:25.64
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:32:25.668
Nov 26 12:32:25.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:32:25.669
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:32:25.694
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:32:25.701
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 11/26/22 12:32:25.706
Nov 26 12:32:25.818: INFO: Waiting up to 5m0s for pod "pod-03f77414-6fbf-40e1-9088-776a0a91e968" in namespace "emptydir-8382" to be "Succeeded or Failed"
Nov 26 12:32:25.824: INFO: Pod "pod-03f77414-6fbf-40e1-9088-776a0a91e968": Phase="Pending", Reason="", readiness=false. Elapsed: 6.772412ms
Nov 26 12:32:27.830: INFO: Pod "pod-03f77414-6fbf-40e1-9088-776a0a91e968": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01260646s
Nov 26 12:32:29.830: INFO: Pod "pod-03f77414-6fbf-40e1-9088-776a0a91e968": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01264964s
STEP: Saw pod success 11/26/22 12:32:29.83
Nov 26 12:32:29.831: INFO: Pod "pod-03f77414-6fbf-40e1-9088-776a0a91e968" satisfied condition "Succeeded or Failed"
Nov 26 12:32:29.836: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-03f77414-6fbf-40e1-9088-776a0a91e968 container test-container: <nil>
STEP: delete the pod 11/26/22 12:32:29.846
Nov 26 12:32:29.866: INFO: Waiting for pod pod-03f77414-6fbf-40e1-9088-776a0a91e968 to disappear
Nov 26 12:32:29.872: INFO: Pod pod-03f77414-6fbf-40e1-9088-776a0a91e968 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:32:29.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8382" for this suite. 11/26/22 12:32:29.878
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":166,"skipped":2999,"failed":0}
------------------------------
â€¢ [4.227 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:32:25.668
    Nov 26 12:32:25.669: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:32:25.669
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:32:25.694
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:32:25.701
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 11/26/22 12:32:25.706
    Nov 26 12:32:25.818: INFO: Waiting up to 5m0s for pod "pod-03f77414-6fbf-40e1-9088-776a0a91e968" in namespace "emptydir-8382" to be "Succeeded or Failed"
    Nov 26 12:32:25.824: INFO: Pod "pod-03f77414-6fbf-40e1-9088-776a0a91e968": Phase="Pending", Reason="", readiness=false. Elapsed: 6.772412ms
    Nov 26 12:32:27.830: INFO: Pod "pod-03f77414-6fbf-40e1-9088-776a0a91e968": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01260646s
    Nov 26 12:32:29.830: INFO: Pod "pod-03f77414-6fbf-40e1-9088-776a0a91e968": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01264964s
    STEP: Saw pod success 11/26/22 12:32:29.83
    Nov 26 12:32:29.831: INFO: Pod "pod-03f77414-6fbf-40e1-9088-776a0a91e968" satisfied condition "Succeeded or Failed"
    Nov 26 12:32:29.836: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-03f77414-6fbf-40e1-9088-776a0a91e968 container test-container: <nil>
    STEP: delete the pod 11/26/22 12:32:29.846
    Nov 26 12:32:29.866: INFO: Waiting for pod pod-03f77414-6fbf-40e1-9088-776a0a91e968 to disappear
    Nov 26 12:32:29.872: INFO: Pod pod-03f77414-6fbf-40e1-9088-776a0a91e968 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:32:29.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8382" for this suite. 11/26/22 12:32:29.878
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:32:29.898
Nov 26 12:32:29.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pod-network-test 11/26/22 12:32:29.899
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:32:29.932
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:32:29.938
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-4499 11/26/22 12:32:29.945
STEP: creating a selector 11/26/22 12:32:29.945
STEP: Creating the service pods in kubernetes 11/26/22 12:32:29.945
Nov 26 12:32:29.946: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov 26 12:32:30.009: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4499" to be "running and ready"
Nov 26 12:32:30.016: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.969807ms
Nov 26 12:32:30.016: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:32:32.028: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.018440786s
Nov 26 12:32:32.028: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:32:34.022: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.01318762s
Nov 26 12:32:34.023: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:32:36.027: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.01819663s
Nov 26 12:32:36.028: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:32:38.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014396742s
Nov 26 12:32:38.024: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:32:40.023: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.014222589s
Nov 26 12:32:40.024: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov 26 12:32:42.029: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.019531498s
Nov 26 12:32:42.029: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov 26 12:32:42.029: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov 26 12:32:42.035: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4499" to be "running and ready"
Nov 26 12:32:42.040: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 5.257293ms
Nov 26 12:32:42.040: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov 26 12:32:44.054: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.019316017s
Nov 26 12:32:44.054: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov 26 12:32:46.050: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.014908522s
Nov 26 12:32:46.050: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov 26 12:32:48.049: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.013517741s
Nov 26 12:32:48.049: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov 26 12:32:50.050: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.015481641s
Nov 26 12:32:50.051: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov 26 12:32:52.049: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.013651068s
Nov 26 12:32:52.049: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov 26 12:32:52.049: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov 26 12:32:52.056: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4499" to be "running and ready"
Nov 26 12:32:52.061: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.948177ms
Nov 26 12:32:52.061: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov 26 12:32:52.061: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/26/22 12:32:52.066
Nov 26 12:32:52.080: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4499" to be "running"
Nov 26 12:32:52.088: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.785933ms
Nov 26 12:32:54.096: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015479572s
Nov 26 12:32:54.096: INFO: Pod "test-container-pod" satisfied condition "running"
Nov 26 12:32:54.100: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov 26 12:32:54.100: INFO: Breadth first check of 192.168.150.136 on host 172.31.0.249...
Nov 26 12:32:54.106: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.4:9080/dial?request=hostname&protocol=http&host=192.168.150.136&port=8083&tries=1'] Namespace:pod-network-test-4499 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:32:54.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:32:54.107: INFO: ExecWithOptions: Clientset creation
Nov 26 12:32:54.107: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4499/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.4%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.150.136%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 26 12:32:54.196: INFO: Waiting for responses: map[]
Nov 26 12:32:54.196: INFO: reached 192.168.150.136 after 0/1 tries
Nov 26 12:32:54.196: INFO: Breadth first check of 192.168.46.221 on host 172.31.29.104...
Nov 26 12:32:54.203: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.4:9080/dial?request=hostname&protocol=http&host=192.168.46.221&port=8083&tries=1'] Namespace:pod-network-test-4499 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:32:54.203: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:32:54.204: INFO: ExecWithOptions: Clientset creation
Nov 26 12:32:54.205: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4499/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.4%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.46.221%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 26 12:32:54.293: INFO: Waiting for responses: map[]
Nov 26 12:32:54.294: INFO: reached 192.168.46.221 after 0/1 tries
Nov 26 12:32:54.294: INFO: Breadth first check of 192.168.34.1 on host 172.31.43.82...
Nov 26 12:32:54.299: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.4:9080/dial?request=hostname&protocol=http&host=192.168.34.1&port=8083&tries=1'] Namespace:pod-network-test-4499 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:32:54.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:32:54.300: INFO: ExecWithOptions: Clientset creation
Nov 26 12:32:54.300: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4499/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.4%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.34.1%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov 26 12:32:54.389: INFO: Waiting for responses: map[]
Nov 26 12:32:54.389: INFO: reached 192.168.34.1 after 0/1 tries
Nov 26 12:32:54.389: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov 26 12:32:54.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4499" for this suite. 11/26/22 12:32:54.397
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":167,"skipped":3011,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.510 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:32:29.898
    Nov 26 12:32:29.898: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pod-network-test 11/26/22 12:32:29.899
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:32:29.932
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:32:29.938
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-4499 11/26/22 12:32:29.945
    STEP: creating a selector 11/26/22 12:32:29.945
    STEP: Creating the service pods in kubernetes 11/26/22 12:32:29.945
    Nov 26 12:32:29.946: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov 26 12:32:30.009: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-4499" to be "running and ready"
    Nov 26 12:32:30.016: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.969807ms
    Nov 26 12:32:30.016: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:32:32.028: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.018440786s
    Nov 26 12:32:32.028: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:32:34.022: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.01318762s
    Nov 26 12:32:34.023: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:32:36.027: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.01819663s
    Nov 26 12:32:36.028: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:32:38.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.014396742s
    Nov 26 12:32:38.024: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:32:40.023: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.014222589s
    Nov 26 12:32:40.024: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov 26 12:32:42.029: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.019531498s
    Nov 26 12:32:42.029: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov 26 12:32:42.029: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov 26 12:32:42.035: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-4499" to be "running and ready"
    Nov 26 12:32:42.040: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 5.257293ms
    Nov 26 12:32:42.040: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov 26 12:32:44.054: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.019316017s
    Nov 26 12:32:44.054: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov 26 12:32:46.050: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.014908522s
    Nov 26 12:32:46.050: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov 26 12:32:48.049: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.013517741s
    Nov 26 12:32:48.049: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov 26 12:32:50.050: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.015481641s
    Nov 26 12:32:50.051: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov 26 12:32:52.049: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.013651068s
    Nov 26 12:32:52.049: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov 26 12:32:52.049: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov 26 12:32:52.056: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-4499" to be "running and ready"
    Nov 26 12:32:52.061: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.948177ms
    Nov 26 12:32:52.061: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov 26 12:32:52.061: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/26/22 12:32:52.066
    Nov 26 12:32:52.080: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-4499" to be "running"
    Nov 26 12:32:52.088: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.785933ms
    Nov 26 12:32:54.096: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015479572s
    Nov 26 12:32:54.096: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov 26 12:32:54.100: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov 26 12:32:54.100: INFO: Breadth first check of 192.168.150.136 on host 172.31.0.249...
    Nov 26 12:32:54.106: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.4:9080/dial?request=hostname&protocol=http&host=192.168.150.136&port=8083&tries=1'] Namespace:pod-network-test-4499 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:32:54.106: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:32:54.107: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:32:54.107: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4499/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.4%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.150.136%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 26 12:32:54.196: INFO: Waiting for responses: map[]
    Nov 26 12:32:54.196: INFO: reached 192.168.150.136 after 0/1 tries
    Nov 26 12:32:54.196: INFO: Breadth first check of 192.168.46.221 on host 172.31.29.104...
    Nov 26 12:32:54.203: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.4:9080/dial?request=hostname&protocol=http&host=192.168.46.221&port=8083&tries=1'] Namespace:pod-network-test-4499 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:32:54.203: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:32:54.204: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:32:54.205: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4499/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.4%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.46.221%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 26 12:32:54.293: INFO: Waiting for responses: map[]
    Nov 26 12:32:54.294: INFO: reached 192.168.46.221 after 0/1 tries
    Nov 26 12:32:54.294: INFO: Breadth first check of 192.168.34.1 on host 172.31.43.82...
    Nov 26 12:32:54.299: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.34.4:9080/dial?request=hostname&protocol=http&host=192.168.34.1&port=8083&tries=1'] Namespace:pod-network-test-4499 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:32:54.300: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:32:54.300: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:32:54.300: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-4499/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.34.4%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.34.1%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov 26 12:32:54.389: INFO: Waiting for responses: map[]
    Nov 26 12:32:54.389: INFO: reached 192.168.34.1 after 0/1 tries
    Nov 26 12:32:54.389: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov 26 12:32:54.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-4499" for this suite. 11/26/22 12:32:54.397
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:32:54.41
Nov 26 12:32:54.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:32:54.413
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:32:54.439
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:32:54.446
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-7751 11/26/22 12:32:54.451
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7751 to expose endpoints map[] 11/26/22 12:32:54.468
Nov 26 12:32:54.477: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Nov 26 12:32:55.491: INFO: successfully validated that service multi-endpoint-test in namespace services-7751 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-7751 11/26/22 12:32:55.491
Nov 26 12:32:55.506: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-7751" to be "running and ready"
Nov 26 12:32:55.515: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.579369ms
Nov 26 12:32:55.515: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:32:57.525: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019708707s
Nov 26 12:32:57.525: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 26 12:32:57.525: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7751 to expose endpoints map[pod1:[100]] 11/26/22 12:32:57.53
Nov 26 12:32:57.550: INFO: successfully validated that service multi-endpoint-test in namespace services-7751 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-7751 11/26/22 12:32:57.55
Nov 26 12:32:57.562: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-7751" to be "running and ready"
Nov 26 12:32:57.572: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.220131ms
Nov 26 12:32:57.572: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:32:59.579: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016950797s
Nov 26 12:32:59.579: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:33:01.582: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.020147417s
Nov 26 12:33:01.582: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 26 12:33:01.582: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7751 to expose endpoints map[pod1:[100] pod2:[101]] 11/26/22 12:33:01.588
Nov 26 12:33:01.614: INFO: successfully validated that service multi-endpoint-test in namespace services-7751 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 11/26/22 12:33:01.614
Nov 26 12:33:01.614: INFO: Creating new exec pod
Nov 26 12:33:01.624: INFO: Waiting up to 5m0s for pod "execpodjj6dz" in namespace "services-7751" to be "running"
Nov 26 12:33:01.630: INFO: Pod "execpodjj6dz": Phase="Pending", Reason="", readiness=false. Elapsed: 5.973457ms
Nov 26 12:33:03.638: INFO: Pod "execpodjj6dz": Phase="Running", Reason="", readiness=true. Elapsed: 2.014086147s
Nov 26 12:33:03.638: INFO: Pod "execpodjj6dz" satisfied condition "running"
Nov 26 12:33:04.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-7751 exec execpodjj6dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Nov 26 12:33:04.923: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Nov 26 12:33:04.923: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:33:04.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-7751 exec execpodjj6dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.135 80'
Nov 26 12:33:05.147: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.135 80\nConnection to 10.152.183.135 80 port [tcp/http] succeeded!\n"
Nov 26 12:33:05.147: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:33:05.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-7751 exec execpodjj6dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Nov 26 12:33:05.453: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Nov 26 12:33:05.453: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:33:05.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-7751 exec execpodjj6dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.135 81'
Nov 26 12:33:05.673: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.135 81\nConnection to 10.152.183.135 81 port [tcp/*] succeeded!\n"
Nov 26 12:33:05.673: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-7751 11/26/22 12:33:05.673
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7751 to expose endpoints map[pod2:[101]] 11/26/22 12:33:05.701
Nov 26 12:33:05.724: INFO: successfully validated that service multi-endpoint-test in namespace services-7751 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-7751 11/26/22 12:33:05.724
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7751 to expose endpoints map[] 11/26/22 12:33:05.761
Nov 26 12:33:05.786: INFO: successfully validated that service multi-endpoint-test in namespace services-7751 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:33:05.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7751" for this suite. 11/26/22 12:33:05.85
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":168,"skipped":3017,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.451 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:32:54.41
    Nov 26 12:32:54.410: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:32:54.413
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:32:54.439
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:32:54.446
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-7751 11/26/22 12:32:54.451
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7751 to expose endpoints map[] 11/26/22 12:32:54.468
    Nov 26 12:32:54.477: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
    Nov 26 12:32:55.491: INFO: successfully validated that service multi-endpoint-test in namespace services-7751 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-7751 11/26/22 12:32:55.491
    Nov 26 12:32:55.506: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-7751" to be "running and ready"
    Nov 26 12:32:55.515: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.579369ms
    Nov 26 12:32:55.515: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:32:57.525: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.019708707s
    Nov 26 12:32:57.525: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 26 12:32:57.525: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7751 to expose endpoints map[pod1:[100]] 11/26/22 12:32:57.53
    Nov 26 12:32:57.550: INFO: successfully validated that service multi-endpoint-test in namespace services-7751 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-7751 11/26/22 12:32:57.55
    Nov 26 12:32:57.562: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-7751" to be "running and ready"
    Nov 26 12:32:57.572: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.220131ms
    Nov 26 12:32:57.572: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:32:59.579: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016950797s
    Nov 26 12:32:59.579: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:33:01.582: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.020147417s
    Nov 26 12:33:01.582: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 26 12:33:01.582: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7751 to expose endpoints map[pod1:[100] pod2:[101]] 11/26/22 12:33:01.588
    Nov 26 12:33:01.614: INFO: successfully validated that service multi-endpoint-test in namespace services-7751 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 11/26/22 12:33:01.614
    Nov 26 12:33:01.614: INFO: Creating new exec pod
    Nov 26 12:33:01.624: INFO: Waiting up to 5m0s for pod "execpodjj6dz" in namespace "services-7751" to be "running"
    Nov 26 12:33:01.630: INFO: Pod "execpodjj6dz": Phase="Pending", Reason="", readiness=false. Elapsed: 5.973457ms
    Nov 26 12:33:03.638: INFO: Pod "execpodjj6dz": Phase="Running", Reason="", readiness=true. Elapsed: 2.014086147s
    Nov 26 12:33:03.638: INFO: Pod "execpodjj6dz" satisfied condition "running"
    Nov 26 12:33:04.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-7751 exec execpodjj6dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Nov 26 12:33:04.923: INFO: stderr: "+ nc -v -t -w 2 multi-endpoint-test 80\n+ echo hostName\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Nov 26 12:33:04.923: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:33:04.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-7751 exec execpodjj6dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.135 80'
    Nov 26 12:33:05.147: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.135 80\nConnection to 10.152.183.135 80 port [tcp/http] succeeded!\n"
    Nov 26 12:33:05.147: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:33:05.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-7751 exec execpodjj6dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Nov 26 12:33:05.453: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Nov 26 12:33:05.453: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:33:05.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-7751 exec execpodjj6dz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.135 81'
    Nov 26 12:33:05.673: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.135 81\nConnection to 10.152.183.135 81 port [tcp/*] succeeded!\n"
    Nov 26 12:33:05.673: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-7751 11/26/22 12:33:05.673
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7751 to expose endpoints map[pod2:[101]] 11/26/22 12:33:05.701
    Nov 26 12:33:05.724: INFO: successfully validated that service multi-endpoint-test in namespace services-7751 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-7751 11/26/22 12:33:05.724
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7751 to expose endpoints map[] 11/26/22 12:33:05.761
    Nov 26 12:33:05.786: INFO: successfully validated that service multi-endpoint-test in namespace services-7751 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:33:05.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7751" for this suite. 11/26/22 12:33:05.85
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:33:05.867
Nov 26 12:33:05.868: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 12:33:05.869
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:05.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:05.897
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 11/26/22 12:33:05.903
Nov 26 12:33:05.916: INFO: Waiting up to 5m0s for pod "downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046" in namespace "downward-api-2168" to be "Succeeded or Failed"
Nov 26 12:33:05.922: INFO: Pod "downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046": Phase="Pending", Reason="", readiness=false. Elapsed: 6.054849ms
Nov 26 12:33:07.931: INFO: Pod "downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014310671s
Nov 26 12:33:09.937: INFO: Pod "downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02026296s
STEP: Saw pod success 11/26/22 12:33:09.937
Nov 26 12:33:09.937: INFO: Pod "downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046" satisfied condition "Succeeded or Failed"
Nov 26 12:33:09.943: INFO: Trying to get logs from node ip-172-31-43-82 pod downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046 container dapi-container: <nil>
STEP: delete the pod 11/26/22 12:33:09.959
Nov 26 12:33:09.983: INFO: Waiting for pod downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046 to disappear
Nov 26 12:33:09.989: INFO: Pod downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 26 12:33:09.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2168" for this suite. 11/26/22 12:33:09.996
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":169,"skipped":3041,"failed":0}
------------------------------
â€¢ [4.139 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:33:05.867
    Nov 26 12:33:05.868: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 12:33:05.869
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:05.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:05.897
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 11/26/22 12:33:05.903
    Nov 26 12:33:05.916: INFO: Waiting up to 5m0s for pod "downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046" in namespace "downward-api-2168" to be "Succeeded or Failed"
    Nov 26 12:33:05.922: INFO: Pod "downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046": Phase="Pending", Reason="", readiness=false. Elapsed: 6.054849ms
    Nov 26 12:33:07.931: INFO: Pod "downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014310671s
    Nov 26 12:33:09.937: INFO: Pod "downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02026296s
    STEP: Saw pod success 11/26/22 12:33:09.937
    Nov 26 12:33:09.937: INFO: Pod "downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046" satisfied condition "Succeeded or Failed"
    Nov 26 12:33:09.943: INFO: Trying to get logs from node ip-172-31-43-82 pod downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046 container dapi-container: <nil>
    STEP: delete the pod 11/26/22 12:33:09.959
    Nov 26 12:33:09.983: INFO: Waiting for pod downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046 to disappear
    Nov 26 12:33:09.989: INFO: Pod downward-api-3a5c3844-d25e-4a3e-8540-27e4f9c15046 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 26 12:33:09.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2168" for this suite. 11/26/22 12:33:09.996
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:33:10.011
Nov 26 12:33:10.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:33:10.013
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:10.037
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:10.049
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:33:10.074
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:33:10.834
STEP: Deploying the webhook pod 11/26/22 12:33:10.846
STEP: Wait for the deployment to be ready 11/26/22 12:33:10.864
Nov 26 12:33:10.892: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/26/22 12:33:12.91
STEP: Verifying the service has paired with the endpoint 11/26/22 12:33:12.926
Nov 26 12:33:13.928: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Nov 26 12:33:13.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Registering the custom resource webhook via the AdmissionRegistration API 11/26/22 12:33:14.45
STEP: Creating a custom resource that should be denied by the webhook 11/26/22 12:33:14.469
STEP: Creating a custom resource whose deletion would be denied by the webhook 11/26/22 12:33:16.543
STEP: Updating the custom resource with disallowed data should be denied 11/26/22 12:33:16.558
STEP: Deleting the custom resource should be denied 11/26/22 12:33:16.574
STEP: Remove the offending key and value from the custom resource data 11/26/22 12:33:16.585
STEP: Deleting the updated custom resource should be successful 11/26/22 12:33:16.6
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:33:17.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4714" for this suite. 11/26/22 12:33:17.149
STEP: Destroying namespace "webhook-4714-markers" for this suite. 11/26/22 12:33:17.161
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":170,"skipped":3045,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.272 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:33:10.011
    Nov 26 12:33:10.011: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:33:10.013
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:10.037
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:10.049
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:33:10.074
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:33:10.834
    STEP: Deploying the webhook pod 11/26/22 12:33:10.846
    STEP: Wait for the deployment to be ready 11/26/22 12:33:10.864
    Nov 26 12:33:10.892: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/26/22 12:33:12.91
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:33:12.926
    Nov 26 12:33:13.928: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Nov 26 12:33:13.933: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 11/26/22 12:33:14.45
    STEP: Creating a custom resource that should be denied by the webhook 11/26/22 12:33:14.469
    STEP: Creating a custom resource whose deletion would be denied by the webhook 11/26/22 12:33:16.543
    STEP: Updating the custom resource with disallowed data should be denied 11/26/22 12:33:16.558
    STEP: Deleting the custom resource should be denied 11/26/22 12:33:16.574
    STEP: Remove the offending key and value from the custom resource data 11/26/22 12:33:16.585
    STEP: Deleting the updated custom resource should be successful 11/26/22 12:33:16.6
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:33:17.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4714" for this suite. 11/26/22 12:33:17.149
    STEP: Destroying namespace "webhook-4714-markers" for this suite. 11/26/22 12:33:17.161
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:33:17.283
Nov 26 12:33:17.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:33:17.284
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:17.325
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:17.352
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 11/26/22 12:33:17.368
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:33:17.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7330" for this suite. 11/26/22 12:33:17.385
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":171,"skipped":3045,"failed":0}
------------------------------
â€¢ [0.122 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:33:17.283
    Nov 26 12:33:17.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:33:17.284
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:17.325
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:17.352
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 11/26/22 12:33:17.368
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:33:17.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7330" for this suite. 11/26/22 12:33:17.385
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:33:17.413
Nov 26 12:33:17.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename disruption 11/26/22 12:33:17.414
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:17.462
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:17.469
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 11/26/22 12:33:17.483
STEP: Waiting for all pods to be running 11/26/22 12:33:19.533
Nov 26 12:33:19.544: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 26 12:33:21.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2906" for this suite. 11/26/22 12:33:21.564
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":172,"skipped":3106,"failed":0}
------------------------------
â€¢ [4.162 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:33:17.413
    Nov 26 12:33:17.413: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename disruption 11/26/22 12:33:17.414
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:17.462
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:17.469
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 11/26/22 12:33:17.483
    STEP: Waiting for all pods to be running 11/26/22 12:33:19.533
    Nov 26 12:33:19.544: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 26 12:33:21.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2906" for this suite. 11/26/22 12:33:21.564
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:33:21.579
Nov 26 12:33:21.579: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename statefulset 11/26/22 12:33:21.58
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:21.603
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:21.611
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9399 11/26/22 12:33:21.618
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-9399 11/26/22 12:33:21.64
Nov 26 12:33:21.660: INFO: Found 0 stateful pods, waiting for 1
Nov 26 12:33:31.669: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 11/26/22 12:33:31.682
STEP: Getting /status 11/26/22 12:33:31.692
Nov 26 12:33:31.699: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 11/26/22 12:33:31.699
Nov 26 12:33:31.713: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 11/26/22 12:33:31.713
Nov 26 12:33:31.718: INFO: Observed &StatefulSet event: ADDED
Nov 26 12:33:31.718: INFO: Found Statefulset ss in namespace statefulset-9399 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 26 12:33:31.718: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 11/26/22 12:33:31.718
Nov 26 12:33:31.718: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov 26 12:33:31.730: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 11/26/22 12:33:31.73
Nov 26 12:33:31.733: INFO: Observed &StatefulSet event: ADDED
Nov 26 12:33:31.733: INFO: Observed Statefulset ss in namespace statefulset-9399 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov 26 12:33:31.734: INFO: Observed &StatefulSet event: MODIFIED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 26 12:33:31.734: INFO: Deleting all statefulset in ns statefulset-9399
Nov 26 12:33:31.740: INFO: Scaling statefulset ss to 0
Nov 26 12:33:41.773: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 12:33:41.779: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 26 12:33:41.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9399" for this suite. 11/26/22 12:33:41.822
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":173,"skipped":3124,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.256 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:33:21.579
    Nov 26 12:33:21.579: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename statefulset 11/26/22 12:33:21.58
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:21.603
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:21.611
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9399 11/26/22 12:33:21.618
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-9399 11/26/22 12:33:21.64
    Nov 26 12:33:21.660: INFO: Found 0 stateful pods, waiting for 1
    Nov 26 12:33:31.669: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 11/26/22 12:33:31.682
    STEP: Getting /status 11/26/22 12:33:31.692
    Nov 26 12:33:31.699: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 11/26/22 12:33:31.699
    Nov 26 12:33:31.713: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 11/26/22 12:33:31.713
    Nov 26 12:33:31.718: INFO: Observed &StatefulSet event: ADDED
    Nov 26 12:33:31.718: INFO: Found Statefulset ss in namespace statefulset-9399 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 26 12:33:31.718: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 11/26/22 12:33:31.718
    Nov 26 12:33:31.718: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov 26 12:33:31.730: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 11/26/22 12:33:31.73
    Nov 26 12:33:31.733: INFO: Observed &StatefulSet event: ADDED
    Nov 26 12:33:31.733: INFO: Observed Statefulset ss in namespace statefulset-9399 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov 26 12:33:31.734: INFO: Observed &StatefulSet event: MODIFIED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 26 12:33:31.734: INFO: Deleting all statefulset in ns statefulset-9399
    Nov 26 12:33:31.740: INFO: Scaling statefulset ss to 0
    Nov 26 12:33:41.773: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 12:33:41.779: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 26 12:33:41.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9399" for this suite. 11/26/22 12:33:41.822
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:33:41.838
Nov 26 12:33:41.839: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename discovery 11/26/22 12:33:41.84
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:41.882
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:41.887
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 11/26/22 12:33:41.895
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Nov 26 12:33:42.211: INFO: Checking APIGroup: apiregistration.k8s.io
Nov 26 12:33:42.213: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Nov 26 12:33:42.213: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Nov 26 12:33:42.213: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Nov 26 12:33:42.213: INFO: Checking APIGroup: apps
Nov 26 12:33:42.215: INFO: PreferredVersion.GroupVersion: apps/v1
Nov 26 12:33:42.215: INFO: Versions found [{apps/v1 v1}]
Nov 26 12:33:42.215: INFO: apps/v1 matches apps/v1
Nov 26 12:33:42.215: INFO: Checking APIGroup: events.k8s.io
Nov 26 12:33:42.217: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Nov 26 12:33:42.217: INFO: Versions found [{events.k8s.io/v1 v1}]
Nov 26 12:33:42.217: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Nov 26 12:33:42.217: INFO: Checking APIGroup: authentication.k8s.io
Nov 26 12:33:42.218: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Nov 26 12:33:42.218: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Nov 26 12:33:42.218: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Nov 26 12:33:42.218: INFO: Checking APIGroup: authorization.k8s.io
Nov 26 12:33:42.220: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Nov 26 12:33:42.220: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Nov 26 12:33:42.220: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Nov 26 12:33:42.220: INFO: Checking APIGroup: autoscaling
Nov 26 12:33:42.222: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Nov 26 12:33:42.222: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Nov 26 12:33:42.222: INFO: autoscaling/v2 matches autoscaling/v2
Nov 26 12:33:42.223: INFO: Checking APIGroup: batch
Nov 26 12:33:42.226: INFO: PreferredVersion.GroupVersion: batch/v1
Nov 26 12:33:42.226: INFO: Versions found [{batch/v1 v1}]
Nov 26 12:33:42.226: INFO: batch/v1 matches batch/v1
Nov 26 12:33:42.226: INFO: Checking APIGroup: certificates.k8s.io
Nov 26 12:33:42.228: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Nov 26 12:33:42.228: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Nov 26 12:33:42.229: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Nov 26 12:33:42.229: INFO: Checking APIGroup: networking.k8s.io
Nov 26 12:33:42.231: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Nov 26 12:33:42.231: INFO: Versions found [{networking.k8s.io/v1 v1}]
Nov 26 12:33:42.231: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Nov 26 12:33:42.231: INFO: Checking APIGroup: policy
Nov 26 12:33:42.233: INFO: PreferredVersion.GroupVersion: policy/v1
Nov 26 12:33:42.233: INFO: Versions found [{policy/v1 v1}]
Nov 26 12:33:42.233: INFO: policy/v1 matches policy/v1
Nov 26 12:33:42.233: INFO: Checking APIGroup: rbac.authorization.k8s.io
Nov 26 12:33:42.237: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Nov 26 12:33:42.237: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Nov 26 12:33:42.237: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Nov 26 12:33:42.237: INFO: Checking APIGroup: storage.k8s.io
Nov 26 12:33:42.239: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Nov 26 12:33:42.239: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Nov 26 12:33:42.239: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Nov 26 12:33:42.239: INFO: Checking APIGroup: admissionregistration.k8s.io
Nov 26 12:33:42.241: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Nov 26 12:33:42.241: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Nov 26 12:33:42.241: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Nov 26 12:33:42.241: INFO: Checking APIGroup: apiextensions.k8s.io
Nov 26 12:33:42.243: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Nov 26 12:33:42.243: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Nov 26 12:33:42.243: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Nov 26 12:33:42.243: INFO: Checking APIGroup: scheduling.k8s.io
Nov 26 12:33:42.245: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Nov 26 12:33:42.245: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Nov 26 12:33:42.245: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Nov 26 12:33:42.245: INFO: Checking APIGroup: coordination.k8s.io
Nov 26 12:33:42.247: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Nov 26 12:33:42.247: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Nov 26 12:33:42.247: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Nov 26 12:33:42.247: INFO: Checking APIGroup: node.k8s.io
Nov 26 12:33:42.249: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Nov 26 12:33:42.249: INFO: Versions found [{node.k8s.io/v1 v1}]
Nov 26 12:33:42.249: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Nov 26 12:33:42.249: INFO: Checking APIGroup: discovery.k8s.io
Nov 26 12:33:42.251: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Nov 26 12:33:42.251: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Nov 26 12:33:42.251: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Nov 26 12:33:42.251: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Nov 26 12:33:42.253: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Nov 26 12:33:42.254: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Nov 26 12:33:42.254: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Nov 26 12:33:42.254: INFO: Checking APIGroup: metrics.k8s.io
Nov 26 12:33:42.256: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Nov 26 12:33:42.256: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Nov 26 12:33:42.256: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Nov 26 12:33:42.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-8128" for this suite. 11/26/22 12:33:42.263
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":174,"skipped":3147,"failed":0}
------------------------------
â€¢ [0.435 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:33:41.838
    Nov 26 12:33:41.839: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename discovery 11/26/22 12:33:41.84
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:41.882
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:41.887
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 11/26/22 12:33:41.895
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Nov 26 12:33:42.211: INFO: Checking APIGroup: apiregistration.k8s.io
    Nov 26 12:33:42.213: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Nov 26 12:33:42.213: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Nov 26 12:33:42.213: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Nov 26 12:33:42.213: INFO: Checking APIGroup: apps
    Nov 26 12:33:42.215: INFO: PreferredVersion.GroupVersion: apps/v1
    Nov 26 12:33:42.215: INFO: Versions found [{apps/v1 v1}]
    Nov 26 12:33:42.215: INFO: apps/v1 matches apps/v1
    Nov 26 12:33:42.215: INFO: Checking APIGroup: events.k8s.io
    Nov 26 12:33:42.217: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Nov 26 12:33:42.217: INFO: Versions found [{events.k8s.io/v1 v1}]
    Nov 26 12:33:42.217: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Nov 26 12:33:42.217: INFO: Checking APIGroup: authentication.k8s.io
    Nov 26 12:33:42.218: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Nov 26 12:33:42.218: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Nov 26 12:33:42.218: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Nov 26 12:33:42.218: INFO: Checking APIGroup: authorization.k8s.io
    Nov 26 12:33:42.220: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Nov 26 12:33:42.220: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Nov 26 12:33:42.220: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Nov 26 12:33:42.220: INFO: Checking APIGroup: autoscaling
    Nov 26 12:33:42.222: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Nov 26 12:33:42.222: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Nov 26 12:33:42.222: INFO: autoscaling/v2 matches autoscaling/v2
    Nov 26 12:33:42.223: INFO: Checking APIGroup: batch
    Nov 26 12:33:42.226: INFO: PreferredVersion.GroupVersion: batch/v1
    Nov 26 12:33:42.226: INFO: Versions found [{batch/v1 v1}]
    Nov 26 12:33:42.226: INFO: batch/v1 matches batch/v1
    Nov 26 12:33:42.226: INFO: Checking APIGroup: certificates.k8s.io
    Nov 26 12:33:42.228: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Nov 26 12:33:42.228: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Nov 26 12:33:42.229: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Nov 26 12:33:42.229: INFO: Checking APIGroup: networking.k8s.io
    Nov 26 12:33:42.231: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Nov 26 12:33:42.231: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Nov 26 12:33:42.231: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Nov 26 12:33:42.231: INFO: Checking APIGroup: policy
    Nov 26 12:33:42.233: INFO: PreferredVersion.GroupVersion: policy/v1
    Nov 26 12:33:42.233: INFO: Versions found [{policy/v1 v1}]
    Nov 26 12:33:42.233: INFO: policy/v1 matches policy/v1
    Nov 26 12:33:42.233: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Nov 26 12:33:42.237: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Nov 26 12:33:42.237: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Nov 26 12:33:42.237: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Nov 26 12:33:42.237: INFO: Checking APIGroup: storage.k8s.io
    Nov 26 12:33:42.239: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Nov 26 12:33:42.239: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Nov 26 12:33:42.239: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Nov 26 12:33:42.239: INFO: Checking APIGroup: admissionregistration.k8s.io
    Nov 26 12:33:42.241: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Nov 26 12:33:42.241: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Nov 26 12:33:42.241: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Nov 26 12:33:42.241: INFO: Checking APIGroup: apiextensions.k8s.io
    Nov 26 12:33:42.243: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Nov 26 12:33:42.243: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Nov 26 12:33:42.243: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Nov 26 12:33:42.243: INFO: Checking APIGroup: scheduling.k8s.io
    Nov 26 12:33:42.245: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Nov 26 12:33:42.245: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Nov 26 12:33:42.245: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Nov 26 12:33:42.245: INFO: Checking APIGroup: coordination.k8s.io
    Nov 26 12:33:42.247: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Nov 26 12:33:42.247: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Nov 26 12:33:42.247: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Nov 26 12:33:42.247: INFO: Checking APIGroup: node.k8s.io
    Nov 26 12:33:42.249: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Nov 26 12:33:42.249: INFO: Versions found [{node.k8s.io/v1 v1}]
    Nov 26 12:33:42.249: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Nov 26 12:33:42.249: INFO: Checking APIGroup: discovery.k8s.io
    Nov 26 12:33:42.251: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Nov 26 12:33:42.251: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Nov 26 12:33:42.251: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Nov 26 12:33:42.251: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Nov 26 12:33:42.253: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Nov 26 12:33:42.254: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Nov 26 12:33:42.254: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Nov 26 12:33:42.254: INFO: Checking APIGroup: metrics.k8s.io
    Nov 26 12:33:42.256: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Nov 26 12:33:42.256: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Nov 26 12:33:42.256: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Nov 26 12:33:42.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-8128" for this suite. 11/26/22 12:33:42.263
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:33:42.276
Nov 26 12:33:42.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:33:42.279
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:42.308
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:42.316
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 11/26/22 12:33:42.322
Nov 26 12:33:42.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 create -f -'
Nov 26 12:33:43.445: INFO: stderr: ""
Nov 26 12:33:43.445: INFO: stdout: "pod/pause created\n"
Nov 26 12:33:43.445: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 26 12:33:43.446: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6524" to be "running and ready"
Nov 26 12:33:43.453: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.512409ms
Nov 26 12:33:43.453: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'ip-172-31-43-82' to be 'Running' but was 'Pending'
Nov 26 12:33:45.461: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.014934213s
Nov 26 12:33:45.461: INFO: Pod "pause" satisfied condition "running and ready"
Nov 26 12:33:45.461: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 11/26/22 12:33:45.461
Nov 26 12:33:45.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 label pods pause testing-label=testing-label-value'
Nov 26 12:33:45.593: INFO: stderr: ""
Nov 26 12:33:45.593: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 11/26/22 12:33:45.593
Nov 26 12:33:45.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 get pod pause -L testing-label'
Nov 26 12:33:45.706: INFO: stderr: ""
Nov 26 12:33:45.706: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 11/26/22 12:33:45.706
Nov 26 12:33:45.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 label pods pause testing-label-'
Nov 26 12:33:45.825: INFO: stderr: ""
Nov 26 12:33:45.825: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 11/26/22 12:33:45.825
Nov 26 12:33:45.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 get pod pause -L testing-label'
Nov 26 12:33:45.942: INFO: stderr: ""
Nov 26 12:33:45.942: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 11/26/22 12:33:45.942
Nov 26 12:33:45.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 delete --grace-period=0 --force -f -'
Nov 26 12:33:46.066: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 26 12:33:46.066: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 26 12:33:46.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 get rc,svc -l name=pause --no-headers'
Nov 26 12:33:46.185: INFO: stderr: "No resources found in kubectl-6524 namespace.\n"
Nov 26 12:33:46.185: INFO: stdout: ""
Nov 26 12:33:46.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 26 12:33:46.275: INFO: stderr: ""
Nov 26 12:33:46.275: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:33:46.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6524" for this suite. 11/26/22 12:33:46.281
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":175,"skipped":3182,"failed":0}
------------------------------
â€¢ [4.016 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:33:42.276
    Nov 26 12:33:42.276: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:33:42.279
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:42.308
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:42.316
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 11/26/22 12:33:42.322
    Nov 26 12:33:42.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 create -f -'
    Nov 26 12:33:43.445: INFO: stderr: ""
    Nov 26 12:33:43.445: INFO: stdout: "pod/pause created\n"
    Nov 26 12:33:43.445: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Nov 26 12:33:43.446: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6524" to be "running and ready"
    Nov 26 12:33:43.453: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.512409ms
    Nov 26 12:33:43.453: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'ip-172-31-43-82' to be 'Running' but was 'Pending'
    Nov 26 12:33:45.461: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.014934213s
    Nov 26 12:33:45.461: INFO: Pod "pause" satisfied condition "running and ready"
    Nov 26 12:33:45.461: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 11/26/22 12:33:45.461
    Nov 26 12:33:45.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 label pods pause testing-label=testing-label-value'
    Nov 26 12:33:45.593: INFO: stderr: ""
    Nov 26 12:33:45.593: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 11/26/22 12:33:45.593
    Nov 26 12:33:45.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 get pod pause -L testing-label'
    Nov 26 12:33:45.706: INFO: stderr: ""
    Nov 26 12:33:45.706: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 11/26/22 12:33:45.706
    Nov 26 12:33:45.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 label pods pause testing-label-'
    Nov 26 12:33:45.825: INFO: stderr: ""
    Nov 26 12:33:45.825: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 11/26/22 12:33:45.825
    Nov 26 12:33:45.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 get pod pause -L testing-label'
    Nov 26 12:33:45.942: INFO: stderr: ""
    Nov 26 12:33:45.942: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 11/26/22 12:33:45.942
    Nov 26 12:33:45.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 delete --grace-period=0 --force -f -'
    Nov 26 12:33:46.066: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 26 12:33:46.066: INFO: stdout: "pod \"pause\" force deleted\n"
    Nov 26 12:33:46.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 get rc,svc -l name=pause --no-headers'
    Nov 26 12:33:46.185: INFO: stderr: "No resources found in kubectl-6524 namespace.\n"
    Nov 26 12:33:46.185: INFO: stdout: ""
    Nov 26 12:33:46.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-6524 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 26 12:33:46.275: INFO: stderr: ""
    Nov 26 12:33:46.275: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:33:46.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6524" for this suite. 11/26/22 12:33:46.281
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:33:46.293
Nov 26 12:33:46.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename watch 11/26/22 12:33:46.294
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:46.312
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:46.319
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 11/26/22 12:33:46.324
STEP: creating a watch on configmaps with label B 11/26/22 12:33:46.326
STEP: creating a watch on configmaps with label A or B 11/26/22 12:33:46.329
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 11/26/22 12:33:46.331
Nov 26 12:33:46.339: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20666 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 12:33:46.339: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20666 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 11/26/22 12:33:46.339
Nov 26 12:33:46.352: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20667 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 12:33:46.352: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20667 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 11/26/22 12:33:46.353
Nov 26 12:33:46.366: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20668 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 12:33:46.366: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20668 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 11/26/22 12:33:46.366
Nov 26 12:33:46.377: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20669 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 12:33:46.377: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20669 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 11/26/22 12:33:46.377
Nov 26 12:33:46.389: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4616  997e7181-cf4f-4622-a7a0-4ecbaf30254f 20670 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 12:33:46.389: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4616  997e7181-cf4f-4622-a7a0-4ecbaf30254f 20670 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 11/26/22 12:33:56.39
Nov 26 12:33:56.402: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4616  997e7181-cf4f-4622-a7a0-4ecbaf30254f 20726 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 12:33:56.402: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4616  997e7181-cf4f-4622-a7a0-4ecbaf30254f 20726 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 26 12:34:06.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4616" for this suite. 11/26/22 12:34:06.41
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":176,"skipped":3193,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.128 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:33:46.293
    Nov 26 12:33:46.293: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename watch 11/26/22 12:33:46.294
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:33:46.312
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:33:46.319
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 11/26/22 12:33:46.324
    STEP: creating a watch on configmaps with label B 11/26/22 12:33:46.326
    STEP: creating a watch on configmaps with label A or B 11/26/22 12:33:46.329
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 11/26/22 12:33:46.331
    Nov 26 12:33:46.339: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20666 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 12:33:46.339: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20666 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 11/26/22 12:33:46.339
    Nov 26 12:33:46.352: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20667 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 12:33:46.352: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20667 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 11/26/22 12:33:46.353
    Nov 26 12:33:46.366: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20668 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 12:33:46.366: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20668 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 11/26/22 12:33:46.366
    Nov 26 12:33:46.377: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20669 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 12:33:46.377: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4616  238aaa50-3e9b-45cc-8881-bb82cb1ed738 20669 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 11/26/22 12:33:46.377
    Nov 26 12:33:46.389: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4616  997e7181-cf4f-4622-a7a0-4ecbaf30254f 20670 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 12:33:46.389: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4616  997e7181-cf4f-4622-a7a0-4ecbaf30254f 20670 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 11/26/22 12:33:56.39
    Nov 26 12:33:56.402: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4616  997e7181-cf4f-4622-a7a0-4ecbaf30254f 20726 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 12:33:56.402: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4616  997e7181-cf4f-4622-a7a0-4ecbaf30254f 20726 0 2022-11-26 12:33:46 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-26 12:33:46 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 26 12:34:06.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4616" for this suite. 11/26/22 12:34:06.41
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:34:06.424
Nov 26 12:34:06.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:34:06.425
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:34:06.451
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:34:06.459
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Nov 26 12:34:06.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 create -f -'
Nov 26 12:34:08.000: INFO: stderr: ""
Nov 26 12:34:08.000: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Nov 26 12:34:08.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 create -f -'
Nov 26 12:34:08.265: INFO: stderr: ""
Nov 26 12:34:08.265: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/26/22 12:34:08.265
Nov 26 12:34:09.273: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 26 12:34:09.273: INFO: Found 0 / 1
Nov 26 12:34:10.271: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 26 12:34:10.271: INFO: Found 1 / 1
Nov 26 12:34:10.271: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 26 12:34:10.277: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 26 12:34:10.277: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 26 12:34:10.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 describe pod agnhost-primary-bqvlx'
Nov 26 12:34:10.418: INFO: stderr: ""
Nov 26 12:34:10.418: INFO: stdout: "Name:             agnhost-primary-bqvlx\nNamespace:        kubectl-173\nPriority:         0\nService Account:  default\nNode:             ip-172-31-43-82/172.31.43.82\nStart Time:       Sat, 26 Nov 2022 12:34:08 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.34.10\nIPs:\n  IP:           192.168.34.10\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://daa989e14fa7cbd202421ff26274d4fdde178053a78c8c7c526ba87064596a6c\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 26 Nov 2022 12:34:09 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xpcnl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-xpcnl:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-173/agnhost-primary-bqvlx to ip-172-31-43-82\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Nov 26 12:34:10.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 describe rc agnhost-primary'
Nov 26 12:34:10.528: INFO: stderr: ""
Nov 26 12:34:10.528: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-173\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-bqvlx\n"
Nov 26 12:34:10.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 describe service agnhost-primary'
Nov 26 12:34:10.649: INFO: stderr: ""
Nov 26 12:34:10.649: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-173\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.164\nIPs:               10.152.183.164\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.34.10:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 26 12:34:10.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 describe node ip-172-31-0-249'
Nov 26 12:34:10.811: INFO: stderr: ""
Nov 26 12:34:10.812: INFO: stdout: "Name:               ip-172-31-0-249\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-0-249\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 26 Nov 2022 11:51:28 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-0-249\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 26 Nov 2022 12:34:07 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 26 Nov 2022 12:32:50 +0000   Sat, 26 Nov 2022 11:52:25 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 26 Nov 2022 12:32:50 +0000   Sat, 26 Nov 2022 11:52:25 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 26 Nov 2022 12:32:50 +0000   Sat, 26 Nov 2022 11:52:25 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 26 Nov 2022 12:32:50 +0000   Sat, 26 Nov 2022 11:54:48 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.0.249\n  Hostname:    ip-172-31-0-249\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8058868Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7956468Ki\n  pods:               110\nSystem Info:\n  Machine ID:                      ec2f71b1e3ffd910340e23042d408f12\n  System UUID:                     ec2f71b1-e3ff-d910-340e-23042d408f12\n  Boot ID:                         66cddcc2-8eac-46fd-9f6e-2602ffa53146\n  Kernel Version:                  5.15.0-1023-aws\n  OS Image:                        Ubuntu 20.04.5 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.5.9\n  Kubelet Version:                 v1.25.4\n  Kube-Proxy Version:              v1.25.4\nNon-terminated Pods:               (8 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  default-http-backend-kubernetes-worker-6546b9855c-4rkhh    10m (0%)      10m (0%)    20Mi (0%)        20Mi (0%)      41m\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-m2kb4           0 (0%)        0 (0%)      0 (0%)           0 (0%)         41m\n  kube-system                      coredns-6bcf44f4cc-q68zx                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     42m\n  kube-system                      kube-state-metrics-74f5d549cc-2xtpf                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\n  kube-system                      metrics-server-v0.5.2-6b48dc6f97-nfgfh                     5m (0%)       100m (5%)   50Mi (0%)        300Mi (3%)     42m\n  kubernetes-dashboard             dashboard-metrics-scraper-85d45476c6-h2vdw                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\n  kubernetes-dashboard             kubernetes-dashboard-7fb574cb-nwk47                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4    0 (0%)        0 (0%)      0 (0%)           0 (0%)         35m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                115m (5%)   110m (5%)\n  memory             140Mi (1%)  490Mi (6%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age                From             Message\n  ----     ------                   ----               ----             -------\n  Normal   Starting                 42m                kube-proxy       \n  Normal   Starting                 41m                kube-proxy       \n  Normal   Starting                 39m                kube-proxy       \n  Normal   Starting                 41m                kube-proxy       \n  Normal   NodeAllocatableEnforced  42m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     42m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientPID\n  Normal   RegisteredNode           42m                node-controller  Node ip-172-31-0-249 event: Registered Node ip-172-31-0-249 in Controller\n  Normal   NodeHasNoDiskPressure    42m (x2 over 42m)  kubelet          Node ip-172-31-0-249 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  42m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  42m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                42m                kubelet          Node ip-172-31-0-249 status is now: NodeReady\n  Normal   NodeNotReady             41m                node-controller  Node ip-172-31-0-249 status is now: NodeNotReady\n  Normal   NodeHasSufficientPID     41m (x4 over 42m)  kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientPID\n  Normal   NodeNotReady             41m                kubelet          Node ip-172-31-0-249 status is now: NodeNotReady\n  Warning  InvalidDiskCapacity      41m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientPID\n  Normal   Starting                 41m                kubelet          Starting kubelet.\n  Normal   NodeAllocatableEnforced  41m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                41m                kubelet          Node ip-172-31-0-249 status is now: NodeReady\n  Normal   NodeHasSufficientPID     41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientPID\n  Warning  InvalidDiskCapacity      41m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 41m                kubelet          Starting kubelet.\n  Normal   NodeNotReady             41m                kubelet          Node ip-172-31-0-249 status is now: NodeNotReady\n  Normal   NodeAllocatableEnforced  41m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                40m                kubelet          Node ip-172-31-0-249 status is now: NodeReady\n  Normal   RegisteredNode           39m                node-controller  Node ip-172-31-0-249 event: Registered Node ip-172-31-0-249 in Controller\n  Normal   NodeHasNoDiskPressure    39m                kubelet          Node ip-172-31-0-249 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 39m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      39m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  39m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     39m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientPID\n  Normal   NodeNotReady             39m                kubelet          Node ip-172-31-0-249 status is now: NodeNotReady\n  Normal   NodeAllocatableEnforced  39m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                39m                kubelet          Node ip-172-31-0-249 status is now: NodeReady\n  Normal   RegisteredNode           37m                node-controller  Node ip-172-31-0-249 event: Registered Node ip-172-31-0-249 in Controller\n"
Nov 26 12:34:10.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 describe namespace kubectl-173'
Nov 26 12:34:10.927: INFO: stderr: ""
Nov 26 12:34:10.927: INFO: stdout: "Name:         kubectl-173\nLabels:       e2e-framework=kubectl\n              e2e-run=96bdeaf3-8155-4385-8ac0-63e14c6369d4\n              kubernetes.io/metadata.name=kubectl-173\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:34:10.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-173" for this suite. 11/26/22 12:34:10.934
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":177,"skipped":3214,"failed":0}
------------------------------
â€¢ [4.519 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:34:06.424
    Nov 26 12:34:06.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:34:06.425
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:34:06.451
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:34:06.459
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Nov 26 12:34:06.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 create -f -'
    Nov 26 12:34:08.000: INFO: stderr: ""
    Nov 26 12:34:08.000: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Nov 26 12:34:08.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 create -f -'
    Nov 26 12:34:08.265: INFO: stderr: ""
    Nov 26 12:34:08.265: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/26/22 12:34:08.265
    Nov 26 12:34:09.273: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 26 12:34:09.273: INFO: Found 0 / 1
    Nov 26 12:34:10.271: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 26 12:34:10.271: INFO: Found 1 / 1
    Nov 26 12:34:10.271: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Nov 26 12:34:10.277: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 26 12:34:10.277: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 26 12:34:10.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 describe pod agnhost-primary-bqvlx'
    Nov 26 12:34:10.418: INFO: stderr: ""
    Nov 26 12:34:10.418: INFO: stdout: "Name:             agnhost-primary-bqvlx\nNamespace:        kubectl-173\nPriority:         0\nService Account:  default\nNode:             ip-172-31-43-82/172.31.43.82\nStart Time:       Sat, 26 Nov 2022 12:34:08 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.34.10\nIPs:\n  IP:           192.168.34.10\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://daa989e14fa7cbd202421ff26274d4fdde178053a78c8c7c526ba87064596a6c\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 26 Nov 2022 12:34:09 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-xpcnl (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-xpcnl:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-173/agnhost-primary-bqvlx to ip-172-31-43-82\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    1s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Nov 26 12:34:10.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 describe rc agnhost-primary'
    Nov 26 12:34:10.528: INFO: stderr: ""
    Nov 26 12:34:10.528: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-173\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-primary-bqvlx\n"
    Nov 26 12:34:10.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 describe service agnhost-primary'
    Nov 26 12:34:10.649: INFO: stderr: ""
    Nov 26 12:34:10.649: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-173\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.164\nIPs:               10.152.183.164\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.34.10:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Nov 26 12:34:10.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 describe node ip-172-31-0-249'
    Nov 26 12:34:10.811: INFO: stderr: ""
    Nov 26 12:34:10.812: INFO: stdout: "Name:               ip-172-31-0-249\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-0-249\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 26 Nov 2022 11:51:28 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-0-249\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 26 Nov 2022 12:34:07 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 26 Nov 2022 12:32:50 +0000   Sat, 26 Nov 2022 11:52:25 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 26 Nov 2022 12:32:50 +0000   Sat, 26 Nov 2022 11:52:25 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 26 Nov 2022 12:32:50 +0000   Sat, 26 Nov 2022 11:52:25 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 26 Nov 2022 12:32:50 +0000   Sat, 26 Nov 2022 11:54:48 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.0.249\n  Hostname:    ip-172-31-0-249\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             8058868Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7956468Ki\n  pods:               110\nSystem Info:\n  Machine ID:                      ec2f71b1e3ffd910340e23042d408f12\n  System UUID:                     ec2f71b1-e3ff-d910-340e-23042d408f12\n  Boot ID:                         66cddcc2-8eac-46fd-9f6e-2602ffa53146\n  Kernel Version:                  5.15.0-1023-aws\n  OS Image:                        Ubuntu 20.04.5 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.5.9\n  Kubelet Version:                 v1.25.4\n  Kube-Proxy Version:              v1.25.4\nNon-terminated Pods:               (8 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  default-http-backend-kubernetes-worker-6546b9855c-4rkhh    10m (0%)      10m (0%)    20Mi (0%)        20Mi (0%)      41m\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-m2kb4           0 (0%)        0 (0%)      0 (0%)           0 (0%)         41m\n  kube-system                      coredns-6bcf44f4cc-q68zx                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (2%)     42m\n  kube-system                      kube-state-metrics-74f5d549cc-2xtpf                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\n  kube-system                      metrics-server-v0.5.2-6b48dc6f97-nfgfh                     5m (0%)       100m (5%)   50Mi (0%)        300Mi (3%)     42m\n  kubernetes-dashboard             dashboard-metrics-scraper-85d45476c6-h2vdw                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\n  kubernetes-dashboard             kubernetes-dashboard-7fb574cb-nwk47                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4    0 (0%)        0 (0%)      0 (0%)           0 (0%)         35m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                115m (5%)   110m (5%)\n  memory             140Mi (1%)  490Mi (6%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age                From             Message\n  ----     ------                   ----               ----             -------\n  Normal   Starting                 42m                kube-proxy       \n  Normal   Starting                 41m                kube-proxy       \n  Normal   Starting                 39m                kube-proxy       \n  Normal   Starting                 41m                kube-proxy       \n  Normal   NodeAllocatableEnforced  42m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeHasSufficientPID     42m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientPID\n  Normal   RegisteredNode           42m                node-controller  Node ip-172-31-0-249 event: Registered Node ip-172-31-0-249 in Controller\n  Normal   NodeHasNoDiskPressure    42m (x2 over 42m)  kubelet          Node ip-172-31-0-249 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientMemory  42m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  42m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                42m                kubelet          Node ip-172-31-0-249 status is now: NodeReady\n  Normal   NodeNotReady             41m                node-controller  Node ip-172-31-0-249 status is now: NodeNotReady\n  Normal   NodeHasSufficientPID     41m (x4 over 42m)  kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientPID\n  Normal   NodeNotReady             41m                kubelet          Node ip-172-31-0-249 status is now: NodeNotReady\n  Warning  InvalidDiskCapacity      41m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientPID\n  Normal   Starting                 41m                kubelet          Starting kubelet.\n  Normal   NodeAllocatableEnforced  41m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                41m                kubelet          Node ip-172-31-0-249 status is now: NodeReady\n  Normal   NodeHasSufficientPID     41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientPID\n  Warning  InvalidDiskCapacity      41m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    41m                kubelet          Node ip-172-31-0-249 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 41m                kubelet          Starting kubelet.\n  Normal   NodeNotReady             41m                kubelet          Node ip-172-31-0-249 status is now: NodeNotReady\n  Normal   NodeAllocatableEnforced  41m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                40m                kubelet          Node ip-172-31-0-249 status is now: NodeReady\n  Normal   RegisteredNode           39m                node-controller  Node ip-172-31-0-249 event: Registered Node ip-172-31-0-249 in Controller\n  Normal   NodeHasNoDiskPressure    39m                kubelet          Node ip-172-31-0-249 status is now: NodeHasNoDiskPressure\n  Normal   Starting                 39m                kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      39m                kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasSufficientMemory  39m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     39m                kubelet          Node ip-172-31-0-249 status is now: NodeHasSufficientPID\n  Normal   NodeNotReady             39m                kubelet          Node ip-172-31-0-249 status is now: NodeNotReady\n  Normal   NodeAllocatableEnforced  39m                kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                39m                kubelet          Node ip-172-31-0-249 status is now: NodeReady\n  Normal   RegisteredNode           37m                node-controller  Node ip-172-31-0-249 event: Registered Node ip-172-31-0-249 in Controller\n"
    Nov 26 12:34:10.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-173 describe namespace kubectl-173'
    Nov 26 12:34:10.927: INFO: stderr: ""
    Nov 26 12:34:10.927: INFO: stdout: "Name:         kubectl-173\nLabels:       e2e-framework=kubectl\n              e2e-run=96bdeaf3-8155-4385-8ac0-63e14c6369d4\n              kubernetes.io/metadata.name=kubectl-173\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:34:10.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-173" for this suite. 11/26/22 12:34:10.934
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:34:10.943
Nov 26 12:34:10.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename dns 11/26/22 12:34:10.945
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:34:10.965
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:34:10.97
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 11/26/22 12:34:10.977
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9563 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9563;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9563 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9563;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9563.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9563.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9563.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9563.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9563.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9563.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9563.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9563.svc;check="$$(dig +notcp +noall +answer +search 141.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.141_udp@PTR;check="$$(dig +tcp +noall +answer +search 141.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.141_tcp@PTR;sleep 1; done
 11/26/22 12:34:11.009
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9563 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9563;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9563 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9563;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9563.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9563.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9563.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9563.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9563.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9563.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9563.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9563.svc;check="$$(dig +notcp +noall +answer +search 141.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.141_udp@PTR;check="$$(dig +tcp +noall +answer +search 141.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.141_tcp@PTR;sleep 1; done
 11/26/22 12:34:11.009
STEP: creating a pod to probe DNS 11/26/22 12:34:11.01
STEP: submitting the pod to kubernetes 11/26/22 12:34:11.01
Nov 26 12:34:11.035: INFO: Waiting up to 15m0s for pod "dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c" in namespace "dns-9563" to be "running"
Nov 26 12:34:11.044: INFO: Pod "dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.873767ms
Nov 26 12:34:13.051: INFO: Pod "dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c": Phase="Running", Reason="", readiness=true. Elapsed: 2.016082671s
Nov 26 12:34:13.051: INFO: Pod "dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c" satisfied condition "running"
STEP: retrieving the pod 11/26/22 12:34:13.051
STEP: looking for the results for each expected name from probers 11/26/22 12:34:13.067
Nov 26 12:34:13.074: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.081: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.087: INFO: Unable to read wheezy_udp@dns-test-service.dns-9563 from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.094: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9563 from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.100: INFO: Unable to read wheezy_udp@dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.106: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.112: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.118: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.150: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.170: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.177: INFO: Unable to read jessie_udp@dns-test-service.dns-9563 from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.184: INFO: Unable to read jessie_tcp@dns-test-service.dns-9563 from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.191: INFO: Unable to read jessie_udp@dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.200: INFO: Unable to read jessie_tcp@dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.209: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.215: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
Nov 26 12:34:13.239: INFO: Lookups using dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9563 wheezy_tcp@dns-test-service.dns-9563 wheezy_udp@dns-test-service.dns-9563.svc wheezy_tcp@dns-test-service.dns-9563.svc wheezy_udp@_http._tcp.dns-test-service.dns-9563.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9563.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9563 jessie_tcp@dns-test-service.dns-9563 jessie_udp@dns-test-service.dns-9563.svc jessie_tcp@dns-test-service.dns-9563.svc jessie_udp@_http._tcp.dns-test-service.dns-9563.svc jessie_tcp@_http._tcp.dns-test-service.dns-9563.svc]

Nov 26 12:34:18.418: INFO: DNS probes using dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c succeeded

STEP: deleting the pod 11/26/22 12:34:18.418
STEP: deleting the test service 11/26/22 12:34:18.471
STEP: deleting the test headless service 11/26/22 12:34:18.581
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 26 12:34:18.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9563" for this suite. 11/26/22 12:34:18.617
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":178,"skipped":3227,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.696 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:34:10.943
    Nov 26 12:34:10.944: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename dns 11/26/22 12:34:10.945
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:34:10.965
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:34:10.97
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 11/26/22 12:34:10.977
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9563 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9563;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9563 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9563;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9563.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9563.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9563.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9563.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9563.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9563.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9563.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9563.svc;check="$$(dig +notcp +noall +answer +search 141.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.141_udp@PTR;check="$$(dig +tcp +noall +answer +search 141.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.141_tcp@PTR;sleep 1; done
     11/26/22 12:34:11.009
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9563 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9563;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9563 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9563;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9563.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9563.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9563.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9563.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9563.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9563.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9563.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9563.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9563.svc;check="$$(dig +notcp +noall +answer +search 141.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.141_udp@PTR;check="$$(dig +tcp +noall +answer +search 141.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.141_tcp@PTR;sleep 1; done
     11/26/22 12:34:11.009
    STEP: creating a pod to probe DNS 11/26/22 12:34:11.01
    STEP: submitting the pod to kubernetes 11/26/22 12:34:11.01
    Nov 26 12:34:11.035: INFO: Waiting up to 15m0s for pod "dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c" in namespace "dns-9563" to be "running"
    Nov 26 12:34:11.044: INFO: Pod "dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.873767ms
    Nov 26 12:34:13.051: INFO: Pod "dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c": Phase="Running", Reason="", readiness=true. Elapsed: 2.016082671s
    Nov 26 12:34:13.051: INFO: Pod "dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c" satisfied condition "running"
    STEP: retrieving the pod 11/26/22 12:34:13.051
    STEP: looking for the results for each expected name from probers 11/26/22 12:34:13.067
    Nov 26 12:34:13.074: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.081: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.087: INFO: Unable to read wheezy_udp@dns-test-service.dns-9563 from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.094: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9563 from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.100: INFO: Unable to read wheezy_udp@dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.106: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.112: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.118: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.150: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.170: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.177: INFO: Unable to read jessie_udp@dns-test-service.dns-9563 from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.184: INFO: Unable to read jessie_tcp@dns-test-service.dns-9563 from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.191: INFO: Unable to read jessie_udp@dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.200: INFO: Unable to read jessie_tcp@dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.209: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.215: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9563.svc from pod dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c: the server could not find the requested resource (get pods dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c)
    Nov 26 12:34:13.239: INFO: Lookups using dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9563 wheezy_tcp@dns-test-service.dns-9563 wheezy_udp@dns-test-service.dns-9563.svc wheezy_tcp@dns-test-service.dns-9563.svc wheezy_udp@_http._tcp.dns-test-service.dns-9563.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9563.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9563 jessie_tcp@dns-test-service.dns-9563 jessie_udp@dns-test-service.dns-9563.svc jessie_tcp@dns-test-service.dns-9563.svc jessie_udp@_http._tcp.dns-test-service.dns-9563.svc jessie_tcp@_http._tcp.dns-test-service.dns-9563.svc]

    Nov 26 12:34:18.418: INFO: DNS probes using dns-9563/dns-test-180d8ef0-0de3-4719-978a-1bacb20b3a8c succeeded

    STEP: deleting the pod 11/26/22 12:34:18.418
    STEP: deleting the test service 11/26/22 12:34:18.471
    STEP: deleting the test headless service 11/26/22 12:34:18.581
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 26 12:34:18.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9563" for this suite. 11/26/22 12:34:18.617
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:34:18.64
Nov 26 12:34:18.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-probe 11/26/22 12:34:18.641
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:34:18.666
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:34:18.671
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-04c2871e-9e96-44a7-963d-1447f1a4986e in namespace container-probe-1632 11/26/22 12:34:18.677
Nov 26 12:34:18.713: INFO: Waiting up to 5m0s for pod "busybox-04c2871e-9e96-44a7-963d-1447f1a4986e" in namespace "container-probe-1632" to be "not pending"
Nov 26 12:34:18.719: INFO: Pod "busybox-04c2871e-9e96-44a7-963d-1447f1a4986e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.563551ms
Nov 26 12:34:20.727: INFO: Pod "busybox-04c2871e-9e96-44a7-963d-1447f1a4986e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013377212s
Nov 26 12:34:22.725: INFO: Pod "busybox-04c2871e-9e96-44a7-963d-1447f1a4986e": Phase="Running", Reason="", readiness=true. Elapsed: 4.011734415s
Nov 26 12:34:22.725: INFO: Pod "busybox-04c2871e-9e96-44a7-963d-1447f1a4986e" satisfied condition "not pending"
Nov 26 12:34:22.725: INFO: Started pod busybox-04c2871e-9e96-44a7-963d-1447f1a4986e in namespace container-probe-1632
STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 12:34:22.725
Nov 26 12:34:22.732: INFO: Initial restart count of pod busybox-04c2871e-9e96-44a7-963d-1447f1a4986e is 0
STEP: deleting the pod 11/26/22 12:38:23.578
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 26 12:38:23.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1632" for this suite. 11/26/22 12:38:23.615
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":179,"skipped":3229,"failed":0}
------------------------------
â€¢ [SLOW TEST] [244.988 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:34:18.64
    Nov 26 12:34:18.640: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-probe 11/26/22 12:34:18.641
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:34:18.666
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:34:18.671
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-04c2871e-9e96-44a7-963d-1447f1a4986e in namespace container-probe-1632 11/26/22 12:34:18.677
    Nov 26 12:34:18.713: INFO: Waiting up to 5m0s for pod "busybox-04c2871e-9e96-44a7-963d-1447f1a4986e" in namespace "container-probe-1632" to be "not pending"
    Nov 26 12:34:18.719: INFO: Pod "busybox-04c2871e-9e96-44a7-963d-1447f1a4986e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.563551ms
    Nov 26 12:34:20.727: INFO: Pod "busybox-04c2871e-9e96-44a7-963d-1447f1a4986e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013377212s
    Nov 26 12:34:22.725: INFO: Pod "busybox-04c2871e-9e96-44a7-963d-1447f1a4986e": Phase="Running", Reason="", readiness=true. Elapsed: 4.011734415s
    Nov 26 12:34:22.725: INFO: Pod "busybox-04c2871e-9e96-44a7-963d-1447f1a4986e" satisfied condition "not pending"
    Nov 26 12:34:22.725: INFO: Started pod busybox-04c2871e-9e96-44a7-963d-1447f1a4986e in namespace container-probe-1632
    STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 12:34:22.725
    Nov 26 12:34:22.732: INFO: Initial restart count of pod busybox-04c2871e-9e96-44a7-963d-1447f1a4986e is 0
    STEP: deleting the pod 11/26/22 12:38:23.578
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 26 12:38:23.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-1632" for this suite. 11/26/22 12:38:23.615
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:38:23.631
Nov 26 12:38:23.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename daemonsets 11/26/22 12:38:23.632
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:23.658
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:23.669
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 11/26/22 12:38:23.719
STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 12:38:23.73
Nov 26 12:38:23.739: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:38:23.739: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:38:23.744: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:38:23.744: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:38:24.751: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:38:24.751: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:38:24.758: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:38:24.758: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:38:25.754: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:38:25.755: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:38:25.761: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov 26 12:38:25.761: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
Nov 26 12:38:26.751: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:38:26.751: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:38:26.757: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 26 12:38:26.757: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 11/26/22 12:38:26.762
STEP: DeleteCollection of the DaemonSets 11/26/22 12:38:26.769
STEP: Verify that ReplicaSets have been deleted 11/26/22 12:38:26.784
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Nov 26 12:38:26.819: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"21429"},"items":null}

Nov 26 12:38:26.827: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"21429"},"items":[{"metadata":{"name":"daemon-set-h95g2","generateName":"daemon-set-","namespace":"daemonsets-8435","uid":"181e3d85-19cd-4a48-8d62-40c4c55b8d8f","resourceVersion":"21426","creationTimestamp":"2022-11-26T12:38:23Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"4554a72f-4b30-49e4-9743-3d25b319b549","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4554a72f-4b30-49e4-9743-3d25b319b549\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-xtjwx","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-xtjwx","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-43-82","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-43-82"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"}],"hostIP":"172.31.43.82","podIP":"192.168.34.17","podIPs":[{"ip":"192.168.34.17"}],"startTime":"2022-11-26T12:38:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-26T12:38:25Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://7086fbf63f4069982270999eb10aba6ba215f686fa70d9e1a55b5be4d322965e","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-vzlv8","generateName":"daemon-set-","namespace":"daemonsets-8435","uid":"ad71347a-6f7d-4d1a-a87d-3fce87d01a45","resourceVersion":"21421","creationTimestamp":"2022-11-26T12:38:23Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"4554a72f-4b30-49e4-9743-3d25b319b549","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4554a72f-4b30-49e4-9743-3d25b319b549\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.223\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-c4ws5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-c4ws5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-29-104","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-29-104"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"}],"hostIP":"172.31.29.104","podIP":"192.168.46.223","podIPs":[{"ip":"192.168.46.223"}],"startTime":"2022-11-26T12:38:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-26T12:38:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://344e0d095aa8b7662a5632eab24520206f2d0274656c5f158bef6ad6891aa5e7","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-z96bz","generateName":"daemon-set-","namespace":"daemonsets-8435","uid":"d4b24c87-7b20-4a12-ab7b-9ac2f65ca77c","resourceVersion":"21418","creationTimestamp":"2022-11-26T12:38:23Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"4554a72f-4b30-49e4-9743-3d25b319b549","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4554a72f-4b30-49e4-9743-3d25b319b549\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.137\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vs9xv","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vs9xv","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-0-249","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-0-249"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"}],"hostIP":"172.31.0.249","podIP":"192.168.150.137","podIPs":[{"ip":"192.168.150.137"}],"startTime":"2022-11-26T12:38:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-26T12:38:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://cd3ec8b921520834731d71146a4c336a7413d4bb0a8f477af748068c201e1900","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:38:26.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8435" for this suite. 11/26/22 12:38:26.887
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":180,"skipped":3234,"failed":0}
------------------------------
â€¢ [3.268 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:38:23.631
    Nov 26 12:38:23.631: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename daemonsets 11/26/22 12:38:23.632
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:23.658
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:23.669
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 11/26/22 12:38:23.719
    STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 12:38:23.73
    Nov 26 12:38:23.739: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:38:23.739: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:38:23.744: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:38:23.744: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:38:24.751: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:38:24.751: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:38:24.758: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:38:24.758: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:38:25.754: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:38:25.755: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:38:25.761: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov 26 12:38:25.761: INFO: Node ip-172-31-43-82 is running 0 daemon pod, expected 1
    Nov 26 12:38:26.751: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:38:26.751: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:38:26.757: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 26 12:38:26.757: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 11/26/22 12:38:26.762
    STEP: DeleteCollection of the DaemonSets 11/26/22 12:38:26.769
    STEP: Verify that ReplicaSets have been deleted 11/26/22 12:38:26.784
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Nov 26 12:38:26.819: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"21429"},"items":null}

    Nov 26 12:38:26.827: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"21429"},"items":[{"metadata":{"name":"daemon-set-h95g2","generateName":"daemon-set-","namespace":"daemonsets-8435","uid":"181e3d85-19cd-4a48-8d62-40c4c55b8d8f","resourceVersion":"21426","creationTimestamp":"2022-11-26T12:38:23Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"4554a72f-4b30-49e4-9743-3d25b319b549","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4554a72f-4b30-49e4-9743-3d25b319b549\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.17\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-xtjwx","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-xtjwx","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-43-82","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-43-82"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"}],"hostIP":"172.31.43.82","podIP":"192.168.34.17","podIPs":[{"ip":"192.168.34.17"}],"startTime":"2022-11-26T12:38:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-26T12:38:25Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://7086fbf63f4069982270999eb10aba6ba215f686fa70d9e1a55b5be4d322965e","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-vzlv8","generateName":"daemon-set-","namespace":"daemonsets-8435","uid":"ad71347a-6f7d-4d1a-a87d-3fce87d01a45","resourceVersion":"21421","creationTimestamp":"2022-11-26T12:38:23Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"4554a72f-4b30-49e4-9743-3d25b319b549","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4554a72f-4b30-49e4-9743-3d25b319b549\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.223\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-c4ws5","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-c4ws5","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-29-104","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-29-104"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"}],"hostIP":"172.31.29.104","podIP":"192.168.46.223","podIPs":[{"ip":"192.168.46.223"}],"startTime":"2022-11-26T12:38:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-26T12:38:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://344e0d095aa8b7662a5632eab24520206f2d0274656c5f158bef6ad6891aa5e7","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-z96bz","generateName":"daemon-set-","namespace":"daemonsets-8435","uid":"d4b24c87-7b20-4a12-ab7b-9ac2f65ca77c","resourceVersion":"21418","creationTimestamp":"2022-11-26T12:38:23Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"4554a72f-4b30-49e4-9743-3d25b319b549","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4554a72f-4b30-49e4-9743-3d25b319b549\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-26T12:38:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.137\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vs9xv","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vs9xv","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-0-249","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-0-249"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-26T12:38:23Z"}],"hostIP":"172.31.0.249","podIP":"192.168.150.137","podIPs":[{"ip":"192.168.150.137"}],"startTime":"2022-11-26T12:38:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-26T12:38:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://cd3ec8b921520834731d71146a4c336a7413d4bb0a8f477af748068c201e1900","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:38:26.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8435" for this suite. 11/26/22 12:38:26.887
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:38:26.9
Nov 26 12:38:26.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename ephemeral-containers-test 11/26/22 12:38:26.901
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:26.939
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:26.948
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 11/26/22 12:38:26.956
Nov 26 12:38:26.974: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6792" to be "running and ready"
Nov 26 12:38:26.985: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.405114ms
Nov 26 12:38:26.985: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:38:28.998: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023458118s
Nov 26 12:38:28.998: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Nov 26 12:38:28.998: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 11/26/22 12:38:29.009
Nov 26 12:38:29.064: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6792" to be "container debugger running"
Nov 26 12:38:29.075: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 10.597367ms
Nov 26 12:38:31.082: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018182677s
Nov 26 12:38:31.082: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 11/26/22 12:38:31.082
Nov 26 12:38:31.083: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6792 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:38:31.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:38:31.083: INFO: ExecWithOptions: Clientset creation
Nov 26 12:38:31.083: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-6792/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Nov 26 12:38:31.168: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 26 12:38:31.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-6792" for this suite. 11/26/22 12:38:31.203
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":181,"skipped":3240,"failed":0}
------------------------------
â€¢ [4.316 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:38:26.9
    Nov 26 12:38:26.900: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename ephemeral-containers-test 11/26/22 12:38:26.901
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:26.939
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:26.948
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 11/26/22 12:38:26.956
    Nov 26 12:38:26.974: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6792" to be "running and ready"
    Nov 26 12:38:26.985: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 10.405114ms
    Nov 26 12:38:26.985: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:38:28.998: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.023458118s
    Nov 26 12:38:28.998: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Nov 26 12:38:28.998: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 11/26/22 12:38:29.009
    Nov 26 12:38:29.064: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6792" to be "container debugger running"
    Nov 26 12:38:29.075: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 10.597367ms
    Nov 26 12:38:31.082: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.018182677s
    Nov 26 12:38:31.082: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 11/26/22 12:38:31.082
    Nov 26 12:38:31.083: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6792 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:38:31.083: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:38:31.083: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:38:31.083: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-6792/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Nov 26 12:38:31.168: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 26 12:38:31.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-6792" for this suite. 11/26/22 12:38:31.203
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:38:31.219
Nov 26 12:38:31.219: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 12:38:31.221
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:31.257
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:31.266
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 11/26/22 12:38:31.272
STEP: setting up watch 11/26/22 12:38:31.272
STEP: submitting the pod to kubernetes 11/26/22 12:38:31.38
STEP: verifying the pod is in kubernetes 11/26/22 12:38:31.397
STEP: verifying pod creation was observed 11/26/22 12:38:31.405
Nov 26 12:38:31.405: INFO: Waiting up to 5m0s for pod "pod-submit-remove-970d68b1-338c-4daf-8ef2-5fc91036ca6d" in namespace "pods-206" to be "running"
Nov 26 12:38:31.417: INFO: Pod "pod-submit-remove-970d68b1-338c-4daf-8ef2-5fc91036ca6d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.795042ms
Nov 26 12:38:33.425: INFO: Pod "pod-submit-remove-970d68b1-338c-4daf-8ef2-5fc91036ca6d": Phase="Running", Reason="", readiness=true. Elapsed: 2.019455111s
Nov 26 12:38:33.425: INFO: Pod "pod-submit-remove-970d68b1-338c-4daf-8ef2-5fc91036ca6d" satisfied condition "running"
STEP: deleting the pod gracefully 11/26/22 12:38:33.431
STEP: verifying pod deletion was observed 11/26/22 12:38:33.449
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 26 12:38:36.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-206" for this suite. 11/26/22 12:38:36.084
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":182,"skipped":3277,"failed":0}
------------------------------
â€¢ [4.884 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:38:31.219
    Nov 26 12:38:31.219: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 12:38:31.221
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:31.257
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:31.266
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 11/26/22 12:38:31.272
    STEP: setting up watch 11/26/22 12:38:31.272
    STEP: submitting the pod to kubernetes 11/26/22 12:38:31.38
    STEP: verifying the pod is in kubernetes 11/26/22 12:38:31.397
    STEP: verifying pod creation was observed 11/26/22 12:38:31.405
    Nov 26 12:38:31.405: INFO: Waiting up to 5m0s for pod "pod-submit-remove-970d68b1-338c-4daf-8ef2-5fc91036ca6d" in namespace "pods-206" to be "running"
    Nov 26 12:38:31.417: INFO: Pod "pod-submit-remove-970d68b1-338c-4daf-8ef2-5fc91036ca6d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.795042ms
    Nov 26 12:38:33.425: INFO: Pod "pod-submit-remove-970d68b1-338c-4daf-8ef2-5fc91036ca6d": Phase="Running", Reason="", readiness=true. Elapsed: 2.019455111s
    Nov 26 12:38:33.425: INFO: Pod "pod-submit-remove-970d68b1-338c-4daf-8ef2-5fc91036ca6d" satisfied condition "running"
    STEP: deleting the pod gracefully 11/26/22 12:38:33.431
    STEP: verifying pod deletion was observed 11/26/22 12:38:33.449
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 26 12:38:36.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-206" for this suite. 11/26/22 12:38:36.084
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:38:36.115
Nov 26 12:38:36.115: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:38:36.116
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:36.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:36.162
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-21ead8c1-ddd1-4a4d-9896-709cac77d449 11/26/22 12:38:36.169
STEP: Creating a pod to test consume configMaps 11/26/22 12:38:36.179
Nov 26 12:38:36.194: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9" in namespace "projected-850" to be "Succeeded or Failed"
Nov 26 12:38:36.203: INFO: Pod "pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.964134ms
Nov 26 12:38:38.212: INFO: Pod "pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017483608s
Nov 26 12:38:40.211: INFO: Pod "pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016264198s
STEP: Saw pod success 11/26/22 12:38:40.211
Nov 26 12:38:40.211: INFO: Pod "pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9" satisfied condition "Succeeded or Failed"
Nov 26 12:38:40.216: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9 container projected-configmap-volume-test: <nil>
STEP: delete the pod 11/26/22 12:38:40.227
Nov 26 12:38:40.248: INFO: Waiting for pod pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9 to disappear
Nov 26 12:38:40.254: INFO: Pod pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 26 12:38:40.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-850" for this suite. 11/26/22 12:38:40.262
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":183,"skipped":3308,"failed":0}
------------------------------
â€¢ [4.158 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:38:36.115
    Nov 26 12:38:36.115: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:38:36.116
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:36.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:36.162
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-21ead8c1-ddd1-4a4d-9896-709cac77d449 11/26/22 12:38:36.169
    STEP: Creating a pod to test consume configMaps 11/26/22 12:38:36.179
    Nov 26 12:38:36.194: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9" in namespace "projected-850" to be "Succeeded or Failed"
    Nov 26 12:38:36.203: INFO: Pod "pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.964134ms
    Nov 26 12:38:38.212: INFO: Pod "pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017483608s
    Nov 26 12:38:40.211: INFO: Pod "pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016264198s
    STEP: Saw pod success 11/26/22 12:38:40.211
    Nov 26 12:38:40.211: INFO: Pod "pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9" satisfied condition "Succeeded or Failed"
    Nov 26 12:38:40.216: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:38:40.227
    Nov 26 12:38:40.248: INFO: Waiting for pod pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9 to disappear
    Nov 26 12:38:40.254: INFO: Pod pod-projected-configmaps-d323f129-775b-485e-ad8b-b86689cba3d9 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 26 12:38:40.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-850" for this suite. 11/26/22 12:38:40.262
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:38:40.278
Nov 26 12:38:40.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename endpointslicemirroring 11/26/22 12:38:40.279
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:40.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:40.313
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 11/26/22 12:38:40.338
Nov 26 12:38:40.363: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 11/26/22 12:38:42.369
STEP: mirroring deletion of a custom Endpoint 11/26/22 12:38:42.389
Nov 26 12:38:42.411: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Nov 26 12:38:44.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-2314" for this suite. 11/26/22 12:38:44.424
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":184,"skipped":3321,"failed":0}
------------------------------
â€¢ [4.159 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:38:40.278
    Nov 26 12:38:40.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename endpointslicemirroring 11/26/22 12:38:40.279
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:40.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:40.313
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 11/26/22 12:38:40.338
    Nov 26 12:38:40.363: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 11/26/22 12:38:42.369
    STEP: mirroring deletion of a custom Endpoint 11/26/22 12:38:42.389
    Nov 26 12:38:42.411: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Nov 26 12:38:44.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-2314" for this suite. 11/26/22 12:38:44.424
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:38:44.448
Nov 26 12:38:44.449: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-watch 11/26/22 12:38:44.45
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:44.475
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:44.48
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Nov 26 12:38:44.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Creating first CR  11/26/22 12:38:47.086
Nov 26 12:38:47.097: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:47Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:38:47Z]] name:name1 resourceVersion:21653 uid:00b53057-a860-48b6-a94d-3fc28e6334ad] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 11/26/22 12:38:57.098
Nov 26 12:38:57.109: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:57Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:38:57Z]] name:name2 resourceVersion:21684 uid:80ba7e29-4cac-4c1c-adcc-b99f07eacabf] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 11/26/22 12:39:07.11
Nov 26 12:39:07.120: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:39:07Z]] name:name1 resourceVersion:21706 uid:00b53057-a860-48b6-a94d-3fc28e6334ad] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 11/26/22 12:39:17.122
Nov 26 12:39:17.134: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:39:17Z]] name:name2 resourceVersion:21731 uid:80ba7e29-4cac-4c1c-adcc-b99f07eacabf] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 11/26/22 12:39:27.138
Nov 26 12:39:27.149: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:39:07Z]] name:name1 resourceVersion:21752 uid:00b53057-a860-48b6-a94d-3fc28e6334ad] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 11/26/22 12:39:37.15
Nov 26 12:39:37.163: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:39:17Z]] name:name2 resourceVersion:21771 uid:80ba7e29-4cac-4c1c-adcc-b99f07eacabf] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:39:47.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-265" for this suite. 11/26/22 12:39:47.695
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":185,"skipped":3361,"failed":0}
------------------------------
â€¢ [SLOW TEST] [63.258 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:38:44.448
    Nov 26 12:38:44.449: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-watch 11/26/22 12:38:44.45
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:38:44.475
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:38:44.48
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Nov 26 12:38:44.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Creating first CR  11/26/22 12:38:47.086
    Nov 26 12:38:47.097: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:47Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:38:47Z]] name:name1 resourceVersion:21653 uid:00b53057-a860-48b6-a94d-3fc28e6334ad] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 11/26/22 12:38:57.098
    Nov 26 12:38:57.109: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:57Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:38:57Z]] name:name2 resourceVersion:21684 uid:80ba7e29-4cac-4c1c-adcc-b99f07eacabf] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 11/26/22 12:39:07.11
    Nov 26 12:39:07.120: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:39:07Z]] name:name1 resourceVersion:21706 uid:00b53057-a860-48b6-a94d-3fc28e6334ad] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 11/26/22 12:39:17.122
    Nov 26 12:39:17.134: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:39:17Z]] name:name2 resourceVersion:21731 uid:80ba7e29-4cac-4c1c-adcc-b99f07eacabf] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 11/26/22 12:39:27.138
    Nov 26 12:39:27.149: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:47Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:39:07Z]] name:name1 resourceVersion:21752 uid:00b53057-a860-48b6-a94d-3fc28e6334ad] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 11/26/22 12:39:37.15
    Nov 26 12:39:37.163: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-26T12:38:57Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-26T12:39:17Z]] name:name2 resourceVersion:21771 uid:80ba7e29-4cac-4c1c-adcc-b99f07eacabf] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:39:47.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-265" for this suite. 11/26/22 12:39:47.695
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:39:47.714
Nov 26 12:39:47.714: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:39:47.715
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:39:47.744
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:39:47.759
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-2513 11/26/22 12:39:47.768
Nov 26 12:39:47.781: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-2513" to be "running and ready"
Nov 26 12:39:47.788: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 6.27861ms
Nov 26 12:39:47.788: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:39:49.793: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.011925946s
Nov 26 12:39:49.793: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Nov 26 12:39:49.793: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Nov 26 12:39:49.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Nov 26 12:39:49.992: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Nov 26 12:39:49.993: INFO: stdout: "iptables"
Nov 26 12:39:49.993: INFO: proxyMode: iptables
Nov 26 12:39:50.008: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Nov 26 12:39:50.014: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-2513 11/26/22 12:39:50.014
STEP: creating replication controller affinity-clusterip-timeout in namespace services-2513 11/26/22 12:39:50.038
I1126 12:39:50.060745      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-2513, replica count: 3
I1126 12:39:53.111572      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 12:39:53.122: INFO: Creating new exec pod
Nov 26 12:39:53.130: INFO: Waiting up to 5m0s for pod "execpod-affinitydjltq" in namespace "services-2513" to be "running"
Nov 26 12:39:53.139: INFO: Pod "execpod-affinitydjltq": Phase="Pending", Reason="", readiness=false. Elapsed: 9.427704ms
Nov 26 12:39:55.148: INFO: Pod "execpod-affinitydjltq": Phase="Running", Reason="", readiness=true. Elapsed: 2.017937355s
Nov 26 12:39:55.148: INFO: Pod "execpod-affinitydjltq" satisfied condition "running"
Nov 26 12:39:56.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Nov 26 12:39:56.352: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Nov 26 12:39:56.352: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:39:56.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.78 80'
Nov 26 12:39:56.529: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.78 80\nConnection to 10.152.183.78 80 port [tcp/http] succeeded!\n"
Nov 26 12:39:56.529: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:39:56.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.78:80/ ; done'
Nov 26 12:39:56.834: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n"
Nov 26 12:39:56.834: INFO: stdout: "\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97"
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
Nov 26 12:39:56.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.78:80/'
Nov 26 12:39:57.003: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n"
Nov 26 12:39:57.003: INFO: stdout: "affinity-clusterip-timeout-trg97"
Nov 26 12:40:17.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.78:80/'
Nov 26 12:40:17.223: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n"
Nov 26 12:40:17.223: INFO: stdout: "affinity-clusterip-timeout-trg97"
Nov 26 12:40:37.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.78:80/'
Nov 26 12:40:37.424: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n"
Nov 26 12:40:37.424: INFO: stdout: "affinity-clusterip-timeout-ngfpc"
Nov 26 12:40:37.424: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-2513, will wait for the garbage collector to delete the pods 11/26/22 12:40:37.452
Nov 26 12:40:37.521: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 11.866925ms
Nov 26 12:40:37.621: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.791749ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:40:39.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2513" for this suite. 11/26/22 12:40:39.771
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":186,"skipped":3439,"failed":0}
------------------------------
â€¢ [SLOW TEST] [52.071 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:39:47.714
    Nov 26 12:39:47.714: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:39:47.715
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:39:47.744
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:39:47.759
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-2513 11/26/22 12:39:47.768
    Nov 26 12:39:47.781: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-2513" to be "running and ready"
    Nov 26 12:39:47.788: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 6.27861ms
    Nov 26 12:39:47.788: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:39:49.793: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.011925946s
    Nov 26 12:39:49.793: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Nov 26 12:39:49.793: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Nov 26 12:39:49.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Nov 26 12:39:49.992: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Nov 26 12:39:49.993: INFO: stdout: "iptables"
    Nov 26 12:39:49.993: INFO: proxyMode: iptables
    Nov 26 12:39:50.008: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Nov 26 12:39:50.014: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-2513 11/26/22 12:39:50.014
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-2513 11/26/22 12:39:50.038
    I1126 12:39:50.060745      19 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-2513, replica count: 3
    I1126 12:39:53.111572      19 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 12:39:53.122: INFO: Creating new exec pod
    Nov 26 12:39:53.130: INFO: Waiting up to 5m0s for pod "execpod-affinitydjltq" in namespace "services-2513" to be "running"
    Nov 26 12:39:53.139: INFO: Pod "execpod-affinitydjltq": Phase="Pending", Reason="", readiness=false. Elapsed: 9.427704ms
    Nov 26 12:39:55.148: INFO: Pod "execpod-affinitydjltq": Phase="Running", Reason="", readiness=true. Elapsed: 2.017937355s
    Nov 26 12:39:55.148: INFO: Pod "execpod-affinitydjltq" satisfied condition "running"
    Nov 26 12:39:56.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Nov 26 12:39:56.352: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Nov 26 12:39:56.352: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:39:56.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.78 80'
    Nov 26 12:39:56.529: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.78 80\nConnection to 10.152.183.78 80 port [tcp/http] succeeded!\n"
    Nov 26 12:39:56.529: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:39:56.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.78:80/ ; done'
    Nov 26 12:39:56.834: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n"
    Nov 26 12:39:56.834: INFO: stdout: "\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97\naffinity-clusterip-timeout-trg97"
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.834: INFO: Received response from host: affinity-clusterip-timeout-trg97
    Nov 26 12:39:56.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.78:80/'
    Nov 26 12:39:57.003: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n"
    Nov 26 12:39:57.003: INFO: stdout: "affinity-clusterip-timeout-trg97"
    Nov 26 12:40:17.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.78:80/'
    Nov 26 12:40:17.223: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n"
    Nov 26 12:40:17.223: INFO: stdout: "affinity-clusterip-timeout-trg97"
    Nov 26 12:40:37.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2513 exec execpod-affinitydjltq -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.78:80/'
    Nov 26 12:40:37.424: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.78:80/\n"
    Nov 26 12:40:37.424: INFO: stdout: "affinity-clusterip-timeout-ngfpc"
    Nov 26 12:40:37.424: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-2513, will wait for the garbage collector to delete the pods 11/26/22 12:40:37.452
    Nov 26 12:40:37.521: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 11.866925ms
    Nov 26 12:40:37.621: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 100.791749ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:40:39.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2513" for this suite. 11/26/22 12:40:39.771
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:40:39.791
Nov 26 12:40:39.791: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:40:39.792
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:40:39.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:40:39.822
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:40:39.851
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:40:40.374
STEP: Deploying the webhook pod 11/26/22 12:40:40.386
STEP: Wait for the deployment to be ready 11/26/22 12:40:40.402
Nov 26 12:40:40.413: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/26/22 12:40:42.431
STEP: Verifying the service has paired with the endpoint 11/26/22 12:40:42.449
Nov 26 12:40:43.450: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Nov 26 12:40:43.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9586-crds.webhook.example.com via the AdmissionRegistration API 11/26/22 12:40:43.974
STEP: Creating a custom resource that should be mutated by the webhook 11/26/22 12:40:43.997
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:40:46.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5954" for this suite. 11/26/22 12:40:46.647
STEP: Destroying namespace "webhook-5954-markers" for this suite. 11/26/22 12:40:46.657
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":187,"skipped":3477,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.951 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:40:39.791
    Nov 26 12:40:39.791: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:40:39.792
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:40:39.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:40:39.822
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:40:39.851
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:40:40.374
    STEP: Deploying the webhook pod 11/26/22 12:40:40.386
    STEP: Wait for the deployment to be ready 11/26/22 12:40:40.402
    Nov 26 12:40:40.413: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/26/22 12:40:42.431
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:40:42.449
    Nov 26 12:40:43.450: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Nov 26 12:40:43.456: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9586-crds.webhook.example.com via the AdmissionRegistration API 11/26/22 12:40:43.974
    STEP: Creating a custom resource that should be mutated by the webhook 11/26/22 12:40:43.997
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:40:46.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5954" for this suite. 11/26/22 12:40:46.647
    STEP: Destroying namespace "webhook-5954-markers" for this suite. 11/26/22 12:40:46.657
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:40:46.749
Nov 26 12:40:46.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:40:46.751
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:40:46.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:40:46.807
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 11/26/22 12:40:46.813
Nov 26 12:40:46.827: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417" in namespace "emptydir-4304" to be "running"
Nov 26 12:40:46.834: INFO: Pod "pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417": Phase="Pending", Reason="", readiness=false. Elapsed: 7.552317ms
Nov 26 12:40:48.842: INFO: Pod "pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417": Phase="Running", Reason="", readiness=false. Elapsed: 2.015572759s
Nov 26 12:40:48.842: INFO: Pod "pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417" satisfied condition "running"
STEP: Reading file content from the nginx-container 11/26/22 12:40:48.842
Nov 26 12:40:48.842: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-4304 PodName:pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 12:40:48.843: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 12:40:48.843: INFO: ExecWithOptions: Clientset creation
Nov 26 12:40:48.843: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-4304/pods/pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Nov 26 12:40:48.930: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:40:48.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4304" for this suite. 11/26/22 12:40:48.937
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":188,"skipped":3566,"failed":0}
------------------------------
â€¢ [2.198 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:40:46.749
    Nov 26 12:40:46.750: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:40:46.751
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:40:46.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:40:46.807
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 11/26/22 12:40:46.813
    Nov 26 12:40:46.827: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417" in namespace "emptydir-4304" to be "running"
    Nov 26 12:40:46.834: INFO: Pod "pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417": Phase="Pending", Reason="", readiness=false. Elapsed: 7.552317ms
    Nov 26 12:40:48.842: INFO: Pod "pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417": Phase="Running", Reason="", readiness=false. Elapsed: 2.015572759s
    Nov 26 12:40:48.842: INFO: Pod "pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417" satisfied condition "running"
    STEP: Reading file content from the nginx-container 11/26/22 12:40:48.842
    Nov 26 12:40:48.842: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-4304 PodName:pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 12:40:48.843: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 12:40:48.843: INFO: ExecWithOptions: Clientset creation
    Nov 26 12:40:48.843: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-4304/pods/pod-sharedvolume-321c31d3-d32c-4fa5-9876-f5caf4d7f417/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Nov 26 12:40:48.930: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:40:48.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4304" for this suite. 11/26/22 12:40:48.937
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:40:48.954
Nov 26 12:40:48.954: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:40:48.955
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:40:48.982
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:40:48.988
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-38695430-785f-47a2-a491-289960602539 11/26/22 12:40:48.994
STEP: Creating secret with name secret-projected-all-test-volume-17ed2488-585c-49fd-bd9b-f127fbd6d0cc 11/26/22 12:40:49.002
STEP: Creating a pod to test Check all projections for projected volume plugin 11/26/22 12:40:49.012
Nov 26 12:40:49.032: INFO: Waiting up to 5m0s for pod "projected-volume-6b142143-252c-48f2-8969-22515af31fee" in namespace "projected-2091" to be "Succeeded or Failed"
Nov 26 12:40:49.039: INFO: Pod "projected-volume-6b142143-252c-48f2-8969-22515af31fee": Phase="Pending", Reason="", readiness=false. Elapsed: 6.877422ms
Nov 26 12:40:51.045: INFO: Pod "projected-volume-6b142143-252c-48f2-8969-22515af31fee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013027262s
Nov 26 12:40:53.045: INFO: Pod "projected-volume-6b142143-252c-48f2-8969-22515af31fee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013388086s
STEP: Saw pod success 11/26/22 12:40:53.045
Nov 26 12:40:53.045: INFO: Pod "projected-volume-6b142143-252c-48f2-8969-22515af31fee" satisfied condition "Succeeded or Failed"
Nov 26 12:40:53.051: INFO: Trying to get logs from node ip-172-31-43-82 pod projected-volume-6b142143-252c-48f2-8969-22515af31fee container projected-all-volume-test: <nil>
STEP: delete the pod 11/26/22 12:40:53.067
Nov 26 12:40:53.084: INFO: Waiting for pod projected-volume-6b142143-252c-48f2-8969-22515af31fee to disappear
Nov 26 12:40:53.090: INFO: Pod projected-volume-6b142143-252c-48f2-8969-22515af31fee no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Nov 26 12:40:53.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2091" for this suite. 11/26/22 12:40:53.099
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":189,"skipped":3600,"failed":0}
------------------------------
â€¢ [4.157 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:40:48.954
    Nov 26 12:40:48.954: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:40:48.955
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:40:48.982
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:40:48.988
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-38695430-785f-47a2-a491-289960602539 11/26/22 12:40:48.994
    STEP: Creating secret with name secret-projected-all-test-volume-17ed2488-585c-49fd-bd9b-f127fbd6d0cc 11/26/22 12:40:49.002
    STEP: Creating a pod to test Check all projections for projected volume plugin 11/26/22 12:40:49.012
    Nov 26 12:40:49.032: INFO: Waiting up to 5m0s for pod "projected-volume-6b142143-252c-48f2-8969-22515af31fee" in namespace "projected-2091" to be "Succeeded or Failed"
    Nov 26 12:40:49.039: INFO: Pod "projected-volume-6b142143-252c-48f2-8969-22515af31fee": Phase="Pending", Reason="", readiness=false. Elapsed: 6.877422ms
    Nov 26 12:40:51.045: INFO: Pod "projected-volume-6b142143-252c-48f2-8969-22515af31fee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013027262s
    Nov 26 12:40:53.045: INFO: Pod "projected-volume-6b142143-252c-48f2-8969-22515af31fee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013388086s
    STEP: Saw pod success 11/26/22 12:40:53.045
    Nov 26 12:40:53.045: INFO: Pod "projected-volume-6b142143-252c-48f2-8969-22515af31fee" satisfied condition "Succeeded or Failed"
    Nov 26 12:40:53.051: INFO: Trying to get logs from node ip-172-31-43-82 pod projected-volume-6b142143-252c-48f2-8969-22515af31fee container projected-all-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:40:53.067
    Nov 26 12:40:53.084: INFO: Waiting for pod projected-volume-6b142143-252c-48f2-8969-22515af31fee to disappear
    Nov 26 12:40:53.090: INFO: Pod projected-volume-6b142143-252c-48f2-8969-22515af31fee no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Nov 26 12:40:53.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2091" for this suite. 11/26/22 12:40:53.099
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:40:53.113
Nov 26 12:40:53.113: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-lifecycle-hook 11/26/22 12:40:53.114
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:40:53.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:40:53.146
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/26/22 12:40:53.158
Nov 26 12:40:53.171: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1852" to be "running and ready"
Nov 26 12:40:53.177: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.133326ms
Nov 26 12:40:53.177: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:40:55.184: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.012508772s
Nov 26 12:40:55.184: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 26 12:40:55.184: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 11/26/22 12:40:55.19
Nov 26 12:40:55.200: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-1852" to be "running and ready"
Nov 26 12:40:55.205: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.27931ms
Nov 26 12:40:55.205: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:40:57.212: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.012266474s
Nov 26 12:40:57.212: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Nov 26 12:40:57.212: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 11/26/22 12:40:57.22
STEP: delete the pod with lifecycle hook 11/26/22 12:40:57.245
Nov 26 12:40:57.258: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 26 12:40:57.264: INFO: Pod pod-with-poststart-http-hook still exists
Nov 26 12:40:59.265: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 26 12:40:59.273: INFO: Pod pod-with-poststart-http-hook still exists
Nov 26 12:41:01.266: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 26 12:41:01.274: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 26 12:41:01.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1852" for this suite. 11/26/22 12:41:01.282
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":190,"skipped":3610,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.181 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:40:53.113
    Nov 26 12:40:53.113: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/26/22 12:40:53.114
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:40:53.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:40:53.146
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/26/22 12:40:53.158
    Nov 26 12:40:53.171: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-1852" to be "running and ready"
    Nov 26 12:40:53.177: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.133326ms
    Nov 26 12:40:53.177: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:40:55.184: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.012508772s
    Nov 26 12:40:55.184: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 26 12:40:55.184: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 11/26/22 12:40:55.19
    Nov 26 12:40:55.200: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-1852" to be "running and ready"
    Nov 26 12:40:55.205: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.27931ms
    Nov 26 12:40:55.205: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:40:57.212: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.012266474s
    Nov 26 12:40:57.212: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Nov 26 12:40:57.212: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 11/26/22 12:40:57.22
    STEP: delete the pod with lifecycle hook 11/26/22 12:40:57.245
    Nov 26 12:40:57.258: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 26 12:40:57.264: INFO: Pod pod-with-poststart-http-hook still exists
    Nov 26 12:40:59.265: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 26 12:40:59.273: INFO: Pod pod-with-poststart-http-hook still exists
    Nov 26 12:41:01.266: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov 26 12:41:01.274: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 26 12:41:01.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-1852" for this suite. 11/26/22 12:41:01.282
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:01.295
Nov 26 12:41:01.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 12:41:01.296
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:01.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:01.325
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-47006970-cb10-4231-85c0-fba859e28d95 11/26/22 12:41:01.332
STEP: Creating a pod to test consume secrets 11/26/22 12:41:01.342
Nov 26 12:41:01.357: INFO: Waiting up to 5m0s for pod "pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8" in namespace "secrets-5001" to be "Succeeded or Failed"
Nov 26 12:41:01.365: INFO: Pod "pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.517666ms
Nov 26 12:41:03.371: INFO: Pod "pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01421984s
Nov 26 12:41:05.370: INFO: Pod "pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013401283s
STEP: Saw pod success 11/26/22 12:41:05.371
Nov 26 12:41:05.371: INFO: Pod "pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8" satisfied condition "Succeeded or Failed"
Nov 26 12:41:05.376: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8 container secret-volume-test: <nil>
STEP: delete the pod 11/26/22 12:41:05.384
Nov 26 12:41:05.414: INFO: Waiting for pod pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8 to disappear
Nov 26 12:41:05.421: INFO: Pod pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 26 12:41:05.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5001" for this suite. 11/26/22 12:41:05.427
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":191,"skipped":3622,"failed":0}
------------------------------
â€¢ [4.142 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:01.295
    Nov 26 12:41:01.295: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 12:41:01.296
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:01.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:01.325
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-47006970-cb10-4231-85c0-fba859e28d95 11/26/22 12:41:01.332
    STEP: Creating a pod to test consume secrets 11/26/22 12:41:01.342
    Nov 26 12:41:01.357: INFO: Waiting up to 5m0s for pod "pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8" in namespace "secrets-5001" to be "Succeeded or Failed"
    Nov 26 12:41:01.365: INFO: Pod "pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.517666ms
    Nov 26 12:41:03.371: INFO: Pod "pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01421984s
    Nov 26 12:41:05.370: INFO: Pod "pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013401283s
    STEP: Saw pod success 11/26/22 12:41:05.371
    Nov 26 12:41:05.371: INFO: Pod "pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8" satisfied condition "Succeeded or Failed"
    Nov 26 12:41:05.376: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8 container secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:41:05.384
    Nov 26 12:41:05.414: INFO: Waiting for pod pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8 to disappear
    Nov 26 12:41:05.421: INFO: Pod pod-secrets-ddc274c8-ab2c-44ab-8cfd-aaa451f6cbd8 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 12:41:05.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5001" for this suite. 11/26/22 12:41:05.427
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:05.437
Nov 26 12:41:05.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 12:41:05.438
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:05.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:05.475
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:41:05.479
Nov 26 12:41:05.493: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523" in namespace "downward-api-4460" to be "Succeeded or Failed"
Nov 26 12:41:05.502: INFO: Pod "downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523": Phase="Pending", Reason="", readiness=false. Elapsed: 9.319763ms
Nov 26 12:41:07.508: INFO: Pod "downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015436555s
Nov 26 12:41:09.508: INFO: Pod "downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015365934s
STEP: Saw pod success 11/26/22 12:41:09.508
Nov 26 12:41:09.508: INFO: Pod "downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523" satisfied condition "Succeeded or Failed"
Nov 26 12:41:09.514: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523 container client-container: <nil>
STEP: delete the pod 11/26/22 12:41:09.529
Nov 26 12:41:09.547: INFO: Waiting for pod downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523 to disappear
Nov 26 12:41:09.553: INFO: Pod downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 12:41:09.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4460" for this suite. 11/26/22 12:41:09.559
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":192,"skipped":3622,"failed":0}
------------------------------
â€¢ [4.134 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:05.437
    Nov 26 12:41:05.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 12:41:05.438
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:05.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:05.475
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:41:05.479
    Nov 26 12:41:05.493: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523" in namespace "downward-api-4460" to be "Succeeded or Failed"
    Nov 26 12:41:05.502: INFO: Pod "downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523": Phase="Pending", Reason="", readiness=false. Elapsed: 9.319763ms
    Nov 26 12:41:07.508: INFO: Pod "downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015436555s
    Nov 26 12:41:09.508: INFO: Pod "downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015365934s
    STEP: Saw pod success 11/26/22 12:41:09.508
    Nov 26 12:41:09.508: INFO: Pod "downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523" satisfied condition "Succeeded or Failed"
    Nov 26 12:41:09.514: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523 container client-container: <nil>
    STEP: delete the pod 11/26/22 12:41:09.529
    Nov 26 12:41:09.547: INFO: Waiting for pod downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523 to disappear
    Nov 26 12:41:09.553: INFO: Pod downwardapi-volume-dba69b44-f1c7-493d-9ddd-c70475145523 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 12:41:09.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4460" for this suite. 11/26/22 12:41:09.559
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:09.573
Nov 26 12:41:09.574: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename gc 11/26/22 12:41:09.575
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:09.598
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:09.613
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 11/26/22 12:41:09.618
STEP: delete the rc 11/26/22 12:41:14.637
STEP: wait for all pods to be garbage collected 11/26/22 12:41:14.655
STEP: Gathering metrics 11/26/22 12:41:19.666
W1126 12:41:19.673293      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 26 12:41:19.673: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 26 12:41:19.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-596" for this suite. 11/26/22 12:41:19.679
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":193,"skipped":3625,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.116 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:09.573
    Nov 26 12:41:09.574: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename gc 11/26/22 12:41:09.575
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:09.598
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:09.613
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 11/26/22 12:41:09.618
    STEP: delete the rc 11/26/22 12:41:14.637
    STEP: wait for all pods to be garbage collected 11/26/22 12:41:14.655
    STEP: Gathering metrics 11/26/22 12:41:19.666
    W1126 12:41:19.673293      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 26 12:41:19.673: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 26 12:41:19.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-596" for this suite. 11/26/22 12:41:19.679
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:19.69
Nov 26 12:41:19.690: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 12:41:19.691
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:19.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:19.724
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 11/26/22 12:41:19.728
STEP: Ensuring ResourceQuota status is calculated 11/26/22 12:41:19.735
STEP: Creating a ResourceQuota with not best effort scope 11/26/22 12:41:21.745
STEP: Ensuring ResourceQuota status is calculated 11/26/22 12:41:21.753
STEP: Creating a best-effort pod 11/26/22 12:41:23.759
STEP: Ensuring resource quota with best effort scope captures the pod usage 11/26/22 12:41:23.786
STEP: Ensuring resource quota with not best effort ignored the pod usage 11/26/22 12:41:25.792
STEP: Deleting the pod 11/26/22 12:41:27.798
STEP: Ensuring resource quota status released the pod usage 11/26/22 12:41:27.831
STEP: Creating a not best-effort pod 11/26/22 12:41:29.839
STEP: Ensuring resource quota with not best effort scope captures the pod usage 11/26/22 12:41:29.863
STEP: Ensuring resource quota with best effort scope ignored the pod usage 11/26/22 12:41:31.869
STEP: Deleting the pod 11/26/22 12:41:33.875
STEP: Ensuring resource quota status released the pod usage 11/26/22 12:41:33.901
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 12:41:35.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8832" for this suite. 11/26/22 12:41:35.916
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":194,"skipped":3627,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.236 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:19.69
    Nov 26 12:41:19.690: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 12:41:19.691
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:19.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:19.724
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 11/26/22 12:41:19.728
    STEP: Ensuring ResourceQuota status is calculated 11/26/22 12:41:19.735
    STEP: Creating a ResourceQuota with not best effort scope 11/26/22 12:41:21.745
    STEP: Ensuring ResourceQuota status is calculated 11/26/22 12:41:21.753
    STEP: Creating a best-effort pod 11/26/22 12:41:23.759
    STEP: Ensuring resource quota with best effort scope captures the pod usage 11/26/22 12:41:23.786
    STEP: Ensuring resource quota with not best effort ignored the pod usage 11/26/22 12:41:25.792
    STEP: Deleting the pod 11/26/22 12:41:27.798
    STEP: Ensuring resource quota status released the pod usage 11/26/22 12:41:27.831
    STEP: Creating a not best-effort pod 11/26/22 12:41:29.839
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 11/26/22 12:41:29.863
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 11/26/22 12:41:31.869
    STEP: Deleting the pod 11/26/22 12:41:33.875
    STEP: Ensuring resource quota status released the pod usage 11/26/22 12:41:33.901
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 12:41:35.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8832" for this suite. 11/26/22 12:41:35.916
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:35.927
Nov 26 12:41:35.928: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename events 11/26/22 12:41:35.929
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:35.955
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:35.96
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 11/26/22 12:41:35.967
Nov 26 12:41:35.977: INFO: created test-event-1
Nov 26 12:41:35.985: INFO: created test-event-2
Nov 26 12:41:35.992: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 11/26/22 12:41:35.993
STEP: delete collection of events 11/26/22 12:41:35.998
Nov 26 12:41:35.998: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 11/26/22 12:41:36.031
Nov 26 12:41:36.032: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Nov 26 12:41:36.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-869" for this suite. 11/26/22 12:41:36.044
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":195,"skipped":3632,"failed":0}
------------------------------
â€¢ [0.127 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:35.927
    Nov 26 12:41:35.928: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename events 11/26/22 12:41:35.929
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:35.955
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:35.96
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 11/26/22 12:41:35.967
    Nov 26 12:41:35.977: INFO: created test-event-1
    Nov 26 12:41:35.985: INFO: created test-event-2
    Nov 26 12:41:35.992: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 11/26/22 12:41:35.993
    STEP: delete collection of events 11/26/22 12:41:35.998
    Nov 26 12:41:35.998: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 11/26/22 12:41:36.031
    Nov 26 12:41:36.032: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Nov 26 12:41:36.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-869" for this suite. 11/26/22 12:41:36.044
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:36.055
Nov 26 12:41:36.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename runtimeclass 11/26/22 12:41:36.057
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:36.102
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:36.108
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 11/26/22 12:41:36.115
STEP: getting /apis/node.k8s.io 11/26/22 12:41:36.121
STEP: getting /apis/node.k8s.io/v1 11/26/22 12:41:36.123
STEP: creating 11/26/22 12:41:36.125
STEP: watching 11/26/22 12:41:36.155
Nov 26 12:41:36.155: INFO: starting watch
STEP: getting 11/26/22 12:41:36.165
STEP: listing 11/26/22 12:41:36.17
STEP: patching 11/26/22 12:41:36.177
STEP: updating 11/26/22 12:41:36.185
Nov 26 12:41:36.193: INFO: waiting for watch events with expected annotations
STEP: deleting 11/26/22 12:41:36.194
STEP: deleting a collection 11/26/22 12:41:36.225
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 26 12:41:36.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-8927" for this suite. 11/26/22 12:41:36.259
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":196,"skipped":3635,"failed":0}
------------------------------
â€¢ [0.215 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:36.055
    Nov 26 12:41:36.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename runtimeclass 11/26/22 12:41:36.057
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:36.102
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:36.108
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 11/26/22 12:41:36.115
    STEP: getting /apis/node.k8s.io 11/26/22 12:41:36.121
    STEP: getting /apis/node.k8s.io/v1 11/26/22 12:41:36.123
    STEP: creating 11/26/22 12:41:36.125
    STEP: watching 11/26/22 12:41:36.155
    Nov 26 12:41:36.155: INFO: starting watch
    STEP: getting 11/26/22 12:41:36.165
    STEP: listing 11/26/22 12:41:36.17
    STEP: patching 11/26/22 12:41:36.177
    STEP: updating 11/26/22 12:41:36.185
    Nov 26 12:41:36.193: INFO: waiting for watch events with expected annotations
    STEP: deleting 11/26/22 12:41:36.194
    STEP: deleting a collection 11/26/22 12:41:36.225
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 26 12:41:36.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-8927" for this suite. 11/26/22 12:41:36.259
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:36.272
Nov 26 12:41:36.273: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename custom-resource-definition 11/26/22 12:41:36.274
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:36.297
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:36.303
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Nov 26 12:41:36.309: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:41:42.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9540" for this suite. 11/26/22 12:41:42.675
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":197,"skipped":3652,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.413 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:36.272
    Nov 26 12:41:36.273: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename custom-resource-definition 11/26/22 12:41:36.274
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:36.297
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:36.303
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Nov 26 12:41:36.309: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:41:42.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-9540" for this suite. 11/26/22 12:41:42.675
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:42.691
Nov 26 12:41:42.691: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:41:42.692
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:42.71
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:42.717
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:41:42.722
Nov 26 12:41:42.734: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409" in namespace "projected-9874" to be "Succeeded or Failed"
Nov 26 12:41:42.750: INFO: Pod "downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409": Phase="Pending", Reason="", readiness=false. Elapsed: 15.447781ms
Nov 26 12:41:44.758: INFO: Pod "downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023229531s
Nov 26 12:41:46.756: INFO: Pod "downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021873175s
STEP: Saw pod success 11/26/22 12:41:46.757
Nov 26 12:41:46.757: INFO: Pod "downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409" satisfied condition "Succeeded or Failed"
Nov 26 12:41:46.761: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409 container client-container: <nil>
STEP: delete the pod 11/26/22 12:41:46.771
Nov 26 12:41:46.790: INFO: Waiting for pod downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409 to disappear
Nov 26 12:41:46.797: INFO: Pod downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 12:41:46.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9874" for this suite. 11/26/22 12:41:46.805
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":198,"skipped":3719,"failed":0}
------------------------------
â€¢ [4.123 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:42.691
    Nov 26 12:41:42.691: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:41:42.692
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:42.71
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:42.717
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:41:42.722
    Nov 26 12:41:42.734: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409" in namespace "projected-9874" to be "Succeeded or Failed"
    Nov 26 12:41:42.750: INFO: Pod "downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409": Phase="Pending", Reason="", readiness=false. Elapsed: 15.447781ms
    Nov 26 12:41:44.758: INFO: Pod "downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023229531s
    Nov 26 12:41:46.756: INFO: Pod "downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021873175s
    STEP: Saw pod success 11/26/22 12:41:46.757
    Nov 26 12:41:46.757: INFO: Pod "downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409" satisfied condition "Succeeded or Failed"
    Nov 26 12:41:46.761: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409 container client-container: <nil>
    STEP: delete the pod 11/26/22 12:41:46.771
    Nov 26 12:41:46.790: INFO: Waiting for pod downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409 to disappear
    Nov 26 12:41:46.797: INFO: Pod downwardapi-volume-f43f8767-9144-4bc7-9c97-faf448fa7409 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 12:41:46.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9874" for this suite. 11/26/22 12:41:46.805
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:46.816
Nov 26 12:41:46.817: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:41:46.818
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:46.841
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:46.853
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:41:46.869
Nov 26 12:41:46.885: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a" in namespace "projected-2063" to be "Succeeded or Failed"
Nov 26 12:41:46.893: INFO: Pod "downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.615998ms
Nov 26 12:41:48.900: INFO: Pod "downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014614871s
Nov 26 12:41:50.900: INFO: Pod "downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014972111s
STEP: Saw pod success 11/26/22 12:41:50.9
Nov 26 12:41:50.901: INFO: Pod "downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a" satisfied condition "Succeeded or Failed"
Nov 26 12:41:50.906: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a container client-container: <nil>
STEP: delete the pod 11/26/22 12:41:50.916
Nov 26 12:41:50.938: INFO: Waiting for pod downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a to disappear
Nov 26 12:41:50.943: INFO: Pod downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 12:41:50.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2063" for this suite. 11/26/22 12:41:50.95
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":199,"skipped":3726,"failed":0}
------------------------------
â€¢ [4.144 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:46.816
    Nov 26 12:41:46.817: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:41:46.818
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:46.841
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:46.853
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:41:46.869
    Nov 26 12:41:46.885: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a" in namespace "projected-2063" to be "Succeeded or Failed"
    Nov 26 12:41:46.893: INFO: Pod "downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.615998ms
    Nov 26 12:41:48.900: INFO: Pod "downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014614871s
    Nov 26 12:41:50.900: INFO: Pod "downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014972111s
    STEP: Saw pod success 11/26/22 12:41:50.9
    Nov 26 12:41:50.901: INFO: Pod "downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a" satisfied condition "Succeeded or Failed"
    Nov 26 12:41:50.906: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a container client-container: <nil>
    STEP: delete the pod 11/26/22 12:41:50.916
    Nov 26 12:41:50.938: INFO: Waiting for pod downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a to disappear
    Nov 26 12:41:50.943: INFO: Pod downwardapi-volume-9d9fecc8-1f89-46e6-b0c2-1122e11bae4a no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 12:41:50.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2063" for this suite. 11/26/22 12:41:50.95
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:50.963
Nov 26 12:41:50.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:41:50.965
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:50.987
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:50.993
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 11/26/22 12:41:51.002
Nov 26 12:41:51.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1916 cluster-info'
Nov 26 12:41:51.093: INFO: stderr: ""
Nov 26 12:41:51.093: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:41:51.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1916" for this suite. 11/26/22 12:41:51.099
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":200,"skipped":3734,"failed":0}
------------------------------
â€¢ [0.147 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:50.963
    Nov 26 12:41:50.963: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:41:50.965
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:50.987
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:50.993
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 11/26/22 12:41:51.002
    Nov 26 12:41:51.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1916 cluster-info'
    Nov 26 12:41:51.093: INFO: stderr: ""
    Nov 26 12:41:51.093: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:41:51.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1916" for this suite. 11/26/22 12:41:51.099
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:51.111
Nov 26 12:41:51.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:41:51.112
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:51.136
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:51.15
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 11/26/22 12:41:51.155
Nov 26 12:41:51.173: INFO: Waiting up to 5m0s for pod "pod-9af14665-3f62-4c2f-b58f-d34548d6e460" in namespace "emptydir-4451" to be "Succeeded or Failed"
Nov 26 12:41:51.183: INFO: Pod "pod-9af14665-3f62-4c2f-b58f-d34548d6e460": Phase="Pending", Reason="", readiness=false. Elapsed: 9.62282ms
Nov 26 12:41:53.192: INFO: Pod "pod-9af14665-3f62-4c2f-b58f-d34548d6e460": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018040114s
Nov 26 12:41:55.190: INFO: Pod "pod-9af14665-3f62-4c2f-b58f-d34548d6e460": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016425803s
STEP: Saw pod success 11/26/22 12:41:55.19
Nov 26 12:41:55.190: INFO: Pod "pod-9af14665-3f62-4c2f-b58f-d34548d6e460" satisfied condition "Succeeded or Failed"
Nov 26 12:41:55.196: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-9af14665-3f62-4c2f-b58f-d34548d6e460 container test-container: <nil>
STEP: delete the pod 11/26/22 12:41:55.207
Nov 26 12:41:55.230: INFO: Waiting for pod pod-9af14665-3f62-4c2f-b58f-d34548d6e460 to disappear
Nov 26 12:41:55.237: INFO: Pod pod-9af14665-3f62-4c2f-b58f-d34548d6e460 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:41:55.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4451" for this suite. 11/26/22 12:41:55.243
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":201,"skipped":3739,"failed":0}
------------------------------
â€¢ [4.144 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:51.111
    Nov 26 12:41:51.111: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:41:51.112
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:51.136
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:51.15
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 11/26/22 12:41:51.155
    Nov 26 12:41:51.173: INFO: Waiting up to 5m0s for pod "pod-9af14665-3f62-4c2f-b58f-d34548d6e460" in namespace "emptydir-4451" to be "Succeeded or Failed"
    Nov 26 12:41:51.183: INFO: Pod "pod-9af14665-3f62-4c2f-b58f-d34548d6e460": Phase="Pending", Reason="", readiness=false. Elapsed: 9.62282ms
    Nov 26 12:41:53.192: INFO: Pod "pod-9af14665-3f62-4c2f-b58f-d34548d6e460": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018040114s
    Nov 26 12:41:55.190: INFO: Pod "pod-9af14665-3f62-4c2f-b58f-d34548d6e460": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016425803s
    STEP: Saw pod success 11/26/22 12:41:55.19
    Nov 26 12:41:55.190: INFO: Pod "pod-9af14665-3f62-4c2f-b58f-d34548d6e460" satisfied condition "Succeeded or Failed"
    Nov 26 12:41:55.196: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-9af14665-3f62-4c2f-b58f-d34548d6e460 container test-container: <nil>
    STEP: delete the pod 11/26/22 12:41:55.207
    Nov 26 12:41:55.230: INFO: Waiting for pod pod-9af14665-3f62-4c2f-b58f-d34548d6e460 to disappear
    Nov 26 12:41:55.237: INFO: Pod pod-9af14665-3f62-4c2f-b58f-d34548d6e460 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:41:55.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4451" for this suite. 11/26/22 12:41:55.243
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:55.259
Nov 26 12:41:55.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename daemonsets 11/26/22 12:41:55.261
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:55.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:55.293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 11/26/22 12:41:55.338
STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 12:41:55.347
Nov 26 12:41:55.357: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:41:55.357: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:41:55.362: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:41:55.363: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:41:56.369: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:41:56.369: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:41:56.377: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:41:56.377: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:41:57.370: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:41:57.370: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 12:41:57.377: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov 26 12:41:57.377: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 11/26/22 12:41:57.384
Nov 26 12:41:57.391: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 11/26/22 12:41:57.392
Nov 26 12:41:57.406: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 11/26/22 12:41:57.406
Nov 26 12:41:57.409: INFO: Observed &DaemonSet event: ADDED
Nov 26 12:41:57.409: INFO: Observed &DaemonSet event: MODIFIED
Nov 26 12:41:57.410: INFO: Observed &DaemonSet event: MODIFIED
Nov 26 12:41:57.410: INFO: Observed &DaemonSet event: MODIFIED
Nov 26 12:41:57.410: INFO: Observed &DaemonSet event: MODIFIED
Nov 26 12:41:57.410: INFO: Found daemon set daemon-set in namespace daemonsets-556 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 26 12:41:57.410: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 11/26/22 12:41:57.41
STEP: watching for the daemon set status to be patched 11/26/22 12:41:57.423
Nov 26 12:41:57.427: INFO: Observed &DaemonSet event: ADDED
Nov 26 12:41:57.428: INFO: Observed &DaemonSet event: MODIFIED
Nov 26 12:41:57.428: INFO: Observed &DaemonSet event: MODIFIED
Nov 26 12:41:57.428: INFO: Observed &DaemonSet event: MODIFIED
Nov 26 12:41:57.428: INFO: Observed &DaemonSet event: MODIFIED
Nov 26 12:41:57.428: INFO: Observed daemon set daemon-set in namespace daemonsets-556 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov 26 12:41:57.429: INFO: Observed &DaemonSet event: MODIFIED
Nov 26 12:41:57.429: INFO: Found daemon set daemon-set in namespace daemonsets-556 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Nov 26 12:41:57.429: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:41:57.436
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-556, will wait for the garbage collector to delete the pods 11/26/22 12:41:57.436
Nov 26 12:41:57.510: INFO: Deleting DaemonSet.extensions daemon-set took: 18.338592ms
Nov 26 12:41:57.611: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.084995ms
Nov 26 12:41:59.819: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:41:59.819: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 26 12:41:59.827: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22874"},"items":null}

Nov 26 12:41:59.831: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22874"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:41:59.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-556" for this suite. 11/26/22 12:41:59.858
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":202,"skipped":3761,"failed":0}
------------------------------
â€¢ [4.609 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:55.259
    Nov 26 12:41:55.260: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename daemonsets 11/26/22 12:41:55.261
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:55.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:55.293
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 11/26/22 12:41:55.338
    STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 12:41:55.347
    Nov 26 12:41:55.357: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:41:55.357: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:41:55.362: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:41:55.363: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:41:56.369: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:41:56.369: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:41:56.377: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:41:56.377: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:41:57.370: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:41:57.370: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 12:41:57.377: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov 26 12:41:57.377: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 11/26/22 12:41:57.384
    Nov 26 12:41:57.391: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 11/26/22 12:41:57.392
    Nov 26 12:41:57.406: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 11/26/22 12:41:57.406
    Nov 26 12:41:57.409: INFO: Observed &DaemonSet event: ADDED
    Nov 26 12:41:57.409: INFO: Observed &DaemonSet event: MODIFIED
    Nov 26 12:41:57.410: INFO: Observed &DaemonSet event: MODIFIED
    Nov 26 12:41:57.410: INFO: Observed &DaemonSet event: MODIFIED
    Nov 26 12:41:57.410: INFO: Observed &DaemonSet event: MODIFIED
    Nov 26 12:41:57.410: INFO: Found daemon set daemon-set in namespace daemonsets-556 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 26 12:41:57.410: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 11/26/22 12:41:57.41
    STEP: watching for the daemon set status to be patched 11/26/22 12:41:57.423
    Nov 26 12:41:57.427: INFO: Observed &DaemonSet event: ADDED
    Nov 26 12:41:57.428: INFO: Observed &DaemonSet event: MODIFIED
    Nov 26 12:41:57.428: INFO: Observed &DaemonSet event: MODIFIED
    Nov 26 12:41:57.428: INFO: Observed &DaemonSet event: MODIFIED
    Nov 26 12:41:57.428: INFO: Observed &DaemonSet event: MODIFIED
    Nov 26 12:41:57.428: INFO: Observed daemon set daemon-set in namespace daemonsets-556 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov 26 12:41:57.429: INFO: Observed &DaemonSet event: MODIFIED
    Nov 26 12:41:57.429: INFO: Found daemon set daemon-set in namespace daemonsets-556 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Nov 26 12:41:57.429: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:41:57.436
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-556, will wait for the garbage collector to delete the pods 11/26/22 12:41:57.436
    Nov 26 12:41:57.510: INFO: Deleting DaemonSet.extensions daemon-set took: 18.338592ms
    Nov 26 12:41:57.611: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.084995ms
    Nov 26 12:41:59.819: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:41:59.819: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 26 12:41:59.827: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"22874"},"items":null}

    Nov 26 12:41:59.831: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"22874"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:41:59.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-556" for this suite. 11/26/22 12:41:59.858
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:41:59.87
Nov 26 12:41:59.870: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-probe 11/26/22 12:41:59.871
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:59.891
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:59.902
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-55db6205-631c-4417-862f-239eaf3cdf7d in namespace container-probe-7610 11/26/22 12:41:59.913
Nov 26 12:41:59.927: INFO: Waiting up to 5m0s for pod "liveness-55db6205-631c-4417-862f-239eaf3cdf7d" in namespace "container-probe-7610" to be "not pending"
Nov 26 12:41:59.940: INFO: Pod "liveness-55db6205-631c-4417-862f-239eaf3cdf7d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.411328ms
Nov 26 12:42:01.946: INFO: Pod "liveness-55db6205-631c-4417-862f-239eaf3cdf7d": Phase="Running", Reason="", readiness=true. Elapsed: 2.019257369s
Nov 26 12:42:01.946: INFO: Pod "liveness-55db6205-631c-4417-862f-239eaf3cdf7d" satisfied condition "not pending"
Nov 26 12:42:01.947: INFO: Started pod liveness-55db6205-631c-4417-862f-239eaf3cdf7d in namespace container-probe-7610
STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 12:42:01.947
Nov 26 12:42:01.952: INFO: Initial restart count of pod liveness-55db6205-631c-4417-862f-239eaf3cdf7d is 0
STEP: deleting the pod 11/26/22 12:46:02.834
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 26 12:46:02.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7610" for this suite. 11/26/22 12:46:02.869
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":203,"skipped":3794,"failed":0}
------------------------------
â€¢ [SLOW TEST] [243.011 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:41:59.87
    Nov 26 12:41:59.870: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-probe 11/26/22 12:41:59.871
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:41:59.891
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:41:59.902
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-55db6205-631c-4417-862f-239eaf3cdf7d in namespace container-probe-7610 11/26/22 12:41:59.913
    Nov 26 12:41:59.927: INFO: Waiting up to 5m0s for pod "liveness-55db6205-631c-4417-862f-239eaf3cdf7d" in namespace "container-probe-7610" to be "not pending"
    Nov 26 12:41:59.940: INFO: Pod "liveness-55db6205-631c-4417-862f-239eaf3cdf7d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.411328ms
    Nov 26 12:42:01.946: INFO: Pod "liveness-55db6205-631c-4417-862f-239eaf3cdf7d": Phase="Running", Reason="", readiness=true. Elapsed: 2.019257369s
    Nov 26 12:42:01.946: INFO: Pod "liveness-55db6205-631c-4417-862f-239eaf3cdf7d" satisfied condition "not pending"
    Nov 26 12:42:01.947: INFO: Started pod liveness-55db6205-631c-4417-862f-239eaf3cdf7d in namespace container-probe-7610
    STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 12:42:01.947
    Nov 26 12:42:01.952: INFO: Initial restart count of pod liveness-55db6205-631c-4417-862f-239eaf3cdf7d is 0
    STEP: deleting the pod 11/26/22 12:46:02.834
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 26 12:46:02.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7610" for this suite. 11/26/22 12:46:02.869
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:46:02.884
Nov 26 12:46:02.884: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 12:46:02.885
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:46:02.91
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:46:02.918
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:46:02.923
Nov 26 12:46:02.938: INFO: Waiting up to 5m0s for pod "downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09" in namespace "downward-api-6376" to be "Succeeded or Failed"
Nov 26 12:46:02.947: INFO: Pod "downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09": Phase="Pending", Reason="", readiness=false. Elapsed: 9.022389ms
Nov 26 12:46:04.953: INFO: Pod "downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014576905s
Nov 26 12:46:06.954: INFO: Pod "downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015621015s
STEP: Saw pod success 11/26/22 12:46:06.954
Nov 26 12:46:06.954: INFO: Pod "downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09" satisfied condition "Succeeded or Failed"
Nov 26 12:46:06.961: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09 container client-container: <nil>
STEP: delete the pod 11/26/22 12:46:06.982
Nov 26 12:46:07.001: INFO: Waiting for pod downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09 to disappear
Nov 26 12:46:07.009: INFO: Pod downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 12:46:07.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6376" for this suite. 11/26/22 12:46:07.023
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":204,"skipped":3808,"failed":0}
------------------------------
â€¢ [4.153 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:46:02.884
    Nov 26 12:46:02.884: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 12:46:02.885
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:46:02.91
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:46:02.918
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:46:02.923
    Nov 26 12:46:02.938: INFO: Waiting up to 5m0s for pod "downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09" in namespace "downward-api-6376" to be "Succeeded or Failed"
    Nov 26 12:46:02.947: INFO: Pod "downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09": Phase="Pending", Reason="", readiness=false. Elapsed: 9.022389ms
    Nov 26 12:46:04.953: INFO: Pod "downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014576905s
    Nov 26 12:46:06.954: INFO: Pod "downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015621015s
    STEP: Saw pod success 11/26/22 12:46:06.954
    Nov 26 12:46:06.954: INFO: Pod "downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09" satisfied condition "Succeeded or Failed"
    Nov 26 12:46:06.961: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09 container client-container: <nil>
    STEP: delete the pod 11/26/22 12:46:06.982
    Nov 26 12:46:07.001: INFO: Waiting for pod downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09 to disappear
    Nov 26 12:46:07.009: INFO: Pod downwardapi-volume-776a2846-5390-44dc-9d5b-80adcb2fbb09 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 12:46:07.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6376" for this suite. 11/26/22 12:46:07.023
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:46:07.04
Nov 26 12:46:07.040: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-runtime 11/26/22 12:46:07.041
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:46:07.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:46:07.071
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 11/26/22 12:46:07.078
STEP: wait for the container to reach Succeeded 11/26/22 12:46:07.091
STEP: get the container status 11/26/22 12:46:11.126
STEP: the container should be terminated 11/26/22 12:46:11.13
STEP: the termination message should be set 11/26/22 12:46:11.13
Nov 26 12:46:11.131: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 11/26/22 12:46:11.131
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 26 12:46:11.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8585" for this suite. 11/26/22 12:46:11.169
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":205,"skipped":3833,"failed":0}
------------------------------
â€¢ [4.143 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:46:07.04
    Nov 26 12:46:07.040: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-runtime 11/26/22 12:46:07.041
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:46:07.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:46:07.071
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 11/26/22 12:46:07.078
    STEP: wait for the container to reach Succeeded 11/26/22 12:46:07.091
    STEP: get the container status 11/26/22 12:46:11.126
    STEP: the container should be terminated 11/26/22 12:46:11.13
    STEP: the termination message should be set 11/26/22 12:46:11.13
    Nov 26 12:46:11.131: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 11/26/22 12:46:11.131
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 26 12:46:11.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-8585" for this suite. 11/26/22 12:46:11.169
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:46:11.188
Nov 26 12:46:11.188: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-webhook 11/26/22 12:46:11.189
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:46:11.211
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:46:11.22
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 11/26/22 12:46:11.224
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/26/22 12:46:12.264
STEP: Deploying the custom resource conversion webhook pod 11/26/22 12:46:12.276
STEP: Wait for the deployment to be ready 11/26/22 12:46:12.304
Nov 26 12:46:12.321: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/26/22 12:46:14.34
STEP: Verifying the service has paired with the endpoint 11/26/22 12:46:14.424
Nov 26 12:46:15.424: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Nov 26 12:46:15.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Creating a v1 custom resource 11/26/22 12:46:18.05
STEP: Create a v2 custom resource 11/26/22 12:46:18.079
STEP: List CRs in v1 11/26/22 12:46:18.159
STEP: List CRs in v2 11/26/22 12:46:18.167
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:46:18.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2548" for this suite. 11/26/22 12:46:18.707
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":206,"skipped":3879,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.622 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:46:11.188
    Nov 26 12:46:11.188: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-webhook 11/26/22 12:46:11.189
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:46:11.211
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:46:11.22
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 11/26/22 12:46:11.224
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/26/22 12:46:12.264
    STEP: Deploying the custom resource conversion webhook pod 11/26/22 12:46:12.276
    STEP: Wait for the deployment to be ready 11/26/22 12:46:12.304
    Nov 26 12:46:12.321: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/26/22 12:46:14.34
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:46:14.424
    Nov 26 12:46:15.424: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Nov 26 12:46:15.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Creating a v1 custom resource 11/26/22 12:46:18.05
    STEP: Create a v2 custom resource 11/26/22 12:46:18.079
    STEP: List CRs in v1 11/26/22 12:46:18.159
    STEP: List CRs in v2 11/26/22 12:46:18.167
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:46:18.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-2548" for this suite. 11/26/22 12:46:18.707
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:46:18.811
Nov 26 12:46:18.811: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename gc 11/26/22 12:46:18.812
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:46:18.858
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:46:18.865
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 11/26/22 12:46:18.879
STEP: Wait for the Deployment to create new ReplicaSet 11/26/22 12:46:18.895
STEP: delete the deployment 11/26/22 12:46:18.903
STEP: wait for all rs to be garbage collected 11/26/22 12:46:18.932
STEP: expected 0 pods, got 2 pods 11/26/22 12:46:18.974
STEP: Gathering metrics 11/26/22 12:46:19.496
W1126 12:46:19.506620      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 26 12:46:19.507: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 26 12:46:19.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-87" for this suite. 11/26/22 12:46:19.514
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":207,"skipped":3882,"failed":0}
------------------------------
â€¢ [0.715 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:46:18.811
    Nov 26 12:46:18.811: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename gc 11/26/22 12:46:18.812
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:46:18.858
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:46:18.865
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 11/26/22 12:46:18.879
    STEP: Wait for the Deployment to create new ReplicaSet 11/26/22 12:46:18.895
    STEP: delete the deployment 11/26/22 12:46:18.903
    STEP: wait for all rs to be garbage collected 11/26/22 12:46:18.932
    STEP: expected 0 pods, got 2 pods 11/26/22 12:46:18.974
    STEP: Gathering metrics 11/26/22 12:46:19.496
    W1126 12:46:19.506620      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 26 12:46:19.507: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 26 12:46:19.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-87" for this suite. 11/26/22 12:46:19.514
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:46:19.529
Nov 26 12:46:19.529: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sched-preemption 11/26/22 12:46:19.53
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:46:19.569
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:46:19.576
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 26 12:46:19.708: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 26 12:47:19.746: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 11/26/22 12:47:19.751
Nov 26 12:47:19.799: INFO: Created pod: pod0-0-sched-preemption-low-priority
Nov 26 12:47:19.815: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Nov 26 12:47:19.852: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Nov 26 12:47:19.867: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Nov 26 12:47:19.902: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Nov 26 12:47:19.915: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 11/26/22 12:47:19.916
Nov 26 12:47:19.916: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-2704" to be "running"
Nov 26 12:47:19.932: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 16.355493ms
Nov 26 12:47:21.940: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024124607s
Nov 26 12:47:23.940: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024205555s
Nov 26 12:47:25.939: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023394617s
Nov 26 12:47:27.943: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.026778571s
Nov 26 12:47:29.939: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.022907092s
Nov 26 12:47:31.940: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.024042256s
Nov 26 12:47:31.940: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Nov 26 12:47:31.940: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-2704" to be "running"
Nov 26 12:47:31.946: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.831554ms
Nov 26 12:47:31.946: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 26 12:47:31.946: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-2704" to be "running"
Nov 26 12:47:31.951: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.732335ms
Nov 26 12:47:31.951: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 26 12:47:31.951: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-2704" to be "running"
Nov 26 12:47:31.956: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.070691ms
Nov 26 12:47:31.956: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 26 12:47:31.956: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-2704" to be "running"
Nov 26 12:47:31.962: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.687236ms
Nov 26 12:47:31.962: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 26 12:47:31.962: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-2704" to be "running"
Nov 26 12:47:31.967: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.861473ms
Nov 26 12:47:31.967: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 11/26/22 12:47:31.967
Nov 26 12:47:31.979: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-2704" to be "running"
Nov 26 12:47:31.984: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.081761ms
Nov 26 12:47:33.990: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011314385s
Nov 26 12:47:35.991: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.011877313s
Nov 26 12:47:35.991: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:47:36.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-2704" for this suite. 11/26/22 12:47:36.04
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":208,"skipped":3885,"failed":0}
------------------------------
â€¢ [SLOW TEST] [76.604 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:46:19.529
    Nov 26 12:46:19.529: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sched-preemption 11/26/22 12:46:19.53
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:46:19.569
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:46:19.576
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 26 12:46:19.708: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 26 12:47:19.746: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 11/26/22 12:47:19.751
    Nov 26 12:47:19.799: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Nov 26 12:47:19.815: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Nov 26 12:47:19.852: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Nov 26 12:47:19.867: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Nov 26 12:47:19.902: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Nov 26 12:47:19.915: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 11/26/22 12:47:19.916
    Nov 26 12:47:19.916: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-2704" to be "running"
    Nov 26 12:47:19.932: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 16.355493ms
    Nov 26 12:47:21.940: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024124607s
    Nov 26 12:47:23.940: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.024205555s
    Nov 26 12:47:25.939: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023394617s
    Nov 26 12:47:27.943: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.026778571s
    Nov 26 12:47:29.939: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.022907092s
    Nov 26 12:47:31.940: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.024042256s
    Nov 26 12:47:31.940: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Nov 26 12:47:31.940: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-2704" to be "running"
    Nov 26 12:47:31.946: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.831554ms
    Nov 26 12:47:31.946: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 26 12:47:31.946: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-2704" to be "running"
    Nov 26 12:47:31.951: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.732335ms
    Nov 26 12:47:31.951: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 26 12:47:31.951: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-2704" to be "running"
    Nov 26 12:47:31.956: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.070691ms
    Nov 26 12:47:31.956: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 26 12:47:31.956: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-2704" to be "running"
    Nov 26 12:47:31.962: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.687236ms
    Nov 26 12:47:31.962: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 26 12:47:31.962: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-2704" to be "running"
    Nov 26 12:47:31.967: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.861473ms
    Nov 26 12:47:31.967: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 11/26/22 12:47:31.967
    Nov 26 12:47:31.979: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-2704" to be "running"
    Nov 26 12:47:31.984: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.081761ms
    Nov 26 12:47:33.990: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011314385s
    Nov 26 12:47:35.991: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.011877313s
    Nov 26 12:47:35.991: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:47:36.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-2704" for this suite. 11/26/22 12:47:36.04
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:47:36.134
Nov 26 12:47:36.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:47:36.135
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:47:36.16
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:47:36.168
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:47:36.201
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:47:36.824
STEP: Deploying the webhook pod 11/26/22 12:47:36.838
STEP: Wait for the deployment to be ready 11/26/22 12:47:36.86
Nov 26 12:47:36.873: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/26/22 12:47:38.892
STEP: Verifying the service has paired with the endpoint 11/26/22 12:47:38.913
Nov 26 12:47:39.913: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 11/26/22 12:47:39.92
STEP: create a pod that should be updated by the webhook 11/26/22 12:47:40.009
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:47:40.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2313" for this suite. 11/26/22 12:47:40.053
STEP: Destroying namespace "webhook-2313-markers" for this suite. 11/26/22 12:47:40.071
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":209,"skipped":3892,"failed":0}
------------------------------
â€¢ [4.061 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:47:36.134
    Nov 26 12:47:36.134: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:47:36.135
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:47:36.16
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:47:36.168
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:47:36.201
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:47:36.824
    STEP: Deploying the webhook pod 11/26/22 12:47:36.838
    STEP: Wait for the deployment to be ready 11/26/22 12:47:36.86
    Nov 26 12:47:36.873: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/26/22 12:47:38.892
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:47:38.913
    Nov 26 12:47:39.913: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 11/26/22 12:47:39.92
    STEP: create a pod that should be updated by the webhook 11/26/22 12:47:40.009
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:47:40.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2313" for this suite. 11/26/22 12:47:40.053
    STEP: Destroying namespace "webhook-2313-markers" for this suite. 11/26/22 12:47:40.071
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:47:40.199
Nov 26 12:47:40.200: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 12:47:40.201
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:47:40.235
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:47:40.24
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 11/26/22 12:47:40.245
Nov 26 12:47:40.258: INFO: Waiting up to 5m0s for pod "pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052" in namespace "pods-1737" to be "running and ready"
Nov 26 12:47:40.273: INFO: Pod "pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052": Phase="Pending", Reason="", readiness=false. Elapsed: 15.175281ms
Nov 26 12:47:40.273: INFO: The phase of Pod pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:47:42.292: INFO: Pod "pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052": Phase="Running", Reason="", readiness=true. Elapsed: 2.033910591s
Nov 26 12:47:42.292: INFO: The phase of Pod pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052 is Running (Ready = true)
Nov 26 12:47:42.292: INFO: Pod "pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052" satisfied condition "running and ready"
Nov 26 12:47:42.306: INFO: Pod pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052 has hostIP: 172.31.43.82
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 26 12:47:42.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1737" for this suite. 11/26/22 12:47:42.315
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":210,"skipped":3919,"failed":0}
------------------------------
â€¢ [2.128 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:47:40.199
    Nov 26 12:47:40.200: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 12:47:40.201
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:47:40.235
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:47:40.24
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 11/26/22 12:47:40.245
    Nov 26 12:47:40.258: INFO: Waiting up to 5m0s for pod "pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052" in namespace "pods-1737" to be "running and ready"
    Nov 26 12:47:40.273: INFO: Pod "pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052": Phase="Pending", Reason="", readiness=false. Elapsed: 15.175281ms
    Nov 26 12:47:40.273: INFO: The phase of Pod pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:47:42.292: INFO: Pod "pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052": Phase="Running", Reason="", readiness=true. Elapsed: 2.033910591s
    Nov 26 12:47:42.292: INFO: The phase of Pod pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052 is Running (Ready = true)
    Nov 26 12:47:42.292: INFO: Pod "pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052" satisfied condition "running and ready"
    Nov 26 12:47:42.306: INFO: Pod pod-hostip-f78906ed-bf4e-4454-ac92-1df578964052 has hostIP: 172.31.43.82
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 26 12:47:42.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-1737" for this suite. 11/26/22 12:47:42.315
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:47:42.337
Nov 26 12:47:42.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename subpath 11/26/22 12:47:42.339
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:47:42.377
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:47:42.383
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/26/22 12:47:42.389
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-hn2h 11/26/22 12:47:42.421
STEP: Creating a pod to test atomic-volume-subpath 11/26/22 12:47:42.421
Nov 26 12:47:42.440: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hn2h" in namespace "subpath-4650" to be "Succeeded or Failed"
Nov 26 12:47:42.446: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Pending", Reason="", readiness=false. Elapsed: 6.215134ms
Nov 26 12:47:44.453: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 2.013344473s
Nov 26 12:47:46.454: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 4.013717831s
Nov 26 12:47:48.453: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 6.013355463s
Nov 26 12:47:50.453: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 8.012660562s
Nov 26 12:47:52.454: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 10.013691452s
Nov 26 12:47:54.453: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 12.012763542s
Nov 26 12:47:56.455: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 14.01484016s
Nov 26 12:47:58.456: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 16.016149367s
Nov 26 12:48:00.455: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 18.015078585s
Nov 26 12:48:02.454: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 20.01446169s
Nov 26 12:48:04.453: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=false. Elapsed: 22.013032162s
Nov 26 12:48:06.463: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023068062s
STEP: Saw pod success 11/26/22 12:48:06.463
Nov 26 12:48:06.463: INFO: Pod "pod-subpath-test-configmap-hn2h" satisfied condition "Succeeded or Failed"
Nov 26 12:48:06.469: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-subpath-test-configmap-hn2h container test-container-subpath-configmap-hn2h: <nil>
STEP: delete the pod 11/26/22 12:48:06.488
Nov 26 12:48:06.509: INFO: Waiting for pod pod-subpath-test-configmap-hn2h to disappear
Nov 26 12:48:06.516: INFO: Pod pod-subpath-test-configmap-hn2h no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hn2h 11/26/22 12:48:06.516
Nov 26 12:48:06.516: INFO: Deleting pod "pod-subpath-test-configmap-hn2h" in namespace "subpath-4650"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 26 12:48:06.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4650" for this suite. 11/26/22 12:48:06.53
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":211,"skipped":3984,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.204 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:47:42.337
    Nov 26 12:47:42.337: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename subpath 11/26/22 12:47:42.339
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:47:42.377
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:47:42.383
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/26/22 12:47:42.389
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-hn2h 11/26/22 12:47:42.421
    STEP: Creating a pod to test atomic-volume-subpath 11/26/22 12:47:42.421
    Nov 26 12:47:42.440: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hn2h" in namespace "subpath-4650" to be "Succeeded or Failed"
    Nov 26 12:47:42.446: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Pending", Reason="", readiness=false. Elapsed: 6.215134ms
    Nov 26 12:47:44.453: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 2.013344473s
    Nov 26 12:47:46.454: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 4.013717831s
    Nov 26 12:47:48.453: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 6.013355463s
    Nov 26 12:47:50.453: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 8.012660562s
    Nov 26 12:47:52.454: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 10.013691452s
    Nov 26 12:47:54.453: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 12.012763542s
    Nov 26 12:47:56.455: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 14.01484016s
    Nov 26 12:47:58.456: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 16.016149367s
    Nov 26 12:48:00.455: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 18.015078585s
    Nov 26 12:48:02.454: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=true. Elapsed: 20.01446169s
    Nov 26 12:48:04.453: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Running", Reason="", readiness=false. Elapsed: 22.013032162s
    Nov 26 12:48:06.463: INFO: Pod "pod-subpath-test-configmap-hn2h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.023068062s
    STEP: Saw pod success 11/26/22 12:48:06.463
    Nov 26 12:48:06.463: INFO: Pod "pod-subpath-test-configmap-hn2h" satisfied condition "Succeeded or Failed"
    Nov 26 12:48:06.469: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-subpath-test-configmap-hn2h container test-container-subpath-configmap-hn2h: <nil>
    STEP: delete the pod 11/26/22 12:48:06.488
    Nov 26 12:48:06.509: INFO: Waiting for pod pod-subpath-test-configmap-hn2h to disappear
    Nov 26 12:48:06.516: INFO: Pod pod-subpath-test-configmap-hn2h no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-hn2h 11/26/22 12:48:06.516
    Nov 26 12:48:06.516: INFO: Deleting pod "pod-subpath-test-configmap-hn2h" in namespace "subpath-4650"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 26 12:48:06.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-4650" for this suite. 11/26/22 12:48:06.53
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:48:06.546
Nov 26 12:48:06.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:48:06.547
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:06.575
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:06.58
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 11/26/22 12:48:06.587
Nov 26 12:48:06.604: INFO: Waiting up to 5m0s for pod "pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b" in namespace "emptydir-950" to be "Succeeded or Failed"
Nov 26 12:48:06.610: INFO: Pod "pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.654075ms
Nov 26 12:48:08.619: INFO: Pod "pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015145495s
Nov 26 12:48:10.617: INFO: Pod "pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012985273s
STEP: Saw pod success 11/26/22 12:48:10.617
Nov 26 12:48:10.617: INFO: Pod "pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b" satisfied condition "Succeeded or Failed"
Nov 26 12:48:10.623: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b container test-container: <nil>
STEP: delete the pod 11/26/22 12:48:10.632
Nov 26 12:48:10.652: INFO: Waiting for pod pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b to disappear
Nov 26 12:48:10.657: INFO: Pod pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:48:10.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-950" for this suite. 11/26/22 12:48:10.664
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":212,"skipped":4020,"failed":0}
------------------------------
â€¢ [4.128 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:48:06.546
    Nov 26 12:48:06.546: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:48:06.547
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:06.575
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:06.58
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 11/26/22 12:48:06.587
    Nov 26 12:48:06.604: INFO: Waiting up to 5m0s for pod "pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b" in namespace "emptydir-950" to be "Succeeded or Failed"
    Nov 26 12:48:06.610: INFO: Pod "pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.654075ms
    Nov 26 12:48:08.619: INFO: Pod "pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015145495s
    Nov 26 12:48:10.617: INFO: Pod "pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012985273s
    STEP: Saw pod success 11/26/22 12:48:10.617
    Nov 26 12:48:10.617: INFO: Pod "pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b" satisfied condition "Succeeded or Failed"
    Nov 26 12:48:10.623: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b container test-container: <nil>
    STEP: delete the pod 11/26/22 12:48:10.632
    Nov 26 12:48:10.652: INFO: Waiting for pod pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b to disappear
    Nov 26 12:48:10.657: INFO: Pod pod-3601b55f-e5a0-426e-8c5e-fc4611dc755b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:48:10.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-950" for this suite. 11/26/22 12:48:10.664
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:48:10.676
Nov 26 12:48:10.676: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 12:48:10.677
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:10.702
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:10.709
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 11/26/22 12:48:10.716
STEP: submitting the pod to kubernetes 11/26/22 12:48:10.716
STEP: verifying QOS class is set on the pod 11/26/22 12:48:10.729
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Nov 26 12:48:10.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4393" for this suite. 11/26/22 12:48:10.745
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":213,"skipped":4022,"failed":0}
------------------------------
â€¢ [0.081 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:48:10.676
    Nov 26 12:48:10.676: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 12:48:10.677
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:10.702
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:10.709
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 11/26/22 12:48:10.716
    STEP: submitting the pod to kubernetes 11/26/22 12:48:10.716
    STEP: verifying QOS class is set on the pod 11/26/22 12:48:10.729
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Nov 26 12:48:10.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4393" for this suite. 11/26/22 12:48:10.745
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:48:10.758
Nov 26 12:48:10.758: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:48:10.76
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:10.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:10.802
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 11/26/22 12:48:10.807
Nov 26 12:48:10.823: INFO: Waiting up to 5m0s for pod "pod-09a1de77-a62b-445a-8c6c-1772a4393264" in namespace "emptydir-909" to be "Succeeded or Failed"
Nov 26 12:48:10.839: INFO: Pod "pod-09a1de77-a62b-445a-8c6c-1772a4393264": Phase="Pending", Reason="", readiness=false. Elapsed: 15.830638ms
Nov 26 12:48:12.846: INFO: Pod "pod-09a1de77-a62b-445a-8c6c-1772a4393264": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022711795s
Nov 26 12:48:14.854: INFO: Pod "pod-09a1de77-a62b-445a-8c6c-1772a4393264": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031203028s
STEP: Saw pod success 11/26/22 12:48:14.854
Nov 26 12:48:14.854: INFO: Pod "pod-09a1de77-a62b-445a-8c6c-1772a4393264" satisfied condition "Succeeded or Failed"
Nov 26 12:48:14.860: INFO: Trying to get logs from node ip-172-31-29-104 pod pod-09a1de77-a62b-445a-8c6c-1772a4393264 container test-container: <nil>
STEP: delete the pod 11/26/22 12:48:14.884
Nov 26 12:48:14.904: INFO: Waiting for pod pod-09a1de77-a62b-445a-8c6c-1772a4393264 to disappear
Nov 26 12:48:14.910: INFO: Pod pod-09a1de77-a62b-445a-8c6c-1772a4393264 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:48:14.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-909" for this suite. 11/26/22 12:48:14.916
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":214,"skipped":4023,"failed":0}
------------------------------
â€¢ [4.168 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:48:10.758
    Nov 26 12:48:10.758: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:48:10.76
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:10.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:10.802
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 11/26/22 12:48:10.807
    Nov 26 12:48:10.823: INFO: Waiting up to 5m0s for pod "pod-09a1de77-a62b-445a-8c6c-1772a4393264" in namespace "emptydir-909" to be "Succeeded or Failed"
    Nov 26 12:48:10.839: INFO: Pod "pod-09a1de77-a62b-445a-8c6c-1772a4393264": Phase="Pending", Reason="", readiness=false. Elapsed: 15.830638ms
    Nov 26 12:48:12.846: INFO: Pod "pod-09a1de77-a62b-445a-8c6c-1772a4393264": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022711795s
    Nov 26 12:48:14.854: INFO: Pod "pod-09a1de77-a62b-445a-8c6c-1772a4393264": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031203028s
    STEP: Saw pod success 11/26/22 12:48:14.854
    Nov 26 12:48:14.854: INFO: Pod "pod-09a1de77-a62b-445a-8c6c-1772a4393264" satisfied condition "Succeeded or Failed"
    Nov 26 12:48:14.860: INFO: Trying to get logs from node ip-172-31-29-104 pod pod-09a1de77-a62b-445a-8c6c-1772a4393264 container test-container: <nil>
    STEP: delete the pod 11/26/22 12:48:14.884
    Nov 26 12:48:14.904: INFO: Waiting for pod pod-09a1de77-a62b-445a-8c6c-1772a4393264 to disappear
    Nov 26 12:48:14.910: INFO: Pod pod-09a1de77-a62b-445a-8c6c-1772a4393264 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:48:14.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-909" for this suite. 11/26/22 12:48:14.916
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:48:14.929
Nov 26 12:48:14.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 12:48:14.93
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:14.955
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:14.961
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-4b5234c6-0e07-4e0f-91f8-7eb4643a956f 11/26/22 12:48:14.968
STEP: Creating a pod to test consume secrets 11/26/22 12:48:14.979
Nov 26 12:48:14.991: INFO: Waiting up to 5m0s for pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00" in namespace "secrets-4131" to be "Succeeded or Failed"
Nov 26 12:48:15.004: INFO: Pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00": Phase="Pending", Reason="", readiness=false. Elapsed: 12.447316ms
Nov 26 12:48:17.010: INFO: Pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00": Phase="Running", Reason="", readiness=true. Elapsed: 2.019112953s
Nov 26 12:48:19.011: INFO: Pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00": Phase="Running", Reason="", readiness=false. Elapsed: 4.019198584s
Nov 26 12:48:21.012: INFO: Pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020993487s
STEP: Saw pod success 11/26/22 12:48:21.012
Nov 26 12:48:21.013: INFO: Pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00" satisfied condition "Succeeded or Failed"
Nov 26 12:48:21.018: INFO: Trying to get logs from node ip-172-31-29-104 pod pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00 container secret-volume-test: <nil>
STEP: delete the pod 11/26/22 12:48:21.03
Nov 26 12:48:21.047: INFO: Waiting for pod pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00 to disappear
Nov 26 12:48:21.054: INFO: Pod pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 26 12:48:21.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4131" for this suite. 11/26/22 12:48:21.059
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":215,"skipped":4034,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.142 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:48:14.929
    Nov 26 12:48:14.929: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 12:48:14.93
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:14.955
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:14.961
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-4b5234c6-0e07-4e0f-91f8-7eb4643a956f 11/26/22 12:48:14.968
    STEP: Creating a pod to test consume secrets 11/26/22 12:48:14.979
    Nov 26 12:48:14.991: INFO: Waiting up to 5m0s for pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00" in namespace "secrets-4131" to be "Succeeded or Failed"
    Nov 26 12:48:15.004: INFO: Pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00": Phase="Pending", Reason="", readiness=false. Elapsed: 12.447316ms
    Nov 26 12:48:17.010: INFO: Pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00": Phase="Running", Reason="", readiness=true. Elapsed: 2.019112953s
    Nov 26 12:48:19.011: INFO: Pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00": Phase="Running", Reason="", readiness=false. Elapsed: 4.019198584s
    Nov 26 12:48:21.012: INFO: Pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.020993487s
    STEP: Saw pod success 11/26/22 12:48:21.012
    Nov 26 12:48:21.013: INFO: Pod "pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00" satisfied condition "Succeeded or Failed"
    Nov 26 12:48:21.018: INFO: Trying to get logs from node ip-172-31-29-104 pod pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00 container secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:48:21.03
    Nov 26 12:48:21.047: INFO: Waiting for pod pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00 to disappear
    Nov 26 12:48:21.054: INFO: Pod pod-secrets-c6feb963-da3f-4b09-ac10-261503534c00 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 12:48:21.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4131" for this suite. 11/26/22 12:48:21.059
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:48:21.077
Nov 26 12:48:21.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename watch 11/26/22 12:48:21.078
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:21.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:21.107
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 11/26/22 12:48:21.121
STEP: starting a background goroutine to produce watch events 11/26/22 12:48:21.127
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 11/26/22 12:48:21.127
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 26 12:48:23.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8379" for this suite. 11/26/22 12:48:23.937
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":216,"skipped":4061,"failed":0}
------------------------------
â€¢ [2.920 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:48:21.077
    Nov 26 12:48:21.077: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename watch 11/26/22 12:48:21.078
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:21.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:21.107
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 11/26/22 12:48:21.121
    STEP: starting a background goroutine to produce watch events 11/26/22 12:48:21.127
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 11/26/22 12:48:21.127
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 26 12:48:23.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8379" for this suite. 11/26/22 12:48:23.937
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:48:24
Nov 26 12:48:24.000: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename deployment 11/26/22 12:48:24.001
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:24.023
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:24.029
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Nov 26 12:48:24.038: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 26 12:48:24.050: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 26 12:48:29.060: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/26/22 12:48:29.06
Nov 26 12:48:29.060: INFO: Creating deployment "test-rolling-update-deployment"
Nov 26 12:48:29.069: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 26 12:48:29.085: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 26 12:48:31.098: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 26 12:48:31.102: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 26 12:48:31.118: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9698  ef67fc1f-2b5f-4902-8a1d-c88f970be66e 24501 1 2022-11-26 12:48:29 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-11-26 12:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:48:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0012e4728 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-26 12:48:29 +0000 UTC,LastTransitionTime:2022-11-26 12:48:29 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-11-26 12:48:30 +0000 UTC,LastTransitionTime:2022-11-26 12:48:29 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 26 12:48:31.123: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-9698  5cafcd3c-9a49-439c-ab30-d138bcb027cf 24491 1 2022-11-26 12:48:29 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment ef67fc1f-2b5f-4902-8a1d-c88f970be66e 0xc00327b8b7 0xc00327b8b8}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ef67fc1f-2b5f-4902-8a1d-c88f970be66e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:48:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00327b968 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:48:31.123: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 26 12:48:31.124: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9698  62b09689-5639-4147-8002-af85c96b8cc9 24500 2 2022-11-26 12:48:24 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment ef67fc1f-2b5f-4902-8a1d-c88f970be66e 0xc00327b787 0xc00327b788}] [] [{e2e.test Update apps/v1 2022-11-26 12:48:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:48:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ef67fc1f-2b5f-4902-8a1d-c88f970be66e\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:48:30 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00327b848 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:48:31.129: INFO: Pod "test-rolling-update-deployment-78f575d8ff-5c92h" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-5c92h test-rolling-update-deployment-78f575d8ff- deployment-9698  37160f31-3777-40d2-b34f-dc1c87c11f69 24490 0 2022-11-26 12:48:29 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 5cafcd3c-9a49-439c-ab30-d138bcb027cf 0xc00327bde7 0xc00327bde8}] [] [{kube-controller-manager Update v1 2022-11-26 12:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5cafcd3c-9a49-439c-ab30-d138bcb027cf\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:48:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.35\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kw2ct,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kw2ct,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:48:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:48:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:48:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:48:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.35,StartTime:2022-11-26 12:48:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:48:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://3c71cee06c4aebde6e11b12d842fe94bb0856642fc510f026c5a2e9e919eaa2d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 26 12:48:31.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9698" for this suite. 11/26/22 12:48:31.135
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":217,"skipped":4073,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.145 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:48:24
    Nov 26 12:48:24.000: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename deployment 11/26/22 12:48:24.001
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:24.023
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:24.029
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Nov 26 12:48:24.038: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Nov 26 12:48:24.050: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 26 12:48:29.060: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/26/22 12:48:29.06
    Nov 26 12:48:29.060: INFO: Creating deployment "test-rolling-update-deployment"
    Nov 26 12:48:29.069: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Nov 26 12:48:29.085: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Nov 26 12:48:31.098: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Nov 26 12:48:31.102: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 26 12:48:31.118: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9698  ef67fc1f-2b5f-4902-8a1d-c88f970be66e 24501 1 2022-11-26 12:48:29 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-11-26 12:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:48:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0012e4728 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-26 12:48:29 +0000 UTC,LastTransitionTime:2022-11-26 12:48:29 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-11-26 12:48:30 +0000 UTC,LastTransitionTime:2022-11-26 12:48:29 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov 26 12:48:31.123: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-9698  5cafcd3c-9a49-439c-ab30-d138bcb027cf 24491 1 2022-11-26 12:48:29 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment ef67fc1f-2b5f-4902-8a1d-c88f970be66e 0xc00327b8b7 0xc00327b8b8}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ef67fc1f-2b5f-4902-8a1d-c88f970be66e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:48:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00327b968 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:48:31.123: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Nov 26 12:48:31.124: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9698  62b09689-5639-4147-8002-af85c96b8cc9 24500 2 2022-11-26 12:48:24 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment ef67fc1f-2b5f-4902-8a1d-c88f970be66e 0xc00327b787 0xc00327b788}] [] [{e2e.test Update apps/v1 2022-11-26 12:48:24 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:48:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"ef67fc1f-2b5f-4902-8a1d-c88f970be66e\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:48:30 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00327b848 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:48:31.129: INFO: Pod "test-rolling-update-deployment-78f575d8ff-5c92h" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-5c92h test-rolling-update-deployment-78f575d8ff- deployment-9698  37160f31-3777-40d2-b34f-dc1c87c11f69 24490 0 2022-11-26 12:48:29 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 5cafcd3c-9a49-439c-ab30-d138bcb027cf 0xc00327bde7 0xc00327bde8}] [] [{kube-controller-manager Update v1 2022-11-26 12:48:29 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5cafcd3c-9a49-439c-ab30-d138bcb027cf\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:48:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.35\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kw2ct,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kw2ct,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:48:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:48:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:48:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:48:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.35,StartTime:2022-11-26 12:48:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:48:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://3c71cee06c4aebde6e11b12d842fe94bb0856642fc510f026c5a2e9e919eaa2d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 26 12:48:31.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9698" for this suite. 11/26/22 12:48:31.135
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:48:31.147
Nov 26 12:48:31.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 12:48:31.149
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:31.172
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:31.176
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 11/26/22 12:48:31.182
STEP: Creating a ResourceQuota 11/26/22 12:48:36.189
STEP: Ensuring resource quota status is calculated 11/26/22 12:48:36.207
STEP: Creating a ReplicaSet 11/26/22 12:48:38.214
STEP: Ensuring resource quota status captures replicaset creation 11/26/22 12:48:38.234
STEP: Deleting a ReplicaSet 11/26/22 12:48:40.24
STEP: Ensuring resource quota status released usage 11/26/22 12:48:40.25
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 12:48:42.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6119" for this suite. 11/26/22 12:48:42.265
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":218,"skipped":4075,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.128 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:48:31.147
    Nov 26 12:48:31.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 12:48:31.149
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:31.172
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:31.176
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 11/26/22 12:48:31.182
    STEP: Creating a ResourceQuota 11/26/22 12:48:36.189
    STEP: Ensuring resource quota status is calculated 11/26/22 12:48:36.207
    STEP: Creating a ReplicaSet 11/26/22 12:48:38.214
    STEP: Ensuring resource quota status captures replicaset creation 11/26/22 12:48:38.234
    STEP: Deleting a ReplicaSet 11/26/22 12:48:40.24
    STEP: Ensuring resource quota status released usage 11/26/22 12:48:40.25
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 12:48:42.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6119" for this suite. 11/26/22 12:48:42.265
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:48:42.283
Nov 26 12:48:42.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 12:48:42.284
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:42.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:42.313
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 11/26/22 12:48:42.319
STEP: Creating a ResourceQuota 11/26/22 12:48:47.324
STEP: Ensuring resource quota status is calculated 11/26/22 12:48:47.334
STEP: Creating a Service 11/26/22 12:48:49.342
STEP: Creating a NodePort Service 11/26/22 12:48:49.374
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 11/26/22 12:48:49.415
STEP: Ensuring resource quota status captures service creation 11/26/22 12:48:49.459
STEP: Deleting Services 11/26/22 12:48:51.467
STEP: Ensuring resource quota status released usage 11/26/22 12:48:51.541
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 12:48:53.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7156" for this suite. 11/26/22 12:48:53.554
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":219,"skipped":4120,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.288 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:48:42.283
    Nov 26 12:48:42.283: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 12:48:42.284
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:42.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:42.313
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 11/26/22 12:48:42.319
    STEP: Creating a ResourceQuota 11/26/22 12:48:47.324
    STEP: Ensuring resource quota status is calculated 11/26/22 12:48:47.334
    STEP: Creating a Service 11/26/22 12:48:49.342
    STEP: Creating a NodePort Service 11/26/22 12:48:49.374
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 11/26/22 12:48:49.415
    STEP: Ensuring resource quota status captures service creation 11/26/22 12:48:49.459
    STEP: Deleting Services 11/26/22 12:48:51.467
    STEP: Ensuring resource quota status released usage 11/26/22 12:48:51.541
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 12:48:53.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7156" for this suite. 11/26/22 12:48:53.554
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:48:53.572
Nov 26 12:48:53.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename cronjob 11/26/22 12:48:53.573
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:53.606
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:53.611
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 11/26/22 12:48:53.619
STEP: Ensuring more than one job is running at a time 11/26/22 12:48:53.628
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 11/26/22 12:50:01.639
STEP: Removing cronjob 11/26/22 12:50:01.649
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 26 12:50:01.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-3070" for this suite. 11/26/22 12:50:01.684
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":220,"skipped":4126,"failed":0}
------------------------------
â€¢ [SLOW TEST] [68.135 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:48:53.572
    Nov 26 12:48:53.572: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename cronjob 11/26/22 12:48:53.573
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:48:53.606
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:48:53.611
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 11/26/22 12:48:53.619
    STEP: Ensuring more than one job is running at a time 11/26/22 12:48:53.628
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 11/26/22 12:50:01.639
    STEP: Removing cronjob 11/26/22 12:50:01.649
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 26 12:50:01.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-3070" for this suite. 11/26/22 12:50:01.684
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:50:01.71
Nov 26 12:50:01.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:50:01.715
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:01.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:01.77
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-2712 11/26/22 12:50:01.785
STEP: creating service affinity-clusterip-transition in namespace services-2712 11/26/22 12:50:01.786
STEP: creating replication controller affinity-clusterip-transition in namespace services-2712 11/26/22 12:50:01.81
I1126 12:50:01.829245      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2712, replica count: 3
I1126 12:50:04.881042      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 12:50:04.891: INFO: Creating new exec pod
Nov 26 12:50:04.898: INFO: Waiting up to 5m0s for pod "execpod-affinitydl7sh" in namespace "services-2712" to be "running"
Nov 26 12:50:04.908: INFO: Pod "execpod-affinitydl7sh": Phase="Pending", Reason="", readiness=false. Elapsed: 10.03907ms
Nov 26 12:50:06.916: INFO: Pod "execpod-affinitydl7sh": Phase="Running", Reason="", readiness=true. Elapsed: 2.018013255s
Nov 26 12:50:06.916: INFO: Pod "execpod-affinitydl7sh" satisfied condition "running"
Nov 26 12:50:07.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2712 exec execpod-affinitydl7sh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Nov 26 12:50:08.113: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Nov 26 12:50:08.113: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:50:08.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2712 exec execpod-affinitydl7sh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.106 80'
Nov 26 12:50:08.297: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.106 80\nConnection to 10.152.183.106 80 port [tcp/http] succeeded!\n"
Nov 26 12:50:08.297: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov 26 12:50:08.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2712 exec execpod-affinitydl7sh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.106:80/ ; done'
Nov 26 12:50:08.645: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n"
Nov 26 12:50:08.645: INFO: stdout: "\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-q9wbm\naffinity-clusterip-transition-q9wbm\naffinity-clusterip-transition-q9wbm\naffinity-clusterip-transition-q9wbm\naffinity-clusterip-transition-q9wbm\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-q9wbm"
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-q9wbm
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-q9wbm
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-q9wbm
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-q9wbm
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-q9wbm
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.647: INFO: Received response from host: affinity-clusterip-transition-b2957
Nov 26 12:50:08.647: INFO: Received response from host: affinity-clusterip-transition-q9wbm
Nov 26 12:50:08.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2712 exec execpod-affinitydl7sh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.106:80/ ; done'
Nov 26 12:50:08.977: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n"
Nov 26 12:50:08.978: INFO: stdout: "\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd"
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
Nov 26 12:50:08.978: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2712, will wait for the garbage collector to delete the pods 11/26/22 12:50:08.997
Nov 26 12:50:09.063: INFO: Deleting ReplicationController affinity-clusterip-transition took: 10.392591ms
Nov 26 12:50:09.163: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.463084ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:50:11.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2712" for this suite. 11/26/22 12:50:11.599
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":221,"skipped":4144,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.900 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:50:01.71
    Nov 26 12:50:01.711: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:50:01.715
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:01.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:01.77
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-2712 11/26/22 12:50:01.785
    STEP: creating service affinity-clusterip-transition in namespace services-2712 11/26/22 12:50:01.786
    STEP: creating replication controller affinity-clusterip-transition in namespace services-2712 11/26/22 12:50:01.81
    I1126 12:50:01.829245      19 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-2712, replica count: 3
    I1126 12:50:04.881042      19 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 12:50:04.891: INFO: Creating new exec pod
    Nov 26 12:50:04.898: INFO: Waiting up to 5m0s for pod "execpod-affinitydl7sh" in namespace "services-2712" to be "running"
    Nov 26 12:50:04.908: INFO: Pod "execpod-affinitydl7sh": Phase="Pending", Reason="", readiness=false. Elapsed: 10.03907ms
    Nov 26 12:50:06.916: INFO: Pod "execpod-affinitydl7sh": Phase="Running", Reason="", readiness=true. Elapsed: 2.018013255s
    Nov 26 12:50:06.916: INFO: Pod "execpod-affinitydl7sh" satisfied condition "running"
    Nov 26 12:50:07.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2712 exec execpod-affinitydl7sh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Nov 26 12:50:08.113: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Nov 26 12:50:08.113: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:50:08.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2712 exec execpod-affinitydl7sh -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.106 80'
    Nov 26 12:50:08.297: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.106 80\nConnection to 10.152.183.106 80 port [tcp/http] succeeded!\n"
    Nov 26 12:50:08.297: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov 26 12:50:08.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2712 exec execpod-affinitydl7sh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.106:80/ ; done'
    Nov 26 12:50:08.645: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n"
    Nov 26 12:50:08.645: INFO: stdout: "\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-q9wbm\naffinity-clusterip-transition-q9wbm\naffinity-clusterip-transition-q9wbm\naffinity-clusterip-transition-q9wbm\naffinity-clusterip-transition-q9wbm\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-b2957\naffinity-clusterip-transition-q9wbm"
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-q9wbm
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-q9wbm
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-q9wbm
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-q9wbm
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-q9wbm
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-b2957
    Nov 26 12:50:08.645: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.647: INFO: Received response from host: affinity-clusterip-transition-b2957
    Nov 26 12:50:08.647: INFO: Received response from host: affinity-clusterip-transition-q9wbm
    Nov 26 12:50:08.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2712 exec execpod-affinitydl7sh -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.106:80/ ; done'
    Nov 26 12:50:08.977: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.106:80/\n"
    Nov 26 12:50:08.978: INFO: stdout: "\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd\naffinity-clusterip-transition-2tjrd"
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Received response from host: affinity-clusterip-transition-2tjrd
    Nov 26 12:50:08.978: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-2712, will wait for the garbage collector to delete the pods 11/26/22 12:50:08.997
    Nov 26 12:50:09.063: INFO: Deleting ReplicationController affinity-clusterip-transition took: 10.392591ms
    Nov 26 12:50:09.163: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.463084ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:50:11.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2712" for this suite. 11/26/22 12:50:11.599
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:50:11.611
Nov 26 12:50:11.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 12:50:11.612
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:11.635
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:11.64
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 11/26/22 12:50:11.648
Nov 26 12:50:11.648: INFO: namespace kubectl-4049
Nov 26 12:50:11.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-4049 create -f -'
Nov 26 12:50:11.880: INFO: stderr: ""
Nov 26 12:50:11.880: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/26/22 12:50:11.88
Nov 26 12:50:12.887: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 26 12:50:12.887: INFO: Found 0 / 1
Nov 26 12:50:13.888: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 26 12:50:13.888: INFO: Found 1 / 1
Nov 26 12:50:13.888: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 26 12:50:13.894: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 26 12:50:13.894: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 26 12:50:13.894: INFO: wait on agnhost-primary startup in kubectl-4049 
Nov 26 12:50:13.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-4049 logs agnhost-primary-55dmj agnhost-primary'
Nov 26 12:50:14.002: INFO: stderr: ""
Nov 26 12:50:14.003: INFO: stdout: "Paused\n"
STEP: exposing RC 11/26/22 12:50:14.003
Nov 26 12:50:14.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-4049 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Nov 26 12:50:14.127: INFO: stderr: ""
Nov 26 12:50:14.127: INFO: stdout: "service/rm2 exposed\n"
Nov 26 12:50:14.137: INFO: Service rm2 in namespace kubectl-4049 found.
STEP: exposing service 11/26/22 12:50:16.152
Nov 26 12:50:16.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-4049 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Nov 26 12:50:16.270: INFO: stderr: ""
Nov 26 12:50:16.270: INFO: stdout: "service/rm3 exposed\n"
Nov 26 12:50:16.277: INFO: Service rm3 in namespace kubectl-4049 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 12:50:18.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4049" for this suite. 11/26/22 12:50:18.297
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":222,"skipped":4148,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.696 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:50:11.611
    Nov 26 12:50:11.611: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 12:50:11.612
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:11.635
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:11.64
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 11/26/22 12:50:11.648
    Nov 26 12:50:11.648: INFO: namespace kubectl-4049
    Nov 26 12:50:11.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-4049 create -f -'
    Nov 26 12:50:11.880: INFO: stderr: ""
    Nov 26 12:50:11.880: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/26/22 12:50:11.88
    Nov 26 12:50:12.887: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 26 12:50:12.887: INFO: Found 0 / 1
    Nov 26 12:50:13.888: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 26 12:50:13.888: INFO: Found 1 / 1
    Nov 26 12:50:13.888: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Nov 26 12:50:13.894: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 26 12:50:13.894: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 26 12:50:13.894: INFO: wait on agnhost-primary startup in kubectl-4049 
    Nov 26 12:50:13.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-4049 logs agnhost-primary-55dmj agnhost-primary'
    Nov 26 12:50:14.002: INFO: stderr: ""
    Nov 26 12:50:14.003: INFO: stdout: "Paused\n"
    STEP: exposing RC 11/26/22 12:50:14.003
    Nov 26 12:50:14.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-4049 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Nov 26 12:50:14.127: INFO: stderr: ""
    Nov 26 12:50:14.127: INFO: stdout: "service/rm2 exposed\n"
    Nov 26 12:50:14.137: INFO: Service rm2 in namespace kubectl-4049 found.
    STEP: exposing service 11/26/22 12:50:16.152
    Nov 26 12:50:16.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-4049 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Nov 26 12:50:16.270: INFO: stderr: ""
    Nov 26 12:50:16.270: INFO: stdout: "service/rm3 exposed\n"
    Nov 26 12:50:16.277: INFO: Service rm3 in namespace kubectl-4049 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 12:50:18.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4049" for this suite. 11/26/22 12:50:18.297
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:50:18.309
Nov 26 12:50:18.309: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename custom-resource-definition 11/26/22 12:50:18.31
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:18.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:18.337
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Nov 26 12:50:18.343: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:50:18.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2354" for this suite. 11/26/22 12:50:18.951
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":223,"skipped":4171,"failed":0}
------------------------------
â€¢ [0.660 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:50:18.309
    Nov 26 12:50:18.309: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename custom-resource-definition 11/26/22 12:50:18.31
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:18.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:18.337
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Nov 26 12:50:18.343: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:50:18.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-2354" for this suite. 11/26/22 12:50:18.951
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:50:18.972
Nov 26 12:50:18.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubelet-test 11/26/22 12:50:18.973
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:18.996
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:19.003
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 26 12:50:19.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7670" for this suite. 11/26/22 12:50:19.054
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":224,"skipped":4195,"failed":0}
------------------------------
â€¢ [0.097 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:50:18.972
    Nov 26 12:50:18.972: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubelet-test 11/26/22 12:50:18.973
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:18.996
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:19.003
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 26 12:50:19.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-7670" for this suite. 11/26/22 12:50:19.054
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:50:19.069
Nov 26 12:50:19.069: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename deployment 11/26/22 12:50:19.071
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:19.094
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:19.1
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Nov 26 12:50:19.108: INFO: Creating deployment "webserver-deployment"
Nov 26 12:50:19.118: INFO: Waiting for observed generation 1
Nov 26 12:50:21.136: INFO: Waiting for all required pods to come up
Nov 26 12:50:21.142: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 11/26/22 12:50:21.143
Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-whqng" in namespace "deployment-8054" to be "running"
Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-468qx" in namespace "deployment-8054" to be "running"
Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-lhw2k" in namespace "deployment-8054" to be "running"
Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-5f2r8" in namespace "deployment-8054" to be "running"
Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bff62" in namespace "deployment-8054" to be "running"
Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-qhwd9" in namespace "deployment-8054" to be "running"
Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vzpzd" in namespace "deployment-8054" to be "running"
Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-w546m" in namespace "deployment-8054" to be "running"
Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-q5dnl" in namespace "deployment-8054" to be "running"
Nov 26 12:50:21.150: INFO: Pod "webserver-deployment-845c8977d9-bff62": Phase="Pending", Reason="", readiness=false. Elapsed: 5.233758ms
Nov 26 12:50:21.150: INFO: Pod "webserver-deployment-845c8977d9-whqng": Phase="Pending", Reason="", readiness=false. Elapsed: 6.927064ms
Nov 26 12:50:21.150: INFO: Pod "webserver-deployment-845c8977d9-5f2r8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.111806ms
Nov 26 12:50:21.150: INFO: Pod "webserver-deployment-845c8977d9-w546m": Phase="Pending", Reason="", readiness=false. Elapsed: 5.365008ms
Nov 26 12:50:21.151: INFO: Pod "webserver-deployment-845c8977d9-vzpzd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.966126ms
Nov 26 12:50:21.151: INFO: Pod "webserver-deployment-845c8977d9-lhw2k": Phase="Pending", Reason="", readiness=false. Elapsed: 7.416612ms
Nov 26 12:50:21.152: INFO: Pod "webserver-deployment-845c8977d9-qhwd9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.011943ms
Nov 26 12:50:21.153: INFO: Pod "webserver-deployment-845c8977d9-468qx": Phase="Pending", Reason="", readiness=false. Elapsed: 9.120679ms
Nov 26 12:50:21.153: INFO: Pod "webserver-deployment-845c8977d9-q5dnl": Phase="Pending", Reason="", readiness=false. Elapsed: 7.676412ms
Nov 26 12:50:23.159: INFO: Pod "webserver-deployment-845c8977d9-lhw2k": Phase="Running", Reason="", readiness=true. Elapsed: 2.015467043s
Nov 26 12:50:23.159: INFO: Pod "webserver-deployment-845c8977d9-lhw2k" satisfied condition "running"
Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-w546m": Phase="Running", Reason="", readiness=true. Elapsed: 2.014530296s
Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-w546m" satisfied condition "running"
Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-whqng": Phase="Running", Reason="", readiness=true. Elapsed: 2.016837121s
Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-whqng" satisfied condition "running"
Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-468qx": Phase="Running", Reason="", readiness=true. Elapsed: 2.016689991s
Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-468qx" satisfied condition "running"
Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-5f2r8": Phase="Running", Reason="", readiness=true. Elapsed: 2.016029772s
Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-5f2r8" satisfied condition "running"
Nov 26 12:50:23.161: INFO: Pod "webserver-deployment-845c8977d9-qhwd9": Phase="Running", Reason="", readiness=true. Elapsed: 2.016810371s
Nov 26 12:50:23.161: INFO: Pod "webserver-deployment-845c8977d9-qhwd9" satisfied condition "running"
Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-vzpzd": Phase="Running", Reason="", readiness=true. Elapsed: 2.016813361s
Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-vzpzd" satisfied condition "running"
Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-bff62": Phase="Running", Reason="", readiness=true. Elapsed: 2.01744384s
Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-bff62" satisfied condition "running"
Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-q5dnl": Phase="Running", Reason="", readiness=true. Elapsed: 2.016713861s
Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-q5dnl" satisfied condition "running"
Nov 26 12:50:23.162: INFO: Waiting for deployment "webserver-deployment" to complete
Nov 26 12:50:23.173: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov 26 12:50:23.193: INFO: Updating deployment webserver-deployment
Nov 26 12:50:23.193: INFO: Waiting for observed generation 2
Nov 26 12:50:25.204: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 26 12:50:25.210: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 26 12:50:25.215: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 26 12:50:25.230: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 26 12:50:25.230: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 26 12:50:25.235: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 26 12:50:25.246: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov 26 12:50:25.246: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov 26 12:50:25.261: INFO: Updating deployment webserver-deployment
Nov 26 12:50:25.261: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov 26 12:50:25.274: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 26 12:50:25.287: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov 26 12:50:25.425: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-8054  3e6a19d1-3348-47a1-b980-0e91aa8a2e79 25360 3 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003fec118 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-11-26 12:50:23 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-26 12:50:25 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov 26 12:50:25.462: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-8054  08a66814-8fab-44e2-936e-f6ac8676c3e1 25353 3 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 3e6a19d1-3348-47a1-b980-0e91aa8a2e79 0xc002747e27 0xc002747e28}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3e6a19d1-3348-47a1-b980-0e91aa8a2e79\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002747ec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:50:25.462: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov 26 12:50:25.462: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-8054  54bd0b98-c3ba-4311-b002-d38241b0bbea 25349 3 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 3e6a19d1-3348-47a1-b980-0e91aa8a2e79 0xc002747f27 0xc002747f28}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3e6a19d1-3348-47a1-b980-0e91aa8a2e79\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002747fb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov 26 12:50:25.569: INFO: Pod "webserver-deployment-69b7448995-2xlrh" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-2xlrh webserver-deployment-69b7448995- deployment-8054  4f095766-ba72-420c-9e21-d0348a0e9e04 25394 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fec4f7 0xc003fec4f8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-97cb8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-97cb8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:,StartTime:2022-11-26 12:50:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.570: INFO: Pod "webserver-deployment-69b7448995-7k4dj" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-7k4dj webserver-deployment-69b7448995- deployment-8054  23ca5739-7098-4193-b922-e81e7b181731 25242 0 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fec6f7 0xc003fec6f8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6q5tb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6q5tb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:,StartTime:2022-11-26 12:50:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.570: INFO: Pod "webserver-deployment-69b7448995-94ls7" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-94ls7 webserver-deployment-69b7448995- deployment-8054  b7d5676b-5ea1-4f9d-95df-24a64d58be61 25336 0 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fec8e7 0xc003fec8e8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.237\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5rct7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5rct7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:192.168.46.237,StartTime:2022-11-26 12:50:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.46.237,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.571: INFO: Pod "webserver-deployment-69b7448995-9h4kg" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-9h4kg webserver-deployment-69b7448995- deployment-8054  6ea9e0b2-9f5c-42f0-b748-31403bd6973a 25268 0 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fecb07 0xc003fecb08}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xxr7w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xxr7w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:,StartTime:2022-11-26 12:50:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.571: INFO: Pod "webserver-deployment-69b7448995-9hgjs" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-9hgjs webserver-deployment-69b7448995- deployment-8054  34ea91f5-2dd8-4a13-b072-75c12e023a6f 25270 0 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003feccf7 0xc003feccf8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q9twn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q9twn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:,StartTime:2022-11-26 12:50:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.571: INFO: Pod "webserver-deployment-69b7448995-9rnqg" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-9rnqg webserver-deployment-69b7448995- deployment-8054  1ca9bda0-b159-4b28-b82d-216c82d32227 25396 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fecee7 0xc003fecee8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qfm2c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qfm2c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.571: INFO: Pod "webserver-deployment-69b7448995-9xltf" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-9xltf webserver-deployment-69b7448995- deployment-8054  6edc7b6f-22b2-4ea0-a441-96a78557125a 25370 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed060 0xc003fed061}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-52vnj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-52vnj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.572: INFO: Pod "webserver-deployment-69b7448995-kq5kn" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-kq5kn webserver-deployment-69b7448995- deployment-8054  3b87e303-c8e6-456f-8a88-8bfe1b3dc9e5 25397 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed1d0 0xc003fed1d1}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6lvs8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6lvs8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.572: INFO: Pod "webserver-deployment-69b7448995-kwcqb" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-kwcqb webserver-deployment-69b7448995- deployment-8054  cc2b3f0d-da2b-4938-92ef-a6b9c9f66c59 25325 0 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed340 0xc003fed341}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.149\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lcnc4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lcnc4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:192.168.150.149,StartTime:2022-11-26 12:50:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.150.149,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.572: INFO: Pod "webserver-deployment-69b7448995-lndbx" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-lndbx webserver-deployment-69b7448995- deployment-8054  640760f6-9e9a-4aab-a410-102d8681ba20 25405 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed557 0xc003fed558}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gvj78,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gvj78,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.573: INFO: Pod "webserver-deployment-69b7448995-n9bk4" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-n9bk4 webserver-deployment-69b7448995- deployment-8054  213c4d8d-e458-4388-b684-5d52a699a7c0 25377 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed6d0 0xc003fed6d1}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qr8tt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qr8tt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:,StartTime:2022-11-26 12:50:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.574: INFO: Pod "webserver-deployment-69b7448995-q9l9t" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-q9l9t webserver-deployment-69b7448995- deployment-8054  c2004c32-7fcf-4a8e-862c-a8c382e264d3 25402 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed8b7 0xc003fed8b8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cv265,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cv265,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:,StartTime:2022-11-26 12:50:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.575: INFO: Pod "webserver-deployment-69b7448995-zfzzm" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-zfzzm webserver-deployment-69b7448995- deployment-8054  4d4a4ff7-9a54-45e3-bb06-4319f380c5a0 25392 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fedaa7 0xc003fedaa8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rsngv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rsngv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.575: INFO: Pod "webserver-deployment-845c8977d9-468qx" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-468qx webserver-deployment-845c8977d9- deployment-8054  a8d10538-0422-4bcb-858a-a08002c0bbfd 25212 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc003fedc20 0xc003fedc21}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.235\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6dhmn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6dhmn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:192.168.46.235,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c92a6a2af93d47c1dd92bdf999b0d8815154182e88b82c9a4a4e927ab8741788,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.46.235,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.575: INFO: Pod "webserver-deployment-845c8977d9-569nr" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-569nr webserver-deployment-845c8977d9- deployment-8054  e90a9076-39ce-471a-afa1-7198525ce6f3 25403 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc003fede17 0xc003fede18}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gmgwc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gmgwc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.576: INFO: Pod "webserver-deployment-845c8977d9-5cp2m" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-5cp2m webserver-deployment-845c8977d9- deployment-8054  ed1bca1b-ee6f-44cd-aa40-0e0646f0b35a 25159 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc003fedf57 0xc003fedf58}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.146\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lhg2f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lhg2f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:192.168.150.146,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8625652fc6c0ec4a3c3d991226f67a941186b60840f6933d5350d89f4242cb96,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.150.146,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.576: INFO: Pod "webserver-deployment-845c8977d9-5f2r8" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-5f2r8 webserver-deployment-845c8977d9- deployment-8054  da60d7a0-89f5-4cd5-ad1b-701d83949e6f 25189 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc6147 0xc002fc6148}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s8xfx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s8xfx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.42,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://da23bb830417468942873edc94bb3d36bd5885bc11f984f9e2c49acc016650a1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.576: INFO: Pod "webserver-deployment-845c8977d9-5s5sl" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-5s5sl webserver-deployment-845c8977d9- deployment-8054  dc39a494-c14f-47b3-a947-a96c672eaef0 25375 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc6347 0xc002fc6348}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s2694,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s2694,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.577: INFO: Pod "webserver-deployment-845c8977d9-8rwtq" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-8rwtq webserver-deployment-845c8977d9- deployment-8054  dc009cd8-e9ba-4ce9-b228-f413782cd5a4 25387 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc64b0 0xc002fc64b1}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bzktk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bzktk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.577: INFO: Pod "webserver-deployment-845c8977d9-9vxsb" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9vxsb webserver-deployment-845c8977d9- deployment-8054  b60230a5-58ca-4df2-86c4-5dd6dc5ae64f 25389 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc65e7 0xc002fc65e8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gt9s6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gt9s6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:,StartTime:2022-11-26 12:50:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.577: INFO: Pod "webserver-deployment-845c8977d9-ffzk9" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ffzk9 webserver-deployment-845c8977d9- deployment-8054  a9cb403a-b56f-49ba-acb3-bc9934530d73 25406 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc67b7 0xc002fc67b8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7qbzw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7qbzw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.578: INFO: Pod "webserver-deployment-845c8977d9-ld7qp" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ld7qp webserver-deployment-845c8977d9- deployment-8054  23c0286e-5c60-4f24-bfeb-3c22b35ab3bc 25399 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc68f7 0xc002fc68f8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gb5qz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gb5qz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.578: INFO: Pod "webserver-deployment-845c8977d9-lhw2k" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-lhw2k webserver-deployment-845c8977d9- deployment-8054  5e800396-502e-49c0-b0df-f76d2fbba813 25197 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc6a60 0xc002fc6a61}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.148\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mbpbx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mbpbx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:192.168.150.148,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://935acad21588f94db029b4ffa9474e201122cd8af9ee1766779cf183821dc427,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.150.148,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.578: INFO: Pod "webserver-deployment-845c8977d9-qhwd9" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-qhwd9 webserver-deployment-845c8977d9- deployment-8054  8c062d2e-5211-4c97-8e83-0be79deaae25 25206 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc6c47 0xc002fc6c48}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rpcdl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rpcdl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:192.168.46.234,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://34ef7a88729ce767c6ac4d0cc2ea26689a2f7171a16e1e504bfdd15911fcd825,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.46.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.579: INFO: Pod "webserver-deployment-845c8977d9-rffbs" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-rffbs webserver-deployment-845c8977d9- deployment-8054  4c82c830-6d75-4c52-86aa-c18f671528e1 25369 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc6e37 0xc002fc6e38}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rpnh4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rpnh4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:,StartTime:2022-11-26 12:50:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.579: INFO: Pod "webserver-deployment-845c8977d9-skppf" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-skppf webserver-deployment-845c8977d9- deployment-8054  2101dc59-02a7-4115-a51d-6129e0ed2b04 25400 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc7007 0xc002fc7008}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xwqcf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xwqcf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.579: INFO: Pod "webserver-deployment-845c8977d9-sq7gv" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-sq7gv webserver-deployment-845c8977d9- deployment-8054  9f244dfd-4019-46c5-af5c-aba2ee974f66 25398 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc7170 0xc002fc7171}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h5mqf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h5mqf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.579: INFO: Pod "webserver-deployment-845c8977d9-vzpzd" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vzpzd webserver-deployment-845c8977d9- deployment-8054  a23c3243-1cfb-4452-9188-56b61473fa43 25209 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc72d0 0xc002fc72d1}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.236\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qj4qx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qj4qx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:192.168.46.236,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://16930020659c484013074b884896fd654fd9df151e5c33d252b110b348bb406f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.46.236,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.580: INFO: Pod "webserver-deployment-845c8977d9-w546m" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-w546m webserver-deployment-845c8977d9- deployment-8054  92f44836-afcf-4b5d-a2b9-8110c2e630d0 25200 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc74b7 0xc002fc74b8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ddnd6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ddnd6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.48,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://843db90daefe88d7dbe51e5455e552d633df6d174518cd5dbb6fc69044868f2f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 12:50:25.580: INFO: Pod "webserver-deployment-845c8977d9-whqng" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-whqng webserver-deployment-845c8977d9- deployment-8054  3b12a259-b491-4e74-944e-51ed5c4c4fc8 25201 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc76a7 0xc002fc76a8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.147\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8627d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8627d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:192.168.150.147,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8c7968f7f82b0a643f3d601666afcc9335c7b90952e518429335c499494079cd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.150.147,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov 26 12:50:25.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8054" for this suite. 11/26/22 12:50:25.639
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":225,"skipped":4202,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.642 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:50:19.069
    Nov 26 12:50:19.069: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename deployment 11/26/22 12:50:19.071
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:19.094
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:19.1
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Nov 26 12:50:19.108: INFO: Creating deployment "webserver-deployment"
    Nov 26 12:50:19.118: INFO: Waiting for observed generation 1
    Nov 26 12:50:21.136: INFO: Waiting for all required pods to come up
    Nov 26 12:50:21.142: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 11/26/22 12:50:21.143
    Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-whqng" in namespace "deployment-8054" to be "running"
    Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-468qx" in namespace "deployment-8054" to be "running"
    Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-lhw2k" in namespace "deployment-8054" to be "running"
    Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-5f2r8" in namespace "deployment-8054" to be "running"
    Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-bff62" in namespace "deployment-8054" to be "running"
    Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-qhwd9" in namespace "deployment-8054" to be "running"
    Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-vzpzd" in namespace "deployment-8054" to be "running"
    Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-w546m" in namespace "deployment-8054" to be "running"
    Nov 26 12:50:21.143: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-q5dnl" in namespace "deployment-8054" to be "running"
    Nov 26 12:50:21.150: INFO: Pod "webserver-deployment-845c8977d9-bff62": Phase="Pending", Reason="", readiness=false. Elapsed: 5.233758ms
    Nov 26 12:50:21.150: INFO: Pod "webserver-deployment-845c8977d9-whqng": Phase="Pending", Reason="", readiness=false. Elapsed: 6.927064ms
    Nov 26 12:50:21.150: INFO: Pod "webserver-deployment-845c8977d9-5f2r8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.111806ms
    Nov 26 12:50:21.150: INFO: Pod "webserver-deployment-845c8977d9-w546m": Phase="Pending", Reason="", readiness=false. Elapsed: 5.365008ms
    Nov 26 12:50:21.151: INFO: Pod "webserver-deployment-845c8977d9-vzpzd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.966126ms
    Nov 26 12:50:21.151: INFO: Pod "webserver-deployment-845c8977d9-lhw2k": Phase="Pending", Reason="", readiness=false. Elapsed: 7.416612ms
    Nov 26 12:50:21.152: INFO: Pod "webserver-deployment-845c8977d9-qhwd9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.011943ms
    Nov 26 12:50:21.153: INFO: Pod "webserver-deployment-845c8977d9-468qx": Phase="Pending", Reason="", readiness=false. Elapsed: 9.120679ms
    Nov 26 12:50:21.153: INFO: Pod "webserver-deployment-845c8977d9-q5dnl": Phase="Pending", Reason="", readiness=false. Elapsed: 7.676412ms
    Nov 26 12:50:23.159: INFO: Pod "webserver-deployment-845c8977d9-lhw2k": Phase="Running", Reason="", readiness=true. Elapsed: 2.015467043s
    Nov 26 12:50:23.159: INFO: Pod "webserver-deployment-845c8977d9-lhw2k" satisfied condition "running"
    Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-w546m": Phase="Running", Reason="", readiness=true. Elapsed: 2.014530296s
    Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-w546m" satisfied condition "running"
    Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-whqng": Phase="Running", Reason="", readiness=true. Elapsed: 2.016837121s
    Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-whqng" satisfied condition "running"
    Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-468qx": Phase="Running", Reason="", readiness=true. Elapsed: 2.016689991s
    Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-468qx" satisfied condition "running"
    Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-5f2r8": Phase="Running", Reason="", readiness=true. Elapsed: 2.016029772s
    Nov 26 12:50:23.160: INFO: Pod "webserver-deployment-845c8977d9-5f2r8" satisfied condition "running"
    Nov 26 12:50:23.161: INFO: Pod "webserver-deployment-845c8977d9-qhwd9": Phase="Running", Reason="", readiness=true. Elapsed: 2.016810371s
    Nov 26 12:50:23.161: INFO: Pod "webserver-deployment-845c8977d9-qhwd9" satisfied condition "running"
    Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-vzpzd": Phase="Running", Reason="", readiness=true. Elapsed: 2.016813361s
    Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-vzpzd" satisfied condition "running"
    Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-bff62": Phase="Running", Reason="", readiness=true. Elapsed: 2.01744384s
    Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-bff62" satisfied condition "running"
    Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-q5dnl": Phase="Running", Reason="", readiness=true. Elapsed: 2.016713861s
    Nov 26 12:50:23.162: INFO: Pod "webserver-deployment-845c8977d9-q5dnl" satisfied condition "running"
    Nov 26 12:50:23.162: INFO: Waiting for deployment "webserver-deployment" to complete
    Nov 26 12:50:23.173: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Nov 26 12:50:23.193: INFO: Updating deployment webserver-deployment
    Nov 26 12:50:23.193: INFO: Waiting for observed generation 2
    Nov 26 12:50:25.204: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Nov 26 12:50:25.210: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Nov 26 12:50:25.215: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Nov 26 12:50:25.230: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Nov 26 12:50:25.230: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Nov 26 12:50:25.235: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Nov 26 12:50:25.246: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Nov 26 12:50:25.246: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Nov 26 12:50:25.261: INFO: Updating deployment webserver-deployment
    Nov 26 12:50:25.261: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Nov 26 12:50:25.274: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Nov 26 12:50:25.287: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov 26 12:50:25.425: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-8054  3e6a19d1-3348-47a1-b980-0e91aa8a2e79 25360 3 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003fec118 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-11-26 12:50:23 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-26 12:50:25 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Nov 26 12:50:25.462: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-8054  08a66814-8fab-44e2-936e-f6ac8676c3e1 25353 3 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 3e6a19d1-3348-47a1-b980-0e91aa8a2e79 0xc002747e27 0xc002747e28}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3e6a19d1-3348-47a1-b980-0e91aa8a2e79\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002747ec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:50:25.462: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Nov 26 12:50:25.462: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-8054  54bd0b98-c3ba-4311-b002-d38241b0bbea 25349 3 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 3e6a19d1-3348-47a1-b980-0e91aa8a2e79 0xc002747f27 0xc002747f28}] [] [{kube-controller-manager Update apps/v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3e6a19d1-3348-47a1-b980-0e91aa8a2e79\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002747fb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Nov 26 12:50:25.569: INFO: Pod "webserver-deployment-69b7448995-2xlrh" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-2xlrh webserver-deployment-69b7448995- deployment-8054  4f095766-ba72-420c-9e21-d0348a0e9e04 25394 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fec4f7 0xc003fec4f8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-97cb8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-97cb8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:,StartTime:2022-11-26 12:50:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.570: INFO: Pod "webserver-deployment-69b7448995-7k4dj" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-7k4dj webserver-deployment-69b7448995- deployment-8054  23ca5739-7098-4193-b922-e81e7b181731 25242 0 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fec6f7 0xc003fec6f8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6q5tb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6q5tb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:,StartTime:2022-11-26 12:50:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.570: INFO: Pod "webserver-deployment-69b7448995-94ls7" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-94ls7 webserver-deployment-69b7448995- deployment-8054  b7d5676b-5ea1-4f9d-95df-24a64d58be61 25336 0 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fec8e7 0xc003fec8e8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.237\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5rct7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5rct7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:192.168.46.237,StartTime:2022-11-26 12:50:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.46.237,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.571: INFO: Pod "webserver-deployment-69b7448995-9h4kg" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-9h4kg webserver-deployment-69b7448995- deployment-8054  6ea9e0b2-9f5c-42f0-b748-31403bd6973a 25268 0 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fecb07 0xc003fecb08}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xxr7w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xxr7w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:,StartTime:2022-11-26 12:50:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.571: INFO: Pod "webserver-deployment-69b7448995-9hgjs" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-9hgjs webserver-deployment-69b7448995- deployment-8054  34ea91f5-2dd8-4a13-b072-75c12e023a6f 25270 0 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003feccf7 0xc003feccf8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-q9twn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-q9twn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:,StartTime:2022-11-26 12:50:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.571: INFO: Pod "webserver-deployment-69b7448995-9rnqg" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-9rnqg webserver-deployment-69b7448995- deployment-8054  1ca9bda0-b159-4b28-b82d-216c82d32227 25396 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fecee7 0xc003fecee8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qfm2c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qfm2c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.571: INFO: Pod "webserver-deployment-69b7448995-9xltf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-9xltf webserver-deployment-69b7448995- deployment-8054  6edc7b6f-22b2-4ea0-a441-96a78557125a 25370 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed060 0xc003fed061}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-52vnj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-52vnj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.572: INFO: Pod "webserver-deployment-69b7448995-kq5kn" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-kq5kn webserver-deployment-69b7448995- deployment-8054  3b87e303-c8e6-456f-8a88-8bfe1b3dc9e5 25397 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed1d0 0xc003fed1d1}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6lvs8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6lvs8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.572: INFO: Pod "webserver-deployment-69b7448995-kwcqb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-kwcqb webserver-deployment-69b7448995- deployment-8054  cc2b3f0d-da2b-4938-92ef-a6b9c9f66c59 25325 0 2022-11-26 12:50:23 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed340 0xc003fed341}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:23 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.149\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lcnc4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lcnc4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:192.168.150.149,StartTime:2022-11-26 12:50:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.150.149,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.572: INFO: Pod "webserver-deployment-69b7448995-lndbx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-lndbx webserver-deployment-69b7448995- deployment-8054  640760f6-9e9a-4aab-a410-102d8681ba20 25405 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed557 0xc003fed558}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gvj78,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gvj78,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.573: INFO: Pod "webserver-deployment-69b7448995-n9bk4" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-n9bk4 webserver-deployment-69b7448995- deployment-8054  213c4d8d-e458-4388-b684-5d52a699a7c0 25377 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed6d0 0xc003fed6d1}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qr8tt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qr8tt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:,StartTime:2022-11-26 12:50:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.574: INFO: Pod "webserver-deployment-69b7448995-q9l9t" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-q9l9t webserver-deployment-69b7448995- deployment-8054  c2004c32-7fcf-4a8e-862c-a8c382e264d3 25402 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fed8b7 0xc003fed8b8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cv265,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cv265,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:,StartTime:2022-11-26 12:50:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.575: INFO: Pod "webserver-deployment-69b7448995-zfzzm" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-zfzzm webserver-deployment-69b7448995- deployment-8054  4d4a4ff7-9a54-45e3-bb06-4319f380c5a0 25392 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 08a66814-8fab-44e2-936e-f6ac8676c3e1 0xc003fedaa7 0xc003fedaa8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"08a66814-8fab-44e2-936e-f6ac8676c3e1\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rsngv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rsngv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.575: INFO: Pod "webserver-deployment-845c8977d9-468qx" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-468qx webserver-deployment-845c8977d9- deployment-8054  a8d10538-0422-4bcb-858a-a08002c0bbfd 25212 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc003fedc20 0xc003fedc21}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.235\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6dhmn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6dhmn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:192.168.46.235,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://c92a6a2af93d47c1dd92bdf999b0d8815154182e88b82c9a4a4e927ab8741788,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.46.235,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.575: INFO: Pod "webserver-deployment-845c8977d9-569nr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-569nr webserver-deployment-845c8977d9- deployment-8054  e90a9076-39ce-471a-afa1-7198525ce6f3 25403 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc003fede17 0xc003fede18}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gmgwc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gmgwc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.576: INFO: Pod "webserver-deployment-845c8977d9-5cp2m" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-5cp2m webserver-deployment-845c8977d9- deployment-8054  ed1bca1b-ee6f-44cd-aa40-0e0646f0b35a 25159 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc003fedf57 0xc003fedf58}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.146\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lhg2f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lhg2f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:192.168.150.146,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8625652fc6c0ec4a3c3d991226f67a941186b60840f6933d5350d89f4242cb96,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.150.146,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.576: INFO: Pod "webserver-deployment-845c8977d9-5f2r8" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-5f2r8 webserver-deployment-845c8977d9- deployment-8054  da60d7a0-89f5-4cd5-ad1b-701d83949e6f 25189 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc6147 0xc002fc6148}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.42\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s8xfx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s8xfx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.42,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://da23bb830417468942873edc94bb3d36bd5885bc11f984f9e2c49acc016650a1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.576: INFO: Pod "webserver-deployment-845c8977d9-5s5sl" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-5s5sl webserver-deployment-845c8977d9- deployment-8054  dc39a494-c14f-47b3-a947-a96c672eaef0 25375 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc6347 0xc002fc6348}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-s2694,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-s2694,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.577: INFO: Pod "webserver-deployment-845c8977d9-8rwtq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-8rwtq webserver-deployment-845c8977d9- deployment-8054  dc009cd8-e9ba-4ce9-b228-f413782cd5a4 25387 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc64b0 0xc002fc64b1}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bzktk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bzktk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.577: INFO: Pod "webserver-deployment-845c8977d9-9vxsb" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9vxsb webserver-deployment-845c8977d9- deployment-8054  b60230a5-58ca-4df2-86c4-5dd6dc5ae64f 25389 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc65e7 0xc002fc65e8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gt9s6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gt9s6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:,StartTime:2022-11-26 12:50:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.577: INFO: Pod "webserver-deployment-845c8977d9-ffzk9" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ffzk9 webserver-deployment-845c8977d9- deployment-8054  a9cb403a-b56f-49ba-acb3-bc9934530d73 25406 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc67b7 0xc002fc67b8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7qbzw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7qbzw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.578: INFO: Pod "webserver-deployment-845c8977d9-ld7qp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ld7qp webserver-deployment-845c8977d9- deployment-8054  23c0286e-5c60-4f24-bfeb-3c22b35ab3bc 25399 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc68f7 0xc002fc68f8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-gb5qz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-gb5qz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.578: INFO: Pod "webserver-deployment-845c8977d9-lhw2k" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-lhw2k webserver-deployment-845c8977d9- deployment-8054  5e800396-502e-49c0-b0df-f76d2fbba813 25197 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc6a60 0xc002fc6a61}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.148\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mbpbx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mbpbx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:192.168.150.148,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://935acad21588f94db029b4ffa9474e201122cd8af9ee1766779cf183821dc427,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.150.148,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.578: INFO: Pod "webserver-deployment-845c8977d9-qhwd9" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-qhwd9 webserver-deployment-845c8977d9- deployment-8054  8c062d2e-5211-4c97-8e83-0be79deaae25 25206 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc6c47 0xc002fc6c48}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.234\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rpcdl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rpcdl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:192.168.46.234,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://34ef7a88729ce767c6ac4d0cc2ea26689a2f7171a16e1e504bfdd15911fcd825,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.46.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.579: INFO: Pod "webserver-deployment-845c8977d9-rffbs" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-rffbs webserver-deployment-845c8977d9- deployment-8054  4c82c830-6d75-4c52-86aa-c18f671528e1 25369 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc6e37 0xc002fc6e38}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rpnh4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rpnh4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:,StartTime:2022-11-26 12:50:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.579: INFO: Pod "webserver-deployment-845c8977d9-skppf" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-skppf webserver-deployment-845c8977d9- deployment-8054  2101dc59-02a7-4115-a51d-6129e0ed2b04 25400 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc7007 0xc002fc7008}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xwqcf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xwqcf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.579: INFO: Pod "webserver-deployment-845c8977d9-sq7gv" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-sq7gv webserver-deployment-845c8977d9- deployment-8054  9f244dfd-4019-46c5-af5c-aba2ee974f66 25398 0 2022-11-26 12:50:25 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc7170 0xc002fc7171}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:25 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h5mqf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h5mqf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.579: INFO: Pod "webserver-deployment-845c8977d9-vzpzd" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vzpzd webserver-deployment-845c8977d9- deployment-8054  a23c3243-1cfb-4452-9188-56b61473fa43 25209 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc72d0 0xc002fc72d1}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.46.236\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qj4qx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qj4qx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-29-104,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.29.104,PodIP:192.168.46.236,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://16930020659c484013074b884896fd654fd9df151e5c33d252b110b348bb406f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.46.236,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.580: INFO: Pod "webserver-deployment-845c8977d9-w546m" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-w546m webserver-deployment-845c8977d9- deployment-8054  92f44836-afcf-4b5d-a2b9-8110c2e630d0 25200 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc74b7 0xc002fc74b8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.34.48\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ddnd6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ddnd6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-43-82,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.43.82,PodIP:192.168.34.48,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://843db90daefe88d7dbe51e5455e552d633df6d174518cd5dbb6fc69044868f2f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.34.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 12:50:25.580: INFO: Pod "webserver-deployment-845c8977d9-whqng" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-whqng webserver-deployment-845c8977d9- deployment-8054  3b12a259-b491-4e74-944e-51ed5c4c4fc8 25201 0 2022-11-26 12:50:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 54bd0b98-c3ba-4311-b002-d38241b0bbea 0xc002fc76a7 0xc002fc76a8}] [] [{kube-controller-manager Update v1 2022-11-26 12:50:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"54bd0b98-c3ba-4311-b002-d38241b0bbea\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-26 12:50:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.150.147\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-8627d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-8627d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-249,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-26 12:50:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.249,PodIP:192.168.150.147,StartTime:2022-11-26 12:50:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-26 12:50:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://8c7968f7f82b0a643f3d601666afcc9335c7b90952e518429335c499494079cd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.150.147,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov 26 12:50:25.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8054" for this suite. 11/26/22 12:50:25.639
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:50:25.716
Nov 26 12:50:25.716: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubelet-test 11/26/22 12:50:25.718
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:25.828
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:25.833
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Nov 26 12:50:25.860: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002" in namespace "kubelet-test-5903" to be "running and ready"
Nov 26 12:50:25.870: INFO: Pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002": Phase="Pending", Reason="", readiness=false. Elapsed: 9.865058ms
Nov 26 12:50:25.870: INFO: The phase of Pod busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:50:27.877: INFO: Pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017580021s
Nov 26 12:50:27.878: INFO: The phase of Pod busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:50:29.878: INFO: Pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017711252s
Nov 26 12:50:29.878: INFO: The phase of Pod busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:50:31.876: INFO: Pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002": Phase="Running", Reason="", readiness=true. Elapsed: 6.016563309s
Nov 26 12:50:31.877: INFO: The phase of Pod busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002 is Running (Ready = true)
Nov 26 12:50:31.877: INFO: Pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 26 12:50:31.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5903" for this suite. 11/26/22 12:50:31.914
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":226,"skipped":4222,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.209 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:50:25.716
    Nov 26 12:50:25.716: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubelet-test 11/26/22 12:50:25.718
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:25.828
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:25.833
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Nov 26 12:50:25.860: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002" in namespace "kubelet-test-5903" to be "running and ready"
    Nov 26 12:50:25.870: INFO: Pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002": Phase="Pending", Reason="", readiness=false. Elapsed: 9.865058ms
    Nov 26 12:50:25.870: INFO: The phase of Pod busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:50:27.877: INFO: Pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017580021s
    Nov 26 12:50:27.878: INFO: The phase of Pod busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:50:29.878: INFO: Pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017711252s
    Nov 26 12:50:29.878: INFO: The phase of Pod busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:50:31.876: INFO: Pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002": Phase="Running", Reason="", readiness=true. Elapsed: 6.016563309s
    Nov 26 12:50:31.877: INFO: The phase of Pod busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002 is Running (Ready = true)
    Nov 26 12:50:31.877: INFO: Pod "busybox-readonly-fs870dcda9-fcd3-408f-bef1-f0d224595002" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 26 12:50:31.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-5903" for this suite. 11/26/22 12:50:31.914
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:50:31.93
Nov 26 12:50:31.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename gc 11/26/22 12:50:31.931
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:32.038
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:32.046
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 11/26/22 12:50:32.068
STEP: delete the rc 11/26/22 12:50:37.084
STEP: wait for the rc to be deleted 11/26/22 12:50:37.121
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 11/26/22 12:50:42.13
STEP: Gathering metrics 11/26/22 12:51:12.155
W1126 12:51:12.162436      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 26 12:51:12.164: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Nov 26 12:51:12.164: INFO: Deleting pod "simpletest.rc-24dc9" in namespace "gc-1090"
Nov 26 12:51:12.182: INFO: Deleting pod "simpletest.rc-2r9pl" in namespace "gc-1090"
Nov 26 12:51:12.203: INFO: Deleting pod "simpletest.rc-2w2wg" in namespace "gc-1090"
Nov 26 12:51:12.228: INFO: Deleting pod "simpletest.rc-2zxk4" in namespace "gc-1090"
Nov 26 12:51:12.258: INFO: Deleting pod "simpletest.rc-422kx" in namespace "gc-1090"
Nov 26 12:51:12.278: INFO: Deleting pod "simpletest.rc-44ctv" in namespace "gc-1090"
Nov 26 12:51:12.297: INFO: Deleting pod "simpletest.rc-4gthp" in namespace "gc-1090"
Nov 26 12:51:12.317: INFO: Deleting pod "simpletest.rc-4xfxz" in namespace "gc-1090"
Nov 26 12:51:12.341: INFO: Deleting pod "simpletest.rc-5m4rx" in namespace "gc-1090"
Nov 26 12:51:12.374: INFO: Deleting pod "simpletest.rc-5sxzx" in namespace "gc-1090"
Nov 26 12:51:12.393: INFO: Deleting pod "simpletest.rc-69klh" in namespace "gc-1090"
Nov 26 12:51:12.417: INFO: Deleting pod "simpletest.rc-6fv6p" in namespace "gc-1090"
Nov 26 12:51:12.439: INFO: Deleting pod "simpletest.rc-6kn75" in namespace "gc-1090"
Nov 26 12:51:12.460: INFO: Deleting pod "simpletest.rc-6ln7j" in namespace "gc-1090"
Nov 26 12:51:12.486: INFO: Deleting pod "simpletest.rc-6xbwc" in namespace "gc-1090"
Nov 26 12:51:12.512: INFO: Deleting pod "simpletest.rc-6zfxq" in namespace "gc-1090"
Nov 26 12:51:12.532: INFO: Deleting pod "simpletest.rc-72nst" in namespace "gc-1090"
Nov 26 12:51:12.552: INFO: Deleting pod "simpletest.rc-74l27" in namespace "gc-1090"
Nov 26 12:51:12.575: INFO: Deleting pod "simpletest.rc-75gw2" in namespace "gc-1090"
Nov 26 12:51:12.594: INFO: Deleting pod "simpletest.rc-75t64" in namespace "gc-1090"
Nov 26 12:51:12.617: INFO: Deleting pod "simpletest.rc-7664k" in namespace "gc-1090"
Nov 26 12:51:12.638: INFO: Deleting pod "simpletest.rc-7cp8c" in namespace "gc-1090"
Nov 26 12:51:12.655: INFO: Deleting pod "simpletest.rc-7fqzf" in namespace "gc-1090"
Nov 26 12:51:12.675: INFO: Deleting pod "simpletest.rc-82ff2" in namespace "gc-1090"
Nov 26 12:51:12.694: INFO: Deleting pod "simpletest.rc-82hkz" in namespace "gc-1090"
Nov 26 12:51:12.714: INFO: Deleting pod "simpletest.rc-8qt6v" in namespace "gc-1090"
Nov 26 12:51:12.731: INFO: Deleting pod "simpletest.rc-8rgjx" in namespace "gc-1090"
Nov 26 12:51:12.752: INFO: Deleting pod "simpletest.rc-92c2q" in namespace "gc-1090"
Nov 26 12:51:12.775: INFO: Deleting pod "simpletest.rc-95hrv" in namespace "gc-1090"
Nov 26 12:51:12.798: INFO: Deleting pod "simpletest.rc-97fbh" in namespace "gc-1090"
Nov 26 12:51:12.818: INFO: Deleting pod "simpletest.rc-9gdf6" in namespace "gc-1090"
Nov 26 12:51:12.842: INFO: Deleting pod "simpletest.rc-9x2wc" in namespace "gc-1090"
Nov 26 12:51:12.863: INFO: Deleting pod "simpletest.rc-bdh6q" in namespace "gc-1090"
Nov 26 12:51:12.882: INFO: Deleting pod "simpletest.rc-bt6cw" in namespace "gc-1090"
Nov 26 12:51:12.910: INFO: Deleting pod "simpletest.rc-cnjt5" in namespace "gc-1090"
Nov 26 12:51:12.934: INFO: Deleting pod "simpletest.rc-crtl2" in namespace "gc-1090"
Nov 26 12:51:12.953: INFO: Deleting pod "simpletest.rc-cx6qr" in namespace "gc-1090"
Nov 26 12:51:12.976: INFO: Deleting pod "simpletest.rc-dgbxn" in namespace "gc-1090"
Nov 26 12:51:12.996: INFO: Deleting pod "simpletest.rc-dtvtn" in namespace "gc-1090"
Nov 26 12:51:13.012: INFO: Deleting pod "simpletest.rc-ffhw7" in namespace "gc-1090"
Nov 26 12:51:13.027: INFO: Deleting pod "simpletest.rc-fst79" in namespace "gc-1090"
Nov 26 12:51:13.051: INFO: Deleting pod "simpletest.rc-fzcgs" in namespace "gc-1090"
Nov 26 12:51:13.068: INFO: Deleting pod "simpletest.rc-gb48s" in namespace "gc-1090"
Nov 26 12:51:13.090: INFO: Deleting pod "simpletest.rc-gmvdp" in namespace "gc-1090"
Nov 26 12:51:13.114: INFO: Deleting pod "simpletest.rc-gnkfd" in namespace "gc-1090"
Nov 26 12:51:13.142: INFO: Deleting pod "simpletest.rc-gtgxt" in namespace "gc-1090"
Nov 26 12:51:13.161: INFO: Deleting pod "simpletest.rc-h92k8" in namespace "gc-1090"
Nov 26 12:51:13.180: INFO: Deleting pod "simpletest.rc-j4b64" in namespace "gc-1090"
Nov 26 12:51:13.197: INFO: Deleting pod "simpletest.rc-jltwb" in namespace "gc-1090"
Nov 26 12:51:13.213: INFO: Deleting pod "simpletest.rc-jvq6d" in namespace "gc-1090"
Nov 26 12:51:13.232: INFO: Deleting pod "simpletest.rc-k72rt" in namespace "gc-1090"
Nov 26 12:51:13.252: INFO: Deleting pod "simpletest.rc-kgvv4" in namespace "gc-1090"
Nov 26 12:51:13.272: INFO: Deleting pod "simpletest.rc-kp5jx" in namespace "gc-1090"
Nov 26 12:51:13.291: INFO: Deleting pod "simpletest.rc-krhxb" in namespace "gc-1090"
Nov 26 12:51:13.311: INFO: Deleting pod "simpletest.rc-kvt2x" in namespace "gc-1090"
Nov 26 12:51:13.327: INFO: Deleting pod "simpletest.rc-kvwc7" in namespace "gc-1090"
Nov 26 12:51:13.347: INFO: Deleting pod "simpletest.rc-l9czr" in namespace "gc-1090"
Nov 26 12:51:13.364: INFO: Deleting pod "simpletest.rc-lfbrq" in namespace "gc-1090"
Nov 26 12:51:13.382: INFO: Deleting pod "simpletest.rc-lph8z" in namespace "gc-1090"
Nov 26 12:51:13.404: INFO: Deleting pod "simpletest.rc-lstrh" in namespace "gc-1090"
Nov 26 12:51:13.423: INFO: Deleting pod "simpletest.rc-lxrn9" in namespace "gc-1090"
Nov 26 12:51:13.445: INFO: Deleting pod "simpletest.rc-m5dq2" in namespace "gc-1090"
Nov 26 12:51:13.464: INFO: Deleting pod "simpletest.rc-m5wbq" in namespace "gc-1090"
Nov 26 12:51:13.483: INFO: Deleting pod "simpletest.rc-m6pq6" in namespace "gc-1090"
Nov 26 12:51:13.497: INFO: Deleting pod "simpletest.rc-m7f59" in namespace "gc-1090"
Nov 26 12:51:13.517: INFO: Deleting pod "simpletest.rc-mc2c9" in namespace "gc-1090"
Nov 26 12:51:13.537: INFO: Deleting pod "simpletest.rc-mqq72" in namespace "gc-1090"
Nov 26 12:51:13.552: INFO: Deleting pod "simpletest.rc-nfjdg" in namespace "gc-1090"
Nov 26 12:51:13.567: INFO: Deleting pod "simpletest.rc-nn4v7" in namespace "gc-1090"
Nov 26 12:51:13.591: INFO: Deleting pod "simpletest.rc-nqw2q" in namespace "gc-1090"
Nov 26 12:51:13.609: INFO: Deleting pod "simpletest.rc-nx2j2" in namespace "gc-1090"
Nov 26 12:51:13.626: INFO: Deleting pod "simpletest.rc-nzc9c" in namespace "gc-1090"
Nov 26 12:51:13.647: INFO: Deleting pod "simpletest.rc-pmh74" in namespace "gc-1090"
Nov 26 12:51:13.664: INFO: Deleting pod "simpletest.rc-pqbsk" in namespace "gc-1090"
Nov 26 12:51:13.679: INFO: Deleting pod "simpletest.rc-pvxnq" in namespace "gc-1090"
Nov 26 12:51:13.700: INFO: Deleting pod "simpletest.rc-qdz8p" in namespace "gc-1090"
Nov 26 12:51:13.717: INFO: Deleting pod "simpletest.rc-qhvrj" in namespace "gc-1090"
Nov 26 12:51:13.741: INFO: Deleting pod "simpletest.rc-r4vb5" in namespace "gc-1090"
Nov 26 12:51:13.767: INFO: Deleting pod "simpletest.rc-r5k5q" in namespace "gc-1090"
Nov 26 12:51:13.787: INFO: Deleting pod "simpletest.rc-rbnbj" in namespace "gc-1090"
Nov 26 12:51:13.805: INFO: Deleting pod "simpletest.rc-rkm4p" in namespace "gc-1090"
Nov 26 12:51:13.823: INFO: Deleting pod "simpletest.rc-rlm2d" in namespace "gc-1090"
Nov 26 12:51:13.852: INFO: Deleting pod "simpletest.rc-rwwb8" in namespace "gc-1090"
Nov 26 12:51:13.903: INFO: Deleting pod "simpletest.rc-svsdl" in namespace "gc-1090"
Nov 26 12:51:13.952: INFO: Deleting pod "simpletest.rc-swbz8" in namespace "gc-1090"
Nov 26 12:51:14.005: INFO: Deleting pod "simpletest.rc-vlp2d" in namespace "gc-1090"
Nov 26 12:51:14.102: INFO: Deleting pod "simpletest.rc-vrpjt" in namespace "gc-1090"
Nov 26 12:51:14.117: INFO: Deleting pod "simpletest.rc-vzzjv" in namespace "gc-1090"
Nov 26 12:51:14.158: INFO: Deleting pod "simpletest.rc-vzzx6" in namespace "gc-1090"
Nov 26 12:51:14.204: INFO: Deleting pod "simpletest.rc-w9lft" in namespace "gc-1090"
Nov 26 12:51:14.255: INFO: Deleting pod "simpletest.rc-wtrlc" in namespace "gc-1090"
Nov 26 12:51:14.304: INFO: Deleting pod "simpletest.rc-xfjh6" in namespace "gc-1090"
Nov 26 12:51:14.354: INFO: Deleting pod "simpletest.rc-xkdkp" in namespace "gc-1090"
Nov 26 12:51:14.406: INFO: Deleting pod "simpletest.rc-xp948" in namespace "gc-1090"
Nov 26 12:51:14.454: INFO: Deleting pod "simpletest.rc-xrng2" in namespace "gc-1090"
Nov 26 12:51:14.503: INFO: Deleting pod "simpletest.rc-xxqzg" in namespace "gc-1090"
Nov 26 12:51:14.557: INFO: Deleting pod "simpletest.rc-z422r" in namespace "gc-1090"
Nov 26 12:51:14.607: INFO: Deleting pod "simpletest.rc-zl2w4" in namespace "gc-1090"
Nov 26 12:51:14.653: INFO: Deleting pod "simpletest.rc-zsff7" in namespace "gc-1090"
Nov 26 12:51:14.703: INFO: Deleting pod "simpletest.rc-zzt8t" in namespace "gc-1090"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 26 12:51:14.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1090" for this suite. 11/26/22 12:51:14.79
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":227,"skipped":4246,"failed":0}
------------------------------
â€¢ [SLOW TEST] [42.915 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:50:31.93
    Nov 26 12:50:31.930: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename gc 11/26/22 12:50:31.931
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:50:32.038
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:50:32.046
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 11/26/22 12:50:32.068
    STEP: delete the rc 11/26/22 12:50:37.084
    STEP: wait for the rc to be deleted 11/26/22 12:50:37.121
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 11/26/22 12:50:42.13
    STEP: Gathering metrics 11/26/22 12:51:12.155
    W1126 12:51:12.162436      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 26 12:51:12.164: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Nov 26 12:51:12.164: INFO: Deleting pod "simpletest.rc-24dc9" in namespace "gc-1090"
    Nov 26 12:51:12.182: INFO: Deleting pod "simpletest.rc-2r9pl" in namespace "gc-1090"
    Nov 26 12:51:12.203: INFO: Deleting pod "simpletest.rc-2w2wg" in namespace "gc-1090"
    Nov 26 12:51:12.228: INFO: Deleting pod "simpletest.rc-2zxk4" in namespace "gc-1090"
    Nov 26 12:51:12.258: INFO: Deleting pod "simpletest.rc-422kx" in namespace "gc-1090"
    Nov 26 12:51:12.278: INFO: Deleting pod "simpletest.rc-44ctv" in namespace "gc-1090"
    Nov 26 12:51:12.297: INFO: Deleting pod "simpletest.rc-4gthp" in namespace "gc-1090"
    Nov 26 12:51:12.317: INFO: Deleting pod "simpletest.rc-4xfxz" in namespace "gc-1090"
    Nov 26 12:51:12.341: INFO: Deleting pod "simpletest.rc-5m4rx" in namespace "gc-1090"
    Nov 26 12:51:12.374: INFO: Deleting pod "simpletest.rc-5sxzx" in namespace "gc-1090"
    Nov 26 12:51:12.393: INFO: Deleting pod "simpletest.rc-69klh" in namespace "gc-1090"
    Nov 26 12:51:12.417: INFO: Deleting pod "simpletest.rc-6fv6p" in namespace "gc-1090"
    Nov 26 12:51:12.439: INFO: Deleting pod "simpletest.rc-6kn75" in namespace "gc-1090"
    Nov 26 12:51:12.460: INFO: Deleting pod "simpletest.rc-6ln7j" in namespace "gc-1090"
    Nov 26 12:51:12.486: INFO: Deleting pod "simpletest.rc-6xbwc" in namespace "gc-1090"
    Nov 26 12:51:12.512: INFO: Deleting pod "simpletest.rc-6zfxq" in namespace "gc-1090"
    Nov 26 12:51:12.532: INFO: Deleting pod "simpletest.rc-72nst" in namespace "gc-1090"
    Nov 26 12:51:12.552: INFO: Deleting pod "simpletest.rc-74l27" in namespace "gc-1090"
    Nov 26 12:51:12.575: INFO: Deleting pod "simpletest.rc-75gw2" in namespace "gc-1090"
    Nov 26 12:51:12.594: INFO: Deleting pod "simpletest.rc-75t64" in namespace "gc-1090"
    Nov 26 12:51:12.617: INFO: Deleting pod "simpletest.rc-7664k" in namespace "gc-1090"
    Nov 26 12:51:12.638: INFO: Deleting pod "simpletest.rc-7cp8c" in namespace "gc-1090"
    Nov 26 12:51:12.655: INFO: Deleting pod "simpletest.rc-7fqzf" in namespace "gc-1090"
    Nov 26 12:51:12.675: INFO: Deleting pod "simpletest.rc-82ff2" in namespace "gc-1090"
    Nov 26 12:51:12.694: INFO: Deleting pod "simpletest.rc-82hkz" in namespace "gc-1090"
    Nov 26 12:51:12.714: INFO: Deleting pod "simpletest.rc-8qt6v" in namespace "gc-1090"
    Nov 26 12:51:12.731: INFO: Deleting pod "simpletest.rc-8rgjx" in namespace "gc-1090"
    Nov 26 12:51:12.752: INFO: Deleting pod "simpletest.rc-92c2q" in namespace "gc-1090"
    Nov 26 12:51:12.775: INFO: Deleting pod "simpletest.rc-95hrv" in namespace "gc-1090"
    Nov 26 12:51:12.798: INFO: Deleting pod "simpletest.rc-97fbh" in namespace "gc-1090"
    Nov 26 12:51:12.818: INFO: Deleting pod "simpletest.rc-9gdf6" in namespace "gc-1090"
    Nov 26 12:51:12.842: INFO: Deleting pod "simpletest.rc-9x2wc" in namespace "gc-1090"
    Nov 26 12:51:12.863: INFO: Deleting pod "simpletest.rc-bdh6q" in namespace "gc-1090"
    Nov 26 12:51:12.882: INFO: Deleting pod "simpletest.rc-bt6cw" in namespace "gc-1090"
    Nov 26 12:51:12.910: INFO: Deleting pod "simpletest.rc-cnjt5" in namespace "gc-1090"
    Nov 26 12:51:12.934: INFO: Deleting pod "simpletest.rc-crtl2" in namespace "gc-1090"
    Nov 26 12:51:12.953: INFO: Deleting pod "simpletest.rc-cx6qr" in namespace "gc-1090"
    Nov 26 12:51:12.976: INFO: Deleting pod "simpletest.rc-dgbxn" in namespace "gc-1090"
    Nov 26 12:51:12.996: INFO: Deleting pod "simpletest.rc-dtvtn" in namespace "gc-1090"
    Nov 26 12:51:13.012: INFO: Deleting pod "simpletest.rc-ffhw7" in namespace "gc-1090"
    Nov 26 12:51:13.027: INFO: Deleting pod "simpletest.rc-fst79" in namespace "gc-1090"
    Nov 26 12:51:13.051: INFO: Deleting pod "simpletest.rc-fzcgs" in namespace "gc-1090"
    Nov 26 12:51:13.068: INFO: Deleting pod "simpletest.rc-gb48s" in namespace "gc-1090"
    Nov 26 12:51:13.090: INFO: Deleting pod "simpletest.rc-gmvdp" in namespace "gc-1090"
    Nov 26 12:51:13.114: INFO: Deleting pod "simpletest.rc-gnkfd" in namespace "gc-1090"
    Nov 26 12:51:13.142: INFO: Deleting pod "simpletest.rc-gtgxt" in namespace "gc-1090"
    Nov 26 12:51:13.161: INFO: Deleting pod "simpletest.rc-h92k8" in namespace "gc-1090"
    Nov 26 12:51:13.180: INFO: Deleting pod "simpletest.rc-j4b64" in namespace "gc-1090"
    Nov 26 12:51:13.197: INFO: Deleting pod "simpletest.rc-jltwb" in namespace "gc-1090"
    Nov 26 12:51:13.213: INFO: Deleting pod "simpletest.rc-jvq6d" in namespace "gc-1090"
    Nov 26 12:51:13.232: INFO: Deleting pod "simpletest.rc-k72rt" in namespace "gc-1090"
    Nov 26 12:51:13.252: INFO: Deleting pod "simpletest.rc-kgvv4" in namespace "gc-1090"
    Nov 26 12:51:13.272: INFO: Deleting pod "simpletest.rc-kp5jx" in namespace "gc-1090"
    Nov 26 12:51:13.291: INFO: Deleting pod "simpletest.rc-krhxb" in namespace "gc-1090"
    Nov 26 12:51:13.311: INFO: Deleting pod "simpletest.rc-kvt2x" in namespace "gc-1090"
    Nov 26 12:51:13.327: INFO: Deleting pod "simpletest.rc-kvwc7" in namespace "gc-1090"
    Nov 26 12:51:13.347: INFO: Deleting pod "simpletest.rc-l9czr" in namespace "gc-1090"
    Nov 26 12:51:13.364: INFO: Deleting pod "simpletest.rc-lfbrq" in namespace "gc-1090"
    Nov 26 12:51:13.382: INFO: Deleting pod "simpletest.rc-lph8z" in namespace "gc-1090"
    Nov 26 12:51:13.404: INFO: Deleting pod "simpletest.rc-lstrh" in namespace "gc-1090"
    Nov 26 12:51:13.423: INFO: Deleting pod "simpletest.rc-lxrn9" in namespace "gc-1090"
    Nov 26 12:51:13.445: INFO: Deleting pod "simpletest.rc-m5dq2" in namespace "gc-1090"
    Nov 26 12:51:13.464: INFO: Deleting pod "simpletest.rc-m5wbq" in namespace "gc-1090"
    Nov 26 12:51:13.483: INFO: Deleting pod "simpletest.rc-m6pq6" in namespace "gc-1090"
    Nov 26 12:51:13.497: INFO: Deleting pod "simpletest.rc-m7f59" in namespace "gc-1090"
    Nov 26 12:51:13.517: INFO: Deleting pod "simpletest.rc-mc2c9" in namespace "gc-1090"
    Nov 26 12:51:13.537: INFO: Deleting pod "simpletest.rc-mqq72" in namespace "gc-1090"
    Nov 26 12:51:13.552: INFO: Deleting pod "simpletest.rc-nfjdg" in namespace "gc-1090"
    Nov 26 12:51:13.567: INFO: Deleting pod "simpletest.rc-nn4v7" in namespace "gc-1090"
    Nov 26 12:51:13.591: INFO: Deleting pod "simpletest.rc-nqw2q" in namespace "gc-1090"
    Nov 26 12:51:13.609: INFO: Deleting pod "simpletest.rc-nx2j2" in namespace "gc-1090"
    Nov 26 12:51:13.626: INFO: Deleting pod "simpletest.rc-nzc9c" in namespace "gc-1090"
    Nov 26 12:51:13.647: INFO: Deleting pod "simpletest.rc-pmh74" in namespace "gc-1090"
    Nov 26 12:51:13.664: INFO: Deleting pod "simpletest.rc-pqbsk" in namespace "gc-1090"
    Nov 26 12:51:13.679: INFO: Deleting pod "simpletest.rc-pvxnq" in namespace "gc-1090"
    Nov 26 12:51:13.700: INFO: Deleting pod "simpletest.rc-qdz8p" in namespace "gc-1090"
    Nov 26 12:51:13.717: INFO: Deleting pod "simpletest.rc-qhvrj" in namespace "gc-1090"
    Nov 26 12:51:13.741: INFO: Deleting pod "simpletest.rc-r4vb5" in namespace "gc-1090"
    Nov 26 12:51:13.767: INFO: Deleting pod "simpletest.rc-r5k5q" in namespace "gc-1090"
    Nov 26 12:51:13.787: INFO: Deleting pod "simpletest.rc-rbnbj" in namespace "gc-1090"
    Nov 26 12:51:13.805: INFO: Deleting pod "simpletest.rc-rkm4p" in namespace "gc-1090"
    Nov 26 12:51:13.823: INFO: Deleting pod "simpletest.rc-rlm2d" in namespace "gc-1090"
    Nov 26 12:51:13.852: INFO: Deleting pod "simpletest.rc-rwwb8" in namespace "gc-1090"
    Nov 26 12:51:13.903: INFO: Deleting pod "simpletest.rc-svsdl" in namespace "gc-1090"
    Nov 26 12:51:13.952: INFO: Deleting pod "simpletest.rc-swbz8" in namespace "gc-1090"
    Nov 26 12:51:14.005: INFO: Deleting pod "simpletest.rc-vlp2d" in namespace "gc-1090"
    Nov 26 12:51:14.102: INFO: Deleting pod "simpletest.rc-vrpjt" in namespace "gc-1090"
    Nov 26 12:51:14.117: INFO: Deleting pod "simpletest.rc-vzzjv" in namespace "gc-1090"
    Nov 26 12:51:14.158: INFO: Deleting pod "simpletest.rc-vzzx6" in namespace "gc-1090"
    Nov 26 12:51:14.204: INFO: Deleting pod "simpletest.rc-w9lft" in namespace "gc-1090"
    Nov 26 12:51:14.255: INFO: Deleting pod "simpletest.rc-wtrlc" in namespace "gc-1090"
    Nov 26 12:51:14.304: INFO: Deleting pod "simpletest.rc-xfjh6" in namespace "gc-1090"
    Nov 26 12:51:14.354: INFO: Deleting pod "simpletest.rc-xkdkp" in namespace "gc-1090"
    Nov 26 12:51:14.406: INFO: Deleting pod "simpletest.rc-xp948" in namespace "gc-1090"
    Nov 26 12:51:14.454: INFO: Deleting pod "simpletest.rc-xrng2" in namespace "gc-1090"
    Nov 26 12:51:14.503: INFO: Deleting pod "simpletest.rc-xxqzg" in namespace "gc-1090"
    Nov 26 12:51:14.557: INFO: Deleting pod "simpletest.rc-z422r" in namespace "gc-1090"
    Nov 26 12:51:14.607: INFO: Deleting pod "simpletest.rc-zl2w4" in namespace "gc-1090"
    Nov 26 12:51:14.653: INFO: Deleting pod "simpletest.rc-zsff7" in namespace "gc-1090"
    Nov 26 12:51:14.703: INFO: Deleting pod "simpletest.rc-zzt8t" in namespace "gc-1090"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 26 12:51:14.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1090" for this suite. 11/26/22 12:51:14.79
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:51:14.848
Nov 26 12:51:14.848: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-runtime 11/26/22 12:51:14.849
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:14.872
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:14.883
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 11/26/22 12:51:14.89
STEP: wait for the container to reach Succeeded 11/26/22 12:51:14.9
STEP: get the container status 11/26/22 12:51:29.066
STEP: the container should be terminated 11/26/22 12:51:29.072
STEP: the termination message should be set 11/26/22 12:51:29.072
Nov 26 12:51:29.073: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 11/26/22 12:51:29.073
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 26 12:51:29.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6463" for this suite. 11/26/22 12:51:29.107
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":228,"skipped":4252,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.269 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:51:14.848
    Nov 26 12:51:14.848: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-runtime 11/26/22 12:51:14.849
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:14.872
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:14.883
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 11/26/22 12:51:14.89
    STEP: wait for the container to reach Succeeded 11/26/22 12:51:14.9
    STEP: get the container status 11/26/22 12:51:29.066
    STEP: the container should be terminated 11/26/22 12:51:29.072
    STEP: the termination message should be set 11/26/22 12:51:29.072
    Nov 26 12:51:29.073: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 11/26/22 12:51:29.073
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 26 12:51:29.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-6463" for this suite. 11/26/22 12:51:29.107
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:51:29.118
Nov 26 12:51:29.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 12:51:29.119
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:29.142
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:29.154
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 11/26/22 12:51:29.162
STEP: submitting the pod to kubernetes 11/26/22 12:51:29.162
Nov 26 12:51:29.176: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8" in namespace "pods-5559" to be "running and ready"
Nov 26 12:51:29.182: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.93661ms
Nov 26 12:51:29.182: INFO: The phase of Pod pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:51:31.189: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012818675s
Nov 26 12:51:31.189: INFO: The phase of Pod pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 12:51:33.191: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Running", Reason="", readiness=true. Elapsed: 4.014288608s
Nov 26 12:51:33.191: INFO: The phase of Pod pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8 is Running (Ready = true)
Nov 26 12:51:33.191: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 11/26/22 12:51:33.197
STEP: updating the pod 11/26/22 12:51:33.203
Nov 26 12:51:33.720: INFO: Successfully updated pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8"
Nov 26 12:51:33.720: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8" in namespace "pods-5559" to be "terminated with reason DeadlineExceeded"
Nov 26 12:51:33.726: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Running", Reason="", readiness=true. Elapsed: 6.044571ms
Nov 26 12:51:35.736: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Running", Reason="", readiness=false. Elapsed: 2.016073226s
Nov 26 12:51:37.736: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.015125686s
Nov 26 12:51:37.736: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 26 12:51:37.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5559" for this suite. 11/26/22 12:51:37.742
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":229,"skipped":4256,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.635 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:51:29.118
    Nov 26 12:51:29.118: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 12:51:29.119
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:29.142
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:29.154
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 11/26/22 12:51:29.162
    STEP: submitting the pod to kubernetes 11/26/22 12:51:29.162
    Nov 26 12:51:29.176: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8" in namespace "pods-5559" to be "running and ready"
    Nov 26 12:51:29.182: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.93661ms
    Nov 26 12:51:29.182: INFO: The phase of Pod pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:51:31.189: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012818675s
    Nov 26 12:51:31.189: INFO: The phase of Pod pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 12:51:33.191: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Running", Reason="", readiness=true. Elapsed: 4.014288608s
    Nov 26 12:51:33.191: INFO: The phase of Pod pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8 is Running (Ready = true)
    Nov 26 12:51:33.191: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 11/26/22 12:51:33.197
    STEP: updating the pod 11/26/22 12:51:33.203
    Nov 26 12:51:33.720: INFO: Successfully updated pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8"
    Nov 26 12:51:33.720: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8" in namespace "pods-5559" to be "terminated with reason DeadlineExceeded"
    Nov 26 12:51:33.726: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Running", Reason="", readiness=true. Elapsed: 6.044571ms
    Nov 26 12:51:35.736: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Running", Reason="", readiness=false. Elapsed: 2.016073226s
    Nov 26 12:51:37.736: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.015125686s
    Nov 26 12:51:37.736: INFO: Pod "pod-update-activedeadlineseconds-41e4672f-9e0f-4614-8830-ff9758a569e8" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 26 12:51:37.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5559" for this suite. 11/26/22 12:51:37.742
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:51:37.758
Nov 26 12:51:37.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename namespaces 11/26/22 12:51:37.76
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:37.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:37.79
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 11/26/22 12:51:37.796
STEP: patching the Namespace 11/26/22 12:51:37.817
STEP: get the Namespace and ensuring it has the label 11/26/22 12:51:37.829
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:51:37.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4640" for this suite. 11/26/22 12:51:37.844
STEP: Destroying namespace "nspatchtest-f82c7c22-e076-4220-b06e-602de2011dbb-8939" for this suite. 11/26/22 12:51:37.853
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":230,"skipped":4295,"failed":0}
------------------------------
â€¢ [0.104 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:51:37.758
    Nov 26 12:51:37.759: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename namespaces 11/26/22 12:51:37.76
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:37.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:37.79
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 11/26/22 12:51:37.796
    STEP: patching the Namespace 11/26/22 12:51:37.817
    STEP: get the Namespace and ensuring it has the label 11/26/22 12:51:37.829
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:51:37.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4640" for this suite. 11/26/22 12:51:37.844
    STEP: Destroying namespace "nspatchtest-f82c7c22-e076-4220-b06e-602de2011dbb-8939" for this suite. 11/26/22 12:51:37.853
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:51:37.871
Nov 26 12:51:37.871: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 12:51:37.872
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:37.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:37.9
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-4a080c3c-2170-40d2-b9da-312fefb90847 11/26/22 12:51:37.911
STEP: Creating a pod to test consume secrets 11/26/22 12:51:37.932
Nov 26 12:51:37.952: INFO: Waiting up to 5m0s for pod "pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c" in namespace "secrets-6195" to be "Succeeded or Failed"
Nov 26 12:51:37.960: INFO: Pod "pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.312292ms
Nov 26 12:51:39.968: INFO: Pod "pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015568242s
Nov 26 12:51:41.967: INFO: Pod "pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014232116s
STEP: Saw pod success 11/26/22 12:51:41.967
Nov 26 12:51:41.967: INFO: Pod "pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c" satisfied condition "Succeeded or Failed"
Nov 26 12:51:41.974: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c container secret-volume-test: <nil>
STEP: delete the pod 11/26/22 12:51:42.002
Nov 26 12:51:42.033: INFO: Waiting for pod pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c to disappear
Nov 26 12:51:42.042: INFO: Pod pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 26 12:51:42.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6195" for this suite. 11/26/22 12:51:42.049
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":231,"skipped":4340,"failed":0}
------------------------------
â€¢ [4.194 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:51:37.871
    Nov 26 12:51:37.871: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 12:51:37.872
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:37.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:37.9
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-4a080c3c-2170-40d2-b9da-312fefb90847 11/26/22 12:51:37.911
    STEP: Creating a pod to test consume secrets 11/26/22 12:51:37.932
    Nov 26 12:51:37.952: INFO: Waiting up to 5m0s for pod "pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c" in namespace "secrets-6195" to be "Succeeded or Failed"
    Nov 26 12:51:37.960: INFO: Pod "pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.312292ms
    Nov 26 12:51:39.968: INFO: Pod "pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015568242s
    Nov 26 12:51:41.967: INFO: Pod "pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014232116s
    STEP: Saw pod success 11/26/22 12:51:41.967
    Nov 26 12:51:41.967: INFO: Pod "pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c" satisfied condition "Succeeded or Failed"
    Nov 26 12:51:41.974: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c container secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:51:42.002
    Nov 26 12:51:42.033: INFO: Waiting for pod pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c to disappear
    Nov 26 12:51:42.042: INFO: Pod pod-secrets-d93d84ec-3b2a-4fa3-9d74-1a53e0af1c1c no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 12:51:42.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6195" for this suite. 11/26/22 12:51:42.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:51:42.066
Nov 26 12:51:42.067: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 12:51:42.067
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:42.093
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:42.102
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 11/26/22 12:51:42.108
Nov 26 12:51:42.123: INFO: Waiting up to 5m0s for pod "pod-17ada554-bb22-4653-9ac8-a44e87d91706" in namespace "emptydir-3600" to be "Succeeded or Failed"
Nov 26 12:51:42.133: INFO: Pod "pod-17ada554-bb22-4653-9ac8-a44e87d91706": Phase="Pending", Reason="", readiness=false. Elapsed: 10.548084ms
Nov 26 12:51:44.141: INFO: Pod "pod-17ada554-bb22-4653-9ac8-a44e87d91706": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017864315s
Nov 26 12:51:46.140: INFO: Pod "pod-17ada554-bb22-4653-9ac8-a44e87d91706": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017321076s
STEP: Saw pod success 11/26/22 12:51:46.14
Nov 26 12:51:46.141: INFO: Pod "pod-17ada554-bb22-4653-9ac8-a44e87d91706" satisfied condition "Succeeded or Failed"
Nov 26 12:51:46.146: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-17ada554-bb22-4653-9ac8-a44e87d91706 container test-container: <nil>
STEP: delete the pod 11/26/22 12:51:46.155
Nov 26 12:51:46.174: INFO: Waiting for pod pod-17ada554-bb22-4653-9ac8-a44e87d91706 to disappear
Nov 26 12:51:46.182: INFO: Pod pod-17ada554-bb22-4653-9ac8-a44e87d91706 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 12:51:46.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3600" for this suite. 11/26/22 12:51:46.189
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":232,"skipped":4356,"failed":0}
------------------------------
â€¢ [4.133 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:51:42.066
    Nov 26 12:51:42.067: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 12:51:42.067
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:42.093
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:42.102
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 11/26/22 12:51:42.108
    Nov 26 12:51:42.123: INFO: Waiting up to 5m0s for pod "pod-17ada554-bb22-4653-9ac8-a44e87d91706" in namespace "emptydir-3600" to be "Succeeded or Failed"
    Nov 26 12:51:42.133: INFO: Pod "pod-17ada554-bb22-4653-9ac8-a44e87d91706": Phase="Pending", Reason="", readiness=false. Elapsed: 10.548084ms
    Nov 26 12:51:44.141: INFO: Pod "pod-17ada554-bb22-4653-9ac8-a44e87d91706": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017864315s
    Nov 26 12:51:46.140: INFO: Pod "pod-17ada554-bb22-4653-9ac8-a44e87d91706": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017321076s
    STEP: Saw pod success 11/26/22 12:51:46.14
    Nov 26 12:51:46.141: INFO: Pod "pod-17ada554-bb22-4653-9ac8-a44e87d91706" satisfied condition "Succeeded or Failed"
    Nov 26 12:51:46.146: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-17ada554-bb22-4653-9ac8-a44e87d91706 container test-container: <nil>
    STEP: delete the pod 11/26/22 12:51:46.155
    Nov 26 12:51:46.174: INFO: Waiting for pod pod-17ada554-bb22-4653-9ac8-a44e87d91706 to disappear
    Nov 26 12:51:46.182: INFO: Pod pod-17ada554-bb22-4653-9ac8-a44e87d91706 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 12:51:46.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3600" for this suite. 11/26/22 12:51:46.189
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:51:46.206
Nov 26 12:51:46.206: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename var-expansion 11/26/22 12:51:46.207
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:46.231
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:46.249
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Nov 26 12:51:46.271: INFO: Waiting up to 2m0s for pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199" in namespace "var-expansion-36" to be "container 0 failed with reason CreateContainerConfigError"
Nov 26 12:51:46.284: INFO: Pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199": Phase="Pending", Reason="", readiness=false. Elapsed: 12.392126ms
Nov 26 12:51:48.289: INFO: Pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017886152s
Nov 26 12:51:48.289: INFO: Pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Nov 26 12:51:48.289: INFO: Deleting pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199" in namespace "var-expansion-36"
Nov 26 12:51:48.303: INFO: Wait up to 5m0s for pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 26 12:51:50.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-36" for this suite. 11/26/22 12:51:50.321
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":233,"skipped":4377,"failed":0}
------------------------------
â€¢ [4.128 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:51:46.206
    Nov 26 12:51:46.206: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename var-expansion 11/26/22 12:51:46.207
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:46.231
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:46.249
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Nov 26 12:51:46.271: INFO: Waiting up to 2m0s for pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199" in namespace "var-expansion-36" to be "container 0 failed with reason CreateContainerConfigError"
    Nov 26 12:51:46.284: INFO: Pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199": Phase="Pending", Reason="", readiness=false. Elapsed: 12.392126ms
    Nov 26 12:51:48.289: INFO: Pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017886152s
    Nov 26 12:51:48.289: INFO: Pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Nov 26 12:51:48.289: INFO: Deleting pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199" in namespace "var-expansion-36"
    Nov 26 12:51:48.303: INFO: Wait up to 5m0s for pod "var-expansion-77b513f1-1558-464c-80f4-d7780dcf1199" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 26 12:51:50.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-36" for this suite. 11/26/22 12:51:50.321
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:51:50.336
Nov 26 12:51:50.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename daemonsets 11/26/22 12:51:50.337
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:50.359
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:50.368
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Nov 26 12:51:50.403: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 11/26/22 12:51:50.413
Nov 26 12:51:50.419: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:51:50.419: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 11/26/22 12:51:50.42
Nov 26 12:51:50.450: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:51:50.450: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:51:51.457: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:51:51.457: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:51:52.456: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 26 12:51:52.456: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 11/26/22 12:51:52.462
Nov 26 12:51:52.491: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 26 12:51:52.491: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Nov 26 12:51:53.497: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:51:53.497: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 11/26/22 12:51:53.497
Nov 26 12:51:53.520: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:51:53.520: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:51:54.529: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:51:54.529: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:51:55.526: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:51:55.526: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:51:56.526: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:51:56.527: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 12:51:57.527: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov 26 12:51:57.527: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:51:57.542
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4014, will wait for the garbage collector to delete the pods 11/26/22 12:51:57.542
Nov 26 12:51:57.609: INFO: Deleting DaemonSet.extensions daemon-set took: 10.67182ms
Nov 26 12:51:57.710: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.151836ms
Nov 26 12:51:59.815: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov 26 12:51:59.815: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov 26 12:51:59.821: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28588"},"items":null}

Nov 26 12:51:59.833: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28588"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:51:59.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4014" for this suite. 11/26/22 12:51:59.885
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":234,"skipped":4396,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.567 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:51:50.336
    Nov 26 12:51:50.336: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename daemonsets 11/26/22 12:51:50.337
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:50.359
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:50.368
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Nov 26 12:51:50.403: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 11/26/22 12:51:50.413
    Nov 26 12:51:50.419: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:51:50.419: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 11/26/22 12:51:50.42
    Nov 26 12:51:50.450: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:51:50.450: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:51:51.457: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:51:51.457: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:51:52.456: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 26 12:51:52.456: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 11/26/22 12:51:52.462
    Nov 26 12:51:52.491: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 26 12:51:52.491: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Nov 26 12:51:53.497: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:51:53.497: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 11/26/22 12:51:53.497
    Nov 26 12:51:53.520: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:51:53.520: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:51:54.529: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:51:54.529: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:51:55.526: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:51:55.526: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:51:56.526: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:51:56.527: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 12:51:57.527: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov 26 12:51:57.527: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/26/22 12:51:57.542
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4014, will wait for the garbage collector to delete the pods 11/26/22 12:51:57.542
    Nov 26 12:51:57.609: INFO: Deleting DaemonSet.extensions daemon-set took: 10.67182ms
    Nov 26 12:51:57.710: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.151836ms
    Nov 26 12:51:59.815: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov 26 12:51:59.815: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov 26 12:51:59.821: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"28588"},"items":null}

    Nov 26 12:51:59.833: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"28588"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:51:59.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4014" for this suite. 11/26/22 12:51:59.885
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:51:59.904
Nov 26 12:51:59.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 12:51:59.905
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:59.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:59.945
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 11/26/22 12:51:59.95
STEP: Creating a ResourceQuota 11/26/22 12:52:04.959
STEP: Ensuring resource quota status is calculated 11/26/22 12:52:04.979
STEP: Creating a Pod that fits quota 11/26/22 12:52:06.986
STEP: Ensuring ResourceQuota status captures the pod usage 11/26/22 12:52:07.021
STEP: Not allowing a pod to be created that exceeds remaining quota 11/26/22 12:52:09.029
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 11/26/22 12:52:09.034
STEP: Ensuring a pod cannot update its resource requirements 11/26/22 12:52:09.038
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 11/26/22 12:52:09.045
STEP: Deleting the pod 11/26/22 12:52:11.054
STEP: Ensuring resource quota status released the pod usage 11/26/22 12:52:11.083
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 12:52:13.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9520" for this suite. 11/26/22 12:52:13.097
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":235,"skipped":4404,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.203 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:51:59.904
    Nov 26 12:51:59.904: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 12:51:59.905
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:51:59.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:51:59.945
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 11/26/22 12:51:59.95
    STEP: Creating a ResourceQuota 11/26/22 12:52:04.959
    STEP: Ensuring resource quota status is calculated 11/26/22 12:52:04.979
    STEP: Creating a Pod that fits quota 11/26/22 12:52:06.986
    STEP: Ensuring ResourceQuota status captures the pod usage 11/26/22 12:52:07.021
    STEP: Not allowing a pod to be created that exceeds remaining quota 11/26/22 12:52:09.029
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 11/26/22 12:52:09.034
    STEP: Ensuring a pod cannot update its resource requirements 11/26/22 12:52:09.038
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 11/26/22 12:52:09.045
    STEP: Deleting the pod 11/26/22 12:52:11.054
    STEP: Ensuring resource quota status released the pod usage 11/26/22 12:52:11.083
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 12:52:13.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9520" for this suite. 11/26/22 12:52:13.097
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:52:13.108
Nov 26 12:52:13.108: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 12:52:13.109
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:52:13.136
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:52:13.144
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 11/26/22 12:52:13.153
STEP: Ensuring ResourceQuota status is calculated 11/26/22 12:52:13.162
STEP: Creating a ResourceQuota with not terminating scope 11/26/22 12:52:15.169
STEP: Ensuring ResourceQuota status is calculated 11/26/22 12:52:15.178
STEP: Creating a long running pod 11/26/22 12:52:17.184
STEP: Ensuring resource quota with not terminating scope captures the pod usage 11/26/22 12:52:17.208
STEP: Ensuring resource quota with terminating scope ignored the pod usage 11/26/22 12:52:19.215
STEP: Deleting the pod 11/26/22 12:52:21.222
STEP: Ensuring resource quota status released the pod usage 11/26/22 12:52:21.245
STEP: Creating a terminating pod 11/26/22 12:52:23.254
STEP: Ensuring resource quota with terminating scope captures the pod usage 11/26/22 12:52:23.271
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 11/26/22 12:52:25.28
STEP: Deleting the pod 11/26/22 12:52:27.287
STEP: Ensuring resource quota status released the pod usage 11/26/22 12:52:27.312
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 12:52:29.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7781" for this suite. 11/26/22 12:52:29.325
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":236,"skipped":4407,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.227 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:52:13.108
    Nov 26 12:52:13.108: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 12:52:13.109
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:52:13.136
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:52:13.144
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 11/26/22 12:52:13.153
    STEP: Ensuring ResourceQuota status is calculated 11/26/22 12:52:13.162
    STEP: Creating a ResourceQuota with not terminating scope 11/26/22 12:52:15.169
    STEP: Ensuring ResourceQuota status is calculated 11/26/22 12:52:15.178
    STEP: Creating a long running pod 11/26/22 12:52:17.184
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 11/26/22 12:52:17.208
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 11/26/22 12:52:19.215
    STEP: Deleting the pod 11/26/22 12:52:21.222
    STEP: Ensuring resource quota status released the pod usage 11/26/22 12:52:21.245
    STEP: Creating a terminating pod 11/26/22 12:52:23.254
    STEP: Ensuring resource quota with terminating scope captures the pod usage 11/26/22 12:52:23.271
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 11/26/22 12:52:25.28
    STEP: Deleting the pod 11/26/22 12:52:27.287
    STEP: Ensuring resource quota status released the pod usage 11/26/22 12:52:27.312
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 12:52:29.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7781" for this suite. 11/26/22 12:52:29.325
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:52:29.338
Nov 26 12:52:29.338: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:52:29.339
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:52:29.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:52:29.373
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:52:29.404
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:52:30.148
STEP: Deploying the webhook pod 11/26/22 12:52:30.166
STEP: Wait for the deployment to be ready 11/26/22 12:52:30.188
Nov 26 12:52:30.208: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 26 12:52:32.227: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 52, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 52, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 52, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 52, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/26/22 12:52:34.233
STEP: Verifying the service has paired with the endpoint 11/26/22 12:52:34.248
Nov 26 12:52:35.250: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 11/26/22 12:52:35.265
STEP: create a pod that should be denied by the webhook 11/26/22 12:52:35.287
STEP: create a pod that causes the webhook to hang 11/26/22 12:52:35.303
STEP: create a configmap that should be denied by the webhook 11/26/22 12:52:45.319
STEP: create a configmap that should be admitted by the webhook 11/26/22 12:52:45.474
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 11/26/22 12:52:45.487
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 11/26/22 12:52:45.504
STEP: create a namespace that bypass the webhook 11/26/22 12:52:45.511
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 11/26/22 12:52:45.532
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:52:45.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6491" for this suite. 11/26/22 12:52:45.593
STEP: Destroying namespace "webhook-6491-markers" for this suite. 11/26/22 12:52:45.608
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":237,"skipped":4423,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.433 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:52:29.338
    Nov 26 12:52:29.338: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:52:29.339
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:52:29.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:52:29.373
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:52:29.404
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:52:30.148
    STEP: Deploying the webhook pod 11/26/22 12:52:30.166
    STEP: Wait for the deployment to be ready 11/26/22 12:52:30.188
    Nov 26 12:52:30.208: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 26 12:52:32.227: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 12, 52, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 52, 30, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 12, 52, 30, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 12, 52, 30, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/26/22 12:52:34.233
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:52:34.248
    Nov 26 12:52:35.250: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 11/26/22 12:52:35.265
    STEP: create a pod that should be denied by the webhook 11/26/22 12:52:35.287
    STEP: create a pod that causes the webhook to hang 11/26/22 12:52:35.303
    STEP: create a configmap that should be denied by the webhook 11/26/22 12:52:45.319
    STEP: create a configmap that should be admitted by the webhook 11/26/22 12:52:45.474
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 11/26/22 12:52:45.487
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 11/26/22 12:52:45.504
    STEP: create a namespace that bypass the webhook 11/26/22 12:52:45.511
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 11/26/22 12:52:45.532
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:52:45.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6491" for this suite. 11/26/22 12:52:45.593
    STEP: Destroying namespace "webhook-6491-markers" for this suite. 11/26/22 12:52:45.608
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:52:45.772
Nov 26 12:52:45.772: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:52:45.774
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:52:45.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:52:45.829
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8447 11/26/22 12:52:45.837
STEP: changing the ExternalName service to type=NodePort 11/26/22 12:52:45.853
STEP: creating replication controller externalname-service in namespace services-8447 11/26/22 12:52:45.895
I1126 12:52:45.907228      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-8447, replica count: 2
I1126 12:52:48.958246      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 12:52:48.958: INFO: Creating new exec pod
Nov 26 12:52:48.967: INFO: Waiting up to 5m0s for pod "execpod5ncsr" in namespace "services-8447" to be "running"
Nov 26 12:52:48.973: INFO: Pod "execpod5ncsr": Phase="Pending", Reason="", readiness=false. Elapsed: 5.528002ms
Nov 26 12:52:50.980: INFO: Pod "execpod5ncsr": Phase="Running", Reason="", readiness=true. Elapsed: 2.012515356s
Nov 26 12:52:50.980: INFO: Pod "execpod5ncsr" satisfied condition "running"
Nov 26 12:52:51.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:52:52.195: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:52:52.196: INFO: stdout: ""
Nov 26 12:52:53.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:52:53.394: INFO: stderr: "+ + ncecho hostName\n -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:52:53.394: INFO: stdout: ""
Nov 26 12:52:54.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:52:54.393: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:52:54.393: INFO: stdout: "externalname-service-gzbj8"
Nov 26 12:52:54.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.234 80'
Nov 26 12:52:54.618: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.234 80\nConnection to 10.152.183.234 80 port [tcp/http] succeeded!\n"
Nov 26 12:52:54.618: INFO: stdout: "externalname-service-mftcz"
Nov 26 12:52:54.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.249 31626'
Nov 26 12:52:54.829: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 172.31.0.249 31626\nConnection to 172.31.0.249 31626 port [tcp/*] succeeded!\n"
Nov 26 12:52:54.829: INFO: stdout: ""
Nov 26 12:52:55.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.249 31626'
Nov 26 12:52:56.084: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 172.31.0.249 31626\nConnection to 172.31.0.249 31626 port [tcp/*] succeeded!\n"
Nov 26 12:52:56.084: INFO: stdout: ""
Nov 26 12:52:56.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.249 31626'
Nov 26 12:52:57.072: INFO: stderr: "+ nc -v -t -w 2 172.31.0.249 31626\n+ echo hostName\nConnection to 172.31.0.249 31626 port [tcp/*] succeeded!\n"
Nov 26 12:52:57.072: INFO: stdout: "externalname-service-mftcz"
Nov 26 12:52:57.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 31626'
Nov 26 12:52:57.281: INFO: stderr: "+ + ncecho -v -t hostName -w\n 2 172.31.29.104 31626\nConnection to 172.31.29.104 31626 port [tcp/*] succeeded!\n"
Nov 26 12:52:57.281: INFO: stdout: ""
Nov 26 12:52:58.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 31626'
Nov 26 12:52:58.534: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.29.104 31626\nConnection to 172.31.29.104 31626 port [tcp/*] succeeded!\n"
Nov 26 12:52:58.534: INFO: stdout: "externalname-service-mftcz"
Nov 26 12:52:58.534: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:52:58.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8447" for this suite. 11/26/22 12:52:58.589
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":238,"skipped":4425,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.833 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:52:45.772
    Nov 26 12:52:45.772: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:52:45.774
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:52:45.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:52:45.829
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-8447 11/26/22 12:52:45.837
    STEP: changing the ExternalName service to type=NodePort 11/26/22 12:52:45.853
    STEP: creating replication controller externalname-service in namespace services-8447 11/26/22 12:52:45.895
    I1126 12:52:45.907228      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-8447, replica count: 2
    I1126 12:52:48.958246      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 12:52:48.958: INFO: Creating new exec pod
    Nov 26 12:52:48.967: INFO: Waiting up to 5m0s for pod "execpod5ncsr" in namespace "services-8447" to be "running"
    Nov 26 12:52:48.973: INFO: Pod "execpod5ncsr": Phase="Pending", Reason="", readiness=false. Elapsed: 5.528002ms
    Nov 26 12:52:50.980: INFO: Pod "execpod5ncsr": Phase="Running", Reason="", readiness=true. Elapsed: 2.012515356s
    Nov 26 12:52:50.980: INFO: Pod "execpod5ncsr" satisfied condition "running"
    Nov 26 12:52:51.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:52:52.195: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:52:52.196: INFO: stdout: ""
    Nov 26 12:52:53.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:52:53.394: INFO: stderr: "+ + ncecho hostName\n -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:52:53.394: INFO: stdout: ""
    Nov 26 12:52:54.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:52:54.393: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:52:54.393: INFO: stdout: "externalname-service-gzbj8"
    Nov 26 12:52:54.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.234 80'
    Nov 26 12:52:54.618: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.234 80\nConnection to 10.152.183.234 80 port [tcp/http] succeeded!\n"
    Nov 26 12:52:54.618: INFO: stdout: "externalname-service-mftcz"
    Nov 26 12:52:54.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.249 31626'
    Nov 26 12:52:54.829: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 172.31.0.249 31626\nConnection to 172.31.0.249 31626 port [tcp/*] succeeded!\n"
    Nov 26 12:52:54.829: INFO: stdout: ""
    Nov 26 12:52:55.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.249 31626'
    Nov 26 12:52:56.084: INFO: stderr: "+ + echonc hostName -v\n -t -w 2 172.31.0.249 31626\nConnection to 172.31.0.249 31626 port [tcp/*] succeeded!\n"
    Nov 26 12:52:56.084: INFO: stdout: ""
    Nov 26 12:52:56.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.249 31626'
    Nov 26 12:52:57.072: INFO: stderr: "+ nc -v -t -w 2 172.31.0.249 31626\n+ echo hostName\nConnection to 172.31.0.249 31626 port [tcp/*] succeeded!\n"
    Nov 26 12:52:57.072: INFO: stdout: "externalname-service-mftcz"
    Nov 26 12:52:57.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 31626'
    Nov 26 12:52:57.281: INFO: stderr: "+ + ncecho -v -t hostName -w\n 2 172.31.29.104 31626\nConnection to 172.31.29.104 31626 port [tcp/*] succeeded!\n"
    Nov 26 12:52:57.281: INFO: stdout: ""
    Nov 26 12:52:58.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-8447 exec execpod5ncsr -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.29.104 31626'
    Nov 26 12:52:58.534: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.29.104 31626\nConnection to 172.31.29.104 31626 port [tcp/*] succeeded!\n"
    Nov 26 12:52:58.534: INFO: stdout: "externalname-service-mftcz"
    Nov 26 12:52:58.534: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:52:58.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-8447" for this suite. 11/26/22 12:52:58.589
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:52:58.606
Nov 26 12:52:58.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:52:58.609
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:52:58.632
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:52:58.641
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:52:58.687
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:52:59.187
STEP: Deploying the webhook pod 11/26/22 12:52:59.196
STEP: Wait for the deployment to be ready 11/26/22 12:52:59.215
Nov 26 12:52:59.233: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/26/22 12:53:01.258
STEP: Verifying the service has paired with the endpoint 11/26/22 12:53:01.276
Nov 26 12:53:02.277: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 11/26/22 12:53:02.282
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 11/26/22 12:53:02.286
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 11/26/22 12:53:02.286
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 11/26/22 12:53:02.286
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 11/26/22 12:53:02.289
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 11/26/22 12:53:02.289
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 11/26/22 12:53:02.291
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:53:02.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6710" for this suite. 11/26/22 12:53:02.299
STEP: Destroying namespace "webhook-6710-markers" for this suite. 11/26/22 12:53:02.314
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":239,"skipped":4426,"failed":0}
------------------------------
â€¢ [3.841 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:52:58.606
    Nov 26 12:52:58.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:52:58.609
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:52:58.632
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:52:58.641
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:52:58.687
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:52:59.187
    STEP: Deploying the webhook pod 11/26/22 12:52:59.196
    STEP: Wait for the deployment to be ready 11/26/22 12:52:59.215
    Nov 26 12:52:59.233: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/26/22 12:53:01.258
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:53:01.276
    Nov 26 12:53:02.277: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 11/26/22 12:53:02.282
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 11/26/22 12:53:02.286
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 11/26/22 12:53:02.286
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 11/26/22 12:53:02.286
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 11/26/22 12:53:02.289
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 11/26/22 12:53:02.289
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 11/26/22 12:53:02.291
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:53:02.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6710" for this suite. 11/26/22 12:53:02.299
    STEP: Destroying namespace "webhook-6710-markers" for this suite. 11/26/22 12:53:02.314
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:02.449
Nov 26 12:53:02.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 12:53:02.451
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:02.481
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:02.493
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 12:53:02.525
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:53:03.575
STEP: Deploying the webhook pod 11/26/22 12:53:03.595
STEP: Wait for the deployment to be ready 11/26/22 12:53:03.671
Nov 26 12:53:03.707: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/26/22 12:53:05.729
STEP: Verifying the service has paired with the endpoint 11/26/22 12:53:05.744
Nov 26 12:53:06.744: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 11/26/22 12:53:06.75
STEP: Creating a configMap that does not comply to the validation webhook rules 11/26/22 12:53:06.77
STEP: Updating a validating webhook configuration's rules to not include the create operation 11/26/22 12:53:06.78
STEP: Creating a configMap that does not comply to the validation webhook rules 11/26/22 12:53:06.795
STEP: Patching a validating webhook configuration's rules to include the create operation 11/26/22 12:53:06.814
STEP: Creating a configMap that does not comply to the validation webhook rules 11/26/22 12:53:06.826
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 12:53:06.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8162" for this suite. 11/26/22 12:53:06.845
STEP: Destroying namespace "webhook-8162-markers" for this suite. 11/26/22 12:53:06.856
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":240,"skipped":4434,"failed":0}
------------------------------
â€¢ [4.497 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:02.449
    Nov 26 12:53:02.450: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 12:53:02.451
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:02.481
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:02.493
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 12:53:02.525
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 12:53:03.575
    STEP: Deploying the webhook pod 11/26/22 12:53:03.595
    STEP: Wait for the deployment to be ready 11/26/22 12:53:03.671
    Nov 26 12:53:03.707: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/26/22 12:53:05.729
    STEP: Verifying the service has paired with the endpoint 11/26/22 12:53:05.744
    Nov 26 12:53:06.744: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 11/26/22 12:53:06.75
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/26/22 12:53:06.77
    STEP: Updating a validating webhook configuration's rules to not include the create operation 11/26/22 12:53:06.78
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/26/22 12:53:06.795
    STEP: Patching a validating webhook configuration's rules to include the create operation 11/26/22 12:53:06.814
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/26/22 12:53:06.826
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 12:53:06.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8162" for this suite. 11/26/22 12:53:06.845
    STEP: Destroying namespace "webhook-8162-markers" for this suite. 11/26/22 12:53:06.856
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:06.988
Nov 26 12:53:06.988: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename security-context-test 11/26/22 12:53:06.993
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:07.016
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:07.03
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Nov 26 12:53:07.056: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-4aca7e96-a60a-4f8b-9dfa-e82ca74a5df3" in namespace "security-context-test-4929" to be "Succeeded or Failed"
Nov 26 12:53:07.071: INFO: Pod "busybox-readonly-false-4aca7e96-a60a-4f8b-9dfa-e82ca74a5df3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.199013ms
Nov 26 12:53:09.078: INFO: Pod "busybox-readonly-false-4aca7e96-a60a-4f8b-9dfa-e82ca74a5df3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022022563s
Nov 26 12:53:11.077: INFO: Pod "busybox-readonly-false-4aca7e96-a60a-4f8b-9dfa-e82ca74a5df3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021003026s
Nov 26 12:53:11.077: INFO: Pod "busybox-readonly-false-4aca7e96-a60a-4f8b-9dfa-e82ca74a5df3" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 26 12:53:11.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4929" for this suite. 11/26/22 12:53:11.084
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":241,"skipped":4490,"failed":0}
------------------------------
â€¢ [4.107 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:06.988
    Nov 26 12:53:06.988: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename security-context-test 11/26/22 12:53:06.993
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:07.016
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:07.03
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Nov 26 12:53:07.056: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-4aca7e96-a60a-4f8b-9dfa-e82ca74a5df3" in namespace "security-context-test-4929" to be "Succeeded or Failed"
    Nov 26 12:53:07.071: INFO: Pod "busybox-readonly-false-4aca7e96-a60a-4f8b-9dfa-e82ca74a5df3": Phase="Pending", Reason="", readiness=false. Elapsed: 15.199013ms
    Nov 26 12:53:09.078: INFO: Pod "busybox-readonly-false-4aca7e96-a60a-4f8b-9dfa-e82ca74a5df3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022022563s
    Nov 26 12:53:11.077: INFO: Pod "busybox-readonly-false-4aca7e96-a60a-4f8b-9dfa-e82ca74a5df3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021003026s
    Nov 26 12:53:11.077: INFO: Pod "busybox-readonly-false-4aca7e96-a60a-4f8b-9dfa-e82ca74a5df3" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 26 12:53:11.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-4929" for this suite. 11/26/22 12:53:11.084
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:11.097
Nov 26 12:53:11.097: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 12:53:11.098
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:11.118
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:11.134
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:53:11.14
Nov 26 12:53:11.157: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8" in namespace "downward-api-1822" to be "Succeeded or Failed"
Nov 26 12:53:11.164: INFO: Pod "downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.678123ms
Nov 26 12:53:13.171: INFO: Pod "downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014602207s
Nov 26 12:53:15.171: INFO: Pod "downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013902373s
STEP: Saw pod success 11/26/22 12:53:15.171
Nov 26 12:53:15.171: INFO: Pod "downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8" satisfied condition "Succeeded or Failed"
Nov 26 12:53:15.177: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8 container client-container: <nil>
STEP: delete the pod 11/26/22 12:53:15.184
Nov 26 12:53:15.207: INFO: Waiting for pod downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8 to disappear
Nov 26 12:53:15.212: INFO: Pod downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 12:53:15.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1822" for this suite. 11/26/22 12:53:15.219
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":242,"skipped":4500,"failed":0}
------------------------------
â€¢ [4.137 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:11.097
    Nov 26 12:53:11.097: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 12:53:11.098
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:11.118
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:11.134
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:53:11.14
    Nov 26 12:53:11.157: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8" in namespace "downward-api-1822" to be "Succeeded or Failed"
    Nov 26 12:53:11.164: INFO: Pod "downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.678123ms
    Nov 26 12:53:13.171: INFO: Pod "downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014602207s
    Nov 26 12:53:15.171: INFO: Pod "downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013902373s
    STEP: Saw pod success 11/26/22 12:53:15.171
    Nov 26 12:53:15.171: INFO: Pod "downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8" satisfied condition "Succeeded or Failed"
    Nov 26 12:53:15.177: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8 container client-container: <nil>
    STEP: delete the pod 11/26/22 12:53:15.184
    Nov 26 12:53:15.207: INFO: Waiting for pod downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8 to disappear
    Nov 26 12:53:15.212: INFO: Pod downwardapi-volume-9844ae45-660b-413d-ba7b-3bd7ece30ff8 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 12:53:15.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1822" for this suite. 11/26/22 12:53:15.219
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:15.238
Nov 26 12:53:15.240: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replicaset 11/26/22 12:53:15.243
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:15.273
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:15.278
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 11/26/22 12:53:15.283
STEP: Verify that the required pods have come up 11/26/22 12:53:15.291
Nov 26 12:53:15.298: INFO: Pod name sample-pod: Found 0 pods out of 3
Nov 26 12:53:20.305: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 11/26/22 12:53:20.305
Nov 26 12:53:20.311: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 11/26/22 12:53:20.311
STEP: DeleteCollection of the ReplicaSets 11/26/22 12:53:20.318
STEP: After DeleteCollection verify that ReplicaSets have been deleted 11/26/22 12:53:20.332
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 26 12:53:20.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6667" for this suite. 11/26/22 12:53:20.364
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":243,"skipped":4537,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.142 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:15.238
    Nov 26 12:53:15.240: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replicaset 11/26/22 12:53:15.243
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:15.273
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:15.278
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 11/26/22 12:53:15.283
    STEP: Verify that the required pods have come up 11/26/22 12:53:15.291
    Nov 26 12:53:15.298: INFO: Pod name sample-pod: Found 0 pods out of 3
    Nov 26 12:53:20.305: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 11/26/22 12:53:20.305
    Nov 26 12:53:20.311: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 11/26/22 12:53:20.311
    STEP: DeleteCollection of the ReplicaSets 11/26/22 12:53:20.318
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 11/26/22 12:53:20.332
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 26 12:53:20.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6667" for this suite. 11/26/22 12:53:20.364
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:20.39
Nov 26 12:53:20.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:53:20.392
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:20.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:20.425
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-1fb10b0e-2adc-414e-8d63-7f2da5f419eb 11/26/22 12:53:20.433
STEP: Creating a pod to test consume secrets 11/26/22 12:53:20.441
Nov 26 12:53:20.462: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1" in namespace "projected-4571" to be "Succeeded or Failed"
Nov 26 12:53:20.469: INFO: Pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.614371ms
Nov 26 12:53:22.474: INFO: Pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012555153s
Nov 26 12:53:24.475: INFO: Pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1": Phase="Running", Reason="", readiness=false. Elapsed: 4.01314517s
Nov 26 12:53:26.477: INFO: Pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015363042s
STEP: Saw pod success 11/26/22 12:53:26.477
Nov 26 12:53:26.478: INFO: Pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1" satisfied condition "Succeeded or Failed"
Nov 26 12:53:26.483: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/26/22 12:53:26.493
Nov 26 12:53:26.511: INFO: Waiting for pod pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1 to disappear
Nov 26 12:53:26.517: INFO: Pod pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 26 12:53:26.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4571" for this suite. 11/26/22 12:53:26.524
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":244,"skipped":4642,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.145 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:20.39
    Nov 26 12:53:20.391: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:53:20.392
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:20.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:20.425
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-1fb10b0e-2adc-414e-8d63-7f2da5f419eb 11/26/22 12:53:20.433
    STEP: Creating a pod to test consume secrets 11/26/22 12:53:20.441
    Nov 26 12:53:20.462: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1" in namespace "projected-4571" to be "Succeeded or Failed"
    Nov 26 12:53:20.469: INFO: Pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.614371ms
    Nov 26 12:53:22.474: INFO: Pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012555153s
    Nov 26 12:53:24.475: INFO: Pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1": Phase="Running", Reason="", readiness=false. Elapsed: 4.01314517s
    Nov 26 12:53:26.477: INFO: Pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015363042s
    STEP: Saw pod success 11/26/22 12:53:26.477
    Nov 26 12:53:26.478: INFO: Pod "pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1" satisfied condition "Succeeded or Failed"
    Nov 26 12:53:26.483: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:53:26.493
    Nov 26 12:53:26.511: INFO: Waiting for pod pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1 to disappear
    Nov 26 12:53:26.517: INFO: Pod pod-projected-secrets-14e13dbb-011b-418c-8005-5e512c0d6df1 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 26 12:53:26.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4571" for this suite. 11/26/22 12:53:26.524
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:26.536
Nov 26 12:53:26.536: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 12:53:26.538
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:26.565
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:26.571
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 11/26/22 12:53:26.578
Nov 26 12:53:26.596: INFO: created test-pod-1
Nov 26 12:53:26.608: INFO: created test-pod-2
Nov 26 12:53:26.617: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 11/26/22 12:53:26.617
Nov 26 12:53:26.617: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-5799' to be running and ready
Nov 26 12:53:26.638: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 26 12:53:26.638: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 26 12:53:26.638: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 26 12:53:26.638: INFO: 0 / 3 pods in namespace 'pods-5799' are running and ready (0 seconds elapsed)
Nov 26 12:53:26.638: INFO: expected 0 pod replicas in namespace 'pods-5799', 0 are Running and Ready.
Nov 26 12:53:26.638: INFO: POD         NODE             PHASE    GRACE  CONDITIONS
Nov 26 12:53:26.638: INFO: test-pod-1  ip-172-31-43-82  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  }]
Nov 26 12:53:26.638: INFO: test-pod-2  ip-172-31-43-82  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  }]
Nov 26 12:53:26.638: INFO: test-pod-3  ip-172-31-43-82  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  }]
Nov 26 12:53:26.638: INFO: 
Nov 26 12:53:28.660: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 26 12:53:28.660: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov 26 12:53:28.660: INFO: 1 / 3 pods in namespace 'pods-5799' are running and ready (2 seconds elapsed)
Nov 26 12:53:28.660: INFO: expected 0 pod replicas in namespace 'pods-5799', 0 are Running and Ready.
Nov 26 12:53:28.660: INFO: POD         NODE             PHASE    GRACE  CONDITIONS
Nov 26 12:53:28.660: INFO: test-pod-1  ip-172-31-43-82  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  }]
Nov 26 12:53:28.660: INFO: test-pod-3  ip-172-31-43-82  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  }]
Nov 26 12:53:28.660: INFO: 
Nov 26 12:53:30.656: INFO: 3 / 3 pods in namespace 'pods-5799' are running and ready (4 seconds elapsed)
Nov 26 12:53:30.656: INFO: expected 0 pod replicas in namespace 'pods-5799', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 11/26/22 12:53:30.686
Nov 26 12:53:30.697: INFO: Pod quantity 3 is different from expected quantity 0
Nov 26 12:53:31.703: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 26 12:53:32.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5799" for this suite. 11/26/22 12:53:32.709
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":245,"skipped":4642,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.187 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:26.536
    Nov 26 12:53:26.536: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 12:53:26.538
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:26.565
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:26.571
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 11/26/22 12:53:26.578
    Nov 26 12:53:26.596: INFO: created test-pod-1
    Nov 26 12:53:26.608: INFO: created test-pod-2
    Nov 26 12:53:26.617: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 11/26/22 12:53:26.617
    Nov 26 12:53:26.617: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-5799' to be running and ready
    Nov 26 12:53:26.638: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 26 12:53:26.638: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 26 12:53:26.638: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 26 12:53:26.638: INFO: 0 / 3 pods in namespace 'pods-5799' are running and ready (0 seconds elapsed)
    Nov 26 12:53:26.638: INFO: expected 0 pod replicas in namespace 'pods-5799', 0 are Running and Ready.
    Nov 26 12:53:26.638: INFO: POD         NODE             PHASE    GRACE  CONDITIONS
    Nov 26 12:53:26.638: INFO: test-pod-1  ip-172-31-43-82  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  }]
    Nov 26 12:53:26.638: INFO: test-pod-2  ip-172-31-43-82  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  }]
    Nov 26 12:53:26.638: INFO: test-pod-3  ip-172-31-43-82  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  }]
    Nov 26 12:53:26.638: INFO: 
    Nov 26 12:53:28.660: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 26 12:53:28.660: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov 26 12:53:28.660: INFO: 1 / 3 pods in namespace 'pods-5799' are running and ready (2 seconds elapsed)
    Nov 26 12:53:28.660: INFO: expected 0 pod replicas in namespace 'pods-5799', 0 are Running and Ready.
    Nov 26 12:53:28.660: INFO: POD         NODE             PHASE    GRACE  CONDITIONS
    Nov 26 12:53:28.660: INFO: test-pod-1  ip-172-31-43-82  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  }]
    Nov 26 12:53:28.660: INFO: test-pod-3  ip-172-31-43-82  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 12:53:26 +0000 UTC  }]
    Nov 26 12:53:28.660: INFO: 
    Nov 26 12:53:30.656: INFO: 3 / 3 pods in namespace 'pods-5799' are running and ready (4 seconds elapsed)
    Nov 26 12:53:30.656: INFO: expected 0 pod replicas in namespace 'pods-5799', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 11/26/22 12:53:30.686
    Nov 26 12:53:30.697: INFO: Pod quantity 3 is different from expected quantity 0
    Nov 26 12:53:31.703: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 26 12:53:32.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5799" for this suite. 11/26/22 12:53:32.709
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:32.725
Nov 26 12:53:32.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename events 11/26/22 12:53:32.729
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:32.754
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:32.763
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 11/26/22 12:53:32.774
STEP: listing events in all namespaces 11/26/22 12:53:32.785
STEP: listing events in test namespace 11/26/22 12:53:32.798
STEP: listing events with field selection filtering on source 11/26/22 12:53:32.805
STEP: listing events with field selection filtering on reportingController 11/26/22 12:53:32.812
STEP: getting the test event 11/26/22 12:53:32.818
STEP: patching the test event 11/26/22 12:53:32.824
STEP: getting the test event 11/26/22 12:53:32.836
STEP: updating the test event 11/26/22 12:53:32.841
STEP: getting the test event 11/26/22 12:53:32.854
STEP: deleting the test event 11/26/22 12:53:32.86
STEP: listing events in all namespaces 11/26/22 12:53:32.878
STEP: listing events in test namespace 11/26/22 12:53:32.892
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Nov 26 12:53:32.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6679" for this suite. 11/26/22 12:53:32.905
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":246,"skipped":4647,"failed":0}
------------------------------
â€¢ [0.190 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:32.725
    Nov 26 12:53:32.725: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename events 11/26/22 12:53:32.729
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:32.754
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:32.763
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 11/26/22 12:53:32.774
    STEP: listing events in all namespaces 11/26/22 12:53:32.785
    STEP: listing events in test namespace 11/26/22 12:53:32.798
    STEP: listing events with field selection filtering on source 11/26/22 12:53:32.805
    STEP: listing events with field selection filtering on reportingController 11/26/22 12:53:32.812
    STEP: getting the test event 11/26/22 12:53:32.818
    STEP: patching the test event 11/26/22 12:53:32.824
    STEP: getting the test event 11/26/22 12:53:32.836
    STEP: updating the test event 11/26/22 12:53:32.841
    STEP: getting the test event 11/26/22 12:53:32.854
    STEP: deleting the test event 11/26/22 12:53:32.86
    STEP: listing events in all namespaces 11/26/22 12:53:32.878
    STEP: listing events in test namespace 11/26/22 12:53:32.892
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Nov 26 12:53:32.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-6679" for this suite. 11/26/22 12:53:32.905
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:32.916
Nov 26 12:53:32.916: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 12:53:32.917
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:32.939
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:32.946
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3526 11/26/22 12:53:32.952
STEP: changing the ExternalName service to type=ClusterIP 11/26/22 12:53:32.964
STEP: creating replication controller externalname-service in namespace services-3526 11/26/22 12:53:32.992
I1126 12:53:33.008598      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-3526, replica count: 2
I1126 12:53:36.060357      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 12:53:36.060: INFO: Creating new exec pod
Nov 26 12:53:36.070: INFO: Waiting up to 5m0s for pod "execpodlrfbp" in namespace "services-3526" to be "running"
Nov 26 12:53:36.079: INFO: Pod "execpodlrfbp": Phase="Pending", Reason="", readiness=false. Elapsed: 8.628351ms
Nov 26 12:53:38.091: INFO: Pod "execpodlrfbp": Phase="Running", Reason="", readiness=true. Elapsed: 2.020222278s
Nov 26 12:53:38.091: INFO: Pod "execpodlrfbp" satisfied condition "running"
Nov 26 12:53:39.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:53:39.280: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:53:39.280: INFO: stdout: ""
Nov 26 12:53:40.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:53:40.501: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:53:40.501: INFO: stdout: ""
Nov 26 12:53:41.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:53:41.448: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:53:41.448: INFO: stdout: ""
Nov 26 12:53:42.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:53:42.469: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:53:42.469: INFO: stdout: ""
Nov 26 12:53:43.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:53:43.484: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:53:43.484: INFO: stdout: ""
Nov 26 12:53:44.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:53:44.458: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:53:44.458: INFO: stdout: ""
Nov 26 12:53:45.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:53:45.462: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:53:45.462: INFO: stdout: ""
Nov 26 12:53:46.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:53:46.448: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:53:46.448: INFO: stdout: ""
Nov 26 12:53:47.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov 26 12:53:47.457: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 26 12:53:47.458: INFO: stdout: "externalname-service-npm6j"
Nov 26 12:53:47.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.204 80'
Nov 26 12:53:47.664: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.204 80\nConnection to 10.152.183.204 80 port [tcp/http] succeeded!\n"
Nov 26 12:53:47.666: INFO: stdout: "externalname-service-npm6j"
Nov 26 12:53:47.666: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 12:53:47.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3526" for this suite. 11/26/22 12:53:47.759
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":247,"skipped":4648,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.861 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:32.916
    Nov 26 12:53:32.916: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 12:53:32.917
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:32.939
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:32.946
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-3526 11/26/22 12:53:32.952
    STEP: changing the ExternalName service to type=ClusterIP 11/26/22 12:53:32.964
    STEP: creating replication controller externalname-service in namespace services-3526 11/26/22 12:53:32.992
    I1126 12:53:33.008598      19 runners.go:193] Created replication controller with name: externalname-service, namespace: services-3526, replica count: 2
    I1126 12:53:36.060357      19 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 12:53:36.060: INFO: Creating new exec pod
    Nov 26 12:53:36.070: INFO: Waiting up to 5m0s for pod "execpodlrfbp" in namespace "services-3526" to be "running"
    Nov 26 12:53:36.079: INFO: Pod "execpodlrfbp": Phase="Pending", Reason="", readiness=false. Elapsed: 8.628351ms
    Nov 26 12:53:38.091: INFO: Pod "execpodlrfbp": Phase="Running", Reason="", readiness=true. Elapsed: 2.020222278s
    Nov 26 12:53:38.091: INFO: Pod "execpodlrfbp" satisfied condition "running"
    Nov 26 12:53:39.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:53:39.280: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:53:39.280: INFO: stdout: ""
    Nov 26 12:53:40.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:53:40.501: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:53:40.501: INFO: stdout: ""
    Nov 26 12:53:41.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:53:41.448: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:53:41.448: INFO: stdout: ""
    Nov 26 12:53:42.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:53:42.469: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:53:42.469: INFO: stdout: ""
    Nov 26 12:53:43.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:53:43.484: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:53:43.484: INFO: stdout: ""
    Nov 26 12:53:44.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:53:44.458: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:53:44.458: INFO: stdout: ""
    Nov 26 12:53:45.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:53:45.462: INFO: stderr: "+ nc -v -t -w 2 externalname-service 80\n+ echo hostName\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:53:45.462: INFO: stdout: ""
    Nov 26 12:53:46.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:53:46.448: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:53:46.448: INFO: stdout: ""
    Nov 26 12:53:47.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov 26 12:53:47.457: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov 26 12:53:47.458: INFO: stdout: "externalname-service-npm6j"
    Nov 26 12:53:47.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-3526 exec execpodlrfbp -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.204 80'
    Nov 26 12:53:47.664: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.204 80\nConnection to 10.152.183.204 80 port [tcp/http] succeeded!\n"
    Nov 26 12:53:47.666: INFO: stdout: "externalname-service-npm6j"
    Nov 26 12:53:47.666: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 12:53:47.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3526" for this suite. 11/26/22 12:53:47.759
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:47.777
Nov 26 12:53:47.777: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:53:47.778
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:47.813
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:47.827
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-8a81deb5-7f42-4963-b317-ff03cc3d1180 11/26/22 12:53:47.836
STEP: Creating a pod to test consume secrets 11/26/22 12:53:47.854
Nov 26 12:53:47.870: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4" in namespace "projected-6087" to be "Succeeded or Failed"
Nov 26 12:53:47.877: INFO: Pod "pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.362748ms
Nov 26 12:53:49.884: INFO: Pod "pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014089227s
Nov 26 12:53:51.885: INFO: Pod "pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015187841s
STEP: Saw pod success 11/26/22 12:53:51.885
Nov 26 12:53:51.885: INFO: Pod "pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4" satisfied condition "Succeeded or Failed"
Nov 26 12:53:51.890: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/26/22 12:53:51.9
Nov 26 12:53:51.925: INFO: Waiting for pod pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4 to disappear
Nov 26 12:53:51.932: INFO: Pod pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 26 12:53:51.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6087" for this suite. 11/26/22 12:53:51.939
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":248,"skipped":4653,"failed":0}
------------------------------
â€¢ [4.174 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:47.777
    Nov 26 12:53:47.777: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:53:47.778
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:47.813
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:47.827
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-8a81deb5-7f42-4963-b317-ff03cc3d1180 11/26/22 12:53:47.836
    STEP: Creating a pod to test consume secrets 11/26/22 12:53:47.854
    Nov 26 12:53:47.870: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4" in namespace "projected-6087" to be "Succeeded or Failed"
    Nov 26 12:53:47.877: INFO: Pod "pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4": Phase="Pending", Reason="", readiness=false. Elapsed: 7.362748ms
    Nov 26 12:53:49.884: INFO: Pod "pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014089227s
    Nov 26 12:53:51.885: INFO: Pod "pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015187841s
    STEP: Saw pod success 11/26/22 12:53:51.885
    Nov 26 12:53:51.885: INFO: Pod "pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4" satisfied condition "Succeeded or Failed"
    Nov 26 12:53:51.890: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:53:51.9
    Nov 26 12:53:51.925: INFO: Waiting for pod pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4 to disappear
    Nov 26 12:53:51.932: INFO: Pod pod-projected-secrets-6af4fb75-d7bb-42ba-a850-d32eeaa97ee4 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 26 12:53:51.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6087" for this suite. 11/26/22 12:53:51.939
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:51.953
Nov 26 12:53:51.953: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:53:51.954
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:51.978
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:51.984
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 11/26/22 12:53:51.997
Nov 26 12:53:52.015: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04" in namespace "projected-1442" to be "Succeeded or Failed"
Nov 26 12:53:52.027: INFO: Pod "downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04": Phase="Pending", Reason="", readiness=false. Elapsed: 12.43547ms
Nov 26 12:53:54.032: INFO: Pod "downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017606332s
Nov 26 12:53:56.034: INFO: Pod "downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019094326s
STEP: Saw pod success 11/26/22 12:53:56.034
Nov 26 12:53:56.034: INFO: Pod "downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04" satisfied condition "Succeeded or Failed"
Nov 26 12:53:56.040: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04 container client-container: <nil>
STEP: delete the pod 11/26/22 12:53:56.048
Nov 26 12:53:56.065: INFO: Waiting for pod downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04 to disappear
Nov 26 12:53:56.071: INFO: Pod downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 12:53:56.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1442" for this suite. 11/26/22 12:53:56.077
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":249,"skipped":4665,"failed":0}
------------------------------
â€¢ [4.136 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:51.953
    Nov 26 12:53:51.953: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:53:51.954
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:51.978
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:51.984
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 11/26/22 12:53:51.997
    Nov 26 12:53:52.015: INFO: Waiting up to 5m0s for pod "downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04" in namespace "projected-1442" to be "Succeeded or Failed"
    Nov 26 12:53:52.027: INFO: Pod "downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04": Phase="Pending", Reason="", readiness=false. Elapsed: 12.43547ms
    Nov 26 12:53:54.032: INFO: Pod "downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017606332s
    Nov 26 12:53:56.034: INFO: Pod "downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019094326s
    STEP: Saw pod success 11/26/22 12:53:56.034
    Nov 26 12:53:56.034: INFO: Pod "downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04" satisfied condition "Succeeded or Failed"
    Nov 26 12:53:56.040: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04 container client-container: <nil>
    STEP: delete the pod 11/26/22 12:53:56.048
    Nov 26 12:53:56.065: INFO: Waiting for pod downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04 to disappear
    Nov 26 12:53:56.071: INFO: Pod downwardapi-volume-77fda7a8-2d25-42ac-ad4c-91ccb2d46b04 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 12:53:56.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1442" for this suite. 11/26/22 12:53:56.077
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:56.089
Nov 26 12:53:56.089: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename dns 11/26/22 12:53:56.09
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:56.11
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:56.116
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 11/26/22 12:53:56.121
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6369.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-6369.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 11/26/22 12:53:56.128
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6369.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-6369.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 11/26/22 12:53:56.128
STEP: creating a pod to probe DNS 11/26/22 12:53:56.128
STEP: submitting the pod to kubernetes 11/26/22 12:53:56.129
Nov 26 12:53:56.146: INFO: Waiting up to 15m0s for pod "dns-test-ea06990d-0459-44ad-a968-fa9c94912766" in namespace "dns-6369" to be "running"
Nov 26 12:53:56.157: INFO: Pod "dns-test-ea06990d-0459-44ad-a968-fa9c94912766": Phase="Pending", Reason="", readiness=false. Elapsed: 10.826243ms
Nov 26 12:53:58.164: INFO: Pod "dns-test-ea06990d-0459-44ad-a968-fa9c94912766": Phase="Running", Reason="", readiness=true. Elapsed: 2.01756319s
Nov 26 12:53:58.164: INFO: Pod "dns-test-ea06990d-0459-44ad-a968-fa9c94912766" satisfied condition "running"
STEP: retrieving the pod 11/26/22 12:53:58.164
STEP: looking for the results for each expected name from probers 11/26/22 12:53:58.169
Nov 26 12:53:58.194: INFO: DNS probes using dns-6369/dns-test-ea06990d-0459-44ad-a968-fa9c94912766 succeeded

STEP: deleting the pod 11/26/22 12:53:58.194
STEP: deleting the test headless service 11/26/22 12:53:58.238
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 26 12:53:58.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6369" for this suite. 11/26/22 12:53:58.271
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":250,"skipped":4667,"failed":0}
------------------------------
â€¢ [2.193 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:56.089
    Nov 26 12:53:56.089: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename dns 11/26/22 12:53:56.09
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:56.11
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:56.116
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 11/26/22 12:53:56.121
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6369.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-6369.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     11/26/22 12:53:56.128
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6369.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-6369.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     11/26/22 12:53:56.128
    STEP: creating a pod to probe DNS 11/26/22 12:53:56.128
    STEP: submitting the pod to kubernetes 11/26/22 12:53:56.129
    Nov 26 12:53:56.146: INFO: Waiting up to 15m0s for pod "dns-test-ea06990d-0459-44ad-a968-fa9c94912766" in namespace "dns-6369" to be "running"
    Nov 26 12:53:56.157: INFO: Pod "dns-test-ea06990d-0459-44ad-a968-fa9c94912766": Phase="Pending", Reason="", readiness=false. Elapsed: 10.826243ms
    Nov 26 12:53:58.164: INFO: Pod "dns-test-ea06990d-0459-44ad-a968-fa9c94912766": Phase="Running", Reason="", readiness=true. Elapsed: 2.01756319s
    Nov 26 12:53:58.164: INFO: Pod "dns-test-ea06990d-0459-44ad-a968-fa9c94912766" satisfied condition "running"
    STEP: retrieving the pod 11/26/22 12:53:58.164
    STEP: looking for the results for each expected name from probers 11/26/22 12:53:58.169
    Nov 26 12:53:58.194: INFO: DNS probes using dns-6369/dns-test-ea06990d-0459-44ad-a968-fa9c94912766 succeeded

    STEP: deleting the pod 11/26/22 12:53:58.194
    STEP: deleting the test headless service 11/26/22 12:53:58.238
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 26 12:53:58.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6369" for this suite. 11/26/22 12:53:58.271
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:58.284
Nov 26 12:53:58.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename cronjob 11/26/22 12:53:58.288
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:58.31
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:58.318
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 11/26/22 12:53:58.331
STEP: creating 11/26/22 12:53:58.332
STEP: getting 11/26/22 12:53:58.341
STEP: listing 11/26/22 12:53:58.346
STEP: watching 11/26/22 12:53:58.352
Nov 26 12:53:58.352: INFO: starting watch
STEP: cluster-wide listing 11/26/22 12:53:58.355
STEP: cluster-wide watching 11/26/22 12:53:58.361
Nov 26 12:53:58.361: INFO: starting watch
STEP: patching 11/26/22 12:53:58.363
STEP: updating 11/26/22 12:53:58.373
Nov 26 12:53:58.394: INFO: waiting for watch events with expected annotations
Nov 26 12:53:58.394: INFO: saw patched and updated annotations
STEP: patching /status 11/26/22 12:53:58.394
STEP: updating /status 11/26/22 12:53:58.416
STEP: get /status 11/26/22 12:53:58.429
STEP: deleting 11/26/22 12:53:58.435
STEP: deleting a collection 11/26/22 12:53:58.458
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 26 12:53:58.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-1799" for this suite. 11/26/22 12:53:58.485
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":251,"skipped":4722,"failed":0}
------------------------------
â€¢ [0.214 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:58.284
    Nov 26 12:53:58.284: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename cronjob 11/26/22 12:53:58.288
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:58.31
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:58.318
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 11/26/22 12:53:58.331
    STEP: creating 11/26/22 12:53:58.332
    STEP: getting 11/26/22 12:53:58.341
    STEP: listing 11/26/22 12:53:58.346
    STEP: watching 11/26/22 12:53:58.352
    Nov 26 12:53:58.352: INFO: starting watch
    STEP: cluster-wide listing 11/26/22 12:53:58.355
    STEP: cluster-wide watching 11/26/22 12:53:58.361
    Nov 26 12:53:58.361: INFO: starting watch
    STEP: patching 11/26/22 12:53:58.363
    STEP: updating 11/26/22 12:53:58.373
    Nov 26 12:53:58.394: INFO: waiting for watch events with expected annotations
    Nov 26 12:53:58.394: INFO: saw patched and updated annotations
    STEP: patching /status 11/26/22 12:53:58.394
    STEP: updating /status 11/26/22 12:53:58.416
    STEP: get /status 11/26/22 12:53:58.429
    STEP: deleting 11/26/22 12:53:58.435
    STEP: deleting a collection 11/26/22 12:53:58.458
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 26 12:53:58.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-1799" for this suite. 11/26/22 12:53:58.485
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:53:58.499
Nov 26 12:53:58.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename svcaccounts 11/26/22 12:53:58.5
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:58.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:58.529
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Nov 26 12:53:58.553: INFO: Waiting up to 5m0s for pod "pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91" in namespace "svcaccounts-8910" to be "running"
Nov 26 12:53:58.559: INFO: Pod "pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91": Phase="Pending", Reason="", readiness=false. Elapsed: 5.051941ms
Nov 26 12:54:00.566: INFO: Pod "pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91": Phase="Running", Reason="", readiness=true. Elapsed: 2.012076862s
Nov 26 12:54:00.566: INFO: Pod "pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91" satisfied condition "running"
STEP: reading a file in the container 11/26/22 12:54:00.566
Nov 26 12:54:00.566: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8910 pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 11/26/22 12:54:00.881
Nov 26 12:54:00.881: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8910 pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 11/26/22 12:54:01.143
Nov 26 12:54:01.143: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8910 pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Nov 26 12:54:01.381: INFO: Got root ca configmap in namespace "svcaccounts-8910"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 26 12:54:01.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8910" for this suite. 11/26/22 12:54:01.4
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":252,"skipped":4737,"failed":0}
------------------------------
â€¢ [2.917 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:53:58.499
    Nov 26 12:53:58.499: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename svcaccounts 11/26/22 12:53:58.5
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:53:58.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:53:58.529
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Nov 26 12:53:58.553: INFO: Waiting up to 5m0s for pod "pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91" in namespace "svcaccounts-8910" to be "running"
    Nov 26 12:53:58.559: INFO: Pod "pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91": Phase="Pending", Reason="", readiness=false. Elapsed: 5.051941ms
    Nov 26 12:54:00.566: INFO: Pod "pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91": Phase="Running", Reason="", readiness=true. Elapsed: 2.012076862s
    Nov 26 12:54:00.566: INFO: Pod "pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91" satisfied condition "running"
    STEP: reading a file in the container 11/26/22 12:54:00.566
    Nov 26 12:54:00.566: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8910 pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 11/26/22 12:54:00.881
    Nov 26 12:54:00.881: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8910 pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 11/26/22 12:54:01.143
    Nov 26 12:54:01.143: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8910 pod-service-account-429ea117-0832-4b7f-8df6-c438da71ab91 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Nov 26 12:54:01.381: INFO: Got root ca configmap in namespace "svcaccounts-8910"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 26 12:54:01.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8910" for this suite. 11/26/22 12:54:01.4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:54:01.419
Nov 26 12:54:01.419: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 12:54:01.42
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:54:01.466
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:54:01.478
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-088c3e5c-8409-4635-8bfe-12bd426784c8 11/26/22 12:54:01.493
STEP: Creating a pod to test consume configMaps 11/26/22 12:54:01.51
Nov 26 12:54:01.543: INFO: Waiting up to 5m0s for pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828" in namespace "configmap-8842" to be "Succeeded or Failed"
Nov 26 12:54:01.560: INFO: Pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828": Phase="Pending", Reason="", readiness=false. Elapsed: 16.913291ms
Nov 26 12:54:03.570: INFO: Pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027196439s
Nov 26 12:54:05.566: INFO: Pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022606858s
Nov 26 12:54:07.572: INFO: Pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029118678s
STEP: Saw pod success 11/26/22 12:54:07.572
Nov 26 12:54:07.573: INFO: Pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828" satisfied condition "Succeeded or Failed"
Nov 26 12:54:07.578: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828 container agnhost-container: <nil>
STEP: delete the pod 11/26/22 12:54:07.587
Nov 26 12:54:07.604: INFO: Waiting for pod pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828 to disappear
Nov 26 12:54:07.609: INFO: Pod pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 12:54:07.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8842" for this suite. 11/26/22 12:54:07.616
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":253,"skipped":4772,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.208 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:54:01.419
    Nov 26 12:54:01.419: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 12:54:01.42
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:54:01.466
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:54:01.478
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-088c3e5c-8409-4635-8bfe-12bd426784c8 11/26/22 12:54:01.493
    STEP: Creating a pod to test consume configMaps 11/26/22 12:54:01.51
    Nov 26 12:54:01.543: INFO: Waiting up to 5m0s for pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828" in namespace "configmap-8842" to be "Succeeded or Failed"
    Nov 26 12:54:01.560: INFO: Pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828": Phase="Pending", Reason="", readiness=false. Elapsed: 16.913291ms
    Nov 26 12:54:03.570: INFO: Pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027196439s
    Nov 26 12:54:05.566: INFO: Pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828": Phase="Pending", Reason="", readiness=false. Elapsed: 4.022606858s
    Nov 26 12:54:07.572: INFO: Pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.029118678s
    STEP: Saw pod success 11/26/22 12:54:07.572
    Nov 26 12:54:07.573: INFO: Pod "pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828" satisfied condition "Succeeded or Failed"
    Nov 26 12:54:07.578: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828 container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 12:54:07.587
    Nov 26 12:54:07.604: INFO: Waiting for pod pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828 to disappear
    Nov 26 12:54:07.609: INFO: Pod pod-configmaps-02366ef5-0b73-4497-bf24-534bf7e58828 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 12:54:07.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8842" for this suite. 11/26/22 12:54:07.616
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:54:07.632
Nov 26 12:54:07.632: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 12:54:07.633
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:54:07.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:54:07.663
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-029c77bf-550a-4ba4-9d34-df3ff1af3e42 11/26/22 12:54:07.668
STEP: Creating a pod to test consume secrets 11/26/22 12:54:07.674
Nov 26 12:54:07.692: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07" in namespace "projected-1903" to be "Succeeded or Failed"
Nov 26 12:54:07.700: INFO: Pod "pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07": Phase="Pending", Reason="", readiness=false. Elapsed: 8.149715ms
Nov 26 12:54:09.708: INFO: Pod "pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0159654s
Nov 26 12:54:11.708: INFO: Pod "pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015904484s
STEP: Saw pod success 11/26/22 12:54:11.708
Nov 26 12:54:11.708: INFO: Pod "pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07" satisfied condition "Succeeded or Failed"
Nov 26 12:54:11.715: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/26/22 12:54:11.725
Nov 26 12:54:11.741: INFO: Waiting for pod pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07 to disappear
Nov 26 12:54:11.747: INFO: Pod pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 26 12:54:11.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1903" for this suite. 11/26/22 12:54:11.754
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":254,"skipped":4808,"failed":0}
------------------------------
â€¢ [4.134 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:54:07.632
    Nov 26 12:54:07.632: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 12:54:07.633
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:54:07.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:54:07.663
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-029c77bf-550a-4ba4-9d34-df3ff1af3e42 11/26/22 12:54:07.668
    STEP: Creating a pod to test consume secrets 11/26/22 12:54:07.674
    Nov 26 12:54:07.692: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07" in namespace "projected-1903" to be "Succeeded or Failed"
    Nov 26 12:54:07.700: INFO: Pod "pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07": Phase="Pending", Reason="", readiness=false. Elapsed: 8.149715ms
    Nov 26 12:54:09.708: INFO: Pod "pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0159654s
    Nov 26 12:54:11.708: INFO: Pod "pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015904484s
    STEP: Saw pod success 11/26/22 12:54:11.708
    Nov 26 12:54:11.708: INFO: Pod "pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07" satisfied condition "Succeeded or Failed"
    Nov 26 12:54:11.715: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 12:54:11.725
    Nov 26 12:54:11.741: INFO: Waiting for pod pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07 to disappear
    Nov 26 12:54:11.747: INFO: Pod pod-projected-secrets-a7d6e807-2bbb-4451-8adc-8cca0f2c6a07 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 26 12:54:11.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1903" for this suite. 11/26/22 12:54:11.754
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:54:11.766
Nov 26 12:54:11.766: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sched-pred 11/26/22 12:54:11.767
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:54:11.792
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:54:11.8
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 26 12:54:11.805: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 26 12:54:11.819: INFO: Waiting for terminating namespaces to be deleted...
Nov 26 12:54:11.826: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-0-249 before test
Nov 26 12:54:11.835: INFO: default-http-backend-kubernetes-worker-6546b9855c-4rkhh from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:36 +0000 UTC (1 container statuses recorded)
Nov 26 12:54:11.835: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov 26 12:54:11.835: INFO: nginx-ingress-controller-kubernetes-worker-m2kb4 from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:35 +0000 UTC (1 container statuses recorded)
Nov 26 12:54:11.835: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
Nov 26 12:54:11.835: INFO: coredns-6bcf44f4cc-q68zx from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 12:54:11.835: INFO: 	Container coredns ready: true, restart count 0
Nov 26 12:54:11.835: INFO: kube-state-metrics-74f5d549cc-2xtpf from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 12:54:11.835: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov 26 12:54:11.835: INFO: metrics-server-v0.5.2-6b48dc6f97-nfgfh from kube-system started at 2022-11-26 11:51:35 +0000 UTC (2 container statuses recorded)
Nov 26 12:54:11.835: INFO: 	Container metrics-server ready: true, restart count 0
Nov 26 12:54:11.835: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 26 12:54:11.835: INFO: dashboard-metrics-scraper-85d45476c6-h2vdw from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 12:54:11.835: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 26 12:54:11.835: INFO: kubernetes-dashboard-7fb574cb-nwk47 from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 12:54:11.835: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 26 12:54:11.835: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4 from sonobuoy started at 2022-11-26 11:58:40 +0000 UTC (2 container statuses recorded)
Nov 26 12:54:11.835: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 12:54:11.835: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 26 12:54:11.835: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-29-104 before test
Nov 26 12:54:11.844: INFO: nginx-ingress-controller-kubernetes-worker-97spf from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:56 +0000 UTC (1 container statuses recorded)
Nov 26 12:54:11.844: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 26 12:54:11.844: INFO: sonobuoy from sonobuoy started at 2022-11-26 11:58:19 +0000 UTC (1 container statuses recorded)
Nov 26 12:54:11.845: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 26 12:54:11.845: INFO: sonobuoy-e2e-job-1d4a77a11cb24dc4 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 12:54:11.845: INFO: 	Container e2e ready: true, restart count 0
Nov 26 12:54:11.845: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 12:54:11.845: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hq4v9 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 12:54:11.845: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 12:54:11.845: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 26 12:54:11.845: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-43-82 before test
Nov 26 12:54:11.854: INFO: nginx-ingress-controller-kubernetes-worker-2dckl from ingress-nginx-kubernetes-worker started at 2022-11-26 12:07:15 +0000 UTC (1 container statuses recorded)
Nov 26 12:54:11.854: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 26 12:54:11.854: INFO: calico-kube-controllers-75648888c-27qdc from kube-system started at 2022-11-26 12:07:03 +0000 UTC (1 container statuses recorded)
Nov 26 12:54:11.854: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 26 12:54:11.854: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hbpwv from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 12:54:11.854: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 12:54:11.854: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/26/22 12:54:11.855
Nov 26 12:54:11.871: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-1473" to be "running"
Nov 26 12:54:11.878: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 7.053571ms
Nov 26 12:54:13.886: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.01469834s
Nov 26 12:54:13.886: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/26/22 12:54:13.891
STEP: Trying to apply a random label on the found node. 11/26/22 12:54:13.914
STEP: verifying the node has the label kubernetes.io/e2e-23ffb968-a62b-4c59-abea-58652b90d6ba 42 11/26/22 12:54:13.928
STEP: Trying to relaunch the pod, now with labels. 11/26/22 12:54:13.936
Nov 26 12:54:13.944: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-1473" to be "not pending"
Nov 26 12:54:13.955: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 10.706047ms
Nov 26 12:54:15.961: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.016169901s
Nov 26 12:54:15.961: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-23ffb968-a62b-4c59-abea-58652b90d6ba off the node ip-172-31-43-82 11/26/22 12:54:15.968
STEP: verifying the node doesn't have the label kubernetes.io/e2e-23ffb968-a62b-4c59-abea-58652b90d6ba 11/26/22 12:54:15.99
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 26 12:54:15.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1473" for this suite. 11/26/22 12:54:16.003
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":255,"skipped":4814,"failed":0}
------------------------------
â€¢ [4.248 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:54:11.766
    Nov 26 12:54:11.766: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sched-pred 11/26/22 12:54:11.767
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:54:11.792
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:54:11.8
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 26 12:54:11.805: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 26 12:54:11.819: INFO: Waiting for terminating namespaces to be deleted...
    Nov 26 12:54:11.826: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-0-249 before test
    Nov 26 12:54:11.835: INFO: default-http-backend-kubernetes-worker-6546b9855c-4rkhh from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:36 +0000 UTC (1 container statuses recorded)
    Nov 26 12:54:11.835: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov 26 12:54:11.835: INFO: nginx-ingress-controller-kubernetes-worker-m2kb4 from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:35 +0000 UTC (1 container statuses recorded)
    Nov 26 12:54:11.835: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
    Nov 26 12:54:11.835: INFO: coredns-6bcf44f4cc-q68zx from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 12:54:11.835: INFO: 	Container coredns ready: true, restart count 0
    Nov 26 12:54:11.835: INFO: kube-state-metrics-74f5d549cc-2xtpf from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 12:54:11.835: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov 26 12:54:11.835: INFO: metrics-server-v0.5.2-6b48dc6f97-nfgfh from kube-system started at 2022-11-26 11:51:35 +0000 UTC (2 container statuses recorded)
    Nov 26 12:54:11.835: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 26 12:54:11.835: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 26 12:54:11.835: INFO: dashboard-metrics-scraper-85d45476c6-h2vdw from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 12:54:11.835: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 26 12:54:11.835: INFO: kubernetes-dashboard-7fb574cb-nwk47 from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 12:54:11.835: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 26 12:54:11.835: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4 from sonobuoy started at 2022-11-26 11:58:40 +0000 UTC (2 container statuses recorded)
    Nov 26 12:54:11.835: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 12:54:11.835: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 26 12:54:11.835: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-29-104 before test
    Nov 26 12:54:11.844: INFO: nginx-ingress-controller-kubernetes-worker-97spf from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:56 +0000 UTC (1 container statuses recorded)
    Nov 26 12:54:11.844: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 26 12:54:11.844: INFO: sonobuoy from sonobuoy started at 2022-11-26 11:58:19 +0000 UTC (1 container statuses recorded)
    Nov 26 12:54:11.845: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 26 12:54:11.845: INFO: sonobuoy-e2e-job-1d4a77a11cb24dc4 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 12:54:11.845: INFO: 	Container e2e ready: true, restart count 0
    Nov 26 12:54:11.845: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 12:54:11.845: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hq4v9 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 12:54:11.845: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 12:54:11.845: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 26 12:54:11.845: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-43-82 before test
    Nov 26 12:54:11.854: INFO: nginx-ingress-controller-kubernetes-worker-2dckl from ingress-nginx-kubernetes-worker started at 2022-11-26 12:07:15 +0000 UTC (1 container statuses recorded)
    Nov 26 12:54:11.854: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 26 12:54:11.854: INFO: calico-kube-controllers-75648888c-27qdc from kube-system started at 2022-11-26 12:07:03 +0000 UTC (1 container statuses recorded)
    Nov 26 12:54:11.854: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 26 12:54:11.854: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hbpwv from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 12:54:11.854: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 12:54:11.854: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/26/22 12:54:11.855
    Nov 26 12:54:11.871: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-1473" to be "running"
    Nov 26 12:54:11.878: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 7.053571ms
    Nov 26 12:54:13.886: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.01469834s
    Nov 26 12:54:13.886: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/26/22 12:54:13.891
    STEP: Trying to apply a random label on the found node. 11/26/22 12:54:13.914
    STEP: verifying the node has the label kubernetes.io/e2e-23ffb968-a62b-4c59-abea-58652b90d6ba 42 11/26/22 12:54:13.928
    STEP: Trying to relaunch the pod, now with labels. 11/26/22 12:54:13.936
    Nov 26 12:54:13.944: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-1473" to be "not pending"
    Nov 26 12:54:13.955: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 10.706047ms
    Nov 26 12:54:15.961: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.016169901s
    Nov 26 12:54:15.961: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-23ffb968-a62b-4c59-abea-58652b90d6ba off the node ip-172-31-43-82 11/26/22 12:54:15.968
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-23ffb968-a62b-4c59-abea-58652b90d6ba 11/26/22 12:54:15.99
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 12:54:15.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-1473" for this suite. 11/26/22 12:54:16.003
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:54:16.016
Nov 26 12:54:16.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-probe 11/26/22 12:54:16.018
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:54:16.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:54:16.045
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18 in namespace container-probe-6253 11/26/22 12:54:16.052
Nov 26 12:54:16.072: INFO: Waiting up to 5m0s for pod "busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18" in namespace "container-probe-6253" to be "not pending"
Nov 26 12:54:16.083: INFO: Pod "busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18": Phase="Pending", Reason="", readiness=false. Elapsed: 10.562058ms
Nov 26 12:54:18.090: INFO: Pod "busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18": Phase="Running", Reason="", readiness=true. Elapsed: 2.0179657s
Nov 26 12:54:18.090: INFO: Pod "busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18" satisfied condition "not pending"
Nov 26 12:54:18.091: INFO: Started pod busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18 in namespace container-probe-6253
STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 12:54:18.091
Nov 26 12:54:18.097: INFO: Initial restart count of pod busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18 is 0
Nov 26 12:55:08.286: INFO: Restart count of pod container-probe-6253/busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18 is now 1 (50.188646768s elapsed)
STEP: deleting the pod 11/26/22 12:55:08.286
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 26 12:55:08.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6253" for this suite. 11/26/22 12:55:08.31
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":256,"skipped":4831,"failed":0}
------------------------------
â€¢ [SLOW TEST] [52.304 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:54:16.016
    Nov 26 12:54:16.017: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-probe 11/26/22 12:54:16.018
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:54:16.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:54:16.045
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18 in namespace container-probe-6253 11/26/22 12:54:16.052
    Nov 26 12:54:16.072: INFO: Waiting up to 5m0s for pod "busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18" in namespace "container-probe-6253" to be "not pending"
    Nov 26 12:54:16.083: INFO: Pod "busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18": Phase="Pending", Reason="", readiness=false. Elapsed: 10.562058ms
    Nov 26 12:54:18.090: INFO: Pod "busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18": Phase="Running", Reason="", readiness=true. Elapsed: 2.0179657s
    Nov 26 12:54:18.090: INFO: Pod "busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18" satisfied condition "not pending"
    Nov 26 12:54:18.091: INFO: Started pod busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18 in namespace container-probe-6253
    STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 12:54:18.091
    Nov 26 12:54:18.097: INFO: Initial restart count of pod busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18 is 0
    Nov 26 12:55:08.286: INFO: Restart count of pod container-probe-6253/busybox-464a1c8c-ebeb-4ce9-870d-b02cffccac18 is now 1 (50.188646768s elapsed)
    STEP: deleting the pod 11/26/22 12:55:08.286
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 26 12:55:08.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6253" for this suite. 11/26/22 12:55:08.31
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 12:55:08.321
Nov 26 12:55:08.321: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename cronjob 11/26/22 12:55:08.322
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:55:08.345
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:55:08.352
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 11/26/22 12:55:08.36
STEP: Ensuring no jobs are scheduled 11/26/22 12:55:08.369
STEP: Ensuring no job exists by listing jobs explicitly 11/26/22 13:00:08.383
STEP: Removing cronjob 11/26/22 13:00:08.39
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 26 13:00:08.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6165" for this suite. 11/26/22 13:00:08.412
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":257,"skipped":4831,"failed":0}
------------------------------
â€¢ [SLOW TEST] [300.104 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 12:55:08.321
    Nov 26 12:55:08.321: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename cronjob 11/26/22 12:55:08.322
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 12:55:08.345
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 12:55:08.352
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 11/26/22 12:55:08.36
    STEP: Ensuring no jobs are scheduled 11/26/22 12:55:08.369
    STEP: Ensuring no job exists by listing jobs explicitly 11/26/22 13:00:08.383
    STEP: Removing cronjob 11/26/22 13:00:08.39
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 26 13:00:08.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6165" for this suite. 11/26/22 13:00:08.412
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:00:08.43
Nov 26 13:00:08.430: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename events 11/26/22 13:00:08.432
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:00:08.474
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:00:08.484
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 11/26/22 13:00:08.495
STEP: get a list of Events with a label in the current namespace 11/26/22 13:00:08.534
STEP: delete a list of events 11/26/22 13:00:08.544
Nov 26 13:00:08.545: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 11/26/22 13:00:08.582
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Nov 26 13:00:08.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1628" for this suite. 11/26/22 13:00:08.6
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":258,"skipped":4849,"failed":0}
------------------------------
â€¢ [0.183 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:00:08.43
    Nov 26 13:00:08.430: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename events 11/26/22 13:00:08.432
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:00:08.474
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:00:08.484
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 11/26/22 13:00:08.495
    STEP: get a list of Events with a label in the current namespace 11/26/22 13:00:08.534
    STEP: delete a list of events 11/26/22 13:00:08.544
    Nov 26 13:00:08.545: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 11/26/22 13:00:08.582
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Nov 26 13:00:08.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1628" for this suite. 11/26/22 13:00:08.6
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:00:08.618
Nov 26 13:00:08.618: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 13:00:08.621
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:00:08.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:00:08.671
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 11/26/22 13:00:08.679
STEP: Counting existing ResourceQuota 11/26/22 13:00:13.687
STEP: Creating a ResourceQuota 11/26/22 13:00:18.695
STEP: Ensuring resource quota status is calculated 11/26/22 13:00:18.705
STEP: Creating a Secret 11/26/22 13:00:20.712
STEP: Ensuring resource quota status captures secret creation 11/26/22 13:00:20.735
STEP: Deleting a secret 11/26/22 13:00:22.742
STEP: Ensuring resource quota status released usage 11/26/22 13:00:22.755
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 13:00:24.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4303" for this suite. 11/26/22 13:00:24.772
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":259,"skipped":4893,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.166 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:00:08.618
    Nov 26 13:00:08.618: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 13:00:08.621
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:00:08.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:00:08.671
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 11/26/22 13:00:08.679
    STEP: Counting existing ResourceQuota 11/26/22 13:00:13.687
    STEP: Creating a ResourceQuota 11/26/22 13:00:18.695
    STEP: Ensuring resource quota status is calculated 11/26/22 13:00:18.705
    STEP: Creating a Secret 11/26/22 13:00:20.712
    STEP: Ensuring resource quota status captures secret creation 11/26/22 13:00:20.735
    STEP: Deleting a secret 11/26/22 13:00:22.742
    STEP: Ensuring resource quota status released usage 11/26/22 13:00:22.755
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 13:00:24.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4303" for this suite. 11/26/22 13:00:24.772
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:00:24.786
Nov 26 13:00:24.786: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename gc 11/26/22 13:00:24.787
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:00:24.817
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:00:24.834
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 11/26/22 13:00:24.841
STEP: Wait for the Deployment to create new ReplicaSet 11/26/22 13:00:24.856
STEP: delete the deployment 11/26/22 13:00:24.98
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 11/26/22 13:00:24.992
STEP: Gathering metrics 11/26/22 13:00:25.561
W1126 13:00:25.568352      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 26 13:00:25.568: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 26 13:00:25.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3145" for this suite. 11/26/22 13:00:25.573
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":260,"skipped":4919,"failed":0}
------------------------------
â€¢ [0.797 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:00:24.786
    Nov 26 13:00:24.786: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename gc 11/26/22 13:00:24.787
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:00:24.817
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:00:24.834
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 11/26/22 13:00:24.841
    STEP: Wait for the Deployment to create new ReplicaSet 11/26/22 13:00:24.856
    STEP: delete the deployment 11/26/22 13:00:24.98
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 11/26/22 13:00:24.992
    STEP: Gathering metrics 11/26/22 13:00:25.561
    W1126 13:00:25.568352      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 26 13:00:25.568: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 26 13:00:25.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-3145" for this suite. 11/26/22 13:00:25.573
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:00:25.585
Nov 26 13:00:25.585: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename statefulset 11/26/22 13:00:25.586
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:00:25.608
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:00:25.615
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6285 11/26/22 13:00:25.626
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-6285 11/26/22 13:00:25.64
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6285 11/26/22 13:00:25.651
Nov 26 13:00:25.666: INFO: Found 0 stateful pods, waiting for 1
Nov 26 13:00:35.675: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 11/26/22 13:00:35.676
Nov 26 13:00:35.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 26 13:00:35.878: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 26 13:00:35.878: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 26 13:00:35.878: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 26 13:00:35.884: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 26 13:00:45.893: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 26 13:00:45.893: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 13:00:45.925: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Nov 26 13:00:45.925: INFO: ss-0  ip-172-31-43-82  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  }]
Nov 26 13:00:45.925: INFO: 
Nov 26 13:00:45.925: INFO: StatefulSet ss has not reached scale 3, at 1
Nov 26 13:00:46.933: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992623628s
Nov 26 13:00:47.941: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984062622s
Nov 26 13:00:48.948: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.976704148s
Nov 26 13:00:49.955: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.969000629s
Nov 26 13:00:50.962: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.962555415s
Nov 26 13:00:51.967: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.955872576s
Nov 26 13:00:52.975: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.949127386s
Nov 26 13:00:53.985: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.941042521s
Nov 26 13:00:54.993: INFO: Verifying statefulset ss doesn't scale past 3 for another 932.030535ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6285 11/26/22 13:00:55.994
Nov 26 13:00:56.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 26 13:00:56.239: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 26 13:00:56.239: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 26 13:00:56.239: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 26 13:00:56.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 26 13:00:56.448: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 26 13:00:56.448: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 26 13:00:56.448: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 26 13:00:56.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 26 13:00:56.642: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 26 13:00:56.642: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 26 13:00:56.642: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 26 13:00:56.648: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Nov 26 13:01:06.659: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 13:01:06.659: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 26 13:01:06.659: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 11/26/22 13:01:06.659
Nov 26 13:01:06.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 26 13:01:06.866: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 26 13:01:06.866: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 26 13:01:06.866: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 26 13:01:06.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 26 13:01:07.102: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 26 13:01:07.102: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 26 13:01:07.102: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 26 13:01:07.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 26 13:01:07.278: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 26 13:01:07.278: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 26 13:01:07.278: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 26 13:01:07.278: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 13:01:07.285: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov 26 13:01:17.301: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 26 13:01:17.301: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 26 13:01:17.301: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 26 13:01:17.322: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Nov 26 13:01:17.322: INFO: ss-0  ip-172-31-43-82   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  }]
Nov 26 13:01:17.322: INFO: ss-1  ip-172-31-29-104  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  }]
Nov 26 13:01:17.322: INFO: ss-2  ip-172-31-0-249   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  }]
Nov 26 13:01:17.322: INFO: 
Nov 26 13:01:17.322: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 26 13:01:18.330: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Nov 26 13:01:18.330: INFO: ss-0  ip-172-31-43-82   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  }]
Nov 26 13:01:18.330: INFO: ss-1  ip-172-31-29-104  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  }]
Nov 26 13:01:18.330: INFO: 
Nov 26 13:01:18.330: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 26 13:01:19.336: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.984586583s
Nov 26 13:01:20.342: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.97959445s
Nov 26 13:01:21.350: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.972150879s
Nov 26 13:01:22.357: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.96496245s
Nov 26 13:01:23.365: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.957388208s
Nov 26 13:01:24.371: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.950705215s
Nov 26 13:01:25.377: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.943643069s
Nov 26 13:01:26.384: INFO: Verifying statefulset ss doesn't scale past 0 for another 938.386632ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6285 11/26/22 13:01:27.384
Nov 26 13:01:27.391: INFO: Scaling statefulset ss to 0
Nov 26 13:01:27.412: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov 26 13:01:27.418: INFO: Deleting all statefulset in ns statefulset-6285
Nov 26 13:01:27.423: INFO: Scaling statefulset ss to 0
Nov 26 13:01:27.442: INFO: Waiting for statefulset status.replicas updated to 0
Nov 26 13:01:27.448: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov 26 13:01:27.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6285" for this suite. 11/26/22 13:01:27.485
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":261,"skipped":4931,"failed":0}
------------------------------
â€¢ [SLOW TEST] [61.914 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:00:25.585
    Nov 26 13:00:25.585: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename statefulset 11/26/22 13:00:25.586
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:00:25.608
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:00:25.615
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6285 11/26/22 13:00:25.626
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-6285 11/26/22 13:00:25.64
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6285 11/26/22 13:00:25.651
    Nov 26 13:00:25.666: INFO: Found 0 stateful pods, waiting for 1
    Nov 26 13:00:35.675: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 11/26/22 13:00:35.676
    Nov 26 13:00:35.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 26 13:00:35.878: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 26 13:00:35.878: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 26 13:00:35.878: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 26 13:00:35.884: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Nov 26 13:00:45.893: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 26 13:00:45.893: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 13:00:45.925: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
    Nov 26 13:00:45.925: INFO: ss-0  ip-172-31-43-82  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  }]
    Nov 26 13:00:45.925: INFO: 
    Nov 26 13:00:45.925: INFO: StatefulSet ss has not reached scale 3, at 1
    Nov 26 13:00:46.933: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992623628s
    Nov 26 13:00:47.941: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.984062622s
    Nov 26 13:00:48.948: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.976704148s
    Nov 26 13:00:49.955: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.969000629s
    Nov 26 13:00:50.962: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.962555415s
    Nov 26 13:00:51.967: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.955872576s
    Nov 26 13:00:52.975: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.949127386s
    Nov 26 13:00:53.985: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.941042521s
    Nov 26 13:00:54.993: INFO: Verifying statefulset ss doesn't scale past 3 for another 932.030535ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6285 11/26/22 13:00:55.994
    Nov 26 13:00:56.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 26 13:00:56.239: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov 26 13:00:56.239: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 26 13:00:56.239: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 26 13:00:56.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 26 13:00:56.448: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Nov 26 13:00:56.448: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 26 13:00:56.448: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 26 13:00:56.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov 26 13:00:56.642: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Nov 26 13:00:56.642: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov 26 13:00:56.642: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov 26 13:00:56.648: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Nov 26 13:01:06.659: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 13:01:06.659: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov 26 13:01:06.659: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 11/26/22 13:01:06.659
    Nov 26 13:01:06.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 26 13:01:06.866: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 26 13:01:06.866: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 26 13:01:06.866: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 26 13:01:06.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 26 13:01:07.102: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 26 13:01:07.102: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 26 13:01:07.102: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 26 13:01:07.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=statefulset-6285 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov 26 13:01:07.278: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov 26 13:01:07.278: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov 26 13:01:07.278: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov 26 13:01:07.278: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 13:01:07.285: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Nov 26 13:01:17.301: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov 26 13:01:17.301: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Nov 26 13:01:17.301: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Nov 26 13:01:17.322: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Nov 26 13:01:17.322: INFO: ss-0  ip-172-31-43-82   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  }]
    Nov 26 13:01:17.322: INFO: ss-1  ip-172-31-29-104  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  }]
    Nov 26 13:01:17.322: INFO: ss-2  ip-172-31-0-249   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  }]
    Nov 26 13:01:17.322: INFO: 
    Nov 26 13:01:17.322: INFO: StatefulSet ss has not reached scale 0, at 3
    Nov 26 13:01:18.330: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Nov 26 13:01:18.330: INFO: ss-0  ip-172-31-43-82   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:25 +0000 UTC  }]
    Nov 26 13:01:18.330: INFO: ss-1  ip-172-31-29-104  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:01:07 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:00:45 +0000 UTC  }]
    Nov 26 13:01:18.330: INFO: 
    Nov 26 13:01:18.330: INFO: StatefulSet ss has not reached scale 0, at 2
    Nov 26 13:01:19.336: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.984586583s
    Nov 26 13:01:20.342: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.97959445s
    Nov 26 13:01:21.350: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.972150879s
    Nov 26 13:01:22.357: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.96496245s
    Nov 26 13:01:23.365: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.957388208s
    Nov 26 13:01:24.371: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.950705215s
    Nov 26 13:01:25.377: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.943643069s
    Nov 26 13:01:26.384: INFO: Verifying statefulset ss doesn't scale past 0 for another 938.386632ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6285 11/26/22 13:01:27.384
    Nov 26 13:01:27.391: INFO: Scaling statefulset ss to 0
    Nov 26 13:01:27.412: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov 26 13:01:27.418: INFO: Deleting all statefulset in ns statefulset-6285
    Nov 26 13:01:27.423: INFO: Scaling statefulset ss to 0
    Nov 26 13:01:27.442: INFO: Waiting for statefulset status.replicas updated to 0
    Nov 26 13:01:27.448: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov 26 13:01:27.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6285" for this suite. 11/26/22 13:01:27.485
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:01:27.5
Nov 26 13:01:27.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename runtimeclass 11/26/22 13:01:27.501
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:01:27.521
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:01:27.529
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Nov 26 13:01:27.557: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1088 to be scheduled
Nov 26 13:01:27.565: INFO: 1 pods are not scheduled: [runtimeclass-1088/test-runtimeclass-runtimeclass-1088-preconfigured-handler-vpt9k(f54da81a-282f-498f-81a4-a6bf50707878)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov 26 13:01:29.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1088" for this suite. 11/26/22 13:01:29.592
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":262,"skipped":4938,"failed":0}
------------------------------
â€¢ [2.104 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:01:27.5
    Nov 26 13:01:27.500: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename runtimeclass 11/26/22 13:01:27.501
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:01:27.521
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:01:27.529
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Nov 26 13:01:27.557: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-1088 to be scheduled
    Nov 26 13:01:27.565: INFO: 1 pods are not scheduled: [runtimeclass-1088/test-runtimeclass-runtimeclass-1088-preconfigured-handler-vpt9k(f54da81a-282f-498f-81a4-a6bf50707878)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov 26 13:01:29.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1088" for this suite. 11/26/22 13:01:29.592
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:01:29.605
Nov 26 13:01:29.605: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 13:01:29.606
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:01:29.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:01:29.634
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 11/26/22 13:01:29.643
Nov 26 13:01:29.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-9895 create -f -'
Nov 26 13:01:30.680: INFO: stderr: ""
Nov 26 13:01:30.680: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/26/22 13:01:30.68
Nov 26 13:01:31.687: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 26 13:01:31.687: INFO: Found 0 / 1
Nov 26 13:01:32.689: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 26 13:01:32.689: INFO: Found 1 / 1
Nov 26 13:01:32.689: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 11/26/22 13:01:32.689
Nov 26 13:01:32.697: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 26 13:01:32.697: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 26 13:01:32.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-9895 patch pod agnhost-primary-bdbgj -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 26 13:01:32.805: INFO: stderr: ""
Nov 26 13:01:32.805: INFO: stdout: "pod/agnhost-primary-bdbgj patched\n"
STEP: checking annotations 11/26/22 13:01:32.805
Nov 26 13:01:32.813: INFO: Selector matched 1 pods for map[app:agnhost]
Nov 26 13:01:32.813: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 13:01:32.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9895" for this suite. 11/26/22 13:01:32.819
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":263,"skipped":4941,"failed":0}
------------------------------
â€¢ [3.229 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:01:29.605
    Nov 26 13:01:29.605: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 13:01:29.606
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:01:29.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:01:29.634
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 11/26/22 13:01:29.643
    Nov 26 13:01:29.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-9895 create -f -'
    Nov 26 13:01:30.680: INFO: stderr: ""
    Nov 26 13:01:30.680: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/26/22 13:01:30.68
    Nov 26 13:01:31.687: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 26 13:01:31.687: INFO: Found 0 / 1
    Nov 26 13:01:32.689: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 26 13:01:32.689: INFO: Found 1 / 1
    Nov 26 13:01:32.689: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 11/26/22 13:01:32.689
    Nov 26 13:01:32.697: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 26 13:01:32.697: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov 26 13:01:32.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-9895 patch pod agnhost-primary-bdbgj -p {"metadata":{"annotations":{"x":"y"}}}'
    Nov 26 13:01:32.805: INFO: stderr: ""
    Nov 26 13:01:32.805: INFO: stdout: "pod/agnhost-primary-bdbgj patched\n"
    STEP: checking annotations 11/26/22 13:01:32.805
    Nov 26 13:01:32.813: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov 26 13:01:32.813: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 13:01:32.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9895" for this suite. 11/26/22 13:01:32.819
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:01:32.834
Nov 26 13:01:32.835: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename ingress 11/26/22 13:01:32.836
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:01:32.867
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:01:32.875
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 11/26/22 13:01:32.883
STEP: getting /apis/networking.k8s.io 11/26/22 13:01:32.888
STEP: getting /apis/networking.k8s.iov1 11/26/22 13:01:32.891
STEP: creating 11/26/22 13:01:32.894
STEP: getting 11/26/22 13:01:32.944
STEP: listing 11/26/22 13:01:32.955
STEP: watching 11/26/22 13:01:32.963
Nov 26 13:01:32.963: INFO: starting watch
STEP: cluster-wide listing 11/26/22 13:01:32.966
STEP: cluster-wide watching 11/26/22 13:01:32.973
Nov 26 13:01:32.974: INFO: starting watch
STEP: patching 11/26/22 13:01:32.976
STEP: updating 11/26/22 13:01:32.994
Nov 26 13:01:33.018: INFO: waiting for watch events with expected annotations
Nov 26 13:01:33.018: INFO: saw patched and updated annotations
STEP: patching /status 11/26/22 13:01:33.018
STEP: updating /status 11/26/22 13:01:33.035
STEP: get /status 11/26/22 13:01:33.065
STEP: deleting 11/26/22 13:01:33.074
STEP: deleting a collection 11/26/22 13:01:33.122
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Nov 26 13:01:33.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-365" for this suite. 11/26/22 13:01:33.167
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":264,"skipped":4941,"failed":0}
------------------------------
â€¢ [0.346 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:01:32.834
    Nov 26 13:01:32.835: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename ingress 11/26/22 13:01:32.836
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:01:32.867
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:01:32.875
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 11/26/22 13:01:32.883
    STEP: getting /apis/networking.k8s.io 11/26/22 13:01:32.888
    STEP: getting /apis/networking.k8s.iov1 11/26/22 13:01:32.891
    STEP: creating 11/26/22 13:01:32.894
    STEP: getting 11/26/22 13:01:32.944
    STEP: listing 11/26/22 13:01:32.955
    STEP: watching 11/26/22 13:01:32.963
    Nov 26 13:01:32.963: INFO: starting watch
    STEP: cluster-wide listing 11/26/22 13:01:32.966
    STEP: cluster-wide watching 11/26/22 13:01:32.973
    Nov 26 13:01:32.974: INFO: starting watch
    STEP: patching 11/26/22 13:01:32.976
    STEP: updating 11/26/22 13:01:32.994
    Nov 26 13:01:33.018: INFO: waiting for watch events with expected annotations
    Nov 26 13:01:33.018: INFO: saw patched and updated annotations
    STEP: patching /status 11/26/22 13:01:33.018
    STEP: updating /status 11/26/22 13:01:33.035
    STEP: get /status 11/26/22 13:01:33.065
    STEP: deleting 11/26/22 13:01:33.074
    STEP: deleting a collection 11/26/22 13:01:33.122
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Nov 26 13:01:33.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-365" for this suite. 11/26/22 13:01:33.167
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:01:33.181
Nov 26 13:01:33.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename proxy 11/26/22 13:01:33.182
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:01:33.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:01:33.213
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Nov 26 13:01:33.229: INFO: Creating pod...
Nov 26 13:01:33.247: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1807" to be "running"
Nov 26 13:01:33.258: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 10.114664ms
Nov 26 13:01:35.265: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.017855762s
Nov 26 13:01:35.266: INFO: Pod "agnhost" satisfied condition "running"
Nov 26 13:01:35.266: INFO: Creating service...
Nov 26 13:01:35.282: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=DELETE
Nov 26 13:01:35.299: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 26 13:01:35.299: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=OPTIONS
Nov 26 13:01:35.307: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 26 13:01:35.307: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=PATCH
Nov 26 13:01:35.314: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 26 13:01:35.314: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=POST
Nov 26 13:01:35.321: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 26 13:01:35.321: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=PUT
Nov 26 13:01:35.329: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 26 13:01:35.329: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=DELETE
Nov 26 13:01:35.341: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov 26 13:01:35.341: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=OPTIONS
Nov 26 13:01:35.356: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov 26 13:01:35.356: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=PATCH
Nov 26 13:01:35.368: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov 26 13:01:35.369: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=POST
Nov 26 13:01:35.379: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov 26 13:01:35.380: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=PUT
Nov 26 13:01:35.388: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov 26 13:01:35.389: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=GET
Nov 26 13:01:35.394: INFO: http.Client request:GET StatusCode:301
Nov 26 13:01:35.394: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=GET
Nov 26 13:01:35.403: INFO: http.Client request:GET StatusCode:301
Nov 26 13:01:35.403: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=HEAD
Nov 26 13:01:35.407: INFO: http.Client request:HEAD StatusCode:301
Nov 26 13:01:35.408: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=HEAD
Nov 26 13:01:35.428: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 26 13:01:35.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1807" for this suite. 11/26/22 13:01:35.434
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":265,"skipped":4948,"failed":0}
------------------------------
â€¢ [2.265 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:01:33.181
    Nov 26 13:01:33.181: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename proxy 11/26/22 13:01:33.182
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:01:33.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:01:33.213
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Nov 26 13:01:33.229: INFO: Creating pod...
    Nov 26 13:01:33.247: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-1807" to be "running"
    Nov 26 13:01:33.258: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 10.114664ms
    Nov 26 13:01:35.265: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.017855762s
    Nov 26 13:01:35.266: INFO: Pod "agnhost" satisfied condition "running"
    Nov 26 13:01:35.266: INFO: Creating service...
    Nov 26 13:01:35.282: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=DELETE
    Nov 26 13:01:35.299: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 26 13:01:35.299: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=OPTIONS
    Nov 26 13:01:35.307: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 26 13:01:35.307: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=PATCH
    Nov 26 13:01:35.314: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 26 13:01:35.314: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=POST
    Nov 26 13:01:35.321: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 26 13:01:35.321: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=PUT
    Nov 26 13:01:35.329: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 26 13:01:35.329: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=DELETE
    Nov 26 13:01:35.341: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov 26 13:01:35.341: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Nov 26 13:01:35.356: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov 26 13:01:35.356: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=PATCH
    Nov 26 13:01:35.368: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov 26 13:01:35.369: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=POST
    Nov 26 13:01:35.379: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov 26 13:01:35.380: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=PUT
    Nov 26 13:01:35.388: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov 26 13:01:35.389: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=GET
    Nov 26 13:01:35.394: INFO: http.Client request:GET StatusCode:301
    Nov 26 13:01:35.394: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=GET
    Nov 26 13:01:35.403: INFO: http.Client request:GET StatusCode:301
    Nov 26 13:01:35.403: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/pods/agnhost/proxy?method=HEAD
    Nov 26 13:01:35.407: INFO: http.Client request:HEAD StatusCode:301
    Nov 26 13:01:35.408: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-1807/services/e2e-proxy-test-service/proxy?method=HEAD
    Nov 26 13:01:35.428: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 26 13:01:35.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-1807" for this suite. 11/26/22 13:01:35.434
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:01:35.447
Nov 26 13:01:35.447: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename var-expansion 11/26/22 13:01:35.448
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:01:35.468
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:01:35.474
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 11/26/22 13:01:35.48
Nov 26 13:01:35.496: INFO: Waiting up to 2m0s for pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d" in namespace "var-expansion-1371" to be "running"
Nov 26 13:01:35.504: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.183311ms
Nov 26 13:01:37.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013537069s
Nov 26 13:01:39.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014143919s
Nov 26 13:01:41.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014223212s
Nov 26 13:01:43.509: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01228572s
Nov 26 13:01:45.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014397622s
Nov 26 13:01:47.513: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016120958s
Nov 26 13:01:49.514: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.017874143s
Nov 26 13:01:51.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.015971734s
Nov 26 13:01:53.515: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018869276s
Nov 26 13:01:55.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.015291242s
Nov 26 13:01:57.509: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 22.012448344s
Nov 26 13:01:59.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.013513438s
Nov 26 13:02:01.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 26.015318027s
Nov 26 13:02:03.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.01337002s
Nov 26 13:02:05.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 30.014820209s
Nov 26 13:02:07.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 32.015111141s
Nov 26 13:02:09.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 34.014011863s
Nov 26 13:02:11.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 36.01365464s
Nov 26 13:02:13.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 38.015293467s
Nov 26 13:02:15.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 40.013897635s
Nov 26 13:02:17.526: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 42.029066592s
Nov 26 13:02:19.509: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 44.012457913s
Nov 26 13:02:21.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 46.015117485s
Nov 26 13:02:23.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 48.01581955s
Nov 26 13:02:25.515: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 50.018297271s
Nov 26 13:02:27.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 52.014252811s
Nov 26 13:02:29.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 54.014578827s
Nov 26 13:02:31.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 56.013905586s
Nov 26 13:02:33.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 58.013468473s
Nov 26 13:02:35.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.015907657s
Nov 26 13:02:37.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.015795616s
Nov 26 13:02:39.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.013725848s
Nov 26 13:02:41.518: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.021135914s
Nov 26 13:02:43.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.014398308s
Nov 26 13:02:45.513: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.016049495s
Nov 26 13:02:47.514: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.017275651s
Nov 26 13:02:49.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.014189049s
Nov 26 13:02:51.515: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.018151355s
Nov 26 13:02:53.509: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.012766063s
Nov 26 13:02:55.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.014125084s
Nov 26 13:02:57.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.014003922s
Nov 26 13:02:59.509: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.012783839s
Nov 26 13:03:01.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.013657424s
Nov 26 13:03:03.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.013556761s
Nov 26 13:03:05.513: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.017010912s
Nov 26 13:03:07.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.013894259s
Nov 26 13:03:09.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.014085316s
Nov 26 13:03:11.514: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.01707947s
Nov 26 13:03:13.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.013211262s
Nov 26 13:03:15.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.015869896s
Nov 26 13:03:17.516: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.019431872s
Nov 26 13:03:19.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.013519216s
Nov 26 13:03:21.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.013732625s
Nov 26 13:03:23.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.013645703s
Nov 26 13:03:25.513: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.016771902s
Nov 26 13:03:27.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.013559284s
Nov 26 13:03:29.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.014338784s
Nov 26 13:03:31.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.014512111s
Nov 26 13:03:33.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.014061835s
Nov 26 13:03:35.514: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.017839047s
Nov 26 13:03:35.520: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.023372995s
STEP: updating the pod 11/26/22 13:03:35.52
Nov 26 13:03:36.039: INFO: Successfully updated pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d"
STEP: waiting for pod running 11/26/22 13:03:36.039
Nov 26 13:03:36.039: INFO: Waiting up to 2m0s for pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d" in namespace "var-expansion-1371" to be "running"
Nov 26 13:03:36.045: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.587289ms
Nov 26 13:03:38.052: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Running", Reason="", readiness=true. Elapsed: 2.012747721s
Nov 26 13:03:38.052: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d" satisfied condition "running"
STEP: deleting the pod gracefully 11/26/22 13:03:38.052
Nov 26 13:03:38.052: INFO: Deleting pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d" in namespace "var-expansion-1371"
Nov 26 13:03:38.068: INFO: Wait up to 5m0s for pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 26 13:04:10.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1371" for this suite. 11/26/22 13:04:10.087
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":266,"skipped":4959,"failed":0}
------------------------------
â€¢ [SLOW TEST] [154.652 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:01:35.447
    Nov 26 13:01:35.447: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename var-expansion 11/26/22 13:01:35.448
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:01:35.468
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:01:35.474
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 11/26/22 13:01:35.48
    Nov 26 13:01:35.496: INFO: Waiting up to 2m0s for pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d" in namespace "var-expansion-1371" to be "running"
    Nov 26 13:01:35.504: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.183311ms
    Nov 26 13:01:37.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013537069s
    Nov 26 13:01:39.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014143919s
    Nov 26 13:01:41.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014223212s
    Nov 26 13:01:43.509: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01228572s
    Nov 26 13:01:45.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014397622s
    Nov 26 13:01:47.513: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016120958s
    Nov 26 13:01:49.514: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.017874143s
    Nov 26 13:01:51.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.015971734s
    Nov 26 13:01:53.515: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.018869276s
    Nov 26 13:01:55.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.015291242s
    Nov 26 13:01:57.509: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 22.012448344s
    Nov 26 13:01:59.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.013513438s
    Nov 26 13:02:01.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 26.015318027s
    Nov 26 13:02:03.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.01337002s
    Nov 26 13:02:05.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 30.014820209s
    Nov 26 13:02:07.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 32.015111141s
    Nov 26 13:02:09.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 34.014011863s
    Nov 26 13:02:11.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 36.01365464s
    Nov 26 13:02:13.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 38.015293467s
    Nov 26 13:02:15.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 40.013897635s
    Nov 26 13:02:17.526: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 42.029066592s
    Nov 26 13:02:19.509: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 44.012457913s
    Nov 26 13:02:21.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 46.015117485s
    Nov 26 13:02:23.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 48.01581955s
    Nov 26 13:02:25.515: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 50.018297271s
    Nov 26 13:02:27.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 52.014252811s
    Nov 26 13:02:29.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 54.014578827s
    Nov 26 13:02:31.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 56.013905586s
    Nov 26 13:02:33.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 58.013468473s
    Nov 26 13:02:35.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.015907657s
    Nov 26 13:02:37.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.015795616s
    Nov 26 13:02:39.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.013725848s
    Nov 26 13:02:41.518: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.021135914s
    Nov 26 13:02:43.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.014398308s
    Nov 26 13:02:45.513: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.016049495s
    Nov 26 13:02:47.514: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.017275651s
    Nov 26 13:02:49.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.014189049s
    Nov 26 13:02:51.515: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.018151355s
    Nov 26 13:02:53.509: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.012766063s
    Nov 26 13:02:55.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.014125084s
    Nov 26 13:02:57.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.014003922s
    Nov 26 13:02:59.509: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.012783839s
    Nov 26 13:03:01.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.013657424s
    Nov 26 13:03:03.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.013556761s
    Nov 26 13:03:05.513: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.017010912s
    Nov 26 13:03:07.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.013894259s
    Nov 26 13:03:09.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.014085316s
    Nov 26 13:03:11.514: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.01707947s
    Nov 26 13:03:13.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.013211262s
    Nov 26 13:03:15.512: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.015869896s
    Nov 26 13:03:17.516: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.019431872s
    Nov 26 13:03:19.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.013519216s
    Nov 26 13:03:21.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.013732625s
    Nov 26 13:03:23.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.013645703s
    Nov 26 13:03:25.513: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.016771902s
    Nov 26 13:03:27.510: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.013559284s
    Nov 26 13:03:29.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.014338784s
    Nov 26 13:03:31.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.014512111s
    Nov 26 13:03:33.511: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.014061835s
    Nov 26 13:03:35.514: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.017839047s
    Nov 26 13:03:35.520: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.023372995s
    STEP: updating the pod 11/26/22 13:03:35.52
    Nov 26 13:03:36.039: INFO: Successfully updated pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d"
    STEP: waiting for pod running 11/26/22 13:03:36.039
    Nov 26 13:03:36.039: INFO: Waiting up to 2m0s for pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d" in namespace "var-expansion-1371" to be "running"
    Nov 26 13:03:36.045: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.587289ms
    Nov 26 13:03:38.052: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d": Phase="Running", Reason="", readiness=true. Elapsed: 2.012747721s
    Nov 26 13:03:38.052: INFO: Pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d" satisfied condition "running"
    STEP: deleting the pod gracefully 11/26/22 13:03:38.052
    Nov 26 13:03:38.052: INFO: Deleting pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d" in namespace "var-expansion-1371"
    Nov 26 13:03:38.068: INFO: Wait up to 5m0s for pod "var-expansion-286720e9-669a-47a4-a06a-b10e865cd70d" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 26 13:04:10.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1371" for this suite. 11/26/22 13:04:10.087
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:04:10.101
Nov 26 13:04:10.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename disruption 11/26/22 13:04:10.102
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:10.126
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:10.131
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 11/26/22 13:04:10.144
STEP: Updating PodDisruptionBudget status 11/26/22 13:04:12.157
STEP: Waiting for all pods to be running 11/26/22 13:04:12.175
Nov 26 13:04:12.191: INFO: running pods: 0 < 1
STEP: locating a running pod 11/26/22 13:04:14.197
STEP: Waiting for the pdb to be processed 11/26/22 13:04:14.216
STEP: Patching PodDisruptionBudget status 11/26/22 13:04:14.235
STEP: Waiting for the pdb to be processed 11/26/22 13:04:14.257
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 26 13:04:14.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-1511" for this suite. 11/26/22 13:04:14.276
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":267,"skipped":4981,"failed":0}
------------------------------
â€¢ [4.186 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:04:10.101
    Nov 26 13:04:10.101: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename disruption 11/26/22 13:04:10.102
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:10.126
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:10.131
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 11/26/22 13:04:10.144
    STEP: Updating PodDisruptionBudget status 11/26/22 13:04:12.157
    STEP: Waiting for all pods to be running 11/26/22 13:04:12.175
    Nov 26 13:04:12.191: INFO: running pods: 0 < 1
    STEP: locating a running pod 11/26/22 13:04:14.197
    STEP: Waiting for the pdb to be processed 11/26/22 13:04:14.216
    STEP: Patching PodDisruptionBudget status 11/26/22 13:04:14.235
    STEP: Waiting for the pdb to be processed 11/26/22 13:04:14.257
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 26 13:04:14.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-1511" for this suite. 11/26/22 13:04:14.276
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:04:14.291
Nov 26 13:04:14.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename dns 11/26/22 13:04:14.292
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:14.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:14.334
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 11/26/22 13:04:14.343
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 11/26/22 13:04:14.343
STEP: creating a pod to probe DNS 11/26/22 13:04:14.343
STEP: submitting the pod to kubernetes 11/26/22 13:04:14.344
Nov 26 13:04:14.360: INFO: Waiting up to 15m0s for pod "dns-test-b0266b35-c8d0-4188-b25a-af97638a93e4" in namespace "dns-387" to be "running"
Nov 26 13:04:14.374: INFO: Pod "dns-test-b0266b35-c8d0-4188-b25a-af97638a93e4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.558384ms
Nov 26 13:04:16.383: INFO: Pod "dns-test-b0266b35-c8d0-4188-b25a-af97638a93e4": Phase="Running", Reason="", readiness=true. Elapsed: 2.022762145s
Nov 26 13:04:16.383: INFO: Pod "dns-test-b0266b35-c8d0-4188-b25a-af97638a93e4" satisfied condition "running"
STEP: retrieving the pod 11/26/22 13:04:16.383
STEP: looking for the results for each expected name from probers 11/26/22 13:04:16.388
Nov 26 13:04:16.420: INFO: DNS probes using dns-387/dns-test-b0266b35-c8d0-4188-b25a-af97638a93e4 succeeded

STEP: deleting the pod 11/26/22 13:04:16.42
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 26 13:04:16.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-387" for this suite. 11/26/22 13:04:16.449
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":268,"skipped":5017,"failed":0}
------------------------------
â€¢ [2.169 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:04:14.291
    Nov 26 13:04:14.291: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename dns 11/26/22 13:04:14.292
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:14.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:14.334
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     11/26/22 13:04:14.343
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     11/26/22 13:04:14.343
    STEP: creating a pod to probe DNS 11/26/22 13:04:14.343
    STEP: submitting the pod to kubernetes 11/26/22 13:04:14.344
    Nov 26 13:04:14.360: INFO: Waiting up to 15m0s for pod "dns-test-b0266b35-c8d0-4188-b25a-af97638a93e4" in namespace "dns-387" to be "running"
    Nov 26 13:04:14.374: INFO: Pod "dns-test-b0266b35-c8d0-4188-b25a-af97638a93e4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.558384ms
    Nov 26 13:04:16.383: INFO: Pod "dns-test-b0266b35-c8d0-4188-b25a-af97638a93e4": Phase="Running", Reason="", readiness=true. Elapsed: 2.022762145s
    Nov 26 13:04:16.383: INFO: Pod "dns-test-b0266b35-c8d0-4188-b25a-af97638a93e4" satisfied condition "running"
    STEP: retrieving the pod 11/26/22 13:04:16.383
    STEP: looking for the results for each expected name from probers 11/26/22 13:04:16.388
    Nov 26 13:04:16.420: INFO: DNS probes using dns-387/dns-test-b0266b35-c8d0-4188-b25a-af97638a93e4 succeeded

    STEP: deleting the pod 11/26/22 13:04:16.42
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 26 13:04:16.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-387" for this suite. 11/26/22 13:04:16.449
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:04:16.462
Nov 26 13:04:16.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 13:04:16.463
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:16.483
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:16.493
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 11/26/22 13:04:16.504
Nov 26 13:04:16.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: rename a version 11/26/22 13:04:23.802
STEP: check the new version name is served 11/26/22 13:04:23.849
STEP: check the old version name is removed 11/26/22 13:04:27.598
STEP: check the other version is not changed 11/26/22 13:04:29.264
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 13:04:35.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6544" for this suite. 11/26/22 13:04:35.45
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":269,"skipped":5018,"failed":0}
------------------------------
â€¢ [SLOW TEST] [19.001 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:04:16.462
    Nov 26 13:04:16.462: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 13:04:16.463
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:16.483
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:16.493
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 11/26/22 13:04:16.504
    Nov 26 13:04:16.506: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: rename a version 11/26/22 13:04:23.802
    STEP: check the new version name is served 11/26/22 13:04:23.849
    STEP: check the old version name is removed 11/26/22 13:04:27.598
    STEP: check the other version is not changed 11/26/22 13:04:29.264
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 13:04:35.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6544" for this suite. 11/26/22 13:04:35.45
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:04:35.466
Nov 26 13:04:35.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 13:04:35.467
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:35.491
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:35.497
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-fe80e049-bd02-4d77-9133-027972bd07ee 11/26/22 13:04:35.509
STEP: Creating the pod 11/26/22 13:04:35.518
Nov 26 13:04:35.532: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c" in namespace "configmap-2002" to be "running and ready"
Nov 26 13:04:35.538: INFO: Pod "pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.235879ms
Nov 26 13:04:35.538: INFO: The phase of Pod pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:04:37.544: INFO: Pod "pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c": Phase="Running", Reason="", readiness=true. Elapsed: 2.012770955s
Nov 26 13:04:37.544: INFO: The phase of Pod pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c is Running (Ready = true)
Nov 26 13:04:37.544: INFO: Pod "pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-fe80e049-bd02-4d77-9133-027972bd07ee 11/26/22 13:04:37.572
STEP: waiting to observe update in volume 11/26/22 13:04:37.582
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 13:04:39.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2002" for this suite. 11/26/22 13:04:39.609
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":270,"skipped":5043,"failed":0}
------------------------------
â€¢ [4.153 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:04:35.466
    Nov 26 13:04:35.466: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 13:04:35.467
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:35.491
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:35.497
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-fe80e049-bd02-4d77-9133-027972bd07ee 11/26/22 13:04:35.509
    STEP: Creating the pod 11/26/22 13:04:35.518
    Nov 26 13:04:35.532: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c" in namespace "configmap-2002" to be "running and ready"
    Nov 26 13:04:35.538: INFO: Pod "pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.235879ms
    Nov 26 13:04:35.538: INFO: The phase of Pod pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:04:37.544: INFO: Pod "pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c": Phase="Running", Reason="", readiness=true. Elapsed: 2.012770955s
    Nov 26 13:04:37.544: INFO: The phase of Pod pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c is Running (Ready = true)
    Nov 26 13:04:37.544: INFO: Pod "pod-configmaps-6c47a02c-7462-4d87-ae7f-9a3395d6580c" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-fe80e049-bd02-4d77-9133-027972bd07ee 11/26/22 13:04:37.572
    STEP: waiting to observe update in volume 11/26/22 13:04:37.582
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 13:04:39.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2002" for this suite. 11/26/22 13:04:39.609
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:04:39.622
Nov 26 13:04:39.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 13:04:39.623
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:39.645
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:39.652
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 13:04:39.682
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 13:04:39.903
STEP: Deploying the webhook pod 11/26/22 13:04:39.916
STEP: Wait for the deployment to be ready 11/26/22 13:04:39.941
Nov 26 13:04:39.961: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/26/22 13:04:41.982
STEP: Verifying the service has paired with the endpoint 11/26/22 13:04:42.006
Nov 26 13:04:43.007: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 11/26/22 13:04:43.013
STEP: create a namespace for the webhook 11/26/22 13:04:43.035
STEP: create a configmap should be unconditionally rejected by the webhook 11/26/22 13:04:43.053
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 13:04:43.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4181" for this suite. 11/26/22 13:04:43.101
STEP: Destroying namespace "webhook-4181-markers" for this suite. 11/26/22 13:04:43.114
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":271,"skipped":5072,"failed":0}
------------------------------
â€¢ [3.645 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:04:39.622
    Nov 26 13:04:39.622: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 13:04:39.623
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:39.645
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:39.652
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 13:04:39.682
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 13:04:39.903
    STEP: Deploying the webhook pod 11/26/22 13:04:39.916
    STEP: Wait for the deployment to be ready 11/26/22 13:04:39.941
    Nov 26 13:04:39.961: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/26/22 13:04:41.982
    STEP: Verifying the service has paired with the endpoint 11/26/22 13:04:42.006
    Nov 26 13:04:43.007: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 11/26/22 13:04:43.013
    STEP: create a namespace for the webhook 11/26/22 13:04:43.035
    STEP: create a configmap should be unconditionally rejected by the webhook 11/26/22 13:04:43.053
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 13:04:43.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4181" for this suite. 11/26/22 13:04:43.101
    STEP: Destroying namespace "webhook-4181-markers" for this suite. 11/26/22 13:04:43.114
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:04:43.27
Nov 26 13:04:43.270: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename disruption 11/26/22 13:04:43.271
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:43.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:43.305
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:04:43.311
Nov 26 13:04:43.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename disruption-2 11/26/22 13:04:43.312
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:43.336
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:43.341
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 11/26/22 13:04:43.355
STEP: Waiting for the pdb to be processed 11/26/22 13:04:45.378
STEP: Waiting for the pdb to be processed 11/26/22 13:04:47.406
STEP: listing a collection of PDBs across all namespaces 11/26/22 13:04:47.416
STEP: listing a collection of PDBs in namespace disruption-2422 11/26/22 13:04:47.423
STEP: deleting a collection of PDBs 11/26/22 13:04:47.43
STEP: Waiting for the PDB collection to be deleted 11/26/22 13:04:47.46
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Nov 26 13:04:47.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-1249" for this suite. 11/26/22 13:04:47.475
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov 26 13:04:47.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2422" for this suite. 11/26/22 13:04:47.494
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":272,"skipped":5087,"failed":0}
------------------------------
â€¢ [4.235 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:04:43.27
    Nov 26 13:04:43.270: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename disruption 11/26/22 13:04:43.271
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:43.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:43.305
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:04:43.311
    Nov 26 13:04:43.311: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename disruption-2 11/26/22 13:04:43.312
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:43.336
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:43.341
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 11/26/22 13:04:43.355
    STEP: Waiting for the pdb to be processed 11/26/22 13:04:45.378
    STEP: Waiting for the pdb to be processed 11/26/22 13:04:47.406
    STEP: listing a collection of PDBs across all namespaces 11/26/22 13:04:47.416
    STEP: listing a collection of PDBs in namespace disruption-2422 11/26/22 13:04:47.423
    STEP: deleting a collection of PDBs 11/26/22 13:04:47.43
    STEP: Waiting for the PDB collection to be deleted 11/26/22 13:04:47.46
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Nov 26 13:04:47.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-1249" for this suite. 11/26/22 13:04:47.475
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov 26 13:04:47.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2422" for this suite. 11/26/22 13:04:47.494
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:04:47.508
Nov 26 13:04:47.508: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sched-pred 11/26/22 13:04:47.509
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:47.54
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:47.548
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 26 13:04:47.555: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 26 13:04:47.574: INFO: Waiting for terminating namespaces to be deleted...
Nov 26 13:04:47.580: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-0-249 before test
Nov 26 13:04:47.593: INFO: default-http-backend-kubernetes-worker-6546b9855c-4rkhh from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:36 +0000 UTC (1 container statuses recorded)
Nov 26 13:04:47.593: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov 26 13:04:47.593: INFO: nginx-ingress-controller-kubernetes-worker-m2kb4 from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:35 +0000 UTC (1 container statuses recorded)
Nov 26 13:04:47.593: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
Nov 26 13:04:47.593: INFO: coredns-6bcf44f4cc-q68zx from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 13:04:47.593: INFO: 	Container coredns ready: true, restart count 0
Nov 26 13:04:47.593: INFO: kube-state-metrics-74f5d549cc-2xtpf from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 13:04:47.593: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov 26 13:04:47.594: INFO: metrics-server-v0.5.2-6b48dc6f97-nfgfh from kube-system started at 2022-11-26 11:51:35 +0000 UTC (2 container statuses recorded)
Nov 26 13:04:47.594: INFO: 	Container metrics-server ready: true, restart count 0
Nov 26 13:04:47.594: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 26 13:04:47.594: INFO: dashboard-metrics-scraper-85d45476c6-h2vdw from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 13:04:47.594: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 26 13:04:47.594: INFO: kubernetes-dashboard-7fb574cb-nwk47 from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 13:04:47.594: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 26 13:04:47.594: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4 from sonobuoy started at 2022-11-26 11:58:40 +0000 UTC (2 container statuses recorded)
Nov 26 13:04:47.594: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 13:04:47.594: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 26 13:04:47.594: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-29-104 before test
Nov 26 13:04:47.603: INFO: nginx-ingress-controller-kubernetes-worker-97spf from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:56 +0000 UTC (1 container statuses recorded)
Nov 26 13:04:47.603: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 26 13:04:47.603: INFO: sonobuoy from sonobuoy started at 2022-11-26 11:58:19 +0000 UTC (1 container statuses recorded)
Nov 26 13:04:47.603: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 26 13:04:47.603: INFO: sonobuoy-e2e-job-1d4a77a11cb24dc4 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 13:04:47.603: INFO: 	Container e2e ready: true, restart count 0
Nov 26 13:04:47.603: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 13:04:47.603: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hq4v9 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 13:04:47.603: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 13:04:47.603: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 26 13:04:47.603: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-43-82 before test
Nov 26 13:04:47.612: INFO: nginx-ingress-controller-kubernetes-worker-2dckl from ingress-nginx-kubernetes-worker started at 2022-11-26 12:07:15 +0000 UTC (1 container statuses recorded)
Nov 26 13:04:47.612: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 26 13:04:47.612: INFO: calico-kube-controllers-75648888c-27qdc from kube-system started at 2022-11-26 12:07:03 +0000 UTC (1 container statuses recorded)
Nov 26 13:04:47.612: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 26 13:04:47.612: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hbpwv from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 13:04:47.612: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 13:04:47.612: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/26/22 13:04:47.612
Nov 26 13:04:47.627: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-1451" to be "running"
Nov 26 13:04:47.633: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 5.900736ms
Nov 26 13:04:49.642: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.014813496s
Nov 26 13:04:49.642: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/26/22 13:04:49.648
STEP: Trying to apply a random label on the found node. 11/26/22 13:04:49.669
STEP: verifying the node has the label kubernetes.io/e2e-4cb78eac-f85d-444a-9b8e-3ee8788a83aa 95 11/26/22 13:04:49.687
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 11/26/22 13:04:49.693
Nov 26 13:04:49.702: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-1451" to be "not pending"
Nov 26 13:04:49.709: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.2233ms
Nov 26 13:04:51.714: INFO: Pod "pod4": Phase="Running", Reason="", readiness=false. Elapsed: 2.011835634s
Nov 26 13:04:51.714: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.43.82 on the node which pod4 resides and expect not scheduled 11/26/22 13:04:51.715
Nov 26 13:04:51.726: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-1451" to be "not pending"
Nov 26 13:04:51.735: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.082247ms
Nov 26 13:04:53.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015803793s
Nov 26 13:04:55.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017055955s
Nov 26 13:04:57.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017014398s
Nov 26 13:04:59.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019241345s
Nov 26 13:05:01.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.01853066s
Nov 26 13:05:03.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016550555s
Nov 26 13:05:05.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016785492s
Nov 26 13:05:07.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.016398198s
Nov 26 13:05:09.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.019466426s
Nov 26 13:05:11.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.016917426s
Nov 26 13:05:13.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.015560067s
Nov 26 13:05:15.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.016754967s
Nov 26 13:05:17.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.015671383s
Nov 26 13:05:19.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.015988412s
Nov 26 13:05:21.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.018762857s
Nov 26 13:05:23.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.015409756s
Nov 26 13:05:25.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.015559996s
Nov 26 13:05:27.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.016396878s
Nov 26 13:05:29.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.015179861s
Nov 26 13:05:31.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.016643343s
Nov 26 13:05:33.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.016456168s
Nov 26 13:05:35.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.016143916s
Nov 26 13:05:37.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.016071681s
Nov 26 13:05:39.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.015862698s
Nov 26 13:05:41.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.016001214s
Nov 26 13:05:43.740: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.01442406s
Nov 26 13:05:45.747: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.020977179s
Nov 26 13:05:47.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.014522449s
Nov 26 13:05:49.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.015933198s
Nov 26 13:05:51.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.01591596s
Nov 26 13:05:53.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.014973785s
Nov 26 13:05:55.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.015532863s
Nov 26 13:05:57.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.016827193s
Nov 26 13:05:59.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.01616187s
Nov 26 13:06:01.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.017153513s
Nov 26 13:06:03.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.015949769s
Nov 26 13:06:05.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.015253426s
Nov 26 13:06:07.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.014665497s
Nov 26 13:06:09.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.015093784s
Nov 26 13:06:11.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.015805758s
Nov 26 13:06:13.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.015411619s
Nov 26 13:06:15.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.018713202s
Nov 26 13:06:17.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.015726674s
Nov 26 13:06:19.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.015600696s
Nov 26 13:06:21.748: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.021882027s
Nov 26 13:06:23.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.016359002s
Nov 26 13:06:25.746: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.020284475s
Nov 26 13:06:27.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.016280974s
Nov 26 13:06:29.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.016322119s
Nov 26 13:06:31.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.015780617s
Nov 26 13:06:33.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.016497364s
Nov 26 13:06:35.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.019012618s
Nov 26 13:06:37.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.018782856s
Nov 26 13:06:39.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.015413134s
Nov 26 13:06:41.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.014661848s
Nov 26 13:06:43.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.016899673s
Nov 26 13:06:45.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.018819735s
Nov 26 13:06:47.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.015526359s
Nov 26 13:06:49.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.015440186s
Nov 26 13:06:51.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.01571814s
Nov 26 13:06:53.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.015229074s
Nov 26 13:06:55.744: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.017594187s
Nov 26 13:06:57.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.017076202s
Nov 26 13:06:59.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.016892022s
Nov 26 13:07:01.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.015441886s
Nov 26 13:07:03.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.016263121s
Nov 26 13:07:05.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.016902364s
Nov 26 13:07:07.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.014914842s
Nov 26 13:07:09.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.016170774s
Nov 26 13:07:11.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.016762457s
Nov 26 13:07:13.740: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.014479951s
Nov 26 13:07:15.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.014945013s
Nov 26 13:07:17.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.016540139s
Nov 26 13:07:19.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.015345308s
Nov 26 13:07:21.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.015622347s
Nov 26 13:07:23.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.015162756s
Nov 26 13:07:25.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.016504478s
Nov 26 13:07:27.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.01560528s
Nov 26 13:07:29.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.016733578s
Nov 26 13:07:31.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.016905844s
Nov 26 13:07:33.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.01566945s
Nov 26 13:07:35.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.015880895s
Nov 26 13:07:37.757: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.031405549s
Nov 26 13:07:39.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.01552007s
Nov 26 13:07:41.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.017192251s
Nov 26 13:07:43.740: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.014207827s
Nov 26 13:07:45.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.017118654s
Nov 26 13:07:47.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.015840722s
Nov 26 13:07:49.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.015530621s
Nov 26 13:07:51.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.01665255s
Nov 26 13:07:53.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.016735733s
Nov 26 13:07:55.746: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.020341453s
Nov 26 13:07:57.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.01519304s
Nov 26 13:07:59.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.016291142s
Nov 26 13:08:01.746: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.019709394s
Nov 26 13:08:03.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.0162539s
Nov 26 13:08:05.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.015168226s
Nov 26 13:08:07.744: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.017898883s
Nov 26 13:08:09.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.017003029s
Nov 26 13:08:11.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.015920039s
Nov 26 13:08:13.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.015268793s
Nov 26 13:08:15.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.015587628s
Nov 26 13:08:17.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.0158156s
Nov 26 13:08:19.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.015608644s
Nov 26 13:08:21.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.016308328s
Nov 26 13:08:23.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.014898829s
Nov 26 13:08:25.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.017349522s
Nov 26 13:08:27.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.017004415s
Nov 26 13:08:29.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.015489988s
Nov 26 13:08:31.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.015790683s
Nov 26 13:08:33.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.015272435s
Nov 26 13:08:35.757: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.030638845s
Nov 26 13:08:37.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.015366464s
Nov 26 13:08:39.747: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.020952742s
Nov 26 13:08:41.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.016933421s
Nov 26 13:08:43.744: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.017660095s
Nov 26 13:08:45.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.01591051s
Nov 26 13:08:47.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.016711339s
Nov 26 13:08:49.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.015586216s
Nov 26 13:08:51.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.017022897s
Nov 26 13:08:53.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.017229547s
Nov 26 13:08:55.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.015386213s
Nov 26 13:08:57.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.015706477s
Nov 26 13:08:59.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.015475461s
Nov 26 13:09:01.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.016061921s
Nov 26 13:09:03.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.015608573s
Nov 26 13:09:05.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.017312242s
Nov 26 13:09:07.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.019354351s
Nov 26 13:09:09.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.016470766s
Nov 26 13:09:11.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.016232896s
Nov 26 13:09:13.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.015436712s
Nov 26 13:09:15.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.016518653s
Nov 26 13:09:17.744: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.017908022s
Nov 26 13:09:19.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.015043826s
Nov 26 13:09:21.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.01871082s
Nov 26 13:09:23.746: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.020122807s
Nov 26 13:09:25.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.016067371s
Nov 26 13:09:27.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.017254486s
Nov 26 13:09:29.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.014685243s
Nov 26 13:09:31.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.014688462s
Nov 26 13:09:33.744: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.017607708s
Nov 26 13:09:35.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.016468422s
Nov 26 13:09:37.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.014611s
Nov 26 13:09:39.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.015296939s
Nov 26 13:09:41.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.015514837s
Nov 26 13:09:43.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.016524821s
Nov 26 13:09:45.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.016549825s
Nov 26 13:09:47.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.015416438s
Nov 26 13:09:49.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.014694713s
Nov 26 13:09:51.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.017402241s
Nov 26 13:09:51.750: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.023715261s
STEP: removing the label kubernetes.io/e2e-4cb78eac-f85d-444a-9b8e-3ee8788a83aa off the node ip-172-31-43-82 11/26/22 13:09:51.75
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4cb78eac-f85d-444a-9b8e-3ee8788a83aa 11/26/22 13:09:51.77
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 26 13:09:51.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1451" for this suite. 11/26/22 13:09:51.794
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":273,"skipped":5102,"failed":0}
------------------------------
â€¢ [SLOW TEST] [304.299 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:04:47.508
    Nov 26 13:04:47.508: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sched-pred 11/26/22 13:04:47.509
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:04:47.54
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:04:47.548
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 26 13:04:47.555: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 26 13:04:47.574: INFO: Waiting for terminating namespaces to be deleted...
    Nov 26 13:04:47.580: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-0-249 before test
    Nov 26 13:04:47.593: INFO: default-http-backend-kubernetes-worker-6546b9855c-4rkhh from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:36 +0000 UTC (1 container statuses recorded)
    Nov 26 13:04:47.593: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov 26 13:04:47.593: INFO: nginx-ingress-controller-kubernetes-worker-m2kb4 from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:35 +0000 UTC (1 container statuses recorded)
    Nov 26 13:04:47.593: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
    Nov 26 13:04:47.593: INFO: coredns-6bcf44f4cc-q68zx from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 13:04:47.593: INFO: 	Container coredns ready: true, restart count 0
    Nov 26 13:04:47.593: INFO: kube-state-metrics-74f5d549cc-2xtpf from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 13:04:47.593: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov 26 13:04:47.594: INFO: metrics-server-v0.5.2-6b48dc6f97-nfgfh from kube-system started at 2022-11-26 11:51:35 +0000 UTC (2 container statuses recorded)
    Nov 26 13:04:47.594: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 26 13:04:47.594: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 26 13:04:47.594: INFO: dashboard-metrics-scraper-85d45476c6-h2vdw from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 13:04:47.594: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 26 13:04:47.594: INFO: kubernetes-dashboard-7fb574cb-nwk47 from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 13:04:47.594: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 26 13:04:47.594: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4 from sonobuoy started at 2022-11-26 11:58:40 +0000 UTC (2 container statuses recorded)
    Nov 26 13:04:47.594: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 13:04:47.594: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 26 13:04:47.594: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-29-104 before test
    Nov 26 13:04:47.603: INFO: nginx-ingress-controller-kubernetes-worker-97spf from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:56 +0000 UTC (1 container statuses recorded)
    Nov 26 13:04:47.603: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 26 13:04:47.603: INFO: sonobuoy from sonobuoy started at 2022-11-26 11:58:19 +0000 UTC (1 container statuses recorded)
    Nov 26 13:04:47.603: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 26 13:04:47.603: INFO: sonobuoy-e2e-job-1d4a77a11cb24dc4 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 13:04:47.603: INFO: 	Container e2e ready: true, restart count 0
    Nov 26 13:04:47.603: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 13:04:47.603: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hq4v9 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 13:04:47.603: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 13:04:47.603: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 26 13:04:47.603: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-43-82 before test
    Nov 26 13:04:47.612: INFO: nginx-ingress-controller-kubernetes-worker-2dckl from ingress-nginx-kubernetes-worker started at 2022-11-26 12:07:15 +0000 UTC (1 container statuses recorded)
    Nov 26 13:04:47.612: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 26 13:04:47.612: INFO: calico-kube-controllers-75648888c-27qdc from kube-system started at 2022-11-26 12:07:03 +0000 UTC (1 container statuses recorded)
    Nov 26 13:04:47.612: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 26 13:04:47.612: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hbpwv from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 13:04:47.612: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 13:04:47.612: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/26/22 13:04:47.612
    Nov 26 13:04:47.627: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-1451" to be "running"
    Nov 26 13:04:47.633: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 5.900736ms
    Nov 26 13:04:49.642: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.014813496s
    Nov 26 13:04:49.642: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/26/22 13:04:49.648
    STEP: Trying to apply a random label on the found node. 11/26/22 13:04:49.669
    STEP: verifying the node has the label kubernetes.io/e2e-4cb78eac-f85d-444a-9b8e-3ee8788a83aa 95 11/26/22 13:04:49.687
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 11/26/22 13:04:49.693
    Nov 26 13:04:49.702: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-1451" to be "not pending"
    Nov 26 13:04:49.709: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.2233ms
    Nov 26 13:04:51.714: INFO: Pod "pod4": Phase="Running", Reason="", readiness=false. Elapsed: 2.011835634s
    Nov 26 13:04:51.714: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.43.82 on the node which pod4 resides and expect not scheduled 11/26/22 13:04:51.715
    Nov 26 13:04:51.726: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-1451" to be "not pending"
    Nov 26 13:04:51.735: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.082247ms
    Nov 26 13:04:53.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015803793s
    Nov 26 13:04:55.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017055955s
    Nov 26 13:04:57.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017014398s
    Nov 26 13:04:59.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019241345s
    Nov 26 13:05:01.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.01853066s
    Nov 26 13:05:03.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016550555s
    Nov 26 13:05:05.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016785492s
    Nov 26 13:05:07.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.016398198s
    Nov 26 13:05:09.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.019466426s
    Nov 26 13:05:11.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.016917426s
    Nov 26 13:05:13.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.015560067s
    Nov 26 13:05:15.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.016754967s
    Nov 26 13:05:17.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.015671383s
    Nov 26 13:05:19.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.015988412s
    Nov 26 13:05:21.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.018762857s
    Nov 26 13:05:23.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.015409756s
    Nov 26 13:05:25.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.015559996s
    Nov 26 13:05:27.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.016396878s
    Nov 26 13:05:29.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.015179861s
    Nov 26 13:05:31.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.016643343s
    Nov 26 13:05:33.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.016456168s
    Nov 26 13:05:35.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.016143916s
    Nov 26 13:05:37.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.016071681s
    Nov 26 13:05:39.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.015862698s
    Nov 26 13:05:41.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.016001214s
    Nov 26 13:05:43.740: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.01442406s
    Nov 26 13:05:45.747: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.020977179s
    Nov 26 13:05:47.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.014522449s
    Nov 26 13:05:49.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.015933198s
    Nov 26 13:05:51.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.01591596s
    Nov 26 13:05:53.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.014973785s
    Nov 26 13:05:55.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.015532863s
    Nov 26 13:05:57.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.016827193s
    Nov 26 13:05:59.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.01616187s
    Nov 26 13:06:01.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.017153513s
    Nov 26 13:06:03.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.015949769s
    Nov 26 13:06:05.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.015253426s
    Nov 26 13:06:07.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.014665497s
    Nov 26 13:06:09.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.015093784s
    Nov 26 13:06:11.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.015805758s
    Nov 26 13:06:13.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.015411619s
    Nov 26 13:06:15.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.018713202s
    Nov 26 13:06:17.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.015726674s
    Nov 26 13:06:19.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.015600696s
    Nov 26 13:06:21.748: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.021882027s
    Nov 26 13:06:23.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.016359002s
    Nov 26 13:06:25.746: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.020284475s
    Nov 26 13:06:27.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.016280974s
    Nov 26 13:06:29.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.016322119s
    Nov 26 13:06:31.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.015780617s
    Nov 26 13:06:33.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.016497364s
    Nov 26 13:06:35.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.019012618s
    Nov 26 13:06:37.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.018782856s
    Nov 26 13:06:39.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.015413134s
    Nov 26 13:06:41.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.014661848s
    Nov 26 13:06:43.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.016899673s
    Nov 26 13:06:45.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.018819735s
    Nov 26 13:06:47.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.015526359s
    Nov 26 13:06:49.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.015440186s
    Nov 26 13:06:51.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.01571814s
    Nov 26 13:06:53.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.015229074s
    Nov 26 13:06:55.744: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.017594187s
    Nov 26 13:06:57.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.017076202s
    Nov 26 13:06:59.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.016892022s
    Nov 26 13:07:01.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.015441886s
    Nov 26 13:07:03.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.016263121s
    Nov 26 13:07:05.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.016902364s
    Nov 26 13:07:07.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.014914842s
    Nov 26 13:07:09.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.016170774s
    Nov 26 13:07:11.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.016762457s
    Nov 26 13:07:13.740: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.014479951s
    Nov 26 13:07:15.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.014945013s
    Nov 26 13:07:17.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.016540139s
    Nov 26 13:07:19.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.015345308s
    Nov 26 13:07:21.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.015622347s
    Nov 26 13:07:23.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.015162756s
    Nov 26 13:07:25.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.016504478s
    Nov 26 13:07:27.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.01560528s
    Nov 26 13:07:29.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.016733578s
    Nov 26 13:07:31.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.016905844s
    Nov 26 13:07:33.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.01566945s
    Nov 26 13:07:35.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.015880895s
    Nov 26 13:07:37.757: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.031405549s
    Nov 26 13:07:39.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.01552007s
    Nov 26 13:07:41.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.017192251s
    Nov 26 13:07:43.740: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.014207827s
    Nov 26 13:07:45.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.017118654s
    Nov 26 13:07:47.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.015840722s
    Nov 26 13:07:49.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.015530621s
    Nov 26 13:07:51.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.01665255s
    Nov 26 13:07:53.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.016735733s
    Nov 26 13:07:55.746: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.020341453s
    Nov 26 13:07:57.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.01519304s
    Nov 26 13:07:59.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.016291142s
    Nov 26 13:08:01.746: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.019709394s
    Nov 26 13:08:03.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.0162539s
    Nov 26 13:08:05.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.015168226s
    Nov 26 13:08:07.744: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.017898883s
    Nov 26 13:08:09.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.017003029s
    Nov 26 13:08:11.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.015920039s
    Nov 26 13:08:13.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.015268793s
    Nov 26 13:08:15.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.015587628s
    Nov 26 13:08:17.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.0158156s
    Nov 26 13:08:19.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.015608644s
    Nov 26 13:08:21.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.016308328s
    Nov 26 13:08:23.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.014898829s
    Nov 26 13:08:25.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.017349522s
    Nov 26 13:08:27.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.017004415s
    Nov 26 13:08:29.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.015489988s
    Nov 26 13:08:31.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.015790683s
    Nov 26 13:08:33.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.015272435s
    Nov 26 13:08:35.757: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.030638845s
    Nov 26 13:08:37.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.015366464s
    Nov 26 13:08:39.747: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.020952742s
    Nov 26 13:08:41.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.016933421s
    Nov 26 13:08:43.744: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.017660095s
    Nov 26 13:08:45.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.01591051s
    Nov 26 13:08:47.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.016711339s
    Nov 26 13:08:49.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.015586216s
    Nov 26 13:08:51.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.017022897s
    Nov 26 13:08:53.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.017229547s
    Nov 26 13:08:55.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.015386213s
    Nov 26 13:08:57.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.015706477s
    Nov 26 13:08:59.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.015475461s
    Nov 26 13:09:01.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.016061921s
    Nov 26 13:09:03.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.015608573s
    Nov 26 13:09:05.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.017312242s
    Nov 26 13:09:07.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.019354351s
    Nov 26 13:09:09.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.016470766s
    Nov 26 13:09:11.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.016232896s
    Nov 26 13:09:13.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.015436712s
    Nov 26 13:09:15.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.016518653s
    Nov 26 13:09:17.744: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.017908022s
    Nov 26 13:09:19.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.015043826s
    Nov 26 13:09:21.745: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.01871082s
    Nov 26 13:09:23.746: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.020122807s
    Nov 26 13:09:25.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.016067371s
    Nov 26 13:09:27.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.017254486s
    Nov 26 13:09:29.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.014685243s
    Nov 26 13:09:31.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.014688462s
    Nov 26 13:09:33.744: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.017607708s
    Nov 26 13:09:35.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.016468422s
    Nov 26 13:09:37.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.014611s
    Nov 26 13:09:39.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.015296939s
    Nov 26 13:09:41.742: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.015514837s
    Nov 26 13:09:43.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.016524821s
    Nov 26 13:09:45.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.016549825s
    Nov 26 13:09:47.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.015416438s
    Nov 26 13:09:49.741: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.014694713s
    Nov 26 13:09:51.743: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.017402241s
    Nov 26 13:09:51.750: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.023715261s
    STEP: removing the label kubernetes.io/e2e-4cb78eac-f85d-444a-9b8e-3ee8788a83aa off the node ip-172-31-43-82 11/26/22 13:09:51.75
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-4cb78eac-f85d-444a-9b8e-3ee8788a83aa 11/26/22 13:09:51.77
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 13:09:51.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-1451" for this suite. 11/26/22 13:09:51.794
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:09:51.808
Nov 26 13:09:51.808: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 13:09:51.809
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:09:51.832
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:09:51.838
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 11/26/22 13:09:51.844
Nov 26 13:09:51.857: INFO: Waiting up to 5m0s for pod "pod-ac435623-5096-447a-a549-292f96cc39bc" in namespace "emptydir-6459" to be "Succeeded or Failed"
Nov 26 13:09:51.870: INFO: Pod "pod-ac435623-5096-447a-a549-292f96cc39bc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.556504ms
Nov 26 13:09:53.877: INFO: Pod "pod-ac435623-5096-447a-a549-292f96cc39bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020227994s
Nov 26 13:09:55.877: INFO: Pod "pod-ac435623-5096-447a-a549-292f96cc39bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019899979s
STEP: Saw pod success 11/26/22 13:09:55.877
Nov 26 13:09:55.877: INFO: Pod "pod-ac435623-5096-447a-a549-292f96cc39bc" satisfied condition "Succeeded or Failed"
Nov 26 13:09:55.883: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-ac435623-5096-447a-a549-292f96cc39bc container test-container: <nil>
STEP: delete the pod 11/26/22 13:09:55.905
Nov 26 13:09:55.924: INFO: Waiting for pod pod-ac435623-5096-447a-a549-292f96cc39bc to disappear
Nov 26 13:09:55.930: INFO: Pod pod-ac435623-5096-447a-a549-292f96cc39bc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 13:09:55.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6459" for this suite. 11/26/22 13:09:55.937
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":274,"skipped":5106,"failed":0}
------------------------------
â€¢ [4.140 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:09:51.808
    Nov 26 13:09:51.808: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 13:09:51.809
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:09:51.832
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:09:51.838
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 11/26/22 13:09:51.844
    Nov 26 13:09:51.857: INFO: Waiting up to 5m0s for pod "pod-ac435623-5096-447a-a549-292f96cc39bc" in namespace "emptydir-6459" to be "Succeeded or Failed"
    Nov 26 13:09:51.870: INFO: Pod "pod-ac435623-5096-447a-a549-292f96cc39bc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.556504ms
    Nov 26 13:09:53.877: INFO: Pod "pod-ac435623-5096-447a-a549-292f96cc39bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020227994s
    Nov 26 13:09:55.877: INFO: Pod "pod-ac435623-5096-447a-a549-292f96cc39bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019899979s
    STEP: Saw pod success 11/26/22 13:09:55.877
    Nov 26 13:09:55.877: INFO: Pod "pod-ac435623-5096-447a-a549-292f96cc39bc" satisfied condition "Succeeded or Failed"
    Nov 26 13:09:55.883: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-ac435623-5096-447a-a549-292f96cc39bc container test-container: <nil>
    STEP: delete the pod 11/26/22 13:09:55.905
    Nov 26 13:09:55.924: INFO: Waiting for pod pod-ac435623-5096-447a-a549-292f96cc39bc to disappear
    Nov 26 13:09:55.930: INFO: Pod pod-ac435623-5096-447a-a549-292f96cc39bc no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 13:09:55.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6459" for this suite. 11/26/22 13:09:55.937
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:09:55.952
Nov 26 13:09:55.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename tables 11/26/22 13:09:55.953
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:09:55.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:09:55.982
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Nov 26 13:09:55.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4379" for this suite. 11/26/22 13:09:55.999
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":275,"skipped":5146,"failed":0}
------------------------------
â€¢ [0.057 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:09:55.952
    Nov 26 13:09:55.952: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename tables 11/26/22 13:09:55.953
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:09:55.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:09:55.982
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Nov 26 13:09:55.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-4379" for this suite. 11/26/22 13:09:55.999
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:09:56.018
Nov 26 13:09:56.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 13:09:56.02
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:09:56.04
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:09:56.05
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-b7cabf92-f71d-470a-85f7-64d1c5ffa6e4 11/26/22 13:09:56.056
STEP: Creating a pod to test consume configMaps 11/26/22 13:09:56.066
Nov 26 13:09:56.080: INFO: Waiting up to 5m0s for pod "pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213" in namespace "configmap-8718" to be "Succeeded or Failed"
Nov 26 13:09:56.093: INFO: Pod "pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213": Phase="Pending", Reason="", readiness=false. Elapsed: 12.754013ms
Nov 26 13:09:58.099: INFO: Pod "pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018832715s
Nov 26 13:10:00.099: INFO: Pod "pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019006228s
STEP: Saw pod success 11/26/22 13:10:00.099
Nov 26 13:10:00.100: INFO: Pod "pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213" satisfied condition "Succeeded or Failed"
Nov 26 13:10:00.107: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213 container configmap-volume-test: <nil>
STEP: delete the pod 11/26/22 13:10:00.117
Nov 26 13:10:00.136: INFO: Waiting for pod pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213 to disappear
Nov 26 13:10:00.142: INFO: Pod pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 13:10:00.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8718" for this suite. 11/26/22 13:10:00.149
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":276,"skipped":5199,"failed":0}
------------------------------
â€¢ [4.143 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:09:56.018
    Nov 26 13:09:56.018: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 13:09:56.02
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:09:56.04
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:09:56.05
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-b7cabf92-f71d-470a-85f7-64d1c5ffa6e4 11/26/22 13:09:56.056
    STEP: Creating a pod to test consume configMaps 11/26/22 13:09:56.066
    Nov 26 13:09:56.080: INFO: Waiting up to 5m0s for pod "pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213" in namespace "configmap-8718" to be "Succeeded or Failed"
    Nov 26 13:09:56.093: INFO: Pod "pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213": Phase="Pending", Reason="", readiness=false. Elapsed: 12.754013ms
    Nov 26 13:09:58.099: INFO: Pod "pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018832715s
    Nov 26 13:10:00.099: INFO: Pod "pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019006228s
    STEP: Saw pod success 11/26/22 13:10:00.099
    Nov 26 13:10:00.100: INFO: Pod "pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213" satisfied condition "Succeeded or Failed"
    Nov 26 13:10:00.107: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213 container configmap-volume-test: <nil>
    STEP: delete the pod 11/26/22 13:10:00.117
    Nov 26 13:10:00.136: INFO: Waiting for pod pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213 to disappear
    Nov 26 13:10:00.142: INFO: Pod pod-configmaps-feaf7ed7-e476-4613-b3f5-8ce40e7f5213 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 13:10:00.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8718" for this suite. 11/26/22 13:10:00.149
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:10:00.163
Nov 26 13:10:00.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 13:10:00.164
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:10:00.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:10:00.191
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2956 11/26/22 13:10:00.198
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/26/22 13:10:00.221
STEP: creating service externalsvc in namespace services-2956 11/26/22 13:10:00.222
STEP: creating replication controller externalsvc in namespace services-2956 11/26/22 13:10:00.241
I1126 13:10:00.257947      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2956, replica count: 2
I1126 13:10:03.309025      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 11/26/22 13:10:03.314
Nov 26 13:10:03.339: INFO: Creating new exec pod
Nov 26 13:10:03.362: INFO: Waiting up to 5m0s for pod "execpodhrb4v" in namespace "services-2956" to be "running"
Nov 26 13:10:03.374: INFO: Pod "execpodhrb4v": Phase="Pending", Reason="", readiness=false. Elapsed: 11.955161ms
Nov 26 13:10:05.383: INFO: Pod "execpodhrb4v": Phase="Running", Reason="", readiness=true. Elapsed: 2.02032126s
Nov 26 13:10:05.383: INFO: Pod "execpodhrb4v" satisfied condition "running"
Nov 26 13:10:05.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2956 exec execpodhrb4v -- /bin/sh -x -c nslookup clusterip-service.services-2956.svc.cluster.local'
Nov 26 13:10:05.697: INFO: stderr: "+ nslookup clusterip-service.services-2956.svc.cluster.local\n"
Nov 26 13:10:05.697: INFO: stdout: "Server:\t\t10.152.183.246\nAddress:\t10.152.183.246#53\n\nclusterip-service.services-2956.svc.cluster.local\tcanonical name = externalsvc.services-2956.svc.cluster.local.\nName:\texternalsvc.services-2956.svc.cluster.local\nAddress: 10.152.183.40\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2956, will wait for the garbage collector to delete the pods 11/26/22 13:10:05.697
Nov 26 13:10:05.769: INFO: Deleting ReplicationController externalsvc took: 13.191249ms
Nov 26 13:10:05.869: INFO: Terminating ReplicationController externalsvc pods took: 100.725689ms
Nov 26 13:10:07.906: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 13:10:07.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2956" for this suite. 11/26/22 13:10:07.959
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":277,"skipped":5214,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.807 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:10:00.163
    Nov 26 13:10:00.163: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 13:10:00.164
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:10:00.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:10:00.191
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2956 11/26/22 13:10:00.198
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/26/22 13:10:00.221
    STEP: creating service externalsvc in namespace services-2956 11/26/22 13:10:00.222
    STEP: creating replication controller externalsvc in namespace services-2956 11/26/22 13:10:00.241
    I1126 13:10:00.257947      19 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2956, replica count: 2
    I1126 13:10:03.309025      19 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 11/26/22 13:10:03.314
    Nov 26 13:10:03.339: INFO: Creating new exec pod
    Nov 26 13:10:03.362: INFO: Waiting up to 5m0s for pod "execpodhrb4v" in namespace "services-2956" to be "running"
    Nov 26 13:10:03.374: INFO: Pod "execpodhrb4v": Phase="Pending", Reason="", readiness=false. Elapsed: 11.955161ms
    Nov 26 13:10:05.383: INFO: Pod "execpodhrb4v": Phase="Running", Reason="", readiness=true. Elapsed: 2.02032126s
    Nov 26 13:10:05.383: INFO: Pod "execpodhrb4v" satisfied condition "running"
    Nov 26 13:10:05.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=services-2956 exec execpodhrb4v -- /bin/sh -x -c nslookup clusterip-service.services-2956.svc.cluster.local'
    Nov 26 13:10:05.697: INFO: stderr: "+ nslookup clusterip-service.services-2956.svc.cluster.local\n"
    Nov 26 13:10:05.697: INFO: stdout: "Server:\t\t10.152.183.246\nAddress:\t10.152.183.246#53\n\nclusterip-service.services-2956.svc.cluster.local\tcanonical name = externalsvc.services-2956.svc.cluster.local.\nName:\texternalsvc.services-2956.svc.cluster.local\nAddress: 10.152.183.40\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-2956, will wait for the garbage collector to delete the pods 11/26/22 13:10:05.697
    Nov 26 13:10:05.769: INFO: Deleting ReplicationController externalsvc took: 13.191249ms
    Nov 26 13:10:05.869: INFO: Terminating ReplicationController externalsvc pods took: 100.725689ms
    Nov 26 13:10:07.906: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 13:10:07.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2956" for this suite. 11/26/22 13:10:07.959
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:10:07.976
Nov 26 13:10:07.976: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-probe 11/26/22 13:10:07.977
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:10:08.017
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:10:08.023
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 26 13:11:08.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2501" for this suite. 11/26/22 13:11:08.06
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":278,"skipped":5249,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.100 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:10:07.976
    Nov 26 13:10:07.976: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-probe 11/26/22 13:10:07.977
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:10:08.017
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:10:08.023
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 26 13:11:08.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2501" for this suite. 11/26/22 13:11:08.06
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:11:08.079
Nov 26 13:11:08.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 13:11:08.081
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:08.105
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:08.111
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-800608ae-9e7b-483c-8fb5-58a6fc0af1bd 11/26/22 13:11:08.118
STEP: Creating a pod to test consume configMaps 11/26/22 13:11:08.127
Nov 26 13:11:08.142: INFO: Waiting up to 5m0s for pod "pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275" in namespace "configmap-3492" to be "Succeeded or Failed"
Nov 26 13:11:08.149: INFO: Pod "pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275": Phase="Pending", Reason="", readiness=false. Elapsed: 6.560186ms
Nov 26 13:11:10.156: INFO: Pod "pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013716116s
Nov 26 13:11:12.156: INFO: Pod "pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01428187s
STEP: Saw pod success 11/26/22 13:11:12.157
Nov 26 13:11:12.157: INFO: Pod "pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275" satisfied condition "Succeeded or Failed"
Nov 26 13:11:12.162: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275 container agnhost-container: <nil>
STEP: delete the pod 11/26/22 13:11:12.171
Nov 26 13:11:12.194: INFO: Waiting for pod pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275 to disappear
Nov 26 13:11:12.200: INFO: Pod pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 13:11:12.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3492" for this suite. 11/26/22 13:11:12.206
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":279,"skipped":5272,"failed":0}
------------------------------
â€¢ [4.143 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:11:08.079
    Nov 26 13:11:08.079: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 13:11:08.081
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:08.105
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:08.111
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-800608ae-9e7b-483c-8fb5-58a6fc0af1bd 11/26/22 13:11:08.118
    STEP: Creating a pod to test consume configMaps 11/26/22 13:11:08.127
    Nov 26 13:11:08.142: INFO: Waiting up to 5m0s for pod "pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275" in namespace "configmap-3492" to be "Succeeded or Failed"
    Nov 26 13:11:08.149: INFO: Pod "pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275": Phase="Pending", Reason="", readiness=false. Elapsed: 6.560186ms
    Nov 26 13:11:10.156: INFO: Pod "pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013716116s
    Nov 26 13:11:12.156: INFO: Pod "pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01428187s
    STEP: Saw pod success 11/26/22 13:11:12.157
    Nov 26 13:11:12.157: INFO: Pod "pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275" satisfied condition "Succeeded or Failed"
    Nov 26 13:11:12.162: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275 container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 13:11:12.171
    Nov 26 13:11:12.194: INFO: Waiting for pod pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275 to disappear
    Nov 26 13:11:12.200: INFO: Pod pod-configmaps-265f6a96-89b2-410a-9854-60028cc5f275 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 13:11:12.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3492" for this suite. 11/26/22 13:11:12.206
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:11:12.225
Nov 26 13:11:12.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename var-expansion 11/26/22 13:11:12.226
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:12.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:12.254
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Nov 26 13:11:12.279: INFO: Waiting up to 2m0s for pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c" in namespace "var-expansion-2247" to be "container 0 failed with reason CreateContainerConfigError"
Nov 26 13:11:12.287: INFO: Pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.836039ms
Nov 26 13:11:14.294: INFO: Pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01567138s
Nov 26 13:11:14.294: INFO: Pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Nov 26 13:11:14.294: INFO: Deleting pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c" in namespace "var-expansion-2247"
Nov 26 13:11:14.305: INFO: Wait up to 5m0s for pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 26 13:11:16.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2247" for this suite. 11/26/22 13:11:16.325
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":280,"skipped":5273,"failed":0}
------------------------------
â€¢ [4.109 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:11:12.225
    Nov 26 13:11:12.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename var-expansion 11/26/22 13:11:12.226
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:12.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:12.254
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Nov 26 13:11:12.279: INFO: Waiting up to 2m0s for pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c" in namespace "var-expansion-2247" to be "container 0 failed with reason CreateContainerConfigError"
    Nov 26 13:11:12.287: INFO: Pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.836039ms
    Nov 26 13:11:14.294: INFO: Pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01567138s
    Nov 26 13:11:14.294: INFO: Pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Nov 26 13:11:14.294: INFO: Deleting pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c" in namespace "var-expansion-2247"
    Nov 26 13:11:14.305: INFO: Wait up to 5m0s for pod "var-expansion-80e0afc4-d9a8-45a5-b4c5-77286ce8fe1c" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 26 13:11:16.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2247" for this suite. 11/26/22 13:11:16.325
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:11:16.34
Nov 26 13:11:16.340: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename podtemplate 11/26/22 13:11:16.342
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:16.367
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:16.373
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 26 13:11:16.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-9464" for this suite. 11/26/22 13:11:16.439
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":281,"skipped":5298,"failed":0}
------------------------------
â€¢ [0.115 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:11:16.34
    Nov 26 13:11:16.340: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename podtemplate 11/26/22 13:11:16.342
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:16.367
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:16.373
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 26 13:11:16.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-9464" for this suite. 11/26/22 13:11:16.439
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:11:16.461
Nov 26 13:11:16.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 13:11:16.468
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:16.49
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:16.498
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 11/26/22 13:11:16.502
Nov 26 13:11:16.515: INFO: Waiting up to 5m0s for pod "pod-121a840e-0997-4756-9188-500f024fd546" in namespace "emptydir-9577" to be "Succeeded or Failed"
Nov 26 13:11:16.526: INFO: Pod "pod-121a840e-0997-4756-9188-500f024fd546": Phase="Pending", Reason="", readiness=false. Elapsed: 11.58145ms
Nov 26 13:11:18.534: INFO: Pod "pod-121a840e-0997-4756-9188-500f024fd546": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019525652s
Nov 26 13:11:20.534: INFO: Pod "pod-121a840e-0997-4756-9188-500f024fd546": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018937253s
STEP: Saw pod success 11/26/22 13:11:20.534
Nov 26 13:11:20.534: INFO: Pod "pod-121a840e-0997-4756-9188-500f024fd546" satisfied condition "Succeeded or Failed"
Nov 26 13:11:20.539: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-121a840e-0997-4756-9188-500f024fd546 container test-container: <nil>
STEP: delete the pod 11/26/22 13:11:20.551
Nov 26 13:11:20.587: INFO: Waiting for pod pod-121a840e-0997-4756-9188-500f024fd546 to disappear
Nov 26 13:11:20.592: INFO: Pod pod-121a840e-0997-4756-9188-500f024fd546 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 13:11:20.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9577" for this suite. 11/26/22 13:11:20.6
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":282,"skipped":5309,"failed":0}
------------------------------
â€¢ [4.151 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:11:16.461
    Nov 26 13:11:16.461: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 13:11:16.468
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:16.49
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:16.498
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 11/26/22 13:11:16.502
    Nov 26 13:11:16.515: INFO: Waiting up to 5m0s for pod "pod-121a840e-0997-4756-9188-500f024fd546" in namespace "emptydir-9577" to be "Succeeded or Failed"
    Nov 26 13:11:16.526: INFO: Pod "pod-121a840e-0997-4756-9188-500f024fd546": Phase="Pending", Reason="", readiness=false. Elapsed: 11.58145ms
    Nov 26 13:11:18.534: INFO: Pod "pod-121a840e-0997-4756-9188-500f024fd546": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019525652s
    Nov 26 13:11:20.534: INFO: Pod "pod-121a840e-0997-4756-9188-500f024fd546": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018937253s
    STEP: Saw pod success 11/26/22 13:11:20.534
    Nov 26 13:11:20.534: INFO: Pod "pod-121a840e-0997-4756-9188-500f024fd546" satisfied condition "Succeeded or Failed"
    Nov 26 13:11:20.539: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-121a840e-0997-4756-9188-500f024fd546 container test-container: <nil>
    STEP: delete the pod 11/26/22 13:11:20.551
    Nov 26 13:11:20.587: INFO: Waiting for pod pod-121a840e-0997-4756-9188-500f024fd546 to disappear
    Nov 26 13:11:20.592: INFO: Pod pod-121a840e-0997-4756-9188-500f024fd546 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 13:11:20.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9577" for this suite. 11/26/22 13:11:20.6
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:11:20.614
Nov 26 13:11:20.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 13:11:20.615
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:20.654
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:20.665
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-d7dae5b2-c047-4177-9046-d94c8042d169 11/26/22 13:11:20.673
STEP: Creating a pod to test consume secrets 11/26/22 13:11:20.686
Nov 26 13:11:20.708: INFO: Waiting up to 5m0s for pod "pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27" in namespace "secrets-3798" to be "Succeeded or Failed"
Nov 26 13:11:20.723: INFO: Pod "pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27": Phase="Pending", Reason="", readiness=false. Elapsed: 15.365935ms
Nov 26 13:11:22.733: INFO: Pod "pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024909147s
Nov 26 13:11:24.729: INFO: Pod "pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021647765s
STEP: Saw pod success 11/26/22 13:11:24.729
Nov 26 13:11:24.730: INFO: Pod "pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27" satisfied condition "Succeeded or Failed"
Nov 26 13:11:24.735: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27 container secret-volume-test: <nil>
STEP: delete the pod 11/26/22 13:11:24.748
Nov 26 13:11:24.776: INFO: Waiting for pod pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27 to disappear
Nov 26 13:11:24.789: INFO: Pod pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 26 13:11:24.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3798" for this suite. 11/26/22 13:11:24.798
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":283,"skipped":5312,"failed":0}
------------------------------
â€¢ [4.198 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:11:20.614
    Nov 26 13:11:20.614: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 13:11:20.615
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:20.654
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:20.665
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-d7dae5b2-c047-4177-9046-d94c8042d169 11/26/22 13:11:20.673
    STEP: Creating a pod to test consume secrets 11/26/22 13:11:20.686
    Nov 26 13:11:20.708: INFO: Waiting up to 5m0s for pod "pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27" in namespace "secrets-3798" to be "Succeeded or Failed"
    Nov 26 13:11:20.723: INFO: Pod "pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27": Phase="Pending", Reason="", readiness=false. Elapsed: 15.365935ms
    Nov 26 13:11:22.733: INFO: Pod "pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024909147s
    Nov 26 13:11:24.729: INFO: Pod "pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021647765s
    STEP: Saw pod success 11/26/22 13:11:24.729
    Nov 26 13:11:24.730: INFO: Pod "pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27" satisfied condition "Succeeded or Failed"
    Nov 26 13:11:24.735: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27 container secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 13:11:24.748
    Nov 26 13:11:24.776: INFO: Waiting for pod pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27 to disappear
    Nov 26 13:11:24.789: INFO: Pod pod-secrets-1290cc98-a5fc-4452-b57f-83bb5346cc27 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 13:11:24.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3798" for this suite. 11/26/22 13:11:24.798
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:11:24.814
Nov 26 13:11:24.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 13:11:24.815
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:24.85
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:24.859
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 11/26/22 13:11:24.868
Nov 26 13:11:24.887: INFO: Waiting up to 5m0s for pod "pod-df7ddf11-e622-4118-bd95-ebefc467cfe4" in namespace "emptydir-3140" to be "Succeeded or Failed"
Nov 26 13:11:24.894: INFO: Pod "pod-df7ddf11-e622-4118-bd95-ebefc467cfe4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.683368ms
Nov 26 13:11:26.900: INFO: Pod "pod-df7ddf11-e622-4118-bd95-ebefc467cfe4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013224313s
Nov 26 13:11:28.901: INFO: Pod "pod-df7ddf11-e622-4118-bd95-ebefc467cfe4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013539959s
STEP: Saw pod success 11/26/22 13:11:28.901
Nov 26 13:11:28.901: INFO: Pod "pod-df7ddf11-e622-4118-bd95-ebefc467cfe4" satisfied condition "Succeeded or Failed"
Nov 26 13:11:28.906: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-df7ddf11-e622-4118-bd95-ebefc467cfe4 container test-container: <nil>
STEP: delete the pod 11/26/22 13:11:28.918
Nov 26 13:11:28.939: INFO: Waiting for pod pod-df7ddf11-e622-4118-bd95-ebefc467cfe4 to disappear
Nov 26 13:11:28.944: INFO: Pod pod-df7ddf11-e622-4118-bd95-ebefc467cfe4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 13:11:28.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3140" for this suite. 11/26/22 13:11:28.951
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":284,"skipped":5323,"failed":0}
------------------------------
â€¢ [4.149 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:11:24.814
    Nov 26 13:11:24.814: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 13:11:24.815
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:24.85
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:24.859
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 11/26/22 13:11:24.868
    Nov 26 13:11:24.887: INFO: Waiting up to 5m0s for pod "pod-df7ddf11-e622-4118-bd95-ebefc467cfe4" in namespace "emptydir-3140" to be "Succeeded or Failed"
    Nov 26 13:11:24.894: INFO: Pod "pod-df7ddf11-e622-4118-bd95-ebefc467cfe4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.683368ms
    Nov 26 13:11:26.900: INFO: Pod "pod-df7ddf11-e622-4118-bd95-ebefc467cfe4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013224313s
    Nov 26 13:11:28.901: INFO: Pod "pod-df7ddf11-e622-4118-bd95-ebefc467cfe4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013539959s
    STEP: Saw pod success 11/26/22 13:11:28.901
    Nov 26 13:11:28.901: INFO: Pod "pod-df7ddf11-e622-4118-bd95-ebefc467cfe4" satisfied condition "Succeeded or Failed"
    Nov 26 13:11:28.906: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-df7ddf11-e622-4118-bd95-ebefc467cfe4 container test-container: <nil>
    STEP: delete the pod 11/26/22 13:11:28.918
    Nov 26 13:11:28.939: INFO: Waiting for pod pod-df7ddf11-e622-4118-bd95-ebefc467cfe4 to disappear
    Nov 26 13:11:28.944: INFO: Pod pod-df7ddf11-e622-4118-bd95-ebefc467cfe4 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 13:11:28.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3140" for this suite. 11/26/22 13:11:28.951
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:11:28.968
Nov 26 13:11:28.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 13:11:28.97
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:28.997
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:29.005
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-76088897-cd3d-4d21-976a-ea2baf89b78a 11/26/22 13:11:29.012
STEP: Creating a pod to test consume configMaps 11/26/22 13:11:29.019
Nov 26 13:11:29.037: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d" in namespace "projected-4955" to be "Succeeded or Failed"
Nov 26 13:11:29.043: INFO: Pod "pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.584472ms
Nov 26 13:11:31.048: INFO: Pod "pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011412071s
Nov 26 13:11:33.049: INFO: Pod "pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012036296s
STEP: Saw pod success 11/26/22 13:11:33.049
Nov 26 13:11:33.049: INFO: Pod "pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d" satisfied condition "Succeeded or Failed"
Nov 26 13:11:33.055: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d container agnhost-container: <nil>
STEP: delete the pod 11/26/22 13:11:33.067
Nov 26 13:11:33.090: INFO: Waiting for pod pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d to disappear
Nov 26 13:11:33.096: INFO: Pod pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 26 13:11:33.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4955" for this suite. 11/26/22 13:11:33.104
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":285,"skipped":5339,"failed":0}
------------------------------
â€¢ [4.149 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:11:28.968
    Nov 26 13:11:28.969: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 13:11:28.97
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:28.997
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:29.005
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-76088897-cd3d-4d21-976a-ea2baf89b78a 11/26/22 13:11:29.012
    STEP: Creating a pod to test consume configMaps 11/26/22 13:11:29.019
    Nov 26 13:11:29.037: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d" in namespace "projected-4955" to be "Succeeded or Failed"
    Nov 26 13:11:29.043: INFO: Pod "pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.584472ms
    Nov 26 13:11:31.048: INFO: Pod "pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011412071s
    Nov 26 13:11:33.049: INFO: Pod "pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012036296s
    STEP: Saw pod success 11/26/22 13:11:33.049
    Nov 26 13:11:33.049: INFO: Pod "pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d" satisfied condition "Succeeded or Failed"
    Nov 26 13:11:33.055: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 13:11:33.067
    Nov 26 13:11:33.090: INFO: Waiting for pod pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d to disappear
    Nov 26 13:11:33.096: INFO: Pod pod-projected-configmaps-16abf028-0213-4789-bd36-244cfbafd40d no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 26 13:11:33.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4955" for this suite. 11/26/22 13:11:33.104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:11:33.126
Nov 26 13:11:33.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 13:11:33.127
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:33.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:33.16
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-3765c2b8-aca2-4936-bcb5-3f39e1972dc7 11/26/22 13:11:33.167
STEP: Creating a pod to test consume secrets 11/26/22 13:11:33.175
Nov 26 13:11:33.207: INFO: Waiting up to 5m0s for pod "pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca" in namespace "secrets-825" to be "Succeeded or Failed"
Nov 26 13:11:33.218: INFO: Pod "pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 10.803719ms
Nov 26 13:11:35.224: INFO: Pod "pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016892738s
Nov 26 13:11:37.224: INFO: Pod "pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017235906s
STEP: Saw pod success 11/26/22 13:11:37.224
Nov 26 13:11:37.225: INFO: Pod "pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca" satisfied condition "Succeeded or Failed"
Nov 26 13:11:37.230: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca container secret-volume-test: <nil>
STEP: delete the pod 11/26/22 13:11:37.239
Nov 26 13:11:37.259: INFO: Waiting for pod pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca to disappear
Nov 26 13:11:37.264: INFO: Pod pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 26 13:11:37.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-825" for this suite. 11/26/22 13:11:37.271
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":286,"skipped":5403,"failed":0}
------------------------------
â€¢ [4.156 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:11:33.126
    Nov 26 13:11:33.126: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 13:11:33.127
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:33.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:33.16
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-3765c2b8-aca2-4936-bcb5-3f39e1972dc7 11/26/22 13:11:33.167
    STEP: Creating a pod to test consume secrets 11/26/22 13:11:33.175
    Nov 26 13:11:33.207: INFO: Waiting up to 5m0s for pod "pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca" in namespace "secrets-825" to be "Succeeded or Failed"
    Nov 26 13:11:33.218: INFO: Pod "pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 10.803719ms
    Nov 26 13:11:35.224: INFO: Pod "pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016892738s
    Nov 26 13:11:37.224: INFO: Pod "pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017235906s
    STEP: Saw pod success 11/26/22 13:11:37.224
    Nov 26 13:11:37.225: INFO: Pod "pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca" satisfied condition "Succeeded or Failed"
    Nov 26 13:11:37.230: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca container secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 13:11:37.239
    Nov 26 13:11:37.259: INFO: Waiting for pod pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca to disappear
    Nov 26 13:11:37.264: INFO: Pod pod-secrets-39584dee-54ec-44a5-823b-dbf24b02c5ca no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 13:11:37.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-825" for this suite. 11/26/22 13:11:37.271
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:11:37.284
Nov 26 13:11:37.285: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename security-context 11/26/22 13:11:37.286
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:37.32
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:37.326
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/26/22 13:11:37.333
Nov 26 13:11:37.347: INFO: Waiting up to 5m0s for pod "security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50" in namespace "security-context-5658" to be "Succeeded or Failed"
Nov 26 13:11:37.356: INFO: Pod "security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50": Phase="Pending", Reason="", readiness=false. Elapsed: 8.740839ms
Nov 26 13:11:39.362: INFO: Pod "security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014794164s
Nov 26 13:11:41.366: INFO: Pod "security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018806829s
STEP: Saw pod success 11/26/22 13:11:41.366
Nov 26 13:11:41.367: INFO: Pod "security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50" satisfied condition "Succeeded or Failed"
Nov 26 13:11:41.375: INFO: Trying to get logs from node ip-172-31-43-82 pod security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50 container test-container: <nil>
STEP: delete the pod 11/26/22 13:11:41.387
Nov 26 13:11:41.412: INFO: Waiting for pod security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50 to disappear
Nov 26 13:11:41.418: INFO: Pod security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 26 13:11:41.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5658" for this suite. 11/26/22 13:11:41.424
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":287,"skipped":5405,"failed":0}
------------------------------
â€¢ [4.151 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:11:37.284
    Nov 26 13:11:37.285: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename security-context 11/26/22 13:11:37.286
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:37.32
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:37.326
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/26/22 13:11:37.333
    Nov 26 13:11:37.347: INFO: Waiting up to 5m0s for pod "security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50" in namespace "security-context-5658" to be "Succeeded or Failed"
    Nov 26 13:11:37.356: INFO: Pod "security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50": Phase="Pending", Reason="", readiness=false. Elapsed: 8.740839ms
    Nov 26 13:11:39.362: INFO: Pod "security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014794164s
    Nov 26 13:11:41.366: INFO: Pod "security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018806829s
    STEP: Saw pod success 11/26/22 13:11:41.366
    Nov 26 13:11:41.367: INFO: Pod "security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50" satisfied condition "Succeeded or Failed"
    Nov 26 13:11:41.375: INFO: Trying to get logs from node ip-172-31-43-82 pod security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50 container test-container: <nil>
    STEP: delete the pod 11/26/22 13:11:41.387
    Nov 26 13:11:41.412: INFO: Waiting for pod security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50 to disappear
    Nov 26 13:11:41.418: INFO: Pod security-context-3bd5f07a-0cea-4a90-827f-9d2b56b50e50 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 26 13:11:41.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-5658" for this suite. 11/26/22 13:11:41.424
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:11:41.437
Nov 26 13:11:41.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename job 11/26/22 13:11:41.439
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:41.46
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:41.466
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 11/26/22 13:11:41.472
STEP: Ensuring active pods == parallelism 11/26/22 13:11:41.479
STEP: delete a job 11/26/22 13:11:43.486
STEP: deleting Job.batch foo in namespace job-3035, will wait for the garbage collector to delete the pods 11/26/22 13:11:43.486
Nov 26 13:11:43.554: INFO: Deleting Job.batch foo took: 11.656711ms
Nov 26 13:11:43.655: INFO: Terminating Job.batch foo pods took: 101.261459ms
STEP: Ensuring job was deleted 11/26/22 13:12:16.355
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 26 13:12:16.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3035" for this suite. 11/26/22 13:12:16.367
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":288,"skipped":5413,"failed":0}
------------------------------
â€¢ [SLOW TEST] [34.942 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:11:41.437
    Nov 26 13:11:41.437: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename job 11/26/22 13:11:41.439
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:11:41.46
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:11:41.466
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 11/26/22 13:11:41.472
    STEP: Ensuring active pods == parallelism 11/26/22 13:11:41.479
    STEP: delete a job 11/26/22 13:11:43.486
    STEP: deleting Job.batch foo in namespace job-3035, will wait for the garbage collector to delete the pods 11/26/22 13:11:43.486
    Nov 26 13:11:43.554: INFO: Deleting Job.batch foo took: 11.656711ms
    Nov 26 13:11:43.655: INFO: Terminating Job.batch foo pods took: 101.261459ms
    STEP: Ensuring job was deleted 11/26/22 13:12:16.355
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 26 13:12:16.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3035" for this suite. 11/26/22 13:12:16.367
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:12:16.38
Nov 26 13:12:16.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 13:12:16.381
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:16.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:16.416
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 11/26/22 13:12:16.422
STEP: submitting the pod to kubernetes 11/26/22 13:12:16.422
Nov 26 13:12:16.437: INFO: Waiting up to 5m0s for pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c" in namespace "pods-676" to be "running and ready"
Nov 26 13:12:16.444: INFO: Pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.206032ms
Nov 26 13:12:16.444: INFO: The phase of Pod pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:12:18.451: INFO: Pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c": Phase="Running", Reason="", readiness=true. Elapsed: 2.013378197s
Nov 26 13:12:18.451: INFO: The phase of Pod pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c is Running (Ready = true)
Nov 26 13:12:18.451: INFO: Pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 11/26/22 13:12:18.455
STEP: updating the pod 11/26/22 13:12:18.461
Nov 26 13:12:18.980: INFO: Successfully updated pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c"
Nov 26 13:12:18.980: INFO: Waiting up to 5m0s for pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c" in namespace "pods-676" to be "running"
Nov 26 13:12:18.986: INFO: Pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c": Phase="Running", Reason="", readiness=true. Elapsed: 5.558682ms
Nov 26 13:12:18.986: INFO: Pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 11/26/22 13:12:18.986
Nov 26 13:12:18.992: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 26 13:12:18.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-676" for this suite. 11/26/22 13:12:18.998
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":289,"skipped":5420,"failed":0}
------------------------------
â€¢ [2.628 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:12:16.38
    Nov 26 13:12:16.380: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 13:12:16.381
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:16.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:16.416
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 11/26/22 13:12:16.422
    STEP: submitting the pod to kubernetes 11/26/22 13:12:16.422
    Nov 26 13:12:16.437: INFO: Waiting up to 5m0s for pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c" in namespace "pods-676" to be "running and ready"
    Nov 26 13:12:16.444: INFO: Pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.206032ms
    Nov 26 13:12:16.444: INFO: The phase of Pod pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:12:18.451: INFO: Pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c": Phase="Running", Reason="", readiness=true. Elapsed: 2.013378197s
    Nov 26 13:12:18.451: INFO: The phase of Pod pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c is Running (Ready = true)
    Nov 26 13:12:18.451: INFO: Pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 11/26/22 13:12:18.455
    STEP: updating the pod 11/26/22 13:12:18.461
    Nov 26 13:12:18.980: INFO: Successfully updated pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c"
    Nov 26 13:12:18.980: INFO: Waiting up to 5m0s for pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c" in namespace "pods-676" to be "running"
    Nov 26 13:12:18.986: INFO: Pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c": Phase="Running", Reason="", readiness=true. Elapsed: 5.558682ms
    Nov 26 13:12:18.986: INFO: Pod "pod-update-1d5dc5a2-c936-4b7c-b362-2f545034471c" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 11/26/22 13:12:18.986
    Nov 26 13:12:18.992: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 26 13:12:18.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-676" for this suite. 11/26/22 13:12:18.998
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:12:19.009
Nov 26 13:12:19.010: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename hostport 11/26/22 13:12:19.011
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:19.044
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:19.05
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 11/26/22 13:12:19.064
Nov 26 13:12:19.076: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-729" to be "running and ready"
Nov 26 13:12:19.082: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.892307ms
Nov 26 13:12:19.082: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:12:21.088: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012104552s
Nov 26 13:12:21.088: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov 26 13:12:21.088: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.29.104 on the node which pod1 resides and expect scheduled 11/26/22 13:12:21.088
Nov 26 13:12:21.097: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-729" to be "running and ready"
Nov 26 13:12:21.104: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.483531ms
Nov 26 13:12:21.104: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:12:23.111: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.01455084s
Nov 26 13:12:23.111: INFO: The phase of Pod pod2 is Running (Ready = false)
Nov 26 13:12:25.110: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.012870809s
Nov 26 13:12:25.110: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov 26 13:12:25.110: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.29.104 but use UDP protocol on the node which pod2 resides 11/26/22 13:12:25.11
Nov 26 13:12:25.120: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-729" to be "running and ready"
Nov 26 13:12:25.135: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.964272ms
Nov 26 13:12:25.135: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:12:27.141: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.021319982s
Nov 26 13:12:27.141: INFO: The phase of Pod pod3 is Running (Ready = true)
Nov 26 13:12:27.141: INFO: Pod "pod3" satisfied condition "running and ready"
Nov 26 13:12:27.151: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-729" to be "running and ready"
Nov 26 13:12:27.157: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 5.869437ms
Nov 26 13:12:27.157: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:12:29.164: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.013431416s
Nov 26 13:12:29.164: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Nov 26 13:12:29.164: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 11/26/22 13:12:29.171
Nov 26 13:12:29.171: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.29.104 http://127.0.0.1:54323/hostname] Namespace:hostport-729 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 13:12:29.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 13:12:29.172: INFO: ExecWithOptions: Clientset creation
Nov 26 13:12:29.172: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-729/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.29.104+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.29.104, port: 54323 11/26/22 13:12:29.358
Nov 26 13:12:29.358: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.29.104:54323/hostname] Namespace:hostport-729 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 13:12:29.358: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 13:12:29.360: INFO: ExecWithOptions: Clientset creation
Nov 26 13:12:29.360: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-729/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.29.104%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.29.104, port: 54323 UDP 11/26/22 13:12:29.553
Nov 26 13:12:29.554: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.29.104 54323] Namespace:hostport-729 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 13:12:29.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 13:12:29.556: INFO: ExecWithOptions: Clientset creation
Nov 26 13:12:29.556: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-729/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.29.104+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Nov 26 13:12:34.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-729" for this suite. 11/26/22 13:12:34.691
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":290,"skipped":5424,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.694 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:12:19.009
    Nov 26 13:12:19.010: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename hostport 11/26/22 13:12:19.011
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:19.044
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:19.05
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 11/26/22 13:12:19.064
    Nov 26 13:12:19.076: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-729" to be "running and ready"
    Nov 26 13:12:19.082: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.892307ms
    Nov 26 13:12:19.082: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:12:21.088: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012104552s
    Nov 26 13:12:21.088: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov 26 13:12:21.088: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.29.104 on the node which pod1 resides and expect scheduled 11/26/22 13:12:21.088
    Nov 26 13:12:21.097: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-729" to be "running and ready"
    Nov 26 13:12:21.104: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.483531ms
    Nov 26 13:12:21.104: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:12:23.111: INFO: Pod "pod2": Phase="Running", Reason="", readiness=false. Elapsed: 2.01455084s
    Nov 26 13:12:23.111: INFO: The phase of Pod pod2 is Running (Ready = false)
    Nov 26 13:12:25.110: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 4.012870809s
    Nov 26 13:12:25.110: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov 26 13:12:25.110: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.29.104 but use UDP protocol on the node which pod2 resides 11/26/22 13:12:25.11
    Nov 26 13:12:25.120: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-729" to be "running and ready"
    Nov 26 13:12:25.135: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.964272ms
    Nov 26 13:12:25.135: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:12:27.141: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.021319982s
    Nov 26 13:12:27.141: INFO: The phase of Pod pod3 is Running (Ready = true)
    Nov 26 13:12:27.141: INFO: Pod "pod3" satisfied condition "running and ready"
    Nov 26 13:12:27.151: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-729" to be "running and ready"
    Nov 26 13:12:27.157: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 5.869437ms
    Nov 26 13:12:27.157: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:12:29.164: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.013431416s
    Nov 26 13:12:29.164: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Nov 26 13:12:29.164: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 11/26/22 13:12:29.171
    Nov 26 13:12:29.171: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.29.104 http://127.0.0.1:54323/hostname] Namespace:hostport-729 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 13:12:29.171: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 13:12:29.172: INFO: ExecWithOptions: Clientset creation
    Nov 26 13:12:29.172: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-729/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.29.104+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.29.104, port: 54323 11/26/22 13:12:29.358
    Nov 26 13:12:29.358: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.29.104:54323/hostname] Namespace:hostport-729 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 13:12:29.358: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 13:12:29.360: INFO: ExecWithOptions: Clientset creation
    Nov 26 13:12:29.360: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-729/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.29.104%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.29.104, port: 54323 UDP 11/26/22 13:12:29.553
    Nov 26 13:12:29.554: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.29.104 54323] Namespace:hostport-729 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 13:12:29.554: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 13:12:29.556: INFO: ExecWithOptions: Clientset creation
    Nov 26 13:12:29.556: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-729/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.29.104+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Nov 26 13:12:34.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-729" for this suite. 11/26/22 13:12:34.691
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:12:34.709
Nov 26 13:12:34.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 13:12:34.711
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:34.735
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:34.742
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 11/26/22 13:12:34.763
STEP: Creating a ResourceQuota 11/26/22 13:12:39.77
STEP: Ensuring resource quota status is calculated 11/26/22 13:12:39.784
STEP: Creating a ReplicationController 11/26/22 13:12:41.79
STEP: Ensuring resource quota status captures replication controller creation 11/26/22 13:12:41.808
STEP: Deleting a ReplicationController 11/26/22 13:12:43.815
STEP: Ensuring resource quota status released usage 11/26/22 13:12:43.825
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 13:12:45.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-27" for this suite. 11/26/22 13:12:45.842
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":291,"skipped":5466,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.144 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:12:34.709
    Nov 26 13:12:34.710: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 13:12:34.711
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:34.735
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:34.742
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 11/26/22 13:12:34.763
    STEP: Creating a ResourceQuota 11/26/22 13:12:39.77
    STEP: Ensuring resource quota status is calculated 11/26/22 13:12:39.784
    STEP: Creating a ReplicationController 11/26/22 13:12:41.79
    STEP: Ensuring resource quota status captures replication controller creation 11/26/22 13:12:41.808
    STEP: Deleting a ReplicationController 11/26/22 13:12:43.815
    STEP: Ensuring resource quota status released usage 11/26/22 13:12:43.825
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 13:12:45.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-27" for this suite. 11/26/22 13:12:45.842
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:12:45.859
Nov 26 13:12:45.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename custom-resource-definition 11/26/22 13:12:45.86
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:45.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:45.888
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Nov 26 13:12:45.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 13:12:46.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8520" for this suite. 11/26/22 13:12:46.944
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":292,"skipped":5481,"failed":0}
------------------------------
â€¢ [1.095 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:12:45.859
    Nov 26 13:12:45.859: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename custom-resource-definition 11/26/22 13:12:45.86
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:45.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:45.888
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Nov 26 13:12:45.895: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 13:12:46.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-8520" for this suite. 11/26/22 13:12:46.944
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:12:46.959
Nov 26 13:12:46.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 13:12:46.961
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:46.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:46.99
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 11/26/22 13:12:46.999
Nov 26 13:12:47.015: INFO: Waiting up to 5m0s for pod "downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71" in namespace "downward-api-2945" to be "Succeeded or Failed"
Nov 26 13:12:47.024: INFO: Pod "downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71": Phase="Pending", Reason="", readiness=false. Elapsed: 9.131155ms
Nov 26 13:12:49.030: INFO: Pod "downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015846958s
Nov 26 13:12:51.030: INFO: Pod "downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01576353s
STEP: Saw pod success 11/26/22 13:12:51.03
Nov 26 13:12:51.031: INFO: Pod "downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71" satisfied condition "Succeeded or Failed"
Nov 26 13:12:51.036: INFO: Trying to get logs from node ip-172-31-43-82 pod downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71 container dapi-container: <nil>
STEP: delete the pod 11/26/22 13:12:51.048
Nov 26 13:12:51.075: INFO: Waiting for pod downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71 to disappear
Nov 26 13:12:51.080: INFO: Pod downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov 26 13:12:51.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2945" for this suite. 11/26/22 13:12:51.089
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":293,"skipped":5540,"failed":0}
------------------------------
â€¢ [4.141 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:12:46.959
    Nov 26 13:12:46.960: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 13:12:46.961
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:46.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:46.99
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 11/26/22 13:12:46.999
    Nov 26 13:12:47.015: INFO: Waiting up to 5m0s for pod "downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71" in namespace "downward-api-2945" to be "Succeeded or Failed"
    Nov 26 13:12:47.024: INFO: Pod "downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71": Phase="Pending", Reason="", readiness=false. Elapsed: 9.131155ms
    Nov 26 13:12:49.030: INFO: Pod "downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015846958s
    Nov 26 13:12:51.030: INFO: Pod "downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01576353s
    STEP: Saw pod success 11/26/22 13:12:51.03
    Nov 26 13:12:51.031: INFO: Pod "downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71" satisfied condition "Succeeded or Failed"
    Nov 26 13:12:51.036: INFO: Trying to get logs from node ip-172-31-43-82 pod downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71 container dapi-container: <nil>
    STEP: delete the pod 11/26/22 13:12:51.048
    Nov 26 13:12:51.075: INFO: Waiting for pod downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71 to disappear
    Nov 26 13:12:51.080: INFO: Pod downward-api-74808043-c8a1-465f-9c0e-5d36058b2f71 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov 26 13:12:51.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2945" for this suite. 11/26/22 13:12:51.089
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:12:51.102
Nov 26 13:12:51.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename init-container 11/26/22 13:12:51.103
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:51.135
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:51.14
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 11/26/22 13:12:51.148
Nov 26 13:12:51.148: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 26 13:12:55.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2633" for this suite. 11/26/22 13:12:55.277
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":294,"skipped":5547,"failed":0}
------------------------------
â€¢ [4.186 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:12:51.102
    Nov 26 13:12:51.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename init-container 11/26/22 13:12:51.103
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:51.135
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:51.14
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 11/26/22 13:12:51.148
    Nov 26 13:12:51.148: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 26 13:12:55.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-2633" for this suite. 11/26/22 13:12:55.277
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:12:55.289
Nov 26 13:12:55.289: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-lifecycle-hook 11/26/22 13:12:55.291
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:55.315
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:55.325
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/26/22 13:12:55.339
Nov 26 13:12:55.355: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2231" to be "running and ready"
Nov 26 13:12:55.364: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 8.455006ms
Nov 26 13:12:55.364: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:12:57.371: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.015263863s
Nov 26 13:12:57.371: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov 26 13:12:57.371: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 11/26/22 13:12:57.377
Nov 26 13:12:57.388: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-2231" to be "running and ready"
Nov 26 13:12:57.394: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.940109ms
Nov 26 13:12:57.394: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:12:59.402: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013291464s
Nov 26 13:12:59.402: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Nov 26 13:12:59.402: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 11/26/22 13:12:59.407
Nov 26 13:12:59.419: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 26 13:12:59.428: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 26 13:13:01.429: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 26 13:13:01.434: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 26 13:13:03.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 26 13:13:03.434: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 11/26/22 13:13:03.434
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov 26 13:13:03.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2231" for this suite. 11/26/22 13:13:03.462
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":295,"skipped":5548,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.184 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:12:55.289
    Nov 26 13:12:55.289: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/26/22 13:12:55.291
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:12:55.315
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:12:55.325
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/26/22 13:12:55.339
    Nov 26 13:12:55.355: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2231" to be "running and ready"
    Nov 26 13:12:55.364: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 8.455006ms
    Nov 26 13:12:55.364: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:12:57.371: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.015263863s
    Nov 26 13:12:57.371: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov 26 13:12:57.371: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 11/26/22 13:12:57.377
    Nov 26 13:12:57.388: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-2231" to be "running and ready"
    Nov 26 13:12:57.394: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.940109ms
    Nov 26 13:12:57.394: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:12:59.402: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013291464s
    Nov 26 13:12:59.402: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Nov 26 13:12:59.402: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 11/26/22 13:12:59.407
    Nov 26 13:12:59.419: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 26 13:12:59.428: INFO: Pod pod-with-prestop-exec-hook still exists
    Nov 26 13:13:01.429: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 26 13:13:01.434: INFO: Pod pod-with-prestop-exec-hook still exists
    Nov 26 13:13:03.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov 26 13:13:03.434: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 11/26/22 13:13:03.434
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov 26 13:13:03.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-2231" for this suite. 11/26/22 13:13:03.462
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:13:03.473
Nov 26 13:13:03.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 13:13:03.474
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:13:03.501
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:13:03.507
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Nov 26 13:13:03.522: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 11/26/22 13:13:06.311
Nov 26 13:13:06.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 create -f -'
Nov 26 13:13:07.233: INFO: stderr: ""
Nov 26 13:13:07.233: INFO: stdout: "e2e-test-crd-publish-openapi-9412-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 26 13:13:07.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 delete e2e-test-crd-publish-openapi-9412-crds test-foo'
Nov 26 13:13:07.382: INFO: stderr: ""
Nov 26 13:13:07.382: INFO: stdout: "e2e-test-crd-publish-openapi-9412-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov 26 13:13:07.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 apply -f -'
Nov 26 13:13:07.717: INFO: stderr: ""
Nov 26 13:13:07.718: INFO: stdout: "e2e-test-crd-publish-openapi-9412-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 26 13:13:07.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 delete e2e-test-crd-publish-openapi-9412-crds test-foo'
Nov 26 13:13:07.819: INFO: stderr: ""
Nov 26 13:13:07.819: INFO: stdout: "e2e-test-crd-publish-openapi-9412-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 11/26/22 13:13:07.819
Nov 26 13:13:07.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 create -f -'
Nov 26 13:13:08.164: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 11/26/22 13:13:08.164
Nov 26 13:13:08.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 create -f -'
Nov 26 13:13:08.504: INFO: rc: 1
Nov 26 13:13:08.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 apply -f -'
Nov 26 13:13:08.854: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 11/26/22 13:13:08.854
Nov 26 13:13:08.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 create -f -'
Nov 26 13:13:09.803: INFO: rc: 1
Nov 26 13:13:09.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 apply -f -'
Nov 26 13:13:10.139: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 11/26/22 13:13:10.139
Nov 26 13:13:10.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 explain e2e-test-crd-publish-openapi-9412-crds'
Nov 26 13:13:10.517: INFO: stderr: ""
Nov 26 13:13:10.517: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9412-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 11/26/22 13:13:10.518
Nov 26 13:13:10.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 explain e2e-test-crd-publish-openapi-9412-crds.metadata'
Nov 26 13:13:10.965: INFO: stderr: ""
Nov 26 13:13:10.965: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9412-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov 26 13:13:10.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 explain e2e-test-crd-publish-openapi-9412-crds.spec'
Nov 26 13:13:11.343: INFO: stderr: ""
Nov 26 13:13:11.343: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9412-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov 26 13:13:11.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 explain e2e-test-crd-publish-openapi-9412-crds.spec.bars'
Nov 26 13:13:11.568: INFO: stderr: ""
Nov 26 13:13:11.568: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9412-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 11/26/22 13:13:11.569
Nov 26 13:13:11.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 explain e2e-test-crd-publish-openapi-9412-crds.spec.bars2'
Nov 26 13:13:11.796: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 13:13:16.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5123" for this suite. 11/26/22 13:13:16.07
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":296,"skipped":5552,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.609 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:13:03.473
    Nov 26 13:13:03.473: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 13:13:03.474
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:13:03.501
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:13:03.507
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Nov 26 13:13:03.522: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 11/26/22 13:13:06.311
    Nov 26 13:13:06.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 create -f -'
    Nov 26 13:13:07.233: INFO: stderr: ""
    Nov 26 13:13:07.233: INFO: stdout: "e2e-test-crd-publish-openapi-9412-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Nov 26 13:13:07.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 delete e2e-test-crd-publish-openapi-9412-crds test-foo'
    Nov 26 13:13:07.382: INFO: stderr: ""
    Nov 26 13:13:07.382: INFO: stdout: "e2e-test-crd-publish-openapi-9412-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Nov 26 13:13:07.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 apply -f -'
    Nov 26 13:13:07.717: INFO: stderr: ""
    Nov 26 13:13:07.718: INFO: stdout: "e2e-test-crd-publish-openapi-9412-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Nov 26 13:13:07.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 delete e2e-test-crd-publish-openapi-9412-crds test-foo'
    Nov 26 13:13:07.819: INFO: stderr: ""
    Nov 26 13:13:07.819: INFO: stdout: "e2e-test-crd-publish-openapi-9412-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 11/26/22 13:13:07.819
    Nov 26 13:13:07.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 create -f -'
    Nov 26 13:13:08.164: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 11/26/22 13:13:08.164
    Nov 26 13:13:08.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 create -f -'
    Nov 26 13:13:08.504: INFO: rc: 1
    Nov 26 13:13:08.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 apply -f -'
    Nov 26 13:13:08.854: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 11/26/22 13:13:08.854
    Nov 26 13:13:08.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 create -f -'
    Nov 26 13:13:09.803: INFO: rc: 1
    Nov 26 13:13:09.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 --namespace=crd-publish-openapi-5123 apply -f -'
    Nov 26 13:13:10.139: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 11/26/22 13:13:10.139
    Nov 26 13:13:10.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 explain e2e-test-crd-publish-openapi-9412-crds'
    Nov 26 13:13:10.517: INFO: stderr: ""
    Nov 26 13:13:10.517: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9412-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 11/26/22 13:13:10.518
    Nov 26 13:13:10.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 explain e2e-test-crd-publish-openapi-9412-crds.metadata'
    Nov 26 13:13:10.965: INFO: stderr: ""
    Nov 26 13:13:10.965: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9412-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Nov 26 13:13:10.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 explain e2e-test-crd-publish-openapi-9412-crds.spec'
    Nov 26 13:13:11.343: INFO: stderr: ""
    Nov 26 13:13:11.343: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9412-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Nov 26 13:13:11.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 explain e2e-test-crd-publish-openapi-9412-crds.spec.bars'
    Nov 26 13:13:11.568: INFO: stderr: ""
    Nov 26 13:13:11.568: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9412-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 11/26/22 13:13:11.569
    Nov 26 13:13:11.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=crd-publish-openapi-5123 explain e2e-test-crd-publish-openapi-9412-crds.spec.bars2'
    Nov 26 13:13:11.796: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 13:13:16.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5123" for this suite. 11/26/22 13:13:16.07
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:13:16.084
Nov 26 13:13:16.084: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename taint-multiple-pods 11/26/22 13:13:16.086
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:13:16.103
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:13:16.11
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Nov 26 13:13:16.120: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 26 13:14:16.144: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Nov 26 13:14:16.150: INFO: Starting informer...
STEP: Starting pods... 11/26/22 13:14:16.15
Nov 26 13:14:16.387: INFO: Pod1 is running on ip-172-31-43-82. Tainting Node
Nov 26 13:14:16.614: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-5604" to be "running"
Nov 26 13:14:16.619: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.390327ms
Nov 26 13:14:18.626: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011487884s
Nov 26 13:14:18.626: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Nov 26 13:14:18.626: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-5604" to be "running"
Nov 26 13:14:18.631: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.522588ms
Nov 26 13:14:18.631: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Nov 26 13:14:18.631: INFO: Pod2 is running on ip-172-31-43-82. Tainting Node
STEP: Trying to apply a taint on the Node 11/26/22 13:14:18.631
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/26/22 13:14:18.648
STEP: Waiting for Pod1 and Pod2 to be deleted 11/26/22 13:14:18.656
Nov 26 13:14:24.468: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov 26 13:14:44.515: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/26/22 13:14:44.533
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Nov 26 13:14:44.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-5604" for this suite. 11/26/22 13:14:44.548
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":297,"skipped":5562,"failed":0}
------------------------------
â€¢ [SLOW TEST] [88.485 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:13:16.084
    Nov 26 13:13:16.084: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename taint-multiple-pods 11/26/22 13:13:16.086
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:13:16.103
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:13:16.11
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Nov 26 13:13:16.120: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 26 13:14:16.144: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Nov 26 13:14:16.150: INFO: Starting informer...
    STEP: Starting pods... 11/26/22 13:14:16.15
    Nov 26 13:14:16.387: INFO: Pod1 is running on ip-172-31-43-82. Tainting Node
    Nov 26 13:14:16.614: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-5604" to be "running"
    Nov 26 13:14:16.619: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.390327ms
    Nov 26 13:14:18.626: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011487884s
    Nov 26 13:14:18.626: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Nov 26 13:14:18.626: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-5604" to be "running"
    Nov 26 13:14:18.631: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.522588ms
    Nov 26 13:14:18.631: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Nov 26 13:14:18.631: INFO: Pod2 is running on ip-172-31-43-82. Tainting Node
    STEP: Trying to apply a taint on the Node 11/26/22 13:14:18.631
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/26/22 13:14:18.648
    STEP: Waiting for Pod1 and Pod2 to be deleted 11/26/22 13:14:18.656
    Nov 26 13:14:24.468: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Nov 26 13:14:44.515: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/26/22 13:14:44.533
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 13:14:44.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-5604" for this suite. 11/26/22 13:14:44.548
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:14:44.57
Nov 26 13:14:44.570: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 13:14:44.571
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:44.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:44.683
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 11/26/22 13:14:44.688
Nov 26 13:14:44.701: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117" in namespace "projected-4608" to be "Succeeded or Failed"
Nov 26 13:14:44.712: INFO: Pod "downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117": Phase="Pending", Reason="", readiness=false. Elapsed: 10.960926ms
Nov 26 13:14:46.719: INFO: Pod "downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018384849s
Nov 26 13:14:48.718: INFO: Pod "downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017006137s
STEP: Saw pod success 11/26/22 13:14:48.718
Nov 26 13:14:48.718: INFO: Pod "downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117" satisfied condition "Succeeded or Failed"
Nov 26 13:14:48.723: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117 container client-container: <nil>
STEP: delete the pod 11/26/22 13:14:48.739
Nov 26 13:14:48.758: INFO: Waiting for pod downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117 to disappear
Nov 26 13:14:48.768: INFO: Pod downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 13:14:48.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4608" for this suite. 11/26/22 13:14:48.774
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":298,"skipped":5572,"failed":0}
------------------------------
â€¢ [4.214 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:14:44.57
    Nov 26 13:14:44.570: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 13:14:44.571
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:44.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:44.683
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 11/26/22 13:14:44.688
    Nov 26 13:14:44.701: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117" in namespace "projected-4608" to be "Succeeded or Failed"
    Nov 26 13:14:44.712: INFO: Pod "downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117": Phase="Pending", Reason="", readiness=false. Elapsed: 10.960926ms
    Nov 26 13:14:46.719: INFO: Pod "downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018384849s
    Nov 26 13:14:48.718: INFO: Pod "downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017006137s
    STEP: Saw pod success 11/26/22 13:14:48.718
    Nov 26 13:14:48.718: INFO: Pod "downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117" satisfied condition "Succeeded or Failed"
    Nov 26 13:14:48.723: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117 container client-container: <nil>
    STEP: delete the pod 11/26/22 13:14:48.739
    Nov 26 13:14:48.758: INFO: Waiting for pod downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117 to disappear
    Nov 26 13:14:48.768: INFO: Pod downwardapi-volume-86384ab5-53f8-4f27-b27b-f5be1b97b117 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 13:14:48.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4608" for this suite. 11/26/22 13:14:48.774
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:14:48.789
Nov 26 13:14:48.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 13:14:48.79
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:48.815
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:48.82
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-5297f769-c494-4970-9dd9-743bd3bff94c 11/26/22 13:14:48.826
STEP: Creating a pod to test consume configMaps 11/26/22 13:14:48.833
Nov 26 13:14:48.854: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b" in namespace "projected-885" to be "Succeeded or Failed"
Nov 26 13:14:48.860: INFO: Pod "pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.326351ms
Nov 26 13:14:50.866: INFO: Pod "pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011599203s
Nov 26 13:14:52.868: INFO: Pod "pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012937539s
STEP: Saw pod success 11/26/22 13:14:52.868
Nov 26 13:14:52.868: INFO: Pod "pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b" satisfied condition "Succeeded or Failed"
Nov 26 13:14:52.876: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b container agnhost-container: <nil>
STEP: delete the pod 11/26/22 13:14:52.889
Nov 26 13:14:52.909: INFO: Waiting for pod pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b to disappear
Nov 26 13:14:52.917: INFO: Pod pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 26 13:14:52.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-885" for this suite. 11/26/22 13:14:52.926
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":299,"skipped":5631,"failed":0}
------------------------------
â€¢ [4.149 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:14:48.789
    Nov 26 13:14:48.789: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 13:14:48.79
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:48.815
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:48.82
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-5297f769-c494-4970-9dd9-743bd3bff94c 11/26/22 13:14:48.826
    STEP: Creating a pod to test consume configMaps 11/26/22 13:14:48.833
    Nov 26 13:14:48.854: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b" in namespace "projected-885" to be "Succeeded or Failed"
    Nov 26 13:14:48.860: INFO: Pod "pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.326351ms
    Nov 26 13:14:50.866: INFO: Pod "pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011599203s
    Nov 26 13:14:52.868: INFO: Pod "pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012937539s
    STEP: Saw pod success 11/26/22 13:14:52.868
    Nov 26 13:14:52.868: INFO: Pod "pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b" satisfied condition "Succeeded or Failed"
    Nov 26 13:14:52.876: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b container agnhost-container: <nil>
    STEP: delete the pod 11/26/22 13:14:52.889
    Nov 26 13:14:52.909: INFO: Waiting for pod pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b to disappear
    Nov 26 13:14:52.917: INFO: Pod pod-projected-configmaps-f9629212-740a-4656-ab29-cf89a9d1d38b no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 26 13:14:52.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-885" for this suite. 11/26/22 13:14:52.926
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:14:52.94
Nov 26 13:14:52.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename namespaces 11/26/22 13:14:52.943
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:52.968
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:52.974
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 11/26/22 13:14:52.979
Nov 26 13:14:52.992: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 11/26/22 13:14:52.992
Nov 26 13:14:53.004: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 11/26/22 13:14:53.005
Nov 26 13:14:53.024: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov 26 13:14:53.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7439" for this suite. 11/26/22 13:14:53.031
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":300,"skipped":5641,"failed":0}
------------------------------
â€¢ [0.108 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:14:52.94
    Nov 26 13:14:52.941: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename namespaces 11/26/22 13:14:52.943
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:52.968
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:52.974
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 11/26/22 13:14:52.979
    Nov 26 13:14:52.992: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 11/26/22 13:14:52.992
    Nov 26 13:14:53.004: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 11/26/22 13:14:53.005
    Nov 26 13:14:53.024: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 13:14:53.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7439" for this suite. 11/26/22 13:14:53.031
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:14:53.055
Nov 26 13:14:53.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename endpointslice 11/26/22 13:14:53.06
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:53.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:53.094
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 11/26/22 13:14:53.099
STEP: getting /apis/discovery.k8s.io 11/26/22 13:14:53.104
STEP: getting /apis/discovery.k8s.iov1 11/26/22 13:14:53.107
STEP: creating 11/26/22 13:14:53.11
STEP: getting 11/26/22 13:14:53.134
STEP: listing 11/26/22 13:14:53.145
STEP: watching 11/26/22 13:14:53.152
Nov 26 13:14:53.152: INFO: starting watch
STEP: cluster-wide listing 11/26/22 13:14:53.154
STEP: cluster-wide watching 11/26/22 13:14:53.16
Nov 26 13:14:53.160: INFO: starting watch
STEP: patching 11/26/22 13:14:53.163
STEP: updating 11/26/22 13:14:53.178
Nov 26 13:14:53.193: INFO: waiting for watch events with expected annotations
Nov 26 13:14:53.193: INFO: saw patched and updated annotations
STEP: deleting 11/26/22 13:14:53.193
STEP: deleting a collection 11/26/22 13:14:53.215
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov 26 13:14:53.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7599" for this suite. 11/26/22 13:14:53.247
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":301,"skipped":5655,"failed":0}
------------------------------
â€¢ [0.202 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:14:53.055
    Nov 26 13:14:53.056: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename endpointslice 11/26/22 13:14:53.06
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:53.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:53.094
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 11/26/22 13:14:53.099
    STEP: getting /apis/discovery.k8s.io 11/26/22 13:14:53.104
    STEP: getting /apis/discovery.k8s.iov1 11/26/22 13:14:53.107
    STEP: creating 11/26/22 13:14:53.11
    STEP: getting 11/26/22 13:14:53.134
    STEP: listing 11/26/22 13:14:53.145
    STEP: watching 11/26/22 13:14:53.152
    Nov 26 13:14:53.152: INFO: starting watch
    STEP: cluster-wide listing 11/26/22 13:14:53.154
    STEP: cluster-wide watching 11/26/22 13:14:53.16
    Nov 26 13:14:53.160: INFO: starting watch
    STEP: patching 11/26/22 13:14:53.163
    STEP: updating 11/26/22 13:14:53.178
    Nov 26 13:14:53.193: INFO: waiting for watch events with expected annotations
    Nov 26 13:14:53.193: INFO: saw patched and updated annotations
    STEP: deleting 11/26/22 13:14:53.193
    STEP: deleting a collection 11/26/22 13:14:53.215
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov 26 13:14:53.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-7599" for this suite. 11/26/22 13:14:53.247
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:14:53.266
Nov 26 13:14:53.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 13:14:53.272
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:53.298
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:53.313
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Nov 26 13:14:53.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7978 version'
Nov 26 13:14:53.417: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Nov 26 13:14:53.417: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-11T02:14:16Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 13:14:53.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7978" for this suite. 11/26/22 13:14:53.429
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":302,"skipped":5726,"failed":0}
------------------------------
â€¢ [0.173 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:14:53.266
    Nov 26 13:14:53.267: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 13:14:53.272
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:53.298
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:53.313
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Nov 26 13:14:53.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-7978 version'
    Nov 26 13:14:53.417: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Nov 26 13:14:53.417: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-09T13:36:36Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.4\", GitCommit:\"872a965c6c6526caa949f0c6ac028ef7aff3fb78\", GitTreeState:\"clean\", BuildDate:\"2022-11-11T02:14:16Z\", GoVersion:\"go1.19.3\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 13:14:53.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7978" for this suite. 11/26/22 13:14:53.429
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:14:53.441
Nov 26 13:14:53.442: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sched-pred 11/26/22 13:14:53.446
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:53.48
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:53.491
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov 26 13:14:53.499: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 26 13:14:53.510: INFO: Waiting for terminating namespaces to be deleted...
Nov 26 13:14:53.519: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-0-249 before test
Nov 26 13:14:53.528: INFO: default-http-backend-kubernetes-worker-6546b9855c-4rkhh from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:36 +0000 UTC (1 container statuses recorded)
Nov 26 13:14:53.528: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov 26 13:14:53.528: INFO: nginx-ingress-controller-kubernetes-worker-m2kb4 from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:35 +0000 UTC (1 container statuses recorded)
Nov 26 13:14:53.528: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
Nov 26 13:14:53.528: INFO: coredns-6bcf44f4cc-q68zx from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 13:14:53.528: INFO: 	Container coredns ready: true, restart count 0
Nov 26 13:14:53.528: INFO: kube-state-metrics-74f5d549cc-2xtpf from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 13:14:53.529: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov 26 13:14:53.529: INFO: metrics-server-v0.5.2-6b48dc6f97-nfgfh from kube-system started at 2022-11-26 11:51:35 +0000 UTC (2 container statuses recorded)
Nov 26 13:14:53.529: INFO: 	Container metrics-server ready: true, restart count 0
Nov 26 13:14:53.529: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov 26 13:14:53.529: INFO: dashboard-metrics-scraper-85d45476c6-h2vdw from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 13:14:53.529: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 26 13:14:53.529: INFO: kubernetes-dashboard-7fb574cb-nwk47 from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
Nov 26 13:14:53.529: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 26 13:14:53.529: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4 from sonobuoy started at 2022-11-26 11:58:40 +0000 UTC (2 container statuses recorded)
Nov 26 13:14:53.529: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 13:14:53.529: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 26 13:14:53.529: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-29-104 before test
Nov 26 13:14:53.538: INFO: nginx-ingress-controller-kubernetes-worker-97spf from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:56 +0000 UTC (1 container statuses recorded)
Nov 26 13:14:53.538: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov 26 13:14:53.538: INFO: calico-kube-controllers-75648888c-rqsxl from kube-system started at 2022-11-26 13:14:18 +0000 UTC (1 container statuses recorded)
Nov 26 13:14:53.538: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 26 13:14:53.538: INFO: sonobuoy from sonobuoy started at 2022-11-26 11:58:19 +0000 UTC (1 container statuses recorded)
Nov 26 13:14:53.538: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 26 13:14:53.538: INFO: sonobuoy-e2e-job-1d4a77a11cb24dc4 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 13:14:53.539: INFO: 	Container e2e ready: true, restart count 0
Nov 26 13:14:53.539: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 13:14:53.539: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hq4v9 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 13:14:53.539: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 13:14:53.539: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 26 13:14:53.539: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-43-82 before test
Nov 26 13:14:53.547: INFO: nginx-ingress-controller-kubernetes-worker-gz7v6 from ingress-nginx-kubernetes-worker started at 2022-11-26 13:14:44 +0000 UTC (1 container statuses recorded)
Nov 26 13:14:53.547: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: false, restart count 0
Nov 26 13:14:53.547: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hbpwv from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
Nov 26 13:14:53.547: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 26 13:14:53.547: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 11/26/22 13:14:53.547
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.172b24bfeac35c55], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 11/26/22 13:14:53.587
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov 26 13:14:54.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2355" for this suite. 11/26/22 13:14:54.597
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":303,"skipped":5751,"failed":0}
------------------------------
â€¢ [1.167 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:14:53.441
    Nov 26 13:14:53.442: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sched-pred 11/26/22 13:14:53.446
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:53.48
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:53.491
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov 26 13:14:53.499: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov 26 13:14:53.510: INFO: Waiting for terminating namespaces to be deleted...
    Nov 26 13:14:53.519: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-0-249 before test
    Nov 26 13:14:53.528: INFO: default-http-backend-kubernetes-worker-6546b9855c-4rkhh from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:36 +0000 UTC (1 container statuses recorded)
    Nov 26 13:14:53.528: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov 26 13:14:53.528: INFO: nginx-ingress-controller-kubernetes-worker-m2kb4 from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:35 +0000 UTC (1 container statuses recorded)
    Nov 26 13:14:53.528: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 1
    Nov 26 13:14:53.528: INFO: coredns-6bcf44f4cc-q68zx from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 13:14:53.528: INFO: 	Container coredns ready: true, restart count 0
    Nov 26 13:14:53.528: INFO: kube-state-metrics-74f5d549cc-2xtpf from kube-system started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 13:14:53.529: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov 26 13:14:53.529: INFO: metrics-server-v0.5.2-6b48dc6f97-nfgfh from kube-system started at 2022-11-26 11:51:35 +0000 UTC (2 container statuses recorded)
    Nov 26 13:14:53.529: INFO: 	Container metrics-server ready: true, restart count 0
    Nov 26 13:14:53.529: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov 26 13:14:53.529: INFO: dashboard-metrics-scraper-85d45476c6-h2vdw from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 13:14:53.529: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov 26 13:14:53.529: INFO: kubernetes-dashboard-7fb574cb-nwk47 from kubernetes-dashboard started at 2022-11-26 11:51:35 +0000 UTC (1 container statuses recorded)
    Nov 26 13:14:53.529: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
    Nov 26 13:14:53.529: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-42fg4 from sonobuoy started at 2022-11-26 11:58:40 +0000 UTC (2 container statuses recorded)
    Nov 26 13:14:53.529: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 13:14:53.529: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 26 13:14:53.529: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-29-104 before test
    Nov 26 13:14:53.538: INFO: nginx-ingress-controller-kubernetes-worker-97spf from ingress-nginx-kubernetes-worker started at 2022-11-26 11:52:56 +0000 UTC (1 container statuses recorded)
    Nov 26 13:14:53.538: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov 26 13:14:53.538: INFO: calico-kube-controllers-75648888c-rqsxl from kube-system started at 2022-11-26 13:14:18 +0000 UTC (1 container statuses recorded)
    Nov 26 13:14:53.538: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov 26 13:14:53.538: INFO: sonobuoy from sonobuoy started at 2022-11-26 11:58:19 +0000 UTC (1 container statuses recorded)
    Nov 26 13:14:53.538: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov 26 13:14:53.538: INFO: sonobuoy-e2e-job-1d4a77a11cb24dc4 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 13:14:53.539: INFO: 	Container e2e ready: true, restart count 0
    Nov 26 13:14:53.539: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 13:14:53.539: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hq4v9 from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 13:14:53.539: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 13:14:53.539: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov 26 13:14:53.539: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-43-82 before test
    Nov 26 13:14:53.547: INFO: nginx-ingress-controller-kubernetes-worker-gz7v6 from ingress-nginx-kubernetes-worker started at 2022-11-26 13:14:44 +0000 UTC (1 container statuses recorded)
    Nov 26 13:14:53.547: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: false, restart count 0
    Nov 26 13:14:53.547: INFO: sonobuoy-systemd-logs-daemon-set-0c1a71445bc44dd1-hbpwv from sonobuoy started at 2022-11-26 11:58:24 +0000 UTC (2 container statuses recorded)
    Nov 26 13:14:53.547: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov 26 13:14:53.547: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 11/26/22 13:14:53.547
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.172b24bfeac35c55], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 11/26/22 13:14:53.587
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 13:14:54.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-2355" for this suite. 11/26/22 13:14:54.597
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:14:54.608
Nov 26 13:14:54.608: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 13:14:54.609
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:54.63
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:54.637
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 11/26/22 13:14:54.642
Nov 26 13:14:54.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 11/26/22 13:15:08.285
Nov 26 13:15:08.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 13:15:10.957: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 13:15:24.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5836" for this suite. 11/26/22 13:15:24.524
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":304,"skipped":5751,"failed":0}
------------------------------
â€¢ [SLOW TEST] [29.931 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:14:54.608
    Nov 26 13:14:54.608: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename crd-publish-openapi 11/26/22 13:14:54.609
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:14:54.63
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:14:54.637
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 11/26/22 13:14:54.642
    Nov 26 13:14:54.643: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 11/26/22 13:15:08.285
    Nov 26 13:15:08.286: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 13:15:10.957: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 13:15:24.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5836" for this suite. 11/26/22 13:15:24.524
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:15:24.55
Nov 26 13:15:24.551: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename watch 11/26/22 13:15:24.552
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:15:24.58
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:15:24.584
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 11/26/22 13:15:24.589
STEP: modifying the configmap once 11/26/22 13:15:24.598
STEP: modifying the configmap a second time 11/26/22 13:15:24.609
STEP: deleting the configmap 11/26/22 13:15:24.619
STEP: creating a watch on configmaps from the resource version returned by the first update 11/26/22 13:15:24.628
STEP: Expecting to observe notifications for all changes to the configmap after the first update 11/26/22 13:15:24.631
Nov 26 13:15:24.631: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8181  a60599e6-e267-4ec2-8a0d-8a8b1a46a376 34490 0 2022-11-26 13:15:24 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-26 13:15:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 13:15:24.631: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8181  a60599e6-e267-4ec2-8a0d-8a8b1a46a376 34491 0 2022-11-26 13:15:24 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-26 13:15:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 26 13:15:24.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8181" for this suite. 11/26/22 13:15:24.637
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":305,"skipped":5786,"failed":0}
------------------------------
â€¢ [0.096 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:15:24.55
    Nov 26 13:15:24.551: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename watch 11/26/22 13:15:24.552
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:15:24.58
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:15:24.584
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 11/26/22 13:15:24.589
    STEP: modifying the configmap once 11/26/22 13:15:24.598
    STEP: modifying the configmap a second time 11/26/22 13:15:24.609
    STEP: deleting the configmap 11/26/22 13:15:24.619
    STEP: creating a watch on configmaps from the resource version returned by the first update 11/26/22 13:15:24.628
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 11/26/22 13:15:24.631
    Nov 26 13:15:24.631: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8181  a60599e6-e267-4ec2-8a0d-8a8b1a46a376 34490 0 2022-11-26 13:15:24 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-26 13:15:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 13:15:24.631: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8181  a60599e6-e267-4ec2-8a0d-8a8b1a46a376 34491 0 2022-11-26 13:15:24 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-26 13:15:24 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 26 13:15:24.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8181" for this suite. 11/26/22 13:15:24.637
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:15:24.646
Nov 26 13:15:24.647: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replicaset 11/26/22 13:15:24.648
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:15:24.683
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:15:24.689
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Nov 26 13:15:24.713: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 26 13:15:29.719: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/26/22 13:15:29.719
STEP: Scaling up "test-rs" replicaset  11/26/22 13:15:29.719
Nov 26 13:15:29.736: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 11/26/22 13:15:29.736
W1126 13:15:29.749672      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov 26 13:15:29.751: INFO: observed ReplicaSet test-rs in namespace replicaset-57 with ReadyReplicas 1, AvailableReplicas 1
Nov 26 13:15:29.778: INFO: observed ReplicaSet test-rs in namespace replicaset-57 with ReadyReplicas 1, AvailableReplicas 1
Nov 26 13:15:29.800: INFO: observed ReplicaSet test-rs in namespace replicaset-57 with ReadyReplicas 1, AvailableReplicas 1
Nov 26 13:15:29.826: INFO: observed ReplicaSet test-rs in namespace replicaset-57 with ReadyReplicas 1, AvailableReplicas 1
Nov 26 13:15:31.431: INFO: observed ReplicaSet test-rs in namespace replicaset-57 with ReadyReplicas 2, AvailableReplicas 2
Nov 26 13:15:31.567: INFO: observed Replicaset test-rs in namespace replicaset-57 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 26 13:15:31.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-57" for this suite. 11/26/22 13:15:31.578
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":306,"skipped":5787,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.946 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:15:24.646
    Nov 26 13:15:24.647: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replicaset 11/26/22 13:15:24.648
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:15:24.683
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:15:24.689
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Nov 26 13:15:24.713: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov 26 13:15:29.719: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/26/22 13:15:29.719
    STEP: Scaling up "test-rs" replicaset  11/26/22 13:15:29.719
    Nov 26 13:15:29.736: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 11/26/22 13:15:29.736
    W1126 13:15:29.749672      19 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov 26 13:15:29.751: INFO: observed ReplicaSet test-rs in namespace replicaset-57 with ReadyReplicas 1, AvailableReplicas 1
    Nov 26 13:15:29.778: INFO: observed ReplicaSet test-rs in namespace replicaset-57 with ReadyReplicas 1, AvailableReplicas 1
    Nov 26 13:15:29.800: INFO: observed ReplicaSet test-rs in namespace replicaset-57 with ReadyReplicas 1, AvailableReplicas 1
    Nov 26 13:15:29.826: INFO: observed ReplicaSet test-rs in namespace replicaset-57 with ReadyReplicas 1, AvailableReplicas 1
    Nov 26 13:15:31.431: INFO: observed ReplicaSet test-rs in namespace replicaset-57 with ReadyReplicas 2, AvailableReplicas 2
    Nov 26 13:15:31.567: INFO: observed Replicaset test-rs in namespace replicaset-57 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 26 13:15:31.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-57" for this suite. 11/26/22 13:15:31.578
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:15:31.594
Nov 26 13:15:31.594: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename cronjob 11/26/22 13:15:31.595
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:15:31.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:15:31.636
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 11/26/22 13:15:31.646
STEP: Ensuring a job is scheduled 11/26/22 13:15:31.658
STEP: Ensuring exactly one is scheduled 11/26/22 13:16:01.663
STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/26/22 13:16:01.669
STEP: Ensuring the job is replaced with a new one 11/26/22 13:16:01.688
STEP: Removing cronjob 11/26/22 13:17:01.694
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 26 13:17:01.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6437" for this suite. 11/26/22 13:17:01.711
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":307,"skipped":5797,"failed":0}
------------------------------
â€¢ [SLOW TEST] [90.183 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:15:31.594
    Nov 26 13:15:31.594: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename cronjob 11/26/22 13:15:31.595
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:15:31.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:15:31.636
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 11/26/22 13:15:31.646
    STEP: Ensuring a job is scheduled 11/26/22 13:15:31.658
    STEP: Ensuring exactly one is scheduled 11/26/22 13:16:01.663
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/26/22 13:16:01.669
    STEP: Ensuring the job is replaced with a new one 11/26/22 13:16:01.688
    STEP: Removing cronjob 11/26/22 13:17:01.694
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 26 13:17:01.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6437" for this suite. 11/26/22 13:17:01.711
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:17:01.778
Nov 26 13:17:01.778: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 13:17:01.779
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:17:01.897
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:17:01.903
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 26 13:17:02.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1076" for this suite. 11/26/22 13:17:02.023
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":308,"skipped":5798,"failed":0}
------------------------------
â€¢ [0.254 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:17:01.778
    Nov 26 13:17:01.778: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 13:17:01.779
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:17:01.897
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:17:01.903
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 13:17:02.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1076" for this suite. 11/26/22 13:17:02.023
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:17:02.039
Nov 26 13:17:02.039: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 13:17:02.041
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:17:02.083
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:17:02.088
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 11/26/22 13:17:02.093
STEP: listing secrets in all namespaces to ensure that there are more than zero 11/26/22 13:17:02.101
STEP: patching the secret 11/26/22 13:17:02.108
STEP: deleting the secret using a LabelSelector 11/26/22 13:17:02.121
STEP: listing secrets in all namespaces, searching for label name and value in patch 11/26/22 13:17:02.134
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov 26 13:17:02.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5655" for this suite. 11/26/22 13:17:02.146
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":309,"skipped":5803,"failed":0}
------------------------------
â€¢ [0.118 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:17:02.039
    Nov 26 13:17:02.039: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 13:17:02.041
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:17:02.083
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:17:02.088
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 11/26/22 13:17:02.093
    STEP: listing secrets in all namespaces to ensure that there are more than zero 11/26/22 13:17:02.101
    STEP: patching the secret 11/26/22 13:17:02.108
    STEP: deleting the secret using a LabelSelector 11/26/22 13:17:02.121
    STEP: listing secrets in all namespaces, searching for label name and value in patch 11/26/22 13:17:02.134
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 13:17:02.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5655" for this suite. 11/26/22 13:17:02.146
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:17:02.159
Nov 26 13:17:02.160: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename cronjob 11/26/22 13:17:02.161
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:17:02.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:17:02.201
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 11/26/22 13:17:02.205
STEP: Ensuring a job is scheduled 11/26/22 13:17:02.218
STEP: Ensuring exactly one is scheduled 11/26/22 13:18:00.223
STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/26/22 13:18:00.228
STEP: Ensuring no more jobs are scheduled 11/26/22 13:18:00.234
STEP: Removing cronjob 11/26/22 13:23:00.244
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov 26 13:23:00.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5090" for this suite. 11/26/22 13:23:00.259
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":310,"skipped":5813,"failed":0}
------------------------------
â€¢ [SLOW TEST] [358.107 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:17:02.159
    Nov 26 13:17:02.160: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename cronjob 11/26/22 13:17:02.161
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:17:02.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:17:02.201
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 11/26/22 13:17:02.205
    STEP: Ensuring a job is scheduled 11/26/22 13:17:02.218
    STEP: Ensuring exactly one is scheduled 11/26/22 13:18:00.223
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/26/22 13:18:00.228
    STEP: Ensuring no more jobs are scheduled 11/26/22 13:18:00.234
    STEP: Removing cronjob 11/26/22 13:23:00.244
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov 26 13:23:00.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5090" for this suite. 11/26/22 13:23:00.259
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:23:00.268
Nov 26 13:23:00.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 13:23:00.269
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:00.296
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:00.318
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-2525/configmap-test-bc4989f7-5026-4d09-a5dd-c4fabb31c9fc 11/26/22 13:23:00.323
STEP: Creating a pod to test consume configMaps 11/26/22 13:23:00.337
Nov 26 13:23:00.359: INFO: Waiting up to 5m0s for pod "pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980" in namespace "configmap-2525" to be "Succeeded or Failed"
Nov 26 13:23:00.363: INFO: Pod "pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980": Phase="Pending", Reason="", readiness=false. Elapsed: 4.269023ms
Nov 26 13:23:02.368: INFO: Pod "pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009809027s
Nov 26 13:23:04.369: INFO: Pod "pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009951087s
STEP: Saw pod success 11/26/22 13:23:04.369
Nov 26 13:23:04.369: INFO: Pod "pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980" satisfied condition "Succeeded or Failed"
Nov 26 13:23:04.375: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980 container env-test: <nil>
STEP: delete the pod 11/26/22 13:23:04.405
Nov 26 13:23:04.419: INFO: Waiting for pod pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980 to disappear
Nov 26 13:23:04.423: INFO: Pod pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 13:23:04.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2525" for this suite. 11/26/22 13:23:04.429
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":311,"skipped":5838,"failed":0}
------------------------------
â€¢ [4.170 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:23:00.268
    Nov 26 13:23:00.268: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 13:23:00.269
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:00.296
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:00.318
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-2525/configmap-test-bc4989f7-5026-4d09-a5dd-c4fabb31c9fc 11/26/22 13:23:00.323
    STEP: Creating a pod to test consume configMaps 11/26/22 13:23:00.337
    Nov 26 13:23:00.359: INFO: Waiting up to 5m0s for pod "pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980" in namespace "configmap-2525" to be "Succeeded or Failed"
    Nov 26 13:23:00.363: INFO: Pod "pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980": Phase="Pending", Reason="", readiness=false. Elapsed: 4.269023ms
    Nov 26 13:23:02.368: INFO: Pod "pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009809027s
    Nov 26 13:23:04.369: INFO: Pod "pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009951087s
    STEP: Saw pod success 11/26/22 13:23:04.369
    Nov 26 13:23:04.369: INFO: Pod "pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980" satisfied condition "Succeeded or Failed"
    Nov 26 13:23:04.375: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980 container env-test: <nil>
    STEP: delete the pod 11/26/22 13:23:04.405
    Nov 26 13:23:04.419: INFO: Waiting for pod pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980 to disappear
    Nov 26 13:23:04.423: INFO: Pod pod-configmaps-29696a83-1469-4252-a8b2-196f0b6d6980 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 13:23:04.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2525" for this suite. 11/26/22 13:23:04.429
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:23:04.439
Nov 26 13:23:04.439: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 13:23:04.44
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:04.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:04.475
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 11/26/22 13:23:04.489
STEP: watching for Pod to be ready 11/26/22 13:23:04.503
Nov 26 13:23:04.506: INFO: observed Pod pod-test in namespace pods-564 in phase Pending with labels: map[test-pod-static:true] & conditions []
Nov 26 13:23:04.510: INFO: observed Pod pod-test in namespace pods-564 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC  }]
Nov 26 13:23:04.535: INFO: observed Pod pod-test in namespace pods-564 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC  }]
Nov 26 13:23:06.499: INFO: Found Pod pod-test in namespace pods-564 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 11/26/22 13:23:06.506
STEP: getting the Pod and ensuring that it's patched 11/26/22 13:23:06.52
STEP: replacing the Pod's status Ready condition to False 11/26/22 13:23:06.525
STEP: check the Pod again to ensure its Ready conditions are False 11/26/22 13:23:06.54
STEP: deleting the Pod via a Collection with a LabelSelector 11/26/22 13:23:06.54
STEP: watching for the Pod to be deleted 11/26/22 13:23:06.553
Nov 26 13:23:06.556: INFO: observed event type MODIFIED
Nov 26 13:23:08.504: INFO: observed event type MODIFIED
Nov 26 13:23:09.511: INFO: observed event type MODIFIED
Nov 26 13:23:09.531: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 26 13:23:09.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-564" for this suite. 11/26/22 13:23:09.552
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":312,"skipped":5842,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.124 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:23:04.439
    Nov 26 13:23:04.439: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 13:23:04.44
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:04.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:04.475
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 11/26/22 13:23:04.489
    STEP: watching for Pod to be ready 11/26/22 13:23:04.503
    Nov 26 13:23:04.506: INFO: observed Pod pod-test in namespace pods-564 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Nov 26 13:23:04.510: INFO: observed Pod pod-test in namespace pods-564 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC  }]
    Nov 26 13:23:04.535: INFO: observed Pod pod-test in namespace pods-564 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC  }]
    Nov 26 13:23:06.499: INFO: Found Pod pod-test in namespace pods-564 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:06 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:06 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-26 13:23:04 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 11/26/22 13:23:06.506
    STEP: getting the Pod and ensuring that it's patched 11/26/22 13:23:06.52
    STEP: replacing the Pod's status Ready condition to False 11/26/22 13:23:06.525
    STEP: check the Pod again to ensure its Ready conditions are False 11/26/22 13:23:06.54
    STEP: deleting the Pod via a Collection with a LabelSelector 11/26/22 13:23:06.54
    STEP: watching for the Pod to be deleted 11/26/22 13:23:06.553
    Nov 26 13:23:06.556: INFO: observed event type MODIFIED
    Nov 26 13:23:08.504: INFO: observed event type MODIFIED
    Nov 26 13:23:09.511: INFO: observed event type MODIFIED
    Nov 26 13:23:09.531: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 26 13:23:09.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-564" for this suite. 11/26/22 13:23:09.552
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:23:09.564
Nov 26 13:23:09.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 13:23:09.566
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:09.591
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:09.601
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-2476058e-7819-47d4-a123-b59f92a55881 11/26/22 13:23:09.614
STEP: Creating secret with name s-test-opt-upd-c2e282ac-ea63-4d2e-bfec-0bbd82135b01 11/26/22 13:23:09.622
STEP: Creating the pod 11/26/22 13:23:09.631
Nov 26 13:23:09.648: INFO: Waiting up to 5m0s for pod "pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d" in namespace "secrets-4595" to be "running and ready"
Nov 26 13:23:09.653: INFO: Pod "pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.039497ms
Nov 26 13:23:09.653: INFO: The phase of Pod pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:23:11.660: INFO: Pod "pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d": Phase="Running", Reason="", readiness=true. Elapsed: 2.011938578s
Nov 26 13:23:11.660: INFO: The phase of Pod pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d is Running (Ready = true)
Nov 26 13:23:11.660: INFO: Pod "pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-2476058e-7819-47d4-a123-b59f92a55881 11/26/22 13:23:11.696
STEP: Updating secret s-test-opt-upd-c2e282ac-ea63-4d2e-bfec-0bbd82135b01 11/26/22 13:23:11.707
STEP: Creating secret with name s-test-opt-create-500f4316-22f2-4be2-b834-df800cd8f63b 11/26/22 13:23:11.714
STEP: waiting to observe update in volume 11/26/22 13:23:11.721
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 26 13:23:15.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4595" for this suite. 11/26/22 13:23:15.78
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":313,"skipped":5846,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.228 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:23:09.564
    Nov 26 13:23:09.564: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 13:23:09.566
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:09.591
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:09.601
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-2476058e-7819-47d4-a123-b59f92a55881 11/26/22 13:23:09.614
    STEP: Creating secret with name s-test-opt-upd-c2e282ac-ea63-4d2e-bfec-0bbd82135b01 11/26/22 13:23:09.622
    STEP: Creating the pod 11/26/22 13:23:09.631
    Nov 26 13:23:09.648: INFO: Waiting up to 5m0s for pod "pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d" in namespace "secrets-4595" to be "running and ready"
    Nov 26 13:23:09.653: INFO: Pod "pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.039497ms
    Nov 26 13:23:09.653: INFO: The phase of Pod pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:23:11.660: INFO: Pod "pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d": Phase="Running", Reason="", readiness=true. Elapsed: 2.011938578s
    Nov 26 13:23:11.660: INFO: The phase of Pod pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d is Running (Ready = true)
    Nov 26 13:23:11.660: INFO: Pod "pod-secrets-aec45cc3-afbb-4894-8231-74474d33352d" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-2476058e-7819-47d4-a123-b59f92a55881 11/26/22 13:23:11.696
    STEP: Updating secret s-test-opt-upd-c2e282ac-ea63-4d2e-bfec-0bbd82135b01 11/26/22 13:23:11.707
    STEP: Creating secret with name s-test-opt-create-500f4316-22f2-4be2-b834-df800cd8f63b 11/26/22 13:23:11.714
    STEP: waiting to observe update in volume 11/26/22 13:23:11.721
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 13:23:15.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4595" for this suite. 11/26/22 13:23:15.78
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:23:15.798
Nov 26 13:23:15.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename gc 11/26/22 13:23:15.799
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:15.823
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:15.829
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 11/26/22 13:23:15.841
STEP: delete the rc 11/26/22 13:23:20.856
STEP: wait for the rc to be deleted 11/26/22 13:23:20.87
Nov 26 13:23:21.892: INFO: 80 pods remaining
Nov 26 13:23:21.892: INFO: 80 pods has nil DeletionTimestamp
Nov 26 13:23:21.892: INFO: 
Nov 26 13:23:22.886: INFO: 71 pods remaining
Nov 26 13:23:22.887: INFO: 71 pods has nil DeletionTimestamp
Nov 26 13:23:22.887: INFO: 
Nov 26 13:23:23.894: INFO: 60 pods remaining
Nov 26 13:23:23.894: INFO: 59 pods has nil DeletionTimestamp
Nov 26 13:23:23.894: INFO: 
Nov 26 13:23:24.885: INFO: 40 pods remaining
Nov 26 13:23:24.885: INFO: 40 pods has nil DeletionTimestamp
Nov 26 13:23:24.885: INFO: 
Nov 26 13:23:25.941: INFO: 33 pods remaining
Nov 26 13:23:25.941: INFO: 31 pods has nil DeletionTimestamp
Nov 26 13:23:25.941: INFO: 
Nov 26 13:23:26.891: INFO: 19 pods remaining
Nov 26 13:23:26.891: INFO: 19 pods has nil DeletionTimestamp
Nov 26 13:23:26.891: INFO: 
STEP: Gathering metrics 11/26/22 13:23:27.882
W1126 13:23:27.888171      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov 26 13:23:27.888: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov 26 13:23:27.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1749" for this suite. 11/26/22 13:23:27.894
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":314,"skipped":5888,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.110 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:23:15.798
    Nov 26 13:23:15.798: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename gc 11/26/22 13:23:15.799
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:15.823
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:15.829
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 11/26/22 13:23:15.841
    STEP: delete the rc 11/26/22 13:23:20.856
    STEP: wait for the rc to be deleted 11/26/22 13:23:20.87
    Nov 26 13:23:21.892: INFO: 80 pods remaining
    Nov 26 13:23:21.892: INFO: 80 pods has nil DeletionTimestamp
    Nov 26 13:23:21.892: INFO: 
    Nov 26 13:23:22.886: INFO: 71 pods remaining
    Nov 26 13:23:22.887: INFO: 71 pods has nil DeletionTimestamp
    Nov 26 13:23:22.887: INFO: 
    Nov 26 13:23:23.894: INFO: 60 pods remaining
    Nov 26 13:23:23.894: INFO: 59 pods has nil DeletionTimestamp
    Nov 26 13:23:23.894: INFO: 
    Nov 26 13:23:24.885: INFO: 40 pods remaining
    Nov 26 13:23:24.885: INFO: 40 pods has nil DeletionTimestamp
    Nov 26 13:23:24.885: INFO: 
    Nov 26 13:23:25.941: INFO: 33 pods remaining
    Nov 26 13:23:25.941: INFO: 31 pods has nil DeletionTimestamp
    Nov 26 13:23:25.941: INFO: 
    Nov 26 13:23:26.891: INFO: 19 pods remaining
    Nov 26 13:23:26.891: INFO: 19 pods has nil DeletionTimestamp
    Nov 26 13:23:26.891: INFO: 
    STEP: Gathering metrics 11/26/22 13:23:27.882
    W1126 13:23:27.888171      19 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov 26 13:23:27.888: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov 26 13:23:27.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1749" for this suite. 11/26/22 13:23:27.894
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:23:27.91
Nov 26 13:23:27.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename services 11/26/22 13:23:27.911
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:27.944
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:27.951
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 11/26/22 13:23:27.957
Nov 26 13:23:27.958: INFO: Creating e2e-svc-a-l544h
Nov 26 13:23:27.973: INFO: Creating e2e-svc-b-p27wx
Nov 26 13:23:27.991: INFO: Creating e2e-svc-c-64kdb
STEP: deleting service collection 11/26/22 13:23:28.021
Nov 26 13:23:28.088: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov 26 13:23:28.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9934" for this suite. 11/26/22 13:23:28.106
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":315,"skipped":5889,"failed":0}
------------------------------
â€¢ [0.211 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:23:27.91
    Nov 26 13:23:27.910: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename services 11/26/22 13:23:27.911
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:27.944
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:27.951
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 11/26/22 13:23:27.957
    Nov 26 13:23:27.958: INFO: Creating e2e-svc-a-l544h
    Nov 26 13:23:27.973: INFO: Creating e2e-svc-b-p27wx
    Nov 26 13:23:27.991: INFO: Creating e2e-svc-c-64kdb
    STEP: deleting service collection 11/26/22 13:23:28.021
    Nov 26 13:23:28.088: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov 26 13:23:28.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9934" for this suite. 11/26/22 13:23:28.106
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:23:28.121
Nov 26 13:23:28.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 13:23:28.122
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:28.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:28.16
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-53293bd5-16a4-4d17-88e4-c3ae2731b6dd 11/26/22 13:23:28.188
STEP: Creating configMap with name cm-test-opt-upd-b5af0976-2b98-43c3-92f0-2d47f68cb883 11/26/22 13:23:28.196
STEP: Creating the pod 11/26/22 13:23:28.206
Nov 26 13:23:28.233: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05" in namespace "configmap-384" to be "running and ready"
Nov 26 13:23:28.238: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 4.744357ms
Nov 26 13:23:28.238: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:23:30.271: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03747504s
Nov 26 13:23:30.271: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:23:32.245: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011984137s
Nov 26 13:23:32.246: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:23:34.248: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014580636s
Nov 26 13:23:34.248: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:23:36.245: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011235612s
Nov 26 13:23:36.245: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:23:38.245: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 10.011239407s
Nov 26 13:23:38.245: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:23:40.243: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 12.009991164s
Nov 26 13:23:40.244: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:23:42.244: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Running", Reason="", readiness=true. Elapsed: 14.010373845s
Nov 26 13:23:42.244: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Running (Ready = true)
Nov 26 13:23:42.244: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-53293bd5-16a4-4d17-88e4-c3ae2731b6dd 11/26/22 13:23:42.282
STEP: Updating configmap cm-test-opt-upd-b5af0976-2b98-43c3-92f0-2d47f68cb883 11/26/22 13:23:42.29
STEP: Creating configMap with name cm-test-opt-create-dfe9a8dc-a7ce-42c5-ba56-484a2aaf8e27 11/26/22 13:23:42.299
STEP: waiting to observe update in volume 11/26/22 13:23:42.306
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 13:25:02.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-384" for this suite. 11/26/22 13:25:02.808
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":316,"skipped":5896,"failed":0}
------------------------------
â€¢ [SLOW TEST] [94.697 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:23:28.121
    Nov 26 13:23:28.121: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 13:23:28.122
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:23:28.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:23:28.16
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-53293bd5-16a4-4d17-88e4-c3ae2731b6dd 11/26/22 13:23:28.188
    STEP: Creating configMap with name cm-test-opt-upd-b5af0976-2b98-43c3-92f0-2d47f68cb883 11/26/22 13:23:28.196
    STEP: Creating the pod 11/26/22 13:23:28.206
    Nov 26 13:23:28.233: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05" in namespace "configmap-384" to be "running and ready"
    Nov 26 13:23:28.238: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 4.744357ms
    Nov 26 13:23:28.238: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:23:30.271: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03747504s
    Nov 26 13:23:30.271: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:23:32.245: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011984137s
    Nov 26 13:23:32.246: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:23:34.248: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014580636s
    Nov 26 13:23:34.248: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:23:36.245: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011235612s
    Nov 26 13:23:36.245: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:23:38.245: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 10.011239407s
    Nov 26 13:23:38.245: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:23:40.243: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Pending", Reason="", readiness=false. Elapsed: 12.009991164s
    Nov 26 13:23:40.244: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:23:42.244: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05": Phase="Running", Reason="", readiness=true. Elapsed: 14.010373845s
    Nov 26 13:23:42.244: INFO: The phase of Pod pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05 is Running (Ready = true)
    Nov 26 13:23:42.244: INFO: Pod "pod-configmaps-d1f73d84-66fb-4cab-a396-9f73d594de05" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-53293bd5-16a4-4d17-88e4-c3ae2731b6dd 11/26/22 13:23:42.282
    STEP: Updating configmap cm-test-opt-upd-b5af0976-2b98-43c3-92f0-2d47f68cb883 11/26/22 13:23:42.29
    STEP: Creating configMap with name cm-test-opt-create-dfe9a8dc-a7ce-42c5-ba56-484a2aaf8e27 11/26/22 13:23:42.299
    STEP: waiting to observe update in volume 11/26/22 13:23:42.306
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 13:25:02.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-384" for this suite. 11/26/22 13:25:02.808
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:25:02.828
Nov 26 13:25:02.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 13:25:02.829
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:02.856
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:02.862
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 13:25:02.891
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 13:25:03.626
STEP: Deploying the webhook pod 11/26/22 13:25:03.638
STEP: Wait for the deployment to be ready 11/26/22 13:25:03.655
Nov 26 13:25:03.668: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/26/22 13:25:05.682
STEP: Verifying the service has paired with the endpoint 11/26/22 13:25:05.694
Nov 26 13:25:06.695: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 11/26/22 13:25:06.7
STEP: Updating a mutating webhook configuration's rules to not include the create operation 11/26/22 13:25:06.727
STEP: Creating a configMap that should not be mutated 11/26/22 13:25:06.736
STEP: Patching a mutating webhook configuration's rules to include the create operation 11/26/22 13:25:06.755
STEP: Creating a configMap that should be mutated 11/26/22 13:25:06.766
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 13:25:06.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2361" for this suite. 11/26/22 13:25:06.806
STEP: Destroying namespace "webhook-2361-markers" for this suite. 11/26/22 13:25:06.816
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":317,"skipped":5940,"failed":0}
------------------------------
â€¢ [4.051 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:25:02.828
    Nov 26 13:25:02.828: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 13:25:02.829
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:02.856
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:02.862
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 13:25:02.891
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 13:25:03.626
    STEP: Deploying the webhook pod 11/26/22 13:25:03.638
    STEP: Wait for the deployment to be ready 11/26/22 13:25:03.655
    Nov 26 13:25:03.668: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/26/22 13:25:05.682
    STEP: Verifying the service has paired with the endpoint 11/26/22 13:25:05.694
    Nov 26 13:25:06.695: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 11/26/22 13:25:06.7
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 11/26/22 13:25:06.727
    STEP: Creating a configMap that should not be mutated 11/26/22 13:25:06.736
    STEP: Patching a mutating webhook configuration's rules to include the create operation 11/26/22 13:25:06.755
    STEP: Creating a configMap that should be mutated 11/26/22 13:25:06.766
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 13:25:06.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2361" for this suite. 11/26/22 13:25:06.806
    STEP: Destroying namespace "webhook-2361-markers" for this suite. 11/26/22 13:25:06.816
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:25:06.881
Nov 26 13:25:06.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename podtemplate 11/26/22 13:25:06.882
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:06.91
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:06.914
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 11/26/22 13:25:06.92
STEP: Replace a pod template 11/26/22 13:25:06.928
Nov 26 13:25:06.942: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov 26 13:25:06.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-5762" for this suite. 11/26/22 13:25:06.947
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":318,"skipped":5947,"failed":0}
------------------------------
â€¢ [0.075 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:25:06.881
    Nov 26 13:25:06.881: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename podtemplate 11/26/22 13:25:06.882
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:06.91
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:06.914
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 11/26/22 13:25:06.92
    STEP: Replace a pod template 11/26/22 13:25:06.928
    Nov 26 13:25:06.942: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov 26 13:25:06.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-5762" for this suite. 11/26/22 13:25:06.947
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:25:06.956
Nov 26 13:25:06.956: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename watch 11/26/22 13:25:06.957
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:06.99
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:06.995
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 11/26/22 13:25:06.999
STEP: creating a new configmap 11/26/22 13:25:07.001
STEP: modifying the configmap once 11/26/22 13:25:07.009
STEP: closing the watch once it receives two notifications 11/26/22 13:25:07.02
Nov 26 13:25:07.020: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2561  83077c25-951a-4df6-ae6e-f6284127d992 37616 0 2022-11-26 13:25:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-26 13:25:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 13:25:07.021: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2561  83077c25-951a-4df6-ae6e-f6284127d992 37617 0 2022-11-26 13:25:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-26 13:25:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 11/26/22 13:25:07.021
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 11/26/22 13:25:07.033
STEP: deleting the configmap 11/26/22 13:25:07.036
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 11/26/22 13:25:07.044
Nov 26 13:25:07.044: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2561  83077c25-951a-4df6-ae6e-f6284127d992 37618 0 2022-11-26 13:25:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-26 13:25:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov 26 13:25:07.045: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2561  83077c25-951a-4df6-ae6e-f6284127d992 37619 0 2022-11-26 13:25:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-26 13:25:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov 26 13:25:07.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2561" for this suite. 11/26/22 13:25:07.05
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":319,"skipped":5947,"failed":0}
------------------------------
â€¢ [0.104 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:25:06.956
    Nov 26 13:25:06.956: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename watch 11/26/22 13:25:06.957
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:06.99
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:06.995
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 11/26/22 13:25:06.999
    STEP: creating a new configmap 11/26/22 13:25:07.001
    STEP: modifying the configmap once 11/26/22 13:25:07.009
    STEP: closing the watch once it receives two notifications 11/26/22 13:25:07.02
    Nov 26 13:25:07.020: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2561  83077c25-951a-4df6-ae6e-f6284127d992 37616 0 2022-11-26 13:25:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-26 13:25:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 13:25:07.021: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2561  83077c25-951a-4df6-ae6e-f6284127d992 37617 0 2022-11-26 13:25:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-26 13:25:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 11/26/22 13:25:07.021
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 11/26/22 13:25:07.033
    STEP: deleting the configmap 11/26/22 13:25:07.036
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 11/26/22 13:25:07.044
    Nov 26 13:25:07.044: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2561  83077c25-951a-4df6-ae6e-f6284127d992 37618 0 2022-11-26 13:25:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-26 13:25:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov 26 13:25:07.045: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2561  83077c25-951a-4df6-ae6e-f6284127d992 37619 0 2022-11-26 13:25:07 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-26 13:25:07 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov 26 13:25:07.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2561" for this suite. 11/26/22 13:25:07.05
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:25:07.066
Nov 26 13:25:07.066: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 13:25:07.067
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:07.091
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:07.095
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 11/26/22 13:25:07.114
Nov 26 13:25:07.128: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9" in namespace "projected-1146" to be "Succeeded or Failed"
Nov 26 13:25:07.134: INFO: Pod "downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.971592ms
Nov 26 13:25:09.142: INFO: Pod "downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013734861s
Nov 26 13:25:11.140: INFO: Pod "downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012286565s
STEP: Saw pod success 11/26/22 13:25:11.141
Nov 26 13:25:11.141: INFO: Pod "downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9" satisfied condition "Succeeded or Failed"
Nov 26 13:25:11.146: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9 container client-container: <nil>
STEP: delete the pod 11/26/22 13:25:11.155
Nov 26 13:25:11.179: INFO: Waiting for pod downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9 to disappear
Nov 26 13:25:11.186: INFO: Pod downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 13:25:11.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1146" for this suite. 11/26/22 13:25:11.194
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":320,"skipped":5966,"failed":0}
------------------------------
â€¢ [4.150 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:25:07.066
    Nov 26 13:25:07.066: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 13:25:07.067
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:07.091
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:07.095
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 11/26/22 13:25:07.114
    Nov 26 13:25:07.128: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9" in namespace "projected-1146" to be "Succeeded or Failed"
    Nov 26 13:25:07.134: INFO: Pod "downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9": Phase="Pending", Reason="", readiness=false. Elapsed: 5.971592ms
    Nov 26 13:25:09.142: INFO: Pod "downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013734861s
    Nov 26 13:25:11.140: INFO: Pod "downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012286565s
    STEP: Saw pod success 11/26/22 13:25:11.141
    Nov 26 13:25:11.141: INFO: Pod "downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9" satisfied condition "Succeeded or Failed"
    Nov 26 13:25:11.146: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9 container client-container: <nil>
    STEP: delete the pod 11/26/22 13:25:11.155
    Nov 26 13:25:11.179: INFO: Waiting for pod downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9 to disappear
    Nov 26 13:25:11.186: INFO: Pod downwardapi-volume-bd7cc7ed-95c3-44e2-b957-9a28881d6ed9 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 13:25:11.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1146" for this suite. 11/26/22 13:25:11.194
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:25:11.225
Nov 26 13:25:11.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename pods 11/26/22 13:25:11.226
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:11.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:11.261
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Nov 26 13:25:11.291: INFO: Waiting up to 5m0s for pod "server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2" in namespace "pods-6034" to be "running and ready"
Nov 26 13:25:11.297: INFO: Pod "server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.805372ms
Nov 26 13:25:11.297: INFO: The phase of Pod server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:25:13.303: INFO: Pod "server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011989646s
Nov 26 13:25:13.303: INFO: The phase of Pod server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2 is Running (Ready = true)
Nov 26 13:25:13.303: INFO: Pod "server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2" satisfied condition "running and ready"
Nov 26 13:25:13.330: INFO: Waiting up to 5m0s for pod "client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb" in namespace "pods-6034" to be "Succeeded or Failed"
Nov 26 13:25:13.340: INFO: Pod "client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.186247ms
Nov 26 13:25:15.348: INFO: Pod "client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017646744s
Nov 26 13:25:17.348: INFO: Pod "client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017850855s
STEP: Saw pod success 11/26/22 13:25:17.348
Nov 26 13:25:17.348: INFO: Pod "client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb" satisfied condition "Succeeded or Failed"
Nov 26 13:25:17.354: INFO: Trying to get logs from node ip-172-31-43-82 pod client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb container env3cont: <nil>
STEP: delete the pod 11/26/22 13:25:17.362
Nov 26 13:25:17.379: INFO: Waiting for pod client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb to disappear
Nov 26 13:25:17.384: INFO: Pod client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov 26 13:25:17.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6034" for this suite. 11/26/22 13:25:17.39
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":321,"skipped":6041,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.174 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:25:11.225
    Nov 26 13:25:11.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename pods 11/26/22 13:25:11.226
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:11.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:11.261
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Nov 26 13:25:11.291: INFO: Waiting up to 5m0s for pod "server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2" in namespace "pods-6034" to be "running and ready"
    Nov 26 13:25:11.297: INFO: Pod "server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.805372ms
    Nov 26 13:25:11.297: INFO: The phase of Pod server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:25:13.303: INFO: Pod "server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011989646s
    Nov 26 13:25:13.303: INFO: The phase of Pod server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2 is Running (Ready = true)
    Nov 26 13:25:13.303: INFO: Pod "server-envvars-f1848d1f-12ab-4a02-a819-45c33d8aacd2" satisfied condition "running and ready"
    Nov 26 13:25:13.330: INFO: Waiting up to 5m0s for pod "client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb" in namespace "pods-6034" to be "Succeeded or Failed"
    Nov 26 13:25:13.340: INFO: Pod "client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.186247ms
    Nov 26 13:25:15.348: INFO: Pod "client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017646744s
    Nov 26 13:25:17.348: INFO: Pod "client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017850855s
    STEP: Saw pod success 11/26/22 13:25:17.348
    Nov 26 13:25:17.348: INFO: Pod "client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb" satisfied condition "Succeeded or Failed"
    Nov 26 13:25:17.354: INFO: Trying to get logs from node ip-172-31-43-82 pod client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb container env3cont: <nil>
    STEP: delete the pod 11/26/22 13:25:17.362
    Nov 26 13:25:17.379: INFO: Waiting for pod client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb to disappear
    Nov 26 13:25:17.384: INFO: Pod client-envvars-18e6fdfa-6b46-44e4-a328-c1843ededfcb no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov 26 13:25:17.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6034" for this suite. 11/26/22 13:25:17.39
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:25:17.403
Nov 26 13:25:17.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename secrets 11/26/22 13:25:17.404
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:17.43
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:17.438
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-e4af0089-ac31-4b76-8b1e-292365148c1c 11/26/22 13:25:17.482
STEP: Creating a pod to test consume secrets 11/26/22 13:25:17.492
Nov 26 13:25:17.511: INFO: Waiting up to 5m0s for pod "pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5" in namespace "secrets-3059" to be "Succeeded or Failed"
Nov 26 13:25:17.518: INFO: Pod "pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168864ms
Nov 26 13:25:19.525: INFO: Pod "pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013263804s
Nov 26 13:25:21.531: INFO: Pod "pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019651712s
STEP: Saw pod success 11/26/22 13:25:21.531
Nov 26 13:25:21.532: INFO: Pod "pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5" satisfied condition "Succeeded or Failed"
Nov 26 13:25:21.537: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5 container secret-volume-test: <nil>
STEP: delete the pod 11/26/22 13:25:21.547
Nov 26 13:25:21.567: INFO: Waiting for pod pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5 to disappear
Nov 26 13:25:21.572: INFO: Pod pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov 26 13:25:21.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3059" for this suite. 11/26/22 13:25:21.579
STEP: Destroying namespace "secret-namespace-1284" for this suite. 11/26/22 13:25:21.59
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":322,"skipped":6053,"failed":0}
------------------------------
â€¢ [4.199 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:25:17.403
    Nov 26 13:25:17.403: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename secrets 11/26/22 13:25:17.404
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:17.43
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:17.438
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-e4af0089-ac31-4b76-8b1e-292365148c1c 11/26/22 13:25:17.482
    STEP: Creating a pod to test consume secrets 11/26/22 13:25:17.492
    Nov 26 13:25:17.511: INFO: Waiting up to 5m0s for pod "pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5" in namespace "secrets-3059" to be "Succeeded or Failed"
    Nov 26 13:25:17.518: INFO: Pod "pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.168864ms
    Nov 26 13:25:19.525: INFO: Pod "pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013263804s
    Nov 26 13:25:21.531: INFO: Pod "pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019651712s
    STEP: Saw pod success 11/26/22 13:25:21.531
    Nov 26 13:25:21.532: INFO: Pod "pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5" satisfied condition "Succeeded or Failed"
    Nov 26 13:25:21.537: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5 container secret-volume-test: <nil>
    STEP: delete the pod 11/26/22 13:25:21.547
    Nov 26 13:25:21.567: INFO: Waiting for pod pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5 to disappear
    Nov 26 13:25:21.572: INFO: Pod pod-secrets-77d49f91-a224-4b53-a3bb-c171c1764de5 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov 26 13:25:21.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3059" for this suite. 11/26/22 13:25:21.579
    STEP: Destroying namespace "secret-namespace-1284" for this suite. 11/26/22 13:25:21.59
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:25:21.606
Nov 26 13:25:21.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename security-context-test 11/26/22 13:25:21.607
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:21.633
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:21.638
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Nov 26 13:25:21.657: INFO: Waiting up to 5m0s for pod "busybox-user-65534-589887e0-37d9-4b72-a917-83a31511cfc7" in namespace "security-context-test-6423" to be "Succeeded or Failed"
Nov 26 13:25:21.662: INFO: Pod "busybox-user-65534-589887e0-37d9-4b72-a917-83a31511cfc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.900718ms
Nov 26 13:25:23.669: INFO: Pod "busybox-user-65534-589887e0-37d9-4b72-a917-83a31511cfc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011895637s
Nov 26 13:25:25.668: INFO: Pod "busybox-user-65534-589887e0-37d9-4b72-a917-83a31511cfc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010798164s
Nov 26 13:25:25.668: INFO: Pod "busybox-user-65534-589887e0-37d9-4b72-a917-83a31511cfc7" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 26 13:25:25.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6423" for this suite. 11/26/22 13:25:25.674
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":323,"skipped":6059,"failed":0}
------------------------------
â€¢ [4.079 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:25:21.606
    Nov 26 13:25:21.606: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename security-context-test 11/26/22 13:25:21.607
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:21.633
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:21.638
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Nov 26 13:25:21.657: INFO: Waiting up to 5m0s for pod "busybox-user-65534-589887e0-37d9-4b72-a917-83a31511cfc7" in namespace "security-context-test-6423" to be "Succeeded or Failed"
    Nov 26 13:25:21.662: INFO: Pod "busybox-user-65534-589887e0-37d9-4b72-a917-83a31511cfc7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.900718ms
    Nov 26 13:25:23.669: INFO: Pod "busybox-user-65534-589887e0-37d9-4b72-a917-83a31511cfc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011895637s
    Nov 26 13:25:25.668: INFO: Pod "busybox-user-65534-589887e0-37d9-4b72-a917-83a31511cfc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010798164s
    Nov 26 13:25:25.668: INFO: Pod "busybox-user-65534-589887e0-37d9-4b72-a917-83a31511cfc7" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 26 13:25:25.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-6423" for this suite. 11/26/22 13:25:25.674
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:25:25.687
Nov 26 13:25:25.687: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-runtime 11/26/22 13:25:25.688
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:25.717
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:25.724
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 11/26/22 13:25:25.741
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 11/26/22 13:25:43.864
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 11/26/22 13:25:43.869
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 11/26/22 13:25:43.878
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 11/26/22 13:25:43.879
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 11/26/22 13:25:43.918
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 11/26/22 13:25:46.944
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 11/26/22 13:25:48.959
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 11/26/22 13:25:48.969
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 11/26/22 13:25:48.97
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 11/26/22 13:25:48.996
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 11/26/22 13:25:50.014
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 11/26/22 13:25:53.04
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 11/26/22 13:25:53.051
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 11/26/22 13:25:53.051
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov 26 13:25:53.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1663" for this suite. 11/26/22 13:25:53.092
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":324,"skipped":6062,"failed":0}
------------------------------
â€¢ [SLOW TEST] [27.415 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:25:25.687
    Nov 26 13:25:25.687: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-runtime 11/26/22 13:25:25.688
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:25.717
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:25.724
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 11/26/22 13:25:25.741
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 11/26/22 13:25:43.864
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 11/26/22 13:25:43.869
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 11/26/22 13:25:43.878
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 11/26/22 13:25:43.879
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 11/26/22 13:25:43.918
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 11/26/22 13:25:46.944
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 11/26/22 13:25:48.959
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 11/26/22 13:25:48.969
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 11/26/22 13:25:48.97
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 11/26/22 13:25:48.996
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 11/26/22 13:25:50.014
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 11/26/22 13:25:53.04
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 11/26/22 13:25:53.051
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 11/26/22 13:25:53.051
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov 26 13:25:53.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1663" for this suite. 11/26/22 13:25:53.092
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:25:53.103
Nov 26 13:25:53.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename dns 11/26/22 13:25:53.104
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:53.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:53.138
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 11/26/22 13:25:53.143
Nov 26 13:25:53.156: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-4524  d60a941b-37d9-45ab-9923-c1a946337274 38021 0 2022-11-26 13:25:53 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-11-26 13:25:53 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-knbfm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-knbfm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 26 13:25:53.157: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-4524" to be "running and ready"
Nov 26 13:25:53.162: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 5.625685ms
Nov 26 13:25:53.162: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:25:55.168: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.011537573s
Nov 26 13:25:55.168: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Nov 26 13:25:55.168: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 11/26/22 13:25:55.168
Nov 26 13:25:55.168: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4524 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 13:25:55.168: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 13:25:55.169: INFO: ExecWithOptions: Clientset creation
Nov 26 13:25:55.169: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-4524/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 11/26/22 13:25:55.278
Nov 26 13:25:55.278: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4524 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 13:25:55.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 13:25:55.279: INFO: ExecWithOptions: Clientset creation
Nov 26 13:25:55.279: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-4524/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov 26 13:25:55.391: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 26 13:25:55.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4524" for this suite. 11/26/22 13:25:55.418
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":325,"skipped":6080,"failed":0}
------------------------------
â€¢ [2.326 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:25:53.103
    Nov 26 13:25:53.103: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename dns 11/26/22 13:25:53.104
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:53.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:53.138
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 11/26/22 13:25:53.143
    Nov 26 13:25:53.156: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-4524  d60a941b-37d9-45ab-9923-c1a946337274 38021 0 2022-11-26 13:25:53 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-11-26 13:25:53 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-knbfm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-knbfm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov 26 13:25:53.157: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-4524" to be "running and ready"
    Nov 26 13:25:53.162: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 5.625685ms
    Nov 26 13:25:53.162: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:25:55.168: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.011537573s
    Nov 26 13:25:55.168: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Nov 26 13:25:55.168: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 11/26/22 13:25:55.168
    Nov 26 13:25:55.168: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4524 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 13:25:55.168: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 13:25:55.169: INFO: ExecWithOptions: Clientset creation
    Nov 26 13:25:55.169: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-4524/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 11/26/22 13:25:55.278
    Nov 26 13:25:55.278: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4524 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 13:25:55.278: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 13:25:55.279: INFO: ExecWithOptions: Clientset creation
    Nov 26 13:25:55.279: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-4524/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov 26 13:25:55.391: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 26 13:25:55.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4524" for this suite. 11/26/22 13:25:55.418
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:25:55.43
Nov 26 13:25:55.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename proxy 11/26/22 13:25:55.433
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:55.461
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:55.466
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 11/26/22 13:25:55.49
STEP: creating replication controller proxy-service-cl28l in namespace proxy-9675 11/26/22 13:25:55.49
I1126 13:25:55.574242      19 runners.go:193] Created replication controller with name: proxy-service-cl28l, namespace: proxy-9675, replica count: 1
I1126 13:25:56.625756      19 runners.go:193] proxy-service-cl28l Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1126 13:25:57.626611      19 runners.go:193] proxy-service-cl28l Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 26 13:25:57.631: INFO: setup took 2.158966924s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 11/26/22 13:25:57.632
Nov 26 13:25:57.646: INFO: (0) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.773035ms)
Nov 26 13:25:57.648: INFO: (0) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 15.99362ms)
Nov 26 13:25:57.648: INFO: (0) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 15.998529ms)
Nov 26 13:25:57.649: INFO: (0) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 17.111037ms)
Nov 26 13:25:57.650: INFO: (0) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 17.8422ms)
Nov 26 13:25:57.651: INFO: (0) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 18.544975ms)
Nov 26 13:25:57.652: INFO: (0) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 19.673972ms)
Nov 26 13:25:57.655: INFO: (0) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 22.465889ms)
Nov 26 13:25:57.656: INFO: (0) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 23.324524ms)
Nov 26 13:25:57.656: INFO: (0) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 23.685256ms)
Nov 26 13:25:57.656: INFO: (0) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 23.119083ms)
Nov 26 13:25:57.660: INFO: (0) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 27.264369ms)
Nov 26 13:25:57.660: INFO: (0) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 27.55344ms)
Nov 26 13:25:57.666: INFO: (0) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 32.874434ms)
Nov 26 13:25:57.666: INFO: (0) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 32.726892ms)
Nov 26 13:25:57.666: INFO: (0) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 33.391476ms)
Nov 26 13:25:57.682: INFO: (1) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 14.744501ms)
Nov 26 13:25:57.685: INFO: (1) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 18.337364ms)
Nov 26 13:25:57.685: INFO: (1) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 18.589145ms)
Nov 26 13:25:57.685: INFO: (1) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 18.089333ms)
Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 26.050621ms)
Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 26.354103ms)
Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 25.951191ms)
Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 26.681555ms)
Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 26.315782ms)
Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 26.073742ms)
Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 26.608365ms)
Nov 26 13:25:57.699: INFO: (1) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 32.253639ms)
Nov 26 13:25:57.699: INFO: (1) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 31.684176ms)
Nov 26 13:25:57.699: INFO: (1) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 32.871893ms)
Nov 26 13:25:57.699: INFO: (1) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 32.905983ms)
Nov 26 13:25:57.700: INFO: (1) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 33.545517ms)
Nov 26 13:25:57.708: INFO: (2) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 7.732258ms)
Nov 26 13:25:57.710: INFO: (2) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 9.59402ms)
Nov 26 13:25:57.711: INFO: (2) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 10.686557ms)
Nov 26 13:25:57.712: INFO: (2) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 11.035628ms)
Nov 26 13:25:57.713: INFO: (2) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 12.386637ms)
Nov 26 13:25:57.714: INFO: (2) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 13.083851ms)
Nov 26 13:25:57.714: INFO: (2) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 12.775999ms)
Nov 26 13:25:57.715: INFO: (2) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.519034ms)
Nov 26 13:25:57.715: INFO: (2) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 13.765145ms)
Nov 26 13:25:57.719: INFO: (2) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 17.374547ms)
Nov 26 13:25:57.719: INFO: (2) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 17.88733ms)
Nov 26 13:25:57.719: INFO: (2) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 17.394147ms)
Nov 26 13:25:57.719: INFO: (2) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 17.875861ms)
Nov 26 13:25:57.719: INFO: (2) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 17.263987ms)
Nov 26 13:25:57.720: INFO: (2) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 18.047741ms)
Nov 26 13:25:57.720: INFO: (2) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 18.831017ms)
Nov 26 13:25:57.729: INFO: (3) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 8.13259ms)
Nov 26 13:25:57.731: INFO: (3) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 11.056648ms)
Nov 26 13:25:57.732: INFO: (3) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 10.959708ms)
Nov 26 13:25:57.734: INFO: (3) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 13.0535ms)
Nov 26 13:25:57.735: INFO: (3) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 13.382733ms)
Nov 26 13:25:57.735: INFO: (3) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 13.809705ms)
Nov 26 13:25:57.735: INFO: (3) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 14.701261ms)
Nov 26 13:25:57.736: INFO: (3) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 14.781451ms)
Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 18.373514ms)
Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 18.878996ms)
Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 18.583075ms)
Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 18.541654ms)
Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 18.824206ms)
Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 18.441954ms)
Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 18.266293ms)
Nov 26 13:25:57.748: INFO: (3) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 27.752952ms)
Nov 26 13:25:57.756: INFO: (4) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 8.163381ms)
Nov 26 13:25:57.757: INFO: (4) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 7.813518ms)
Nov 26 13:25:57.759: INFO: (4) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 10.189843ms)
Nov 26 13:25:57.760: INFO: (4) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 10.722216ms)
Nov 26 13:25:57.760: INFO: (4) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 10.475494ms)
Nov 26 13:25:57.764: INFO: (4) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 15.591396ms)
Nov 26 13:25:57.765: INFO: (4) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 16.25963ms)
Nov 26 13:25:57.765: INFO: (4) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 15.679356ms)
Nov 26 13:25:57.769: INFO: (4) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 19.721472ms)
Nov 26 13:25:57.769: INFO: (4) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 19.889363ms)
Nov 26 13:25:57.769: INFO: (4) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 19.563861ms)
Nov 26 13:25:57.769: INFO: (4) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 20.267715ms)
Nov 26 13:25:57.769: INFO: (4) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 20.453026ms)
Nov 26 13:25:57.770: INFO: (4) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 20.045404ms)
Nov 26 13:25:57.770: INFO: (4) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 21.258991ms)
Nov 26 13:25:57.781: INFO: (4) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 32.044398ms)
Nov 26 13:25:57.789: INFO: (5) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 7.907949ms)
Nov 26 13:25:57.791: INFO: (5) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 9.64561ms)
Nov 26 13:25:57.791: INFO: (5) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 9.409218ms)
Nov 26 13:25:57.793: INFO: (5) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 11.445361ms)
Nov 26 13:25:57.794: INFO: (5) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 11.563502ms)
Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 18.952107ms)
Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 18.592066ms)
Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 18.781386ms)
Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 18.751786ms)
Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 19.799072ms)
Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 19.978593ms)
Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 19.577832ms)
Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 19.700262ms)
Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 19.801043ms)
Nov 26 13:25:57.802: INFO: (5) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 19.36344ms)
Nov 26 13:25:57.802: INFO: (5) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 19.538021ms)
Nov 26 13:25:57.811: INFO: (6) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 7.936569ms)
Nov 26 13:25:57.811: INFO: (6) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 9.261157ms)
Nov 26 13:25:57.813: INFO: (6) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 10.050162ms)
Nov 26 13:25:57.815: INFO: (6) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 12.415006ms)
Nov 26 13:25:57.816: INFO: (6) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 9.907772ms)
Nov 26 13:25:57.817: INFO: (6) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 14.46929ms)
Nov 26 13:25:57.818: INFO: (6) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 14.68605ms)
Nov 26 13:25:57.818: INFO: (6) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 12.102375ms)
Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 21.04598ms)
Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 22.024936ms)
Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 20.666617ms)
Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 17.84336ms)
Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 18.051021ms)
Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 17.82284ms)
Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 17.978911ms)
Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 17.960321ms)
Nov 26 13:25:57.836: INFO: (7) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 11.742663ms)
Nov 26 13:25:57.837: INFO: (7) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 12.502828ms)
Nov 26 13:25:57.837: INFO: (7) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 12.84861ms)
Nov 26 13:25:57.838: INFO: (7) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.156442ms)
Nov 26 13:25:57.840: INFO: (7) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 14.951863ms)
Nov 26 13:25:57.841: INFO: (7) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 16.590403ms)
Nov 26 13:25:57.843: INFO: (7) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 18.276573ms)
Nov 26 13:25:57.843: INFO: (7) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 18.605196ms)
Nov 26 13:25:57.843: INFO: (7) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 18.198683ms)
Nov 26 13:25:57.843: INFO: (7) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 18.839057ms)
Nov 26 13:25:57.844: INFO: (7) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 19.029658ms)
Nov 26 13:25:57.844: INFO: (7) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 19.190849ms)
Nov 26 13:25:57.844: INFO: (7) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 18.886347ms)
Nov 26 13:25:57.844: INFO: (7) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 18.768296ms)
Nov 26 13:25:57.847: INFO: (7) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 22.992372ms)
Nov 26 13:25:57.847: INFO: (7) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 23.056953ms)
Nov 26 13:25:57.858: INFO: (8) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 10.316164ms)
Nov 26 13:25:57.860: INFO: (8) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 12.401187ms)
Nov 26 13:25:57.861: INFO: (8) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 13.098721ms)
Nov 26 13:25:57.861: INFO: (8) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 13.345813ms)
Nov 26 13:25:57.861: INFO: (8) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 13.296762ms)
Nov 26 13:25:57.862: INFO: (8) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.365142ms)
Nov 26 13:25:57.862: INFO: (8) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 14.358479ms)
Nov 26 13:25:57.863: INFO: (8) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 15.066283ms)
Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 20.481416ms)
Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 20.208615ms)
Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 20.308015ms)
Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 20.529347ms)
Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 20.394756ms)
Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 20.826149ms)
Nov 26 13:25:57.869: INFO: (8) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 20.513127ms)
Nov 26 13:25:57.870: INFO: (8) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 22.284847ms)
Nov 26 13:25:57.882: INFO: (9) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 11.262519ms)
Nov 26 13:25:57.885: INFO: (9) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 12.009114ms)
Nov 26 13:25:57.886: INFO: (9) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 14.464369ms)
Nov 26 13:25:57.886: INFO: (9) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 12.740369ms)
Nov 26 13:25:57.886: INFO: (9) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 13.383073ms)
Nov 26 13:25:57.889: INFO: (9) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 15.898209ms)
Nov 26 13:25:57.889: INFO: (9) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 15.591117ms)
Nov 26 13:25:57.889: INFO: (9) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 17.457328ms)
Nov 26 13:25:57.890: INFO: (9) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 16.834184ms)
Nov 26 13:25:57.890: INFO: (9) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 16.763243ms)
Nov 26 13:25:57.890: INFO: (9) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 17.027505ms)
Nov 26 13:25:57.895: INFO: (9) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 23.957887ms)
Nov 26 13:25:57.895: INFO: (9) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 22.208447ms)
Nov 26 13:25:57.895: INFO: (9) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 24.114669ms)
Nov 26 13:25:57.895: INFO: (9) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 22.157106ms)
Nov 26 13:25:57.895: INFO: (9) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 22.472919ms)
Nov 26 13:25:57.905: INFO: (10) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 9.949252ms)
Nov 26 13:25:57.908: INFO: (10) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 12.501328ms)
Nov 26 13:25:57.913: INFO: (10) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 16.415192ms)
Nov 26 13:25:57.914: INFO: (10) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 17.655609ms)
Nov 26 13:25:57.914: INFO: (10) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 18.314314ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 20.320616ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 20.020865ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 19.506291ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 19.583202ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 19.974064ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 19.787473ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 19.861573ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 20.301836ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 20.381056ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 20.542737ms)
Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 19.936203ms)
Nov 26 13:25:57.927: INFO: (11) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 10.625465ms)
Nov 26 13:25:57.927: INFO: (11) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 10.739006ms)
Nov 26 13:25:57.927: INFO: (11) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 10.611766ms)
Nov 26 13:25:57.928: INFO: (11) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 11.759882ms)
Nov 26 13:25:57.937: INFO: (11) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 20.253945ms)
Nov 26 13:25:57.937: INFO: (11) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 20.590498ms)
Nov 26 13:25:57.937: INFO: (11) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 20.564377ms)
Nov 26 13:25:57.937: INFO: (11) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 20.656577ms)
Nov 26 13:25:57.938: INFO: (11) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 20.98295ms)
Nov 26 13:25:57.938: INFO: (11) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 21.04112ms)
Nov 26 13:25:57.939: INFO: (11) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 21.865655ms)
Nov 26 13:25:57.940: INFO: (11) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 23.081483ms)
Nov 26 13:25:57.941: INFO: (11) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 24.12028ms)
Nov 26 13:25:57.941: INFO: (11) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 24.089399ms)
Nov 26 13:25:57.943: INFO: (11) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 25.611349ms)
Nov 26 13:25:57.943: INFO: (11) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 25.800569ms)
Nov 26 13:25:57.952: INFO: (12) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 9.446038ms)
Nov 26 13:25:57.953: INFO: (12) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 9.65227ms)
Nov 26 13:25:57.960: INFO: (12) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 17.502618ms)
Nov 26 13:25:57.963: INFO: (12) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 10.894728ms)
Nov 26 13:25:57.963: INFO: (12) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 10.667936ms)
Nov 26 13:25:57.964: INFO: (12) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.613114ms)
Nov 26 13:25:57.965: INFO: (12) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 13.257882ms)
Nov 26 13:25:57.966: INFO: (12) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 13.310822ms)
Nov 26 13:25:57.966: INFO: (12) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 13.216971ms)
Nov 26 13:25:57.966: INFO: (12) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 13.130711ms)
Nov 26 13:25:57.967: INFO: (12) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 14.58912ms)
Nov 26 13:25:57.978: INFO: (12) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 26.107932ms)
Nov 26 13:25:57.978: INFO: (12) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 25.612809ms)
Nov 26 13:25:57.978: INFO: (12) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 27.775212ms)
Nov 26 13:25:57.978: INFO: (12) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 34.648944ms)
Nov 26 13:25:57.978: INFO: (12) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 27.718012ms)
Nov 26 13:25:57.988: INFO: (13) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 9.031585ms)
Nov 26 13:25:57.989: INFO: (13) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 10.768197ms)
Nov 26 13:25:57.991: INFO: (13) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 12.173855ms)
Nov 26 13:25:57.993: INFO: (13) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 14.150067ms)
Nov 26 13:25:57.995: INFO: (13) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 16.106049ms)
Nov 26 13:25:57.995: INFO: (13) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 16.057539ms)
Nov 26 13:25:57.995: INFO: (13) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 16.007568ms)
Nov 26 13:25:57.995: INFO: (13) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 15.874028ms)
Nov 26 13:25:57.995: INFO: (13) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 15.961659ms)
Nov 26 13:25:57.997: INFO: (13) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 17.74799ms)
Nov 26 13:25:57.997: INFO: (13) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 18.004891ms)
Nov 26 13:25:57.997: INFO: (13) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 17.733629ms)
Nov 26 13:25:57.998: INFO: (13) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 18.454274ms)
Nov 26 13:25:57.998: INFO: (13) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 18.558035ms)
Nov 26 13:25:57.998: INFO: (13) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 18.897407ms)
Nov 26 13:25:57.998: INFO: (13) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 19.158168ms)
Nov 26 13:25:58.007: INFO: (14) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 9.279018ms)
Nov 26 13:25:58.008: INFO: (14) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 9.460618ms)
Nov 26 13:25:58.008: INFO: (14) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 9.6783ms)
Nov 26 13:25:58.009: INFO: (14) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 7.412566ms)
Nov 26 13:25:58.010: INFO: (14) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 11.238609ms)
Nov 26 13:25:58.011: INFO: (14) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 13.06154ms)
Nov 26 13:25:58.013: INFO: (14) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 15.350365ms)
Nov 26 13:25:58.014: INFO: (14) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 15.823418ms)
Nov 26 13:25:58.014: INFO: (14) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 16.07342ms)
Nov 26 13:25:58.014: INFO: (14) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 15.850438ms)
Nov 26 13:25:58.014: INFO: (14) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 15.893349ms)
Nov 26 13:25:58.015: INFO: (14) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 16.628243ms)
Nov 26 13:25:58.015: INFO: (14) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 13.397053ms)
Nov 26 13:25:58.015: INFO: (14) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 13.609305ms)
Nov 26 13:25:58.016: INFO: (14) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 17.417538ms)
Nov 26 13:25:58.016: INFO: (14) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 17.148456ms)
Nov 26 13:25:58.025: INFO: (15) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 9.272517ms)
Nov 26 13:25:58.026: INFO: (15) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 10.449405ms)
Nov 26 13:25:58.026: INFO: (15) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 10.733146ms)
Nov 26 13:25:58.029: INFO: (15) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 12.89338ms)
Nov 26 13:25:58.031: INFO: (15) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 14.50885ms)
Nov 26 13:25:58.031: INFO: (15) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 14.331669ms)
Nov 26 13:25:58.031: INFO: (15) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 14.113627ms)
Nov 26 13:25:58.031: INFO: (15) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 13.986047ms)
Nov 26 13:25:58.033: INFO: (15) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 15.764748ms)
Nov 26 13:25:58.033: INFO: (15) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 15.876629ms)
Nov 26 13:25:58.033: INFO: (15) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 15.613217ms)
Nov 26 13:25:58.035: INFO: (15) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 17.72116ms)
Nov 26 13:25:58.035: INFO: (15) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 17.359158ms)
Nov 26 13:25:58.035: INFO: (15) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 17.993161ms)
Nov 26 13:25:58.035: INFO: (15) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 18.051672ms)
Nov 26 13:25:58.036: INFO: (15) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 18.207494ms)
Nov 26 13:25:58.045: INFO: (16) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 9.063996ms)
Nov 26 13:25:58.045: INFO: (16) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 8.925265ms)
Nov 26 13:25:58.046: INFO: (16) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 8.311122ms)
Nov 26 13:25:58.050: INFO: (16) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 13.216472ms)
Nov 26 13:25:58.053: INFO: (16) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 15.470826ms)
Nov 26 13:25:58.053: INFO: (16) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 15.827388ms)
Nov 26 13:25:58.053: INFO: (16) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 15.625447ms)
Nov 26 13:25:58.054: INFO: (16) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 15.972449ms)
Nov 26 13:25:58.055: INFO: (16) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 17.053405ms)
Nov 26 13:25:58.055: INFO: (16) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 17.595809ms)
Nov 26 13:25:58.055: INFO: (16) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 17.201267ms)
Nov 26 13:25:58.055: INFO: (16) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 17.310758ms)
Nov 26 13:25:58.056: INFO: (16) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 17.999611ms)
Nov 26 13:25:58.056: INFO: (16) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 17.995032ms)
Nov 26 13:25:58.057: INFO: (16) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 19.016928ms)
Nov 26 13:25:58.057: INFO: (16) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 19.276519ms)
Nov 26 13:25:58.065: INFO: (17) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 8.084891ms)
Nov 26 13:25:58.080: INFO: (17) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 22.697321ms)
Nov 26 13:25:58.082: INFO: (17) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 24.764773ms)
Nov 26 13:25:58.082: INFO: (17) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 24.435781ms)
Nov 26 13:25:58.084: INFO: (17) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 26.614385ms)
Nov 26 13:25:58.084: INFO: (17) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 26.112222ms)
Nov 26 13:25:58.085: INFO: (17) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 26.611505ms)
Nov 26 13:25:58.085: INFO: (17) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 27.796473ms)
Nov 26 13:25:58.086: INFO: (17) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 28.126054ms)
Nov 26 13:25:58.086: INFO: (17) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 28.766378ms)
Nov 26 13:25:58.088: INFO: (17) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 30.69851ms)
Nov 26 13:25:58.089: INFO: (17) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 31.523326ms)
Nov 26 13:25:58.090: INFO: (17) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 31.669446ms)
Nov 26 13:25:58.090: INFO: (17) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 32.344671ms)
Nov 26 13:25:58.090: INFO: (17) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 33.177995ms)
Nov 26 13:25:58.091: INFO: (17) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 33.010455ms)
Nov 26 13:25:58.099: INFO: (18) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 7.540387ms)
Nov 26 13:25:58.101: INFO: (18) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 9.65331ms)
Nov 26 13:25:58.102: INFO: (18) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 9.887941ms)
Nov 26 13:25:58.102: INFO: (18) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 10.436394ms)
Nov 26 13:25:58.103: INFO: (18) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 11.760983ms)
Nov 26 13:25:58.105: INFO: (18) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 12.513308ms)
Nov 26 13:25:58.105: INFO: (18) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 13.562574ms)
Nov 26 13:25:58.106: INFO: (18) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 14.054377ms)
Nov 26 13:25:58.106: INFO: (18) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 14.42812ms)
Nov 26 13:25:58.106: INFO: (18) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 14.336669ms)
Nov 26 13:25:58.106: INFO: (18) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 14.57287ms)
Nov 26 13:25:58.107: INFO: (18) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 15.368546ms)
Nov 26 13:25:58.108: INFO: (18) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 15.657408ms)
Nov 26 13:25:58.108: INFO: (18) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 15.617347ms)
Nov 26 13:25:58.108: INFO: (18) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 15.700388ms)
Nov 26 13:25:58.108: INFO: (18) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 16.418292ms)
Nov 26 13:25:58.119: INFO: (19) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 10.394675ms)
Nov 26 13:25:58.120: INFO: (19) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 10.787087ms)
Nov 26 13:25:58.122: INFO: (19) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 12.824169ms)
Nov 26 13:25:58.122: INFO: (19) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.506944ms)
Nov 26 13:25:58.124: INFO: (19) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 14.607271ms)
Nov 26 13:25:58.124: INFO: (19) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 15.040744ms)
Nov 26 13:25:58.124: INFO: (19) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 15.013563ms)
Nov 26 13:25:58.126: INFO: (19) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 17.230007ms)
Nov 26 13:25:58.126: INFO: (19) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 18.032262ms)
Nov 26 13:25:58.126: INFO: (19) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 17.211197ms)
Nov 26 13:25:58.127: INFO: (19) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 17.586829ms)
Nov 26 13:25:58.127: INFO: (19) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 18.476975ms)
Nov 26 13:25:58.127: INFO: (19) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 18.263973ms)
Nov 26 13:25:58.128: INFO: (19) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 19.34468ms)
Nov 26 13:25:58.129: INFO: (19) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 19.832063ms)
Nov 26 13:25:58.129: INFO: (19) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 19.824093ms)
STEP: deleting ReplicationController proxy-service-cl28l in namespace proxy-9675, will wait for the garbage collector to delete the pods 11/26/22 13:25:58.129
Nov 26 13:25:58.202: INFO: Deleting ReplicationController proxy-service-cl28l took: 17.378467ms
Nov 26 13:25:58.303: INFO: Terminating ReplicationController proxy-service-cl28l pods took: 100.756875ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov 26 13:26:01.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9675" for this suite. 11/26/22 13:26:01.213
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":326,"skipped":6080,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.803 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:25:55.43
    Nov 26 13:25:55.431: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename proxy 11/26/22 13:25:55.433
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:25:55.461
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:25:55.466
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 11/26/22 13:25:55.49
    STEP: creating replication controller proxy-service-cl28l in namespace proxy-9675 11/26/22 13:25:55.49
    I1126 13:25:55.574242      19 runners.go:193] Created replication controller with name: proxy-service-cl28l, namespace: proxy-9675, replica count: 1
    I1126 13:25:56.625756      19 runners.go:193] proxy-service-cl28l Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1126 13:25:57.626611      19 runners.go:193] proxy-service-cl28l Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov 26 13:25:57.631: INFO: setup took 2.158966924s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 11/26/22 13:25:57.632
    Nov 26 13:25:57.646: INFO: (0) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.773035ms)
    Nov 26 13:25:57.648: INFO: (0) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 15.99362ms)
    Nov 26 13:25:57.648: INFO: (0) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 15.998529ms)
    Nov 26 13:25:57.649: INFO: (0) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 17.111037ms)
    Nov 26 13:25:57.650: INFO: (0) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 17.8422ms)
    Nov 26 13:25:57.651: INFO: (0) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 18.544975ms)
    Nov 26 13:25:57.652: INFO: (0) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 19.673972ms)
    Nov 26 13:25:57.655: INFO: (0) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 22.465889ms)
    Nov 26 13:25:57.656: INFO: (0) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 23.324524ms)
    Nov 26 13:25:57.656: INFO: (0) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 23.685256ms)
    Nov 26 13:25:57.656: INFO: (0) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 23.119083ms)
    Nov 26 13:25:57.660: INFO: (0) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 27.264369ms)
    Nov 26 13:25:57.660: INFO: (0) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 27.55344ms)
    Nov 26 13:25:57.666: INFO: (0) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 32.874434ms)
    Nov 26 13:25:57.666: INFO: (0) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 32.726892ms)
    Nov 26 13:25:57.666: INFO: (0) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 33.391476ms)
    Nov 26 13:25:57.682: INFO: (1) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 14.744501ms)
    Nov 26 13:25:57.685: INFO: (1) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 18.337364ms)
    Nov 26 13:25:57.685: INFO: (1) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 18.589145ms)
    Nov 26 13:25:57.685: INFO: (1) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 18.089333ms)
    Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 26.050621ms)
    Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 26.354103ms)
    Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 25.951191ms)
    Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 26.681555ms)
    Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 26.315782ms)
    Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 26.073742ms)
    Nov 26 13:25:57.693: INFO: (1) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 26.608365ms)
    Nov 26 13:25:57.699: INFO: (1) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 32.253639ms)
    Nov 26 13:25:57.699: INFO: (1) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 31.684176ms)
    Nov 26 13:25:57.699: INFO: (1) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 32.871893ms)
    Nov 26 13:25:57.699: INFO: (1) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 32.905983ms)
    Nov 26 13:25:57.700: INFO: (1) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 33.545517ms)
    Nov 26 13:25:57.708: INFO: (2) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 7.732258ms)
    Nov 26 13:25:57.710: INFO: (2) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 9.59402ms)
    Nov 26 13:25:57.711: INFO: (2) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 10.686557ms)
    Nov 26 13:25:57.712: INFO: (2) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 11.035628ms)
    Nov 26 13:25:57.713: INFO: (2) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 12.386637ms)
    Nov 26 13:25:57.714: INFO: (2) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 13.083851ms)
    Nov 26 13:25:57.714: INFO: (2) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 12.775999ms)
    Nov 26 13:25:57.715: INFO: (2) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.519034ms)
    Nov 26 13:25:57.715: INFO: (2) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 13.765145ms)
    Nov 26 13:25:57.719: INFO: (2) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 17.374547ms)
    Nov 26 13:25:57.719: INFO: (2) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 17.88733ms)
    Nov 26 13:25:57.719: INFO: (2) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 17.394147ms)
    Nov 26 13:25:57.719: INFO: (2) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 17.875861ms)
    Nov 26 13:25:57.719: INFO: (2) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 17.263987ms)
    Nov 26 13:25:57.720: INFO: (2) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 18.047741ms)
    Nov 26 13:25:57.720: INFO: (2) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 18.831017ms)
    Nov 26 13:25:57.729: INFO: (3) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 8.13259ms)
    Nov 26 13:25:57.731: INFO: (3) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 11.056648ms)
    Nov 26 13:25:57.732: INFO: (3) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 10.959708ms)
    Nov 26 13:25:57.734: INFO: (3) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 13.0535ms)
    Nov 26 13:25:57.735: INFO: (3) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 13.382733ms)
    Nov 26 13:25:57.735: INFO: (3) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 13.809705ms)
    Nov 26 13:25:57.735: INFO: (3) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 14.701261ms)
    Nov 26 13:25:57.736: INFO: (3) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 14.781451ms)
    Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 18.373514ms)
    Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 18.878996ms)
    Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 18.583075ms)
    Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 18.541654ms)
    Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 18.824206ms)
    Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 18.441954ms)
    Nov 26 13:25:57.740: INFO: (3) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 18.266293ms)
    Nov 26 13:25:57.748: INFO: (3) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 27.752952ms)
    Nov 26 13:25:57.756: INFO: (4) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 8.163381ms)
    Nov 26 13:25:57.757: INFO: (4) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 7.813518ms)
    Nov 26 13:25:57.759: INFO: (4) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 10.189843ms)
    Nov 26 13:25:57.760: INFO: (4) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 10.722216ms)
    Nov 26 13:25:57.760: INFO: (4) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 10.475494ms)
    Nov 26 13:25:57.764: INFO: (4) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 15.591396ms)
    Nov 26 13:25:57.765: INFO: (4) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 16.25963ms)
    Nov 26 13:25:57.765: INFO: (4) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 15.679356ms)
    Nov 26 13:25:57.769: INFO: (4) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 19.721472ms)
    Nov 26 13:25:57.769: INFO: (4) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 19.889363ms)
    Nov 26 13:25:57.769: INFO: (4) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 19.563861ms)
    Nov 26 13:25:57.769: INFO: (4) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 20.267715ms)
    Nov 26 13:25:57.769: INFO: (4) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 20.453026ms)
    Nov 26 13:25:57.770: INFO: (4) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 20.045404ms)
    Nov 26 13:25:57.770: INFO: (4) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 21.258991ms)
    Nov 26 13:25:57.781: INFO: (4) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 32.044398ms)
    Nov 26 13:25:57.789: INFO: (5) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 7.907949ms)
    Nov 26 13:25:57.791: INFO: (5) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 9.64561ms)
    Nov 26 13:25:57.791: INFO: (5) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 9.409218ms)
    Nov 26 13:25:57.793: INFO: (5) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 11.445361ms)
    Nov 26 13:25:57.794: INFO: (5) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 11.563502ms)
    Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 18.952107ms)
    Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 18.592066ms)
    Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 18.781386ms)
    Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 18.751786ms)
    Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 19.799072ms)
    Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 19.978593ms)
    Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 19.577832ms)
    Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 19.700262ms)
    Nov 26 13:25:57.801: INFO: (5) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 19.801043ms)
    Nov 26 13:25:57.802: INFO: (5) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 19.36344ms)
    Nov 26 13:25:57.802: INFO: (5) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 19.538021ms)
    Nov 26 13:25:57.811: INFO: (6) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 7.936569ms)
    Nov 26 13:25:57.811: INFO: (6) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 9.261157ms)
    Nov 26 13:25:57.813: INFO: (6) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 10.050162ms)
    Nov 26 13:25:57.815: INFO: (6) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 12.415006ms)
    Nov 26 13:25:57.816: INFO: (6) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 9.907772ms)
    Nov 26 13:25:57.817: INFO: (6) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 14.46929ms)
    Nov 26 13:25:57.818: INFO: (6) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 14.68605ms)
    Nov 26 13:25:57.818: INFO: (6) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 12.102375ms)
    Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 21.04598ms)
    Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 22.024936ms)
    Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 20.666617ms)
    Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 17.84336ms)
    Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 18.051021ms)
    Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 17.82284ms)
    Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 17.978911ms)
    Nov 26 13:25:57.824: INFO: (6) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 17.960321ms)
    Nov 26 13:25:57.836: INFO: (7) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 11.742663ms)
    Nov 26 13:25:57.837: INFO: (7) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 12.502828ms)
    Nov 26 13:25:57.837: INFO: (7) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 12.84861ms)
    Nov 26 13:25:57.838: INFO: (7) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.156442ms)
    Nov 26 13:25:57.840: INFO: (7) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 14.951863ms)
    Nov 26 13:25:57.841: INFO: (7) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 16.590403ms)
    Nov 26 13:25:57.843: INFO: (7) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 18.276573ms)
    Nov 26 13:25:57.843: INFO: (7) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 18.605196ms)
    Nov 26 13:25:57.843: INFO: (7) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 18.198683ms)
    Nov 26 13:25:57.843: INFO: (7) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 18.839057ms)
    Nov 26 13:25:57.844: INFO: (7) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 19.029658ms)
    Nov 26 13:25:57.844: INFO: (7) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 19.190849ms)
    Nov 26 13:25:57.844: INFO: (7) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 18.886347ms)
    Nov 26 13:25:57.844: INFO: (7) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 18.768296ms)
    Nov 26 13:25:57.847: INFO: (7) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 22.992372ms)
    Nov 26 13:25:57.847: INFO: (7) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 23.056953ms)
    Nov 26 13:25:57.858: INFO: (8) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 10.316164ms)
    Nov 26 13:25:57.860: INFO: (8) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 12.401187ms)
    Nov 26 13:25:57.861: INFO: (8) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 13.098721ms)
    Nov 26 13:25:57.861: INFO: (8) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 13.345813ms)
    Nov 26 13:25:57.861: INFO: (8) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 13.296762ms)
    Nov 26 13:25:57.862: INFO: (8) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.365142ms)
    Nov 26 13:25:57.862: INFO: (8) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 14.358479ms)
    Nov 26 13:25:57.863: INFO: (8) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 15.066283ms)
    Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 20.481416ms)
    Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 20.208615ms)
    Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 20.308015ms)
    Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 20.529347ms)
    Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 20.394756ms)
    Nov 26 13:25:57.868: INFO: (8) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 20.826149ms)
    Nov 26 13:25:57.869: INFO: (8) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 20.513127ms)
    Nov 26 13:25:57.870: INFO: (8) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 22.284847ms)
    Nov 26 13:25:57.882: INFO: (9) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 11.262519ms)
    Nov 26 13:25:57.885: INFO: (9) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 12.009114ms)
    Nov 26 13:25:57.886: INFO: (9) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 14.464369ms)
    Nov 26 13:25:57.886: INFO: (9) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 12.740369ms)
    Nov 26 13:25:57.886: INFO: (9) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 13.383073ms)
    Nov 26 13:25:57.889: INFO: (9) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 15.898209ms)
    Nov 26 13:25:57.889: INFO: (9) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 15.591117ms)
    Nov 26 13:25:57.889: INFO: (9) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 17.457328ms)
    Nov 26 13:25:57.890: INFO: (9) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 16.834184ms)
    Nov 26 13:25:57.890: INFO: (9) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 16.763243ms)
    Nov 26 13:25:57.890: INFO: (9) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 17.027505ms)
    Nov 26 13:25:57.895: INFO: (9) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 23.957887ms)
    Nov 26 13:25:57.895: INFO: (9) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 22.208447ms)
    Nov 26 13:25:57.895: INFO: (9) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 24.114669ms)
    Nov 26 13:25:57.895: INFO: (9) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 22.157106ms)
    Nov 26 13:25:57.895: INFO: (9) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 22.472919ms)
    Nov 26 13:25:57.905: INFO: (10) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 9.949252ms)
    Nov 26 13:25:57.908: INFO: (10) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 12.501328ms)
    Nov 26 13:25:57.913: INFO: (10) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 16.415192ms)
    Nov 26 13:25:57.914: INFO: (10) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 17.655609ms)
    Nov 26 13:25:57.914: INFO: (10) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 18.314314ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 20.320616ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 20.020865ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 19.506291ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 19.583202ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 19.974064ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 19.787473ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 19.861573ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 20.301836ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 20.381056ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 20.542737ms)
    Nov 26 13:25:57.916: INFO: (10) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 19.936203ms)
    Nov 26 13:25:57.927: INFO: (11) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 10.625465ms)
    Nov 26 13:25:57.927: INFO: (11) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 10.739006ms)
    Nov 26 13:25:57.927: INFO: (11) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 10.611766ms)
    Nov 26 13:25:57.928: INFO: (11) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 11.759882ms)
    Nov 26 13:25:57.937: INFO: (11) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 20.253945ms)
    Nov 26 13:25:57.937: INFO: (11) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 20.590498ms)
    Nov 26 13:25:57.937: INFO: (11) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 20.564377ms)
    Nov 26 13:25:57.937: INFO: (11) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 20.656577ms)
    Nov 26 13:25:57.938: INFO: (11) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 20.98295ms)
    Nov 26 13:25:57.938: INFO: (11) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 21.04112ms)
    Nov 26 13:25:57.939: INFO: (11) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 21.865655ms)
    Nov 26 13:25:57.940: INFO: (11) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 23.081483ms)
    Nov 26 13:25:57.941: INFO: (11) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 24.12028ms)
    Nov 26 13:25:57.941: INFO: (11) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 24.089399ms)
    Nov 26 13:25:57.943: INFO: (11) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 25.611349ms)
    Nov 26 13:25:57.943: INFO: (11) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 25.800569ms)
    Nov 26 13:25:57.952: INFO: (12) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 9.446038ms)
    Nov 26 13:25:57.953: INFO: (12) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 9.65227ms)
    Nov 26 13:25:57.960: INFO: (12) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 17.502618ms)
    Nov 26 13:25:57.963: INFO: (12) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 10.894728ms)
    Nov 26 13:25:57.963: INFO: (12) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 10.667936ms)
    Nov 26 13:25:57.964: INFO: (12) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.613114ms)
    Nov 26 13:25:57.965: INFO: (12) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 13.257882ms)
    Nov 26 13:25:57.966: INFO: (12) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 13.310822ms)
    Nov 26 13:25:57.966: INFO: (12) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 13.216971ms)
    Nov 26 13:25:57.966: INFO: (12) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 13.130711ms)
    Nov 26 13:25:57.967: INFO: (12) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 14.58912ms)
    Nov 26 13:25:57.978: INFO: (12) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 26.107932ms)
    Nov 26 13:25:57.978: INFO: (12) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 25.612809ms)
    Nov 26 13:25:57.978: INFO: (12) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 27.775212ms)
    Nov 26 13:25:57.978: INFO: (12) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 34.648944ms)
    Nov 26 13:25:57.978: INFO: (12) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 27.718012ms)
    Nov 26 13:25:57.988: INFO: (13) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 9.031585ms)
    Nov 26 13:25:57.989: INFO: (13) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 10.768197ms)
    Nov 26 13:25:57.991: INFO: (13) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 12.173855ms)
    Nov 26 13:25:57.993: INFO: (13) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 14.150067ms)
    Nov 26 13:25:57.995: INFO: (13) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 16.106049ms)
    Nov 26 13:25:57.995: INFO: (13) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 16.057539ms)
    Nov 26 13:25:57.995: INFO: (13) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 16.007568ms)
    Nov 26 13:25:57.995: INFO: (13) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 15.874028ms)
    Nov 26 13:25:57.995: INFO: (13) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 15.961659ms)
    Nov 26 13:25:57.997: INFO: (13) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 17.74799ms)
    Nov 26 13:25:57.997: INFO: (13) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 18.004891ms)
    Nov 26 13:25:57.997: INFO: (13) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 17.733629ms)
    Nov 26 13:25:57.998: INFO: (13) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 18.454274ms)
    Nov 26 13:25:57.998: INFO: (13) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 18.558035ms)
    Nov 26 13:25:57.998: INFO: (13) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 18.897407ms)
    Nov 26 13:25:57.998: INFO: (13) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 19.158168ms)
    Nov 26 13:25:58.007: INFO: (14) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 9.279018ms)
    Nov 26 13:25:58.008: INFO: (14) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 9.460618ms)
    Nov 26 13:25:58.008: INFO: (14) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 9.6783ms)
    Nov 26 13:25:58.009: INFO: (14) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 7.412566ms)
    Nov 26 13:25:58.010: INFO: (14) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 11.238609ms)
    Nov 26 13:25:58.011: INFO: (14) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 13.06154ms)
    Nov 26 13:25:58.013: INFO: (14) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 15.350365ms)
    Nov 26 13:25:58.014: INFO: (14) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 15.823418ms)
    Nov 26 13:25:58.014: INFO: (14) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 16.07342ms)
    Nov 26 13:25:58.014: INFO: (14) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 15.850438ms)
    Nov 26 13:25:58.014: INFO: (14) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 15.893349ms)
    Nov 26 13:25:58.015: INFO: (14) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 16.628243ms)
    Nov 26 13:25:58.015: INFO: (14) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 13.397053ms)
    Nov 26 13:25:58.015: INFO: (14) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 13.609305ms)
    Nov 26 13:25:58.016: INFO: (14) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 17.417538ms)
    Nov 26 13:25:58.016: INFO: (14) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 17.148456ms)
    Nov 26 13:25:58.025: INFO: (15) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 9.272517ms)
    Nov 26 13:25:58.026: INFO: (15) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 10.449405ms)
    Nov 26 13:25:58.026: INFO: (15) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 10.733146ms)
    Nov 26 13:25:58.029: INFO: (15) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 12.89338ms)
    Nov 26 13:25:58.031: INFO: (15) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 14.50885ms)
    Nov 26 13:25:58.031: INFO: (15) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 14.331669ms)
    Nov 26 13:25:58.031: INFO: (15) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 14.113627ms)
    Nov 26 13:25:58.031: INFO: (15) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 13.986047ms)
    Nov 26 13:25:58.033: INFO: (15) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 15.764748ms)
    Nov 26 13:25:58.033: INFO: (15) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 15.876629ms)
    Nov 26 13:25:58.033: INFO: (15) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 15.613217ms)
    Nov 26 13:25:58.035: INFO: (15) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 17.72116ms)
    Nov 26 13:25:58.035: INFO: (15) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 17.359158ms)
    Nov 26 13:25:58.035: INFO: (15) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 17.993161ms)
    Nov 26 13:25:58.035: INFO: (15) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 18.051672ms)
    Nov 26 13:25:58.036: INFO: (15) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 18.207494ms)
    Nov 26 13:25:58.045: INFO: (16) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 9.063996ms)
    Nov 26 13:25:58.045: INFO: (16) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 8.925265ms)
    Nov 26 13:25:58.046: INFO: (16) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 8.311122ms)
    Nov 26 13:25:58.050: INFO: (16) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 13.216472ms)
    Nov 26 13:25:58.053: INFO: (16) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 15.470826ms)
    Nov 26 13:25:58.053: INFO: (16) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 15.827388ms)
    Nov 26 13:25:58.053: INFO: (16) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 15.625447ms)
    Nov 26 13:25:58.054: INFO: (16) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 15.972449ms)
    Nov 26 13:25:58.055: INFO: (16) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 17.053405ms)
    Nov 26 13:25:58.055: INFO: (16) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 17.595809ms)
    Nov 26 13:25:58.055: INFO: (16) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 17.201267ms)
    Nov 26 13:25:58.055: INFO: (16) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 17.310758ms)
    Nov 26 13:25:58.056: INFO: (16) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 17.999611ms)
    Nov 26 13:25:58.056: INFO: (16) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 17.995032ms)
    Nov 26 13:25:58.057: INFO: (16) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 19.016928ms)
    Nov 26 13:25:58.057: INFO: (16) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 19.276519ms)
    Nov 26 13:25:58.065: INFO: (17) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 8.084891ms)
    Nov 26 13:25:58.080: INFO: (17) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 22.697321ms)
    Nov 26 13:25:58.082: INFO: (17) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 24.764773ms)
    Nov 26 13:25:58.082: INFO: (17) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 24.435781ms)
    Nov 26 13:25:58.084: INFO: (17) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 26.614385ms)
    Nov 26 13:25:58.084: INFO: (17) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 26.112222ms)
    Nov 26 13:25:58.085: INFO: (17) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 26.611505ms)
    Nov 26 13:25:58.085: INFO: (17) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 27.796473ms)
    Nov 26 13:25:58.086: INFO: (17) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 28.126054ms)
    Nov 26 13:25:58.086: INFO: (17) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 28.766378ms)
    Nov 26 13:25:58.088: INFO: (17) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 30.69851ms)
    Nov 26 13:25:58.089: INFO: (17) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 31.523326ms)
    Nov 26 13:25:58.090: INFO: (17) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 31.669446ms)
    Nov 26 13:25:58.090: INFO: (17) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 32.344671ms)
    Nov 26 13:25:58.090: INFO: (17) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 33.177995ms)
    Nov 26 13:25:58.091: INFO: (17) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 33.010455ms)
    Nov 26 13:25:58.099: INFO: (18) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 7.540387ms)
    Nov 26 13:25:58.101: INFO: (18) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 9.65331ms)
    Nov 26 13:25:58.102: INFO: (18) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 9.887941ms)
    Nov 26 13:25:58.102: INFO: (18) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 10.436394ms)
    Nov 26 13:25:58.103: INFO: (18) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 11.760983ms)
    Nov 26 13:25:58.105: INFO: (18) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 12.513308ms)
    Nov 26 13:25:58.105: INFO: (18) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 13.562574ms)
    Nov 26 13:25:58.106: INFO: (18) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 14.054377ms)
    Nov 26 13:25:58.106: INFO: (18) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 14.42812ms)
    Nov 26 13:25:58.106: INFO: (18) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 14.336669ms)
    Nov 26 13:25:58.106: INFO: (18) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 14.57287ms)
    Nov 26 13:25:58.107: INFO: (18) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 15.368546ms)
    Nov 26 13:25:58.108: INFO: (18) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 15.657408ms)
    Nov 26 13:25:58.108: INFO: (18) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 15.617347ms)
    Nov 26 13:25:58.108: INFO: (18) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 15.700388ms)
    Nov 26 13:25:58.108: INFO: (18) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 16.418292ms)
    Nov 26 13:25:58.119: INFO: (19) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66/proxy/rewriteme">test</a> (200; 10.394675ms)
    Nov 26 13:25:58.120: INFO: (19) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:1080/proxy/rewriteme">... (200; 10.787087ms)
    Nov 26 13:25:58.122: INFO: (19) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:162/proxy/: bar (200; 12.824169ms)
    Nov 26 13:25:58.122: INFO: (19) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:162/proxy/: bar (200; 13.506944ms)
    Nov 26 13:25:58.124: INFO: (19) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname2/proxy/: tls qux (200; 14.607271ms)
    Nov 26 13:25:58.124: INFO: (19) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:1080/proxy/rewriteme">test<... (200; 15.040744ms)
    Nov 26 13:25:58.124: INFO: (19) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:460/proxy/: tls baz (200; 15.013563ms)
    Nov 26 13:25:58.126: INFO: (19) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname1/proxy/: foo (200; 17.230007ms)
    Nov 26 13:25:58.126: INFO: (19) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname1/proxy/: foo (200; 18.032262ms)
    Nov 26 13:25:58.126: INFO: (19) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/: <a href="/api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:443/proxy/tlsrewritem... (200; 17.211197ms)
    Nov 26 13:25:58.127: INFO: (19) /api/v1/namespaces/proxy-9675/pods/https:proxy-service-cl28l-psf66:462/proxy/: tls qux (200; 17.586829ms)
    Nov 26 13:25:58.127: INFO: (19) /api/v1/namespaces/proxy-9675/services/http:proxy-service-cl28l:portname2/proxy/: bar (200; 18.476975ms)
    Nov 26 13:25:58.127: INFO: (19) /api/v1/namespaces/proxy-9675/pods/http:proxy-service-cl28l-psf66:160/proxy/: foo (200; 18.263973ms)
    Nov 26 13:25:58.128: INFO: (19) /api/v1/namespaces/proxy-9675/pods/proxy-service-cl28l-psf66:160/proxy/: foo (200; 19.34468ms)
    Nov 26 13:25:58.129: INFO: (19) /api/v1/namespaces/proxy-9675/services/https:proxy-service-cl28l:tlsportname1/proxy/: tls baz (200; 19.832063ms)
    Nov 26 13:25:58.129: INFO: (19) /api/v1/namespaces/proxy-9675/services/proxy-service-cl28l:portname2/proxy/: bar (200; 19.824093ms)
    STEP: deleting ReplicationController proxy-service-cl28l in namespace proxy-9675, will wait for the garbage collector to delete the pods 11/26/22 13:25:58.129
    Nov 26 13:25:58.202: INFO: Deleting ReplicationController proxy-service-cl28l took: 17.378467ms
    Nov 26 13:25:58.303: INFO: Terminating ReplicationController proxy-service-cl28l pods took: 100.756875ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov 26 13:26:01.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-9675" for this suite. 11/26/22 13:26:01.213
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:26:01.233
Nov 26 13:26:01.233: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 13:26:01.234
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:01.266
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:01.27
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 11/26/22 13:26:01.287
Nov 26 13:26:01.300: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572" in namespace "downward-api-4181" to be "Succeeded or Failed"
Nov 26 13:26:01.306: INFO: Pod "downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572": Phase="Pending", Reason="", readiness=false. Elapsed: 5.936127ms
Nov 26 13:26:03.314: INFO: Pod "downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014058119s
Nov 26 13:26:05.312: INFO: Pod "downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011783524s
STEP: Saw pod success 11/26/22 13:26:05.312
Nov 26 13:26:05.312: INFO: Pod "downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572" satisfied condition "Succeeded or Failed"
Nov 26 13:26:05.317: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572 container client-container: <nil>
STEP: delete the pod 11/26/22 13:26:05.33
Nov 26 13:26:05.352: INFO: Waiting for pod downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572 to disappear
Nov 26 13:26:05.358: INFO: Pod downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 13:26:05.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4181" for this suite. 11/26/22 13:26:05.365
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":327,"skipped":6081,"failed":0}
------------------------------
â€¢ [4.140 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:26:01.233
    Nov 26 13:26:01.233: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 13:26:01.234
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:01.266
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:01.27
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 11/26/22 13:26:01.287
    Nov 26 13:26:01.300: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572" in namespace "downward-api-4181" to be "Succeeded or Failed"
    Nov 26 13:26:01.306: INFO: Pod "downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572": Phase="Pending", Reason="", readiness=false. Elapsed: 5.936127ms
    Nov 26 13:26:03.314: INFO: Pod "downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014058119s
    Nov 26 13:26:05.312: INFO: Pod "downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011783524s
    STEP: Saw pod success 11/26/22 13:26:05.312
    Nov 26 13:26:05.312: INFO: Pod "downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572" satisfied condition "Succeeded or Failed"
    Nov 26 13:26:05.317: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572 container client-container: <nil>
    STEP: delete the pod 11/26/22 13:26:05.33
    Nov 26 13:26:05.352: INFO: Waiting for pod downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572 to disappear
    Nov 26 13:26:05.358: INFO: Pod downwardapi-volume-e7370562-23cc-4f83-9d8b-afe2c24ee572 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 13:26:05.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4181" for this suite. 11/26/22 13:26:05.365
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:26:05.376
Nov 26 13:26:05.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename aggregator 11/26/22 13:26:05.377
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:05.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:05.41
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Nov 26 13:26:05.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 11/26/22 13:26:05.417
Nov 26 13:26:06.064: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov 26 13:26:08.146: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:10.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:12.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:14.155: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:16.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:18.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:20.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:22.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:24.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:26.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:28.154: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 26 13:26:30.310: INFO: Waited 142.905801ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 11/26/22 13:26:30.389
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 11/26/22 13:26:30.395
STEP: List APIServices 11/26/22 13:26:30.407
Nov 26 13:26:30.414: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Nov 26 13:26:30.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4605" for this suite. 11/26/22 13:26:30.635
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":328,"skipped":6089,"failed":0}
------------------------------
â€¢ [SLOW TEST] [25.273 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:26:05.376
    Nov 26 13:26:05.376: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename aggregator 11/26/22 13:26:05.377
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:05.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:05.41
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Nov 26 13:26:05.416: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 11/26/22 13:26:05.417
    Nov 26 13:26:06.064: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Nov 26 13:26:08.146: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:10.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:12.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:14.155: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:16.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:18.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:20.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:22.152: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:24.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:26.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:28.154: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 26, 6, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-b5b45d9d4\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov 26 13:26:30.310: INFO: Waited 142.905801ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 11/26/22 13:26:30.389
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 11/26/22 13:26:30.395
    STEP: List APIServices 11/26/22 13:26:30.407
    Nov 26 13:26:30.414: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Nov 26 13:26:30.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-4605" for this suite. 11/26/22 13:26:30.635
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:26:30.651
Nov 26 13:26:30.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 13:26:30.652
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:30.688
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:30.693
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-dd890679-7219-4edd-be4e-55206c203e3b 11/26/22 13:26:30.705
STEP: Creating the pod 11/26/22 13:26:30.719
Nov 26 13:26:30.744: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b" in namespace "projected-1224" to be "running and ready"
Nov 26 13:26:30.749: INFO: Pod "pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.54949ms
Nov 26 13:26:30.749: INFO: The phase of Pod pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:26:32.755: INFO: Pod "pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b": Phase="Running", Reason="", readiness=true. Elapsed: 2.010645534s
Nov 26 13:26:32.755: INFO: The phase of Pod pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b is Running (Ready = true)
Nov 26 13:26:32.755: INFO: Pod "pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-dd890679-7219-4edd-be4e-55206c203e3b 11/26/22 13:26:32.769
STEP: waiting to observe update in volume 11/26/22 13:26:32.776
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov 26 13:26:34.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1224" for this suite. 11/26/22 13:26:34.802
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":329,"skipped":6111,"failed":0}
------------------------------
â€¢ [4.169 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:26:30.651
    Nov 26 13:26:30.651: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 13:26:30.652
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:30.688
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:30.693
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-dd890679-7219-4edd-be4e-55206c203e3b 11/26/22 13:26:30.705
    STEP: Creating the pod 11/26/22 13:26:30.719
    Nov 26 13:26:30.744: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b" in namespace "projected-1224" to be "running and ready"
    Nov 26 13:26:30.749: INFO: Pod "pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.54949ms
    Nov 26 13:26:30.749: INFO: The phase of Pod pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:26:32.755: INFO: Pod "pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b": Phase="Running", Reason="", readiness=true. Elapsed: 2.010645534s
    Nov 26 13:26:32.755: INFO: The phase of Pod pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b is Running (Ready = true)
    Nov 26 13:26:32.755: INFO: Pod "pod-projected-configmaps-14b85044-54dc-4d83-b64b-e45250cf9a9b" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-dd890679-7219-4edd-be4e-55206c203e3b 11/26/22 13:26:32.769
    STEP: waiting to observe update in volume 11/26/22 13:26:32.776
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov 26 13:26:34.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1224" for this suite. 11/26/22 13:26:34.802
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:26:34.82
Nov 26 13:26:34.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 13:26:34.821
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:34.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:34.854
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 11/26/22 13:26:34.861
Nov 26 13:26:34.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f" in namespace "projected-8111" to be "Succeeded or Failed"
Nov 26 13:26:34.885: INFO: Pod "downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.716614ms
Nov 26 13:26:36.891: INFO: Pod "downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012967774s
Nov 26 13:26:38.893: INFO: Pod "downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014580596s
STEP: Saw pod success 11/26/22 13:26:38.893
Nov 26 13:26:38.893: INFO: Pod "downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f" satisfied condition "Succeeded or Failed"
Nov 26 13:26:38.898: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f container client-container: <nil>
STEP: delete the pod 11/26/22 13:26:38.909
Nov 26 13:26:38.927: INFO: Waiting for pod downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f to disappear
Nov 26 13:26:38.932: INFO: Pod downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov 26 13:26:38.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8111" for this suite. 11/26/22 13:26:38.938
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":330,"skipped":6120,"failed":0}
------------------------------
â€¢ [4.129 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:26:34.82
    Nov 26 13:26:34.820: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 13:26:34.821
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:34.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:34.854
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 11/26/22 13:26:34.861
    Nov 26 13:26:34.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f" in namespace "projected-8111" to be "Succeeded or Failed"
    Nov 26 13:26:34.885: INFO: Pod "downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.716614ms
    Nov 26 13:26:36.891: INFO: Pod "downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012967774s
    Nov 26 13:26:38.893: INFO: Pod "downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014580596s
    STEP: Saw pod success 11/26/22 13:26:38.893
    Nov 26 13:26:38.893: INFO: Pod "downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f" satisfied condition "Succeeded or Failed"
    Nov 26 13:26:38.898: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f container client-container: <nil>
    STEP: delete the pod 11/26/22 13:26:38.909
    Nov 26 13:26:38.927: INFO: Waiting for pod downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f to disappear
    Nov 26 13:26:38.932: INFO: Pod downwardapi-volume-5af89e9f-15d8-468b-9fd6-a0f1860e266f no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov 26 13:26:38.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8111" for this suite. 11/26/22 13:26:38.938
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:26:38.951
Nov 26 13:26:38.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 13:26:38.953
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:38.983
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:38.987
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 11/26/22 13:26:38.992
STEP: Creating a ResourceQuota 11/26/22 13:26:43.998
STEP: Ensuring resource quota status is calculated 11/26/22 13:26:44.006
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 13:26:46.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7437" for this suite. 11/26/22 13:26:46.018
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":331,"skipped":6132,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.076 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:26:38.951
    Nov 26 13:26:38.951: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 13:26:38.953
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:38.983
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:38.987
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 11/26/22 13:26:38.992
    STEP: Creating a ResourceQuota 11/26/22 13:26:43.998
    STEP: Ensuring resource quota status is calculated 11/26/22 13:26:44.006
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 13:26:46.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7437" for this suite. 11/26/22 13:26:46.018
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:26:46.029
Nov 26 13:26:46.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 13:26:46.03
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:46.057
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:46.064
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 11/26/22 13:26:46.068
STEP: Getting a ResourceQuota 11/26/22 13:26:46.076
STEP: Listing all ResourceQuotas with LabelSelector 11/26/22 13:26:46.08
STEP: Patching the ResourceQuota 11/26/22 13:26:46.086
STEP: Deleting a Collection of ResourceQuotas 11/26/22 13:26:46.095
STEP: Verifying the deleted ResourceQuota 11/26/22 13:26:46.112
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 13:26:46.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6519" for this suite. 11/26/22 13:26:46.122
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":332,"skipped":6150,"failed":0}
------------------------------
â€¢ [0.107 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:26:46.029
    Nov 26 13:26:46.029: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 13:26:46.03
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:46.057
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:46.064
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 11/26/22 13:26:46.068
    STEP: Getting a ResourceQuota 11/26/22 13:26:46.076
    STEP: Listing all ResourceQuotas with LabelSelector 11/26/22 13:26:46.08
    STEP: Patching the ResourceQuota 11/26/22 13:26:46.086
    STEP: Deleting a Collection of ResourceQuotas 11/26/22 13:26:46.095
    STEP: Verifying the deleted ResourceQuota 11/26/22 13:26:46.112
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 13:26:46.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6519" for this suite. 11/26/22 13:26:46.122
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:26:46.141
Nov 26 13:26:46.142: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 13:26:46.143
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:46.18
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:46.185
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 11/26/22 13:26:46.19
Nov 26 13:26:46.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 create -f -'
Nov 26 13:26:47.431: INFO: stderr: ""
Nov 26 13:26:47.431: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/26/22 13:26:47.431
Nov 26 13:26:47.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 26 13:26:47.536: INFO: stderr: ""
Nov 26 13:26:47.536: INFO: stdout: "update-demo-nautilus-gx4jn update-demo-nautilus-jch9h "
Nov 26 13:26:47.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-gx4jn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 13:26:47.622: INFO: stderr: ""
Nov 26 13:26:47.622: INFO: stdout: ""
Nov 26 13:26:47.622: INFO: update-demo-nautilus-gx4jn is created but not running
Nov 26 13:26:52.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 26 13:26:52.731: INFO: stderr: ""
Nov 26 13:26:52.731: INFO: stdout: "update-demo-nautilus-gx4jn update-demo-nautilus-jch9h "
Nov 26 13:26:52.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-gx4jn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 13:26:52.827: INFO: stderr: ""
Nov 26 13:26:52.827: INFO: stdout: "true"
Nov 26 13:26:52.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-gx4jn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 26 13:26:52.930: INFO: stderr: ""
Nov 26 13:26:52.930: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 26 13:26:52.930: INFO: validating pod update-demo-nautilus-gx4jn
Nov 26 13:26:52.938: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 26 13:26:52.938: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 26 13:26:52.938: INFO: update-demo-nautilus-gx4jn is verified up and running
Nov 26 13:26:52.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 13:26:53.047: INFO: stderr: ""
Nov 26 13:26:53.047: INFO: stdout: "true"
Nov 26 13:26:53.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 26 13:26:53.149: INFO: stderr: ""
Nov 26 13:26:53.149: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 26 13:26:53.149: INFO: validating pod update-demo-nautilus-jch9h
Nov 26 13:26:53.157: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 26 13:26:53.157: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 26 13:26:53.157: INFO: update-demo-nautilus-jch9h is verified up and running
STEP: scaling down the replication controller 11/26/22 13:26:53.157
Nov 26 13:26:53.159: INFO: scanned /root for discovery docs: <nil>
Nov 26 13:26:53.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Nov 26 13:26:54.306: INFO: stderr: ""
Nov 26 13:26:54.306: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/26/22 13:26:54.306
Nov 26 13:26:54.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 26 13:26:54.428: INFO: stderr: ""
Nov 26 13:26:54.428: INFO: stdout: "update-demo-nautilus-jch9h "
Nov 26 13:26:54.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 13:26:54.545: INFO: stderr: ""
Nov 26 13:26:54.545: INFO: stdout: "true"
Nov 26 13:26:54.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 26 13:26:54.650: INFO: stderr: ""
Nov 26 13:26:54.650: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 26 13:26:54.651: INFO: validating pod update-demo-nautilus-jch9h
Nov 26 13:26:54.658: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 26 13:26:54.658: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 26 13:26:54.658: INFO: update-demo-nautilus-jch9h is verified up and running
STEP: scaling up the replication controller 11/26/22 13:26:54.658
Nov 26 13:26:54.660: INFO: scanned /root for discovery docs: <nil>
Nov 26 13:26:54.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Nov 26 13:26:55.808: INFO: stderr: ""
Nov 26 13:26:55.808: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/26/22 13:26:55.808
Nov 26 13:26:55.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 26 13:26:55.906: INFO: stderr: ""
Nov 26 13:26:55.906: INFO: stdout: "update-demo-nautilus-7495j update-demo-nautilus-jch9h "
Nov 26 13:26:55.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-7495j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 13:26:55.992: INFO: stderr: ""
Nov 26 13:26:55.992: INFO: stdout: ""
Nov 26 13:26:55.992: INFO: update-demo-nautilus-7495j is created but not running
Nov 26 13:27:00.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov 26 13:27:01.232: INFO: stderr: ""
Nov 26 13:27:01.232: INFO: stdout: "update-demo-nautilus-7495j update-demo-nautilus-jch9h "
Nov 26 13:27:01.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-7495j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 13:27:01.398: INFO: stderr: ""
Nov 26 13:27:01.398: INFO: stdout: "true"
Nov 26 13:27:01.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-7495j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 26 13:27:01.515: INFO: stderr: ""
Nov 26 13:27:01.515: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 26 13:27:01.515: INFO: validating pod update-demo-nautilus-7495j
Nov 26 13:27:01.525: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 26 13:27:01.525: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 26 13:27:01.525: INFO: update-demo-nautilus-7495j is verified up and running
Nov 26 13:27:01.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov 26 13:27:01.644: INFO: stderr: ""
Nov 26 13:27:01.644: INFO: stdout: "true"
Nov 26 13:27:01.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov 26 13:27:01.759: INFO: stderr: ""
Nov 26 13:27:01.759: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov 26 13:27:01.759: INFO: validating pod update-demo-nautilus-jch9h
Nov 26 13:27:01.766: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 26 13:27:01.766: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 26 13:27:01.767: INFO: update-demo-nautilus-jch9h is verified up and running
STEP: using delete to clean up resources 11/26/22 13:27:01.767
Nov 26 13:27:01.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 delete --grace-period=0 --force -f -'
Nov 26 13:27:01.927: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 26 13:27:01.927: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 26 13:27:01.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get rc,svc -l name=update-demo --no-headers'
Nov 26 13:27:02.068: INFO: stderr: "No resources found in kubectl-1062 namespace.\n"
Nov 26 13:27:02.068: INFO: stdout: ""
Nov 26 13:27:02.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 26 13:27:02.224: INFO: stderr: ""
Nov 26 13:27:02.224: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 13:27:02.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1062" for this suite. 11/26/22 13:27:02.231
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":333,"skipped":6225,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.102 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:26:46.141
    Nov 26 13:26:46.142: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 13:26:46.143
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:26:46.18
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:26:46.185
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 11/26/22 13:26:46.19
    Nov 26 13:26:46.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 create -f -'
    Nov 26 13:26:47.431: INFO: stderr: ""
    Nov 26 13:26:47.431: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/26/22 13:26:47.431
    Nov 26 13:26:47.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 26 13:26:47.536: INFO: stderr: ""
    Nov 26 13:26:47.536: INFO: stdout: "update-demo-nautilus-gx4jn update-demo-nautilus-jch9h "
    Nov 26 13:26:47.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-gx4jn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 13:26:47.622: INFO: stderr: ""
    Nov 26 13:26:47.622: INFO: stdout: ""
    Nov 26 13:26:47.622: INFO: update-demo-nautilus-gx4jn is created but not running
    Nov 26 13:26:52.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 26 13:26:52.731: INFO: stderr: ""
    Nov 26 13:26:52.731: INFO: stdout: "update-demo-nautilus-gx4jn update-demo-nautilus-jch9h "
    Nov 26 13:26:52.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-gx4jn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 13:26:52.827: INFO: stderr: ""
    Nov 26 13:26:52.827: INFO: stdout: "true"
    Nov 26 13:26:52.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-gx4jn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 26 13:26:52.930: INFO: stderr: ""
    Nov 26 13:26:52.930: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 26 13:26:52.930: INFO: validating pod update-demo-nautilus-gx4jn
    Nov 26 13:26:52.938: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 26 13:26:52.938: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 26 13:26:52.938: INFO: update-demo-nautilus-gx4jn is verified up and running
    Nov 26 13:26:52.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 13:26:53.047: INFO: stderr: ""
    Nov 26 13:26:53.047: INFO: stdout: "true"
    Nov 26 13:26:53.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 26 13:26:53.149: INFO: stderr: ""
    Nov 26 13:26:53.149: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 26 13:26:53.149: INFO: validating pod update-demo-nautilus-jch9h
    Nov 26 13:26:53.157: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 26 13:26:53.157: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 26 13:26:53.157: INFO: update-demo-nautilus-jch9h is verified up and running
    STEP: scaling down the replication controller 11/26/22 13:26:53.157
    Nov 26 13:26:53.159: INFO: scanned /root for discovery docs: <nil>
    Nov 26 13:26:53.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Nov 26 13:26:54.306: INFO: stderr: ""
    Nov 26 13:26:54.306: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/26/22 13:26:54.306
    Nov 26 13:26:54.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 26 13:26:54.428: INFO: stderr: ""
    Nov 26 13:26:54.428: INFO: stdout: "update-demo-nautilus-jch9h "
    Nov 26 13:26:54.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 13:26:54.545: INFO: stderr: ""
    Nov 26 13:26:54.545: INFO: stdout: "true"
    Nov 26 13:26:54.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 26 13:26:54.650: INFO: stderr: ""
    Nov 26 13:26:54.650: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 26 13:26:54.651: INFO: validating pod update-demo-nautilus-jch9h
    Nov 26 13:26:54.658: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 26 13:26:54.658: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 26 13:26:54.658: INFO: update-demo-nautilus-jch9h is verified up and running
    STEP: scaling up the replication controller 11/26/22 13:26:54.658
    Nov 26 13:26:54.660: INFO: scanned /root for discovery docs: <nil>
    Nov 26 13:26:54.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Nov 26 13:26:55.808: INFO: stderr: ""
    Nov 26 13:26:55.808: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/26/22 13:26:55.808
    Nov 26 13:26:55.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 26 13:26:55.906: INFO: stderr: ""
    Nov 26 13:26:55.906: INFO: stdout: "update-demo-nautilus-7495j update-demo-nautilus-jch9h "
    Nov 26 13:26:55.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-7495j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 13:26:55.992: INFO: stderr: ""
    Nov 26 13:26:55.992: INFO: stdout: ""
    Nov 26 13:26:55.992: INFO: update-demo-nautilus-7495j is created but not running
    Nov 26 13:27:00.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov 26 13:27:01.232: INFO: stderr: ""
    Nov 26 13:27:01.232: INFO: stdout: "update-demo-nautilus-7495j update-demo-nautilus-jch9h "
    Nov 26 13:27:01.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-7495j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 13:27:01.398: INFO: stderr: ""
    Nov 26 13:27:01.398: INFO: stdout: "true"
    Nov 26 13:27:01.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-7495j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 26 13:27:01.515: INFO: stderr: ""
    Nov 26 13:27:01.515: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 26 13:27:01.515: INFO: validating pod update-demo-nautilus-7495j
    Nov 26 13:27:01.525: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 26 13:27:01.525: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 26 13:27:01.525: INFO: update-demo-nautilus-7495j is verified up and running
    Nov 26 13:27:01.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov 26 13:27:01.644: INFO: stderr: ""
    Nov 26 13:27:01.644: INFO: stdout: "true"
    Nov 26 13:27:01.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods update-demo-nautilus-jch9h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov 26 13:27:01.759: INFO: stderr: ""
    Nov 26 13:27:01.759: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov 26 13:27:01.759: INFO: validating pod update-demo-nautilus-jch9h
    Nov 26 13:27:01.766: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov 26 13:27:01.766: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov 26 13:27:01.767: INFO: update-demo-nautilus-jch9h is verified up and running
    STEP: using delete to clean up resources 11/26/22 13:27:01.767
    Nov 26 13:27:01.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 delete --grace-period=0 --force -f -'
    Nov 26 13:27:01.927: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 26 13:27:01.927: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Nov 26 13:27:01.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get rc,svc -l name=update-demo --no-headers'
    Nov 26 13:27:02.068: INFO: stderr: "No resources found in kubectl-1062 namespace.\n"
    Nov 26 13:27:02.068: INFO: stdout: ""
    Nov 26 13:27:02.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-1062 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov 26 13:27:02.224: INFO: stderr: ""
    Nov 26 13:27:02.224: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 13:27:02.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-1062" for this suite. 11/26/22 13:27:02.231
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:27:02.244
Nov 26 13:27:02.244: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename container-probe 11/26/22 13:27:02.245
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:27:02.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:27:02.289
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 in namespace container-probe-3309 11/26/22 13:27:02.293
Nov 26 13:27:02.312: INFO: Waiting up to 5m0s for pod "liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654" in namespace "container-probe-3309" to be "not pending"
Nov 26 13:27:02.317: INFO: Pod "liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654": Phase="Pending", Reason="", readiness=false. Elapsed: 4.392652ms
Nov 26 13:27:04.323: INFO: Pod "liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654": Phase="Running", Reason="", readiness=true. Elapsed: 2.010117418s
Nov 26 13:27:04.323: INFO: Pod "liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654" satisfied condition "not pending"
Nov 26 13:27:04.323: INFO: Started pod liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 in namespace container-probe-3309
STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 13:27:04.323
Nov 26 13:27:04.327: INFO: Initial restart count of pod liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is 0
Nov 26 13:27:24.401: INFO: Restart count of pod container-probe-3309/liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is now 1 (20.073820672s elapsed)
Nov 26 13:27:44.469: INFO: Restart count of pod container-probe-3309/liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is now 2 (40.141973407s elapsed)
Nov 26 13:28:04.534: INFO: Restart count of pod container-probe-3309/liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is now 3 (1m0.207782651s elapsed)
Nov 26 13:28:24.593: INFO: Restart count of pod container-probe-3309/liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is now 4 (1m20.266464433s elapsed)
Nov 26 13:29:24.783: INFO: Restart count of pod container-probe-3309/liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is now 5 (2m20.455912573s elapsed)
STEP: deleting the pod 11/26/22 13:29:24.783
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov 26 13:29:24.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3309" for this suite. 11/26/22 13:29:24.809
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":334,"skipped":6235,"failed":0}
------------------------------
â€¢ [SLOW TEST] [142.573 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:27:02.244
    Nov 26 13:27:02.244: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename container-probe 11/26/22 13:27:02.245
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:27:02.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:27:02.289
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 in namespace container-probe-3309 11/26/22 13:27:02.293
    Nov 26 13:27:02.312: INFO: Waiting up to 5m0s for pod "liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654" in namespace "container-probe-3309" to be "not pending"
    Nov 26 13:27:02.317: INFO: Pod "liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654": Phase="Pending", Reason="", readiness=false. Elapsed: 4.392652ms
    Nov 26 13:27:04.323: INFO: Pod "liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654": Phase="Running", Reason="", readiness=true. Elapsed: 2.010117418s
    Nov 26 13:27:04.323: INFO: Pod "liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654" satisfied condition "not pending"
    Nov 26 13:27:04.323: INFO: Started pod liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 in namespace container-probe-3309
    STEP: checking the pod's current state and verifying that restartCount is present 11/26/22 13:27:04.323
    Nov 26 13:27:04.327: INFO: Initial restart count of pod liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is 0
    Nov 26 13:27:24.401: INFO: Restart count of pod container-probe-3309/liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is now 1 (20.073820672s elapsed)
    Nov 26 13:27:44.469: INFO: Restart count of pod container-probe-3309/liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is now 2 (40.141973407s elapsed)
    Nov 26 13:28:04.534: INFO: Restart count of pod container-probe-3309/liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is now 3 (1m0.207782651s elapsed)
    Nov 26 13:28:24.593: INFO: Restart count of pod container-probe-3309/liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is now 4 (1m20.266464433s elapsed)
    Nov 26 13:29:24.783: INFO: Restart count of pod container-probe-3309/liveness-58d1e4f7-2a9d-4c15-9206-3f9145921654 is now 5 (2m20.455912573s elapsed)
    STEP: deleting the pod 11/26/22 13:29:24.783
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov 26 13:29:24.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3309" for this suite. 11/26/22 13:29:24.809
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:29:24.822
Nov 26 13:29:24.822: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename certificates 11/26/22 13:29:24.823
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:29:24.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:29:24.86
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 11/26/22 13:29:25.643
STEP: getting /apis/certificates.k8s.io 11/26/22 13:29:25.648
STEP: getting /apis/certificates.k8s.io/v1 11/26/22 13:29:25.65
STEP: creating 11/26/22 13:29:25.652
STEP: getting 11/26/22 13:29:25.683
STEP: listing 11/26/22 13:29:25.69
STEP: watching 11/26/22 13:29:25.698
Nov 26 13:29:25.698: INFO: starting watch
STEP: patching 11/26/22 13:29:25.701
STEP: updating 11/26/22 13:29:25.714
Nov 26 13:29:25.726: INFO: waiting for watch events with expected annotations
Nov 26 13:29:25.726: INFO: saw patched and updated annotations
STEP: getting /approval 11/26/22 13:29:25.727
STEP: patching /approval 11/26/22 13:29:25.734
STEP: updating /approval 11/26/22 13:29:25.747
STEP: getting /status 11/26/22 13:29:25.758
STEP: patching /status 11/26/22 13:29:25.765
STEP: updating /status 11/26/22 13:29:25.781
STEP: deleting 11/26/22 13:29:25.796
STEP: deleting a collection 11/26/22 13:29:25.82
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 13:29:25.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-2764" for this suite. 11/26/22 13:29:25.861
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":335,"skipped":6259,"failed":0}
------------------------------
â€¢ [1.051 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:29:24.822
    Nov 26 13:29:24.822: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename certificates 11/26/22 13:29:24.823
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:29:24.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:29:24.86
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 11/26/22 13:29:25.643
    STEP: getting /apis/certificates.k8s.io 11/26/22 13:29:25.648
    STEP: getting /apis/certificates.k8s.io/v1 11/26/22 13:29:25.65
    STEP: creating 11/26/22 13:29:25.652
    STEP: getting 11/26/22 13:29:25.683
    STEP: listing 11/26/22 13:29:25.69
    STEP: watching 11/26/22 13:29:25.698
    Nov 26 13:29:25.698: INFO: starting watch
    STEP: patching 11/26/22 13:29:25.701
    STEP: updating 11/26/22 13:29:25.714
    Nov 26 13:29:25.726: INFO: waiting for watch events with expected annotations
    Nov 26 13:29:25.726: INFO: saw patched and updated annotations
    STEP: getting /approval 11/26/22 13:29:25.727
    STEP: patching /approval 11/26/22 13:29:25.734
    STEP: updating /approval 11/26/22 13:29:25.747
    STEP: getting /status 11/26/22 13:29:25.758
    STEP: patching /status 11/26/22 13:29:25.765
    STEP: updating /status 11/26/22 13:29:25.781
    STEP: deleting 11/26/22 13:29:25.796
    STEP: deleting a collection 11/26/22 13:29:25.82
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 13:29:25.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-2764" for this suite. 11/26/22 13:29:25.861
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:29:25.875
Nov 26 13:29:25.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubectl 11/26/22 13:29:25.876
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:29:25.911
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:29:25.932
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 11/26/22 13:29:25.938
Nov 26 13:29:25.939: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Nov 26 13:29:25.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
Nov 26 13:29:26.186: INFO: stderr: ""
Nov 26 13:29:26.186: INFO: stdout: "service/agnhost-replica created\n"
Nov 26 13:29:26.186: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Nov 26 13:29:26.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
Nov 26 13:29:26.477: INFO: stderr: ""
Nov 26 13:29:26.477: INFO: stdout: "service/agnhost-primary created\n"
Nov 26 13:29:26.478: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 26 13:29:26.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
Nov 26 13:29:26.704: INFO: stderr: ""
Nov 26 13:29:26.704: INFO: stdout: "service/frontend created\n"
Nov 26 13:29:26.704: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Nov 26 13:29:26.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
Nov 26 13:29:27.012: INFO: stderr: ""
Nov 26 13:29:27.012: INFO: stdout: "deployment.apps/frontend created\n"
Nov 26 13:29:27.012: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 26 13:29:27.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
Nov 26 13:29:27.341: INFO: stderr: ""
Nov 26 13:29:27.341: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Nov 26 13:29:27.341: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 26 13:29:27.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
Nov 26 13:29:27.737: INFO: stderr: ""
Nov 26 13:29:27.737: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 11/26/22 13:29:27.737
Nov 26 13:29:27.738: INFO: Waiting for all frontend pods to be Running.
Nov 26 13:29:32.789: INFO: Waiting for frontend to serve content.
Nov 26 13:29:32.804: INFO: Trying to add a new entry to the guestbook.
Nov 26 13:29:32.822: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 11/26/22 13:29:32.836
Nov 26 13:29:32.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
Nov 26 13:29:32.949: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 26 13:29:32.949: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 11/26/22 13:29:32.949
Nov 26 13:29:32.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
Nov 26 13:29:33.107: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 26 13:29:33.107: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 11/26/22 13:29:33.107
Nov 26 13:29:33.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
Nov 26 13:29:33.231: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 26 13:29:33.231: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 11/26/22 13:29:33.231
Nov 26 13:29:33.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
Nov 26 13:29:33.315: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 26 13:29:33.315: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 11/26/22 13:29:33.315
Nov 26 13:29:33.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
Nov 26 13:29:33.440: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 26 13:29:33.440: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 11/26/22 13:29:33.44
Nov 26 13:29:33.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
Nov 26 13:29:33.572: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 26 13:29:33.573: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov 26 13:29:33.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8743" for this suite. 11/26/22 13:29:33.586
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":336,"skipped":6277,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.720 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:29:25.875
    Nov 26 13:29:25.875: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubectl 11/26/22 13:29:25.876
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:29:25.911
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:29:25.932
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 11/26/22 13:29:25.938
    Nov 26 13:29:25.939: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Nov 26 13:29:25.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
    Nov 26 13:29:26.186: INFO: stderr: ""
    Nov 26 13:29:26.186: INFO: stdout: "service/agnhost-replica created\n"
    Nov 26 13:29:26.186: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Nov 26 13:29:26.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
    Nov 26 13:29:26.477: INFO: stderr: ""
    Nov 26 13:29:26.477: INFO: stdout: "service/agnhost-primary created\n"
    Nov 26 13:29:26.478: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Nov 26 13:29:26.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
    Nov 26 13:29:26.704: INFO: stderr: ""
    Nov 26 13:29:26.704: INFO: stdout: "service/frontend created\n"
    Nov 26 13:29:26.704: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Nov 26 13:29:26.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
    Nov 26 13:29:27.012: INFO: stderr: ""
    Nov 26 13:29:27.012: INFO: stdout: "deployment.apps/frontend created\n"
    Nov 26 13:29:27.012: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Nov 26 13:29:27.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
    Nov 26 13:29:27.341: INFO: stderr: ""
    Nov 26 13:29:27.341: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Nov 26 13:29:27.341: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Nov 26 13:29:27.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 create -f -'
    Nov 26 13:29:27.737: INFO: stderr: ""
    Nov 26 13:29:27.737: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 11/26/22 13:29:27.737
    Nov 26 13:29:27.738: INFO: Waiting for all frontend pods to be Running.
    Nov 26 13:29:32.789: INFO: Waiting for frontend to serve content.
    Nov 26 13:29:32.804: INFO: Trying to add a new entry to the guestbook.
    Nov 26 13:29:32.822: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 11/26/22 13:29:32.836
    Nov 26 13:29:32.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
    Nov 26 13:29:32.949: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 26 13:29:32.949: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 11/26/22 13:29:32.949
    Nov 26 13:29:32.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
    Nov 26 13:29:33.107: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 26 13:29:33.107: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 11/26/22 13:29:33.107
    Nov 26 13:29:33.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
    Nov 26 13:29:33.231: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 26 13:29:33.231: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 11/26/22 13:29:33.231
    Nov 26 13:29:33.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
    Nov 26 13:29:33.315: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 26 13:29:33.315: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 11/26/22 13:29:33.315
    Nov 26 13:29:33.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
    Nov 26 13:29:33.440: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 26 13:29:33.440: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 11/26/22 13:29:33.44
    Nov 26 13:29:33.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-2065173477 --namespace=kubectl-8743 delete --grace-period=0 --force -f -'
    Nov 26 13:29:33.572: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov 26 13:29:33.573: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov 26 13:29:33.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8743" for this suite. 11/26/22 13:29:33.586
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:29:33.596
Nov 26 13:29:33.596: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename configmap 11/26/22 13:29:33.597
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:29:33.625
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:29:33.629
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov 26 13:29:33.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4309" for this suite. 11/26/22 13:29:33.707
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":337,"skipped":6280,"failed":0}
------------------------------
â€¢ [0.121 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:29:33.596
    Nov 26 13:29:33.596: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename configmap 11/26/22 13:29:33.597
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:29:33.625
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:29:33.629
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov 26 13:29:33.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4309" for this suite. 11/26/22 13:29:33.707
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:29:33.719
Nov 26 13:29:33.719: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename webhook 11/26/22 13:29:33.72
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:29:33.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:29:33.754
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/26/22 13:29:33.795
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 13:29:34.326
STEP: Deploying the webhook pod 11/26/22 13:29:34.338
STEP: Wait for the deployment to be ready 11/26/22 13:29:34.358
Nov 26 13:29:34.372: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 26 13:29:36.387: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 29, 34, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 29, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 29, 34, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 29, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 11/26/22 13:29:38.394
STEP: Verifying the service has paired with the endpoint 11/26/22 13:29:38.412
Nov 26 13:29:39.412: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 11/26/22 13:29:39.502
STEP: Creating a configMap that should be mutated 11/26/22 13:29:39.517
STEP: Deleting the collection of validation webhooks 11/26/22 13:29:39.559
STEP: Creating a configMap that should not be mutated 11/26/22 13:29:39.621
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov 26 13:29:39.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4688" for this suite. 11/26/22 13:29:39.643
STEP: Destroying namespace "webhook-4688-markers" for this suite. 11/26/22 13:29:39.652
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":338,"skipped":6284,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.002 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:29:33.719
    Nov 26 13:29:33.719: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename webhook 11/26/22 13:29:33.72
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:29:33.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:29:33.754
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/26/22 13:29:33.795
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/26/22 13:29:34.326
    STEP: Deploying the webhook pod 11/26/22 13:29:34.338
    STEP: Wait for the deployment to be ready 11/26/22 13:29:34.358
    Nov 26 13:29:34.372: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    Nov 26 13:29:36.387: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 26, 13, 29, 34, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 29, 34, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 26, 13, 29, 34, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 26, 13, 29, 34, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 11/26/22 13:29:38.394
    STEP: Verifying the service has paired with the endpoint 11/26/22 13:29:38.412
    Nov 26 13:29:39.412: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 11/26/22 13:29:39.502
    STEP: Creating a configMap that should be mutated 11/26/22 13:29:39.517
    STEP: Deleting the collection of validation webhooks 11/26/22 13:29:39.559
    STEP: Creating a configMap that should not be mutated 11/26/22 13:29:39.621
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov 26 13:29:39.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4688" for this suite. 11/26/22 13:29:39.643
    STEP: Destroying namespace "webhook-4688-markers" for this suite. 11/26/22 13:29:39.652
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:29:39.721
Nov 26 13:29:39.721: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename svcaccounts 11/26/22 13:29:39.722
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:29:39.75
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:29:39.754
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Nov 26 13:29:39.775: INFO: created pod
Nov 26 13:29:39.775: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-1789" to be "Succeeded or Failed"
Nov 26 13:29:39.778: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.643102ms
Nov 26 13:29:41.784: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009276171s
Nov 26 13:29:43.784: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009253369s
STEP: Saw pod success 11/26/22 13:29:43.784
Nov 26 13:29:43.784: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Nov 26 13:30:13.784: INFO: polling logs
Nov 26 13:30:13.809: INFO: Pod logs: 
I1126 13:29:40.767832       1 log.go:195] OK: Got token
I1126 13:29:40.767878       1 log.go:195] validating with in-cluster discovery
I1126 13:29:40.768260       1 log.go:195] OK: got issuer https://kubernetes.default.svc
I1126 13:29:40.768294       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1789:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1669469979, NotBefore:1669469379, IssuedAt:1669469379, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1789", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"59562eff-f61a-478f-a0ad-141d7f93486e"}}}
I1126 13:29:40.783572       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
I1126 13:29:40.790917       1 log.go:195] OK: Validated signature on JWT
I1126 13:29:40.791056       1 log.go:195] OK: Got valid claims from token!
I1126 13:29:40.791093       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1789:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1669469979, NotBefore:1669469379, IssuedAt:1669469379, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1789", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"59562eff-f61a-478f-a0ad-141d7f93486e"}}}

Nov 26 13:30:13.809: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov 26 13:30:13.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1789" for this suite. 11/26/22 13:30:13.827
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":339,"skipped":6285,"failed":0}
------------------------------
â€¢ [SLOW TEST] [34.114 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:29:39.721
    Nov 26 13:29:39.721: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename svcaccounts 11/26/22 13:29:39.722
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:29:39.75
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:29:39.754
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Nov 26 13:29:39.775: INFO: created pod
    Nov 26 13:29:39.775: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-1789" to be "Succeeded or Failed"
    Nov 26 13:29:39.778: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.643102ms
    Nov 26 13:29:41.784: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009276171s
    Nov 26 13:29:43.784: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009253369s
    STEP: Saw pod success 11/26/22 13:29:43.784
    Nov 26 13:29:43.784: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Nov 26 13:30:13.784: INFO: polling logs
    Nov 26 13:30:13.809: INFO: Pod logs: 
    I1126 13:29:40.767832       1 log.go:195] OK: Got token
    I1126 13:29:40.767878       1 log.go:195] validating with in-cluster discovery
    I1126 13:29:40.768260       1 log.go:195] OK: got issuer https://kubernetes.default.svc
    I1126 13:29:40.768294       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1789:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1669469979, NotBefore:1669469379, IssuedAt:1669469379, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1789", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"59562eff-f61a-478f-a0ad-141d7f93486e"}}}
    I1126 13:29:40.783572       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
    I1126 13:29:40.790917       1 log.go:195] OK: Validated signature on JWT
    I1126 13:29:40.791056       1 log.go:195] OK: Got valid claims from token!
    I1126 13:29:40.791093       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-1789:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1669469979, NotBefore:1669469379, IssuedAt:1669469379, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-1789", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"59562eff-f61a-478f-a0ad-141d7f93486e"}}}

    Nov 26 13:30:13.809: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov 26 13:30:13.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1789" for this suite. 11/26/22 13:30:13.827
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:30:13.839
Nov 26 13:30:13.839: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replication-controller 11/26/22 13:30:13.84
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:30:13.867
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:30:13.872
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87 11/26/22 13:30:13.879
Nov 26 13:30:13.894: INFO: Pod name my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87: Found 0 pods out of 1
Nov 26 13:30:18.903: INFO: Pod name my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87: Found 1 pods out of 1
Nov 26 13:30:18.903: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87" are running
Nov 26 13:30:18.903: INFO: Waiting up to 5m0s for pod "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf" in namespace "replication-controller-8808" to be "running"
Nov 26 13:30:18.907: INFO: Pod "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf": Phase="Running", Reason="", readiness=true. Elapsed: 4.367391ms
Nov 26 13:30:18.907: INFO: Pod "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf" satisfied condition "running"
Nov 26 13:30:18.907: INFO: Pod "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 13:30:13 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 13:30:15 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 13:30:15 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 13:30:13 +0000 UTC Reason: Message:}])
Nov 26 13:30:18.907: INFO: Trying to dial the pod
Nov 26 13:30:23.936: INFO: Controller my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87: Got expected result from replica 1 [my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf]: "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 26 13:30:23.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8808" for this suite. 11/26/22 13:30:23.948
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":340,"skipped":6300,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.119 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:30:13.839
    Nov 26 13:30:13.839: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replication-controller 11/26/22 13:30:13.84
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:30:13.867
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:30:13.872
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87 11/26/22 13:30:13.879
    Nov 26 13:30:13.894: INFO: Pod name my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87: Found 0 pods out of 1
    Nov 26 13:30:18.903: INFO: Pod name my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87: Found 1 pods out of 1
    Nov 26 13:30:18.903: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87" are running
    Nov 26 13:30:18.903: INFO: Waiting up to 5m0s for pod "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf" in namespace "replication-controller-8808" to be "running"
    Nov 26 13:30:18.907: INFO: Pod "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf": Phase="Running", Reason="", readiness=true. Elapsed: 4.367391ms
    Nov 26 13:30:18.907: INFO: Pod "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf" satisfied condition "running"
    Nov 26 13:30:18.907: INFO: Pod "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 13:30:13 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 13:30:15 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 13:30:15 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-26 13:30:13 +0000 UTC Reason: Message:}])
    Nov 26 13:30:18.907: INFO: Trying to dial the pod
    Nov 26 13:30:23.936: INFO: Controller my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87: Got expected result from replica 1 [my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf]: "my-hostname-basic-8633aa44-0d5b-4915-82c6-620cd890be87-nx4zf", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 26 13:30:23.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-8808" for this suite. 11/26/22 13:30:23.948
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:30:23.961
Nov 26 13:30:23.961: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename security-context-test 11/26/22 13:30:23.962
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:30:23.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:30:23.99
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Nov 26 13:30:24.006: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500" in namespace "security-context-test-9044" to be "Succeeded or Failed"
Nov 26 13:30:24.011: INFO: Pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500": Phase="Pending", Reason="", readiness=false. Elapsed: 4.710723ms
Nov 26 13:30:26.017: INFO: Pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010150308s
Nov 26 13:30:28.019: INFO: Pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012228168s
Nov 26 13:30:30.018: INFO: Pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011116832s
Nov 26 13:30:30.018: INFO: Pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 26 13:30:30.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9044" for this suite. 11/26/22 13:30:30.039
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":341,"skipped":6313,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.088 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:30:23.961
    Nov 26 13:30:23.961: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename security-context-test 11/26/22 13:30:23.962
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:30:23.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:30:23.99
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Nov 26 13:30:24.006: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500" in namespace "security-context-test-9044" to be "Succeeded or Failed"
    Nov 26 13:30:24.011: INFO: Pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500": Phase="Pending", Reason="", readiness=false. Elapsed: 4.710723ms
    Nov 26 13:30:26.017: INFO: Pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010150308s
    Nov 26 13:30:28.019: INFO: Pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012228168s
    Nov 26 13:30:30.018: INFO: Pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011116832s
    Nov 26 13:30:30.018: INFO: Pod "alpine-nnp-false-5eddae18-3b73-4f77-89d7-b6421d4cf500" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 26 13:30:30.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-9044" for this suite. 11/26/22 13:30:30.039
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:30:30.052
Nov 26 13:30:30.052: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename events 11/26/22 13:30:30.053
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:30:30.075
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:30:30.081
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 11/26/22 13:30:30.087
STEP: listing all events in all namespaces 11/26/22 13:30:30.097
STEP: patching the test event 11/26/22 13:30:30.103
STEP: fetching the test event 11/26/22 13:30:30.111
STEP: updating the test event 11/26/22 13:30:30.116
STEP: getting the test event 11/26/22 13:30:30.128
STEP: deleting the test event 11/26/22 13:30:30.133
STEP: listing all events in all namespaces 11/26/22 13:30:30.151
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Nov 26 13:30:30.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1417" for this suite. 11/26/22 13:30:30.162
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":342,"skipped":6323,"failed":0}
------------------------------
â€¢ [0.122 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:30:30.052
    Nov 26 13:30:30.052: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename events 11/26/22 13:30:30.053
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:30:30.075
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:30:30.081
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 11/26/22 13:30:30.087
    STEP: listing all events in all namespaces 11/26/22 13:30:30.097
    STEP: patching the test event 11/26/22 13:30:30.103
    STEP: fetching the test event 11/26/22 13:30:30.111
    STEP: updating the test event 11/26/22 13:30:30.116
    STEP: getting the test event 11/26/22 13:30:30.128
    STEP: deleting the test event 11/26/22 13:30:30.133
    STEP: listing all events in all namespaces 11/26/22 13:30:30.151
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Nov 26 13:30:30.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1417" for this suite. 11/26/22 13:30:30.162
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:30:30.175
Nov 26 13:30:30.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename init-container 11/26/22 13:30:30.177
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:30:30.305
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:30:30.311
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 11/26/22 13:30:30.317
Nov 26 13:30:30.317: INFO: PodSpec: initContainers in spec.initContainers
Nov 26 13:31:15.870: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-81df6181-5c25-4323-940c-f0bd2758dd66", GenerateName:"", Namespace:"init-container-7048", SelfLink:"", UID:"39fb3736-0aeb-452c-b051-154c0983a8ad", ResourceVersion:"39662", Generation:0, CreationTimestamp:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"317454783"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00501bc38), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 26, 13, 31, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00501bc68), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-b688w", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0034ced60), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-b688w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-b688w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-b688w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0012e5818), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-43-82", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0036f2620), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0012e58a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0012e58c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0012e58c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0012e58cc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000e33fa0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.43.82", PodIP:"192.168.34.7", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.34.7"}}, StartTime:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0036f2700)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0036f2770)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://07f60254e0a987a9626abedaaab692a89c0873305199af1f4e00a66377bb0055", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0034cede0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0034cedc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0012e596f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov 26 13:31:15.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7048" for this suite. 11/26/22 13:31:15.876
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":343,"skipped":6342,"failed":0}
------------------------------
â€¢ [SLOW TEST] [45.715 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:30:30.175
    Nov 26 13:30:30.176: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename init-container 11/26/22 13:30:30.177
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:30:30.305
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:30:30.311
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 11/26/22 13:30:30.317
    Nov 26 13:30:30.317: INFO: PodSpec: initContainers in spec.initContainers
    Nov 26 13:31:15.870: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-81df6181-5c25-4323-940c-f0bd2758dd66", GenerateName:"", Namespace:"init-container-7048", SelfLink:"", UID:"39fb3736-0aeb-452c-b051-154c0983a8ad", ResourceVersion:"39662", Generation:0, CreationTimestamp:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"317454783"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00501bc38), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 26, 13, 31, 15, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00501bc68), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-b688w", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc0034ced60), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-b688w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-b688w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-b688w", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0012e5818), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-43-82", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0036f2620), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0012e58a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0012e58c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0012e58c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0012e58cc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc000e33fa0), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.43.82", PodIP:"192.168.34.7", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.34.7"}}, StartTime:time.Date(2022, time.November, 26, 13, 30, 30, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0036f2700)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0036f2770)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://07f60254e0a987a9626abedaaab692a89c0873305199af1f4e00a66377bb0055", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0034cede0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0034cedc0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc0012e596f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov 26 13:31:15.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-7048" for this suite. 11/26/22 13:31:15.876
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:31:15.891
Nov 26 13:31:15.892: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename kubelet-test 11/26/22 13:31:15.892
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:15.923
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:15.927
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 11/26/22 13:31:15.943
Nov 26 13:31:15.943: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases58e25ad8-b4a7-4563-8a60-9bba0a740816" in namespace "kubelet-test-3752" to be "completed"
Nov 26 13:31:15.948: INFO: Pod "agnhost-host-aliases58e25ad8-b4a7-4563-8a60-9bba0a740816": Phase="Pending", Reason="", readiness=false. Elapsed: 4.551164ms
Nov 26 13:31:17.954: INFO: Pod "agnhost-host-aliases58e25ad8-b4a7-4563-8a60-9bba0a740816": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011249475s
Nov 26 13:31:19.953: INFO: Pod "agnhost-host-aliases58e25ad8-b4a7-4563-8a60-9bba0a740816": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009740968s
Nov 26 13:31:19.953: INFO: Pod "agnhost-host-aliases58e25ad8-b4a7-4563-8a60-9bba0a740816" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov 26 13:31:19.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3752" for this suite. 11/26/22 13:31:19.968
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":344,"skipped":6346,"failed":0}
------------------------------
â€¢ [4.086 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:31:15.891
    Nov 26 13:31:15.892: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename kubelet-test 11/26/22 13:31:15.892
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:15.923
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:15.927
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 11/26/22 13:31:15.943
    Nov 26 13:31:15.943: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases58e25ad8-b4a7-4563-8a60-9bba0a740816" in namespace "kubelet-test-3752" to be "completed"
    Nov 26 13:31:15.948: INFO: Pod "agnhost-host-aliases58e25ad8-b4a7-4563-8a60-9bba0a740816": Phase="Pending", Reason="", readiness=false. Elapsed: 4.551164ms
    Nov 26 13:31:17.954: INFO: Pod "agnhost-host-aliases58e25ad8-b4a7-4563-8a60-9bba0a740816": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011249475s
    Nov 26 13:31:19.953: INFO: Pod "agnhost-host-aliases58e25ad8-b4a7-4563-8a60-9bba0a740816": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009740968s
    Nov 26 13:31:19.953: INFO: Pod "agnhost-host-aliases58e25ad8-b4a7-4563-8a60-9bba0a740816" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov 26 13:31:19.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-3752" for this suite. 11/26/22 13:31:19.968
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:31:19.979
Nov 26 13:31:19.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename emptydir 11/26/22 13:31:19.98
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:20.054
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:20.06
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 11/26/22 13:31:20.065
Nov 26 13:31:20.079: INFO: Waiting up to 5m0s for pod "pod-31e34dc2-bed2-4f52-942d-3909242e63ee" in namespace "emptydir-6630" to be "Succeeded or Failed"
Nov 26 13:31:20.083: INFO: Pod "pod-31e34dc2-bed2-4f52-942d-3909242e63ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.14854ms
Nov 26 13:31:22.088: INFO: Pod "pod-31e34dc2-bed2-4f52-942d-3909242e63ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00916561s
Nov 26 13:31:24.090: INFO: Pod "pod-31e34dc2-bed2-4f52-942d-3909242e63ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010447815s
STEP: Saw pod success 11/26/22 13:31:24.09
Nov 26 13:31:24.090: INFO: Pod "pod-31e34dc2-bed2-4f52-942d-3909242e63ee" satisfied condition "Succeeded or Failed"
Nov 26 13:31:24.095: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-31e34dc2-bed2-4f52-942d-3909242e63ee container test-container: <nil>
STEP: delete the pod 11/26/22 13:31:24.104
Nov 26 13:31:24.124: INFO: Waiting for pod pod-31e34dc2-bed2-4f52-942d-3909242e63ee to disappear
Nov 26 13:31:24.129: INFO: Pod pod-31e34dc2-bed2-4f52-942d-3909242e63ee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov 26 13:31:24.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6630" for this suite. 11/26/22 13:31:24.135
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":345,"skipped":6374,"failed":0}
------------------------------
â€¢ [4.166 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:31:19.979
    Nov 26 13:31:19.979: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename emptydir 11/26/22 13:31:19.98
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:20.054
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:20.06
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 11/26/22 13:31:20.065
    Nov 26 13:31:20.079: INFO: Waiting up to 5m0s for pod "pod-31e34dc2-bed2-4f52-942d-3909242e63ee" in namespace "emptydir-6630" to be "Succeeded or Failed"
    Nov 26 13:31:20.083: INFO: Pod "pod-31e34dc2-bed2-4f52-942d-3909242e63ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.14854ms
    Nov 26 13:31:22.088: INFO: Pod "pod-31e34dc2-bed2-4f52-942d-3909242e63ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00916561s
    Nov 26 13:31:24.090: INFO: Pod "pod-31e34dc2-bed2-4f52-942d-3909242e63ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010447815s
    STEP: Saw pod success 11/26/22 13:31:24.09
    Nov 26 13:31:24.090: INFO: Pod "pod-31e34dc2-bed2-4f52-942d-3909242e63ee" satisfied condition "Succeeded or Failed"
    Nov 26 13:31:24.095: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-31e34dc2-bed2-4f52-942d-3909242e63ee container test-container: <nil>
    STEP: delete the pod 11/26/22 13:31:24.104
    Nov 26 13:31:24.124: INFO: Waiting for pod pod-31e34dc2-bed2-4f52-942d-3909242e63ee to disappear
    Nov 26 13:31:24.129: INFO: Pod pod-31e34dc2-bed2-4f52-942d-3909242e63ee no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov 26 13:31:24.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-6630" for this suite. 11/26/22 13:31:24.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:31:24.147
Nov 26 13:31:24.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename dns 11/26/22 13:31:24.148
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:24.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:24.181
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 11/26/22 13:31:24.188
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-303.svc.cluster.local;sleep 1; done
 11/26/22 13:31:24.199
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-303.svc.cluster.local;sleep 1; done
 11/26/22 13:31:24.199
STEP: creating a pod to probe DNS 11/26/22 13:31:24.2
STEP: submitting the pod to kubernetes 11/26/22 13:31:24.2
Nov 26 13:31:24.215: INFO: Waiting up to 15m0s for pod "dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9" in namespace "dns-303" to be "running"
Nov 26 13:31:24.221: INFO: Pod "dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.15156ms
Nov 26 13:31:26.227: INFO: Pod "dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9": Phase="Running", Reason="", readiness=true. Elapsed: 2.012142143s
Nov 26 13:31:26.227: INFO: Pod "dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9" satisfied condition "running"
STEP: retrieving the pod 11/26/22 13:31:26.227
STEP: looking for the results for each expected name from probers 11/26/22 13:31:26.233
Nov 26 13:31:26.239: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
Nov 26 13:31:26.245: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
Nov 26 13:31:26.250: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
Nov 26 13:31:26.258: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
Nov 26 13:31:26.267: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
Nov 26 13:31:26.273: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
Nov 26 13:31:26.279: INFO: Unable to read jessie_udp@dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
Nov 26 13:31:26.286: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
Nov 26 13:31:26.286: INFO: Lookups using dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local wheezy_udp@dns-test-service-2.dns-303.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-303.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local jessie_udp@dns-test-service-2.dns-303.svc.cluster.local jessie_tcp@dns-test-service-2.dns-303.svc.cluster.local]

Nov 26 13:31:31.349: INFO: DNS probes using dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9 succeeded

STEP: deleting the pod 11/26/22 13:31:31.349
STEP: deleting the test headless service 11/26/22 13:31:31.377
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 26 13:31:31.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-303" for this suite. 11/26/22 13:31:31.407
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":346,"skipped":6384,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.275 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:31:24.147
    Nov 26 13:31:24.147: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename dns 11/26/22 13:31:24.148
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:24.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:24.181
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 11/26/22 13:31:24.188
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-303.svc.cluster.local;sleep 1; done
     11/26/22 13:31:24.199
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-303.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-303.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-303.svc.cluster.local;sleep 1; done
     11/26/22 13:31:24.199
    STEP: creating a pod to probe DNS 11/26/22 13:31:24.2
    STEP: submitting the pod to kubernetes 11/26/22 13:31:24.2
    Nov 26 13:31:24.215: INFO: Waiting up to 15m0s for pod "dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9" in namespace "dns-303" to be "running"
    Nov 26 13:31:24.221: INFO: Pod "dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.15156ms
    Nov 26 13:31:26.227: INFO: Pod "dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9": Phase="Running", Reason="", readiness=true. Elapsed: 2.012142143s
    Nov 26 13:31:26.227: INFO: Pod "dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9" satisfied condition "running"
    STEP: retrieving the pod 11/26/22 13:31:26.227
    STEP: looking for the results for each expected name from probers 11/26/22 13:31:26.233
    Nov 26 13:31:26.239: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
    Nov 26 13:31:26.245: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
    Nov 26 13:31:26.250: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
    Nov 26 13:31:26.258: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
    Nov 26 13:31:26.267: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
    Nov 26 13:31:26.273: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
    Nov 26 13:31:26.279: INFO: Unable to read jessie_udp@dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
    Nov 26 13:31:26.286: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-303.svc.cluster.local from pod dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9: the server could not find the requested resource (get pods dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9)
    Nov 26 13:31:26.286: INFO: Lookups using dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local wheezy_udp@dns-test-service-2.dns-303.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-303.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-303.svc.cluster.local jessie_udp@dns-test-service-2.dns-303.svc.cluster.local jessie_tcp@dns-test-service-2.dns-303.svc.cluster.local]

    Nov 26 13:31:31.349: INFO: DNS probes using dns-303/dns-test-0511f7e1-a8b5-49f6-bfa8-e0d75057e7f9 succeeded

    STEP: deleting the pod 11/26/22 13:31:31.349
    STEP: deleting the test headless service 11/26/22 13:31:31.377
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 26 13:31:31.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-303" for this suite. 11/26/22 13:31:31.407
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:31:31.424
Nov 26 13:31:31.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename controllerrevisions 11/26/22 13:31:31.426
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:31.463
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:31.485
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-fhdsm-daemon-set" 11/26/22 13:31:31.521
STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 13:31:31.531
Nov 26 13:31:31.542: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 13:31:31.542: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 13:31:31.559: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 0
Nov 26 13:31:31.559: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 13:31:32.566: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 13:31:32.566: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 13:31:32.571: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 0
Nov 26 13:31:32.571: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 13:31:33.567: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 13:31:33.567: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 13:31:33.575: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 0
Nov 26 13:31:33.575: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 13:31:34.564: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 13:31:34.565: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 13:31:34.571: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 2
Nov 26 13:31:34.571: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
Nov 26 13:31:35.565: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 13:31:35.565: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 26 13:31:35.570: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 3
Nov 26 13:31:35.570: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-fhdsm-daemon-set
STEP: Confirm DaemonSet "e2e-fhdsm-daemon-set" successfully created with "daemonset-name=e2e-fhdsm-daemon-set" label 11/26/22 13:31:35.578
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-fhdsm-daemon-set" 11/26/22 13:31:35.597
Nov 26 13:31:35.602: INFO: Located ControllerRevision: "e2e-fhdsm-daemon-set-7d67bfbd45"
STEP: Patching ControllerRevision "e2e-fhdsm-daemon-set-7d67bfbd45" 11/26/22 13:31:35.607
Nov 26 13:31:35.619: INFO: e2e-fhdsm-daemon-set-7d67bfbd45 has been patched
STEP: Create a new ControllerRevision 11/26/22 13:31:35.619
Nov 26 13:31:35.629: INFO: Created ControllerRevision: e2e-fhdsm-daemon-set-846598b69
STEP: Confirm that there are two ControllerRevisions 11/26/22 13:31:35.629
Nov 26 13:31:35.630: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 26 13:31:35.635: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-fhdsm-daemon-set-7d67bfbd45" 11/26/22 13:31:35.635
STEP: Confirm that there is only one ControllerRevision 11/26/22 13:31:35.647
Nov 26 13:31:35.647: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 26 13:31:35.652: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-fhdsm-daemon-set-846598b69" 11/26/22 13:31:35.665
Nov 26 13:31:35.685: INFO: e2e-fhdsm-daemon-set-846598b69 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 11/26/22 13:31:35.685
W1126 13:31:35.706869      19 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 11/26/22 13:31:35.707
Nov 26 13:31:35.707: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 26 13:31:36.713: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 26 13:31:36.719: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-fhdsm-daemon-set-846598b69=updated" 11/26/22 13:31:36.719
STEP: Confirm that there is only one ControllerRevision 11/26/22 13:31:36.733
Nov 26 13:31:36.734: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov 26 13:31:36.739: INFO: Found 1 ControllerRevisions
Nov 26 13:31:36.745: INFO: ControllerRevision "e2e-fhdsm-daemon-set-7b7c97ffbd" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-fhdsm-daemon-set" 11/26/22 13:31:36.75
STEP: deleting DaemonSet.extensions e2e-fhdsm-daemon-set in namespace controllerrevisions-7980, will wait for the garbage collector to delete the pods 11/26/22 13:31:36.75
Nov 26 13:31:36.815: INFO: Deleting DaemonSet.extensions e2e-fhdsm-daemon-set took: 9.706046ms
Nov 26 13:31:36.916: INFO: Terminating DaemonSet.extensions e2e-fhdsm-daemon-set pods took: 100.868191ms
Nov 26 13:31:38.222: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 0
Nov 26 13:31:38.222: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-fhdsm-daemon-set
Nov 26 13:31:38.227: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39940"},"items":null}

Nov 26 13:31:38.232: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39940"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Nov 26 13:31:38.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-7980" for this suite. 11/26/22 13:31:38.262
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":347,"skipped":6400,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.848 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:31:31.424
    Nov 26 13:31:31.424: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename controllerrevisions 11/26/22 13:31:31.426
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:31.463
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:31.485
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-fhdsm-daemon-set" 11/26/22 13:31:31.521
    STEP: Check that daemon pods launch on every node of the cluster. 11/26/22 13:31:31.531
    Nov 26 13:31:31.542: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 13:31:31.542: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 13:31:31.559: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 0
    Nov 26 13:31:31.559: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 13:31:32.566: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 13:31:32.566: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 13:31:32.571: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 0
    Nov 26 13:31:32.571: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 13:31:33.567: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 13:31:33.567: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 13:31:33.575: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 0
    Nov 26 13:31:33.575: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 13:31:34.564: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 13:31:34.565: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 13:31:34.571: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 2
    Nov 26 13:31:34.571: INFO: Node ip-172-31-0-249 is running 0 daemon pod, expected 1
    Nov 26 13:31:35.565: INFO: DaemonSet pods can't tolerate node ip-172-31-39-222 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 13:31:35.565: INFO: DaemonSet pods can't tolerate node ip-172-31-88-138 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov 26 13:31:35.570: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 3
    Nov 26 13:31:35.570: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-fhdsm-daemon-set
    STEP: Confirm DaemonSet "e2e-fhdsm-daemon-set" successfully created with "daemonset-name=e2e-fhdsm-daemon-set" label 11/26/22 13:31:35.578
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-fhdsm-daemon-set" 11/26/22 13:31:35.597
    Nov 26 13:31:35.602: INFO: Located ControllerRevision: "e2e-fhdsm-daemon-set-7d67bfbd45"
    STEP: Patching ControllerRevision "e2e-fhdsm-daemon-set-7d67bfbd45" 11/26/22 13:31:35.607
    Nov 26 13:31:35.619: INFO: e2e-fhdsm-daemon-set-7d67bfbd45 has been patched
    STEP: Create a new ControllerRevision 11/26/22 13:31:35.619
    Nov 26 13:31:35.629: INFO: Created ControllerRevision: e2e-fhdsm-daemon-set-846598b69
    STEP: Confirm that there are two ControllerRevisions 11/26/22 13:31:35.629
    Nov 26 13:31:35.630: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 26 13:31:35.635: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-fhdsm-daemon-set-7d67bfbd45" 11/26/22 13:31:35.635
    STEP: Confirm that there is only one ControllerRevision 11/26/22 13:31:35.647
    Nov 26 13:31:35.647: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 26 13:31:35.652: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-fhdsm-daemon-set-846598b69" 11/26/22 13:31:35.665
    Nov 26 13:31:35.685: INFO: e2e-fhdsm-daemon-set-846598b69 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 11/26/22 13:31:35.685
    W1126 13:31:35.706869      19 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 11/26/22 13:31:35.707
    Nov 26 13:31:35.707: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 26 13:31:36.713: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 26 13:31:36.719: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-fhdsm-daemon-set-846598b69=updated" 11/26/22 13:31:36.719
    STEP: Confirm that there is only one ControllerRevision 11/26/22 13:31:36.733
    Nov 26 13:31:36.734: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov 26 13:31:36.739: INFO: Found 1 ControllerRevisions
    Nov 26 13:31:36.745: INFO: ControllerRevision "e2e-fhdsm-daemon-set-7b7c97ffbd" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-fhdsm-daemon-set" 11/26/22 13:31:36.75
    STEP: deleting DaemonSet.extensions e2e-fhdsm-daemon-set in namespace controllerrevisions-7980, will wait for the garbage collector to delete the pods 11/26/22 13:31:36.75
    Nov 26 13:31:36.815: INFO: Deleting DaemonSet.extensions e2e-fhdsm-daemon-set took: 9.706046ms
    Nov 26 13:31:36.916: INFO: Terminating DaemonSet.extensions e2e-fhdsm-daemon-set pods took: 100.868191ms
    Nov 26 13:31:38.222: INFO: Number of nodes with available pods controlled by daemonset e2e-fhdsm-daemon-set: 0
    Nov 26 13:31:38.222: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-fhdsm-daemon-set
    Nov 26 13:31:38.227: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39940"},"items":null}

    Nov 26 13:31:38.232: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39940"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 13:31:38.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-7980" for this suite. 11/26/22 13:31:38.262
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:31:38.275
Nov 26 13:31:38.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename job 11/26/22 13:31:38.276
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:38.3
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:38.307
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 11/26/22 13:31:38.312
STEP: Ensure pods equal to paralellism count is attached to the job 11/26/22 13:31:38.321
STEP: patching /status 11/26/22 13:31:40.328
STEP: updating /status 11/26/22 13:31:40.338
STEP: get /status 11/26/22 13:31:40.378
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 26 13:31:40.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2533" for this suite. 11/26/22 13:31:40.393
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":348,"skipped":6421,"failed":0}
------------------------------
â€¢ [2.127 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:31:38.275
    Nov 26 13:31:38.275: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename job 11/26/22 13:31:38.276
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:38.3
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:38.307
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 11/26/22 13:31:38.312
    STEP: Ensure pods equal to paralellism count is attached to the job 11/26/22 13:31:38.321
    STEP: patching /status 11/26/22 13:31:40.328
    STEP: updating /status 11/26/22 13:31:40.338
    STEP: get /status 11/26/22 13:31:40.378
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 26 13:31:40.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2533" for this suite. 11/26/22 13:31:40.393
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:31:40.404
Nov 26 13:31:40.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename security-context 11/26/22 13:31:40.405
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:40.429
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:40.435
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/26/22 13:31:40.441
Nov 26 13:31:40.454: INFO: Waiting up to 5m0s for pod "security-context-3acc8471-525f-49a3-9c80-18b230fb6f98" in namespace "security-context-5772" to be "Succeeded or Failed"
Nov 26 13:31:40.459: INFO: Pod "security-context-3acc8471-525f-49a3-9c80-18b230fb6f98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.710417ms
Nov 26 13:31:42.464: INFO: Pod "security-context-3acc8471-525f-49a3-9c80-18b230fb6f98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009955181s
Nov 26 13:31:44.463: INFO: Pod "security-context-3acc8471-525f-49a3-9c80-18b230fb6f98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008996564s
STEP: Saw pod success 11/26/22 13:31:44.463
Nov 26 13:31:44.464: INFO: Pod "security-context-3acc8471-525f-49a3-9c80-18b230fb6f98" satisfied condition "Succeeded or Failed"
Nov 26 13:31:44.475: INFO: Trying to get logs from node ip-172-31-43-82 pod security-context-3acc8471-525f-49a3-9c80-18b230fb6f98 container test-container: <nil>
STEP: delete the pod 11/26/22 13:31:44.489
Nov 26 13:31:44.508: INFO: Waiting for pod security-context-3acc8471-525f-49a3-9c80-18b230fb6f98 to disappear
Nov 26 13:31:44.513: INFO: Pod security-context-3acc8471-525f-49a3-9c80-18b230fb6f98 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov 26 13:31:44.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-5772" for this suite. 11/26/22 13:31:44.519
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":349,"skipped":6449,"failed":0}
------------------------------
â€¢ [4.125 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:31:40.404
    Nov 26 13:31:40.404: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename security-context 11/26/22 13:31:40.405
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:40.429
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:40.435
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/26/22 13:31:40.441
    Nov 26 13:31:40.454: INFO: Waiting up to 5m0s for pod "security-context-3acc8471-525f-49a3-9c80-18b230fb6f98" in namespace "security-context-5772" to be "Succeeded or Failed"
    Nov 26 13:31:40.459: INFO: Pod "security-context-3acc8471-525f-49a3-9c80-18b230fb6f98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.710417ms
    Nov 26 13:31:42.464: INFO: Pod "security-context-3acc8471-525f-49a3-9c80-18b230fb6f98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009955181s
    Nov 26 13:31:44.463: INFO: Pod "security-context-3acc8471-525f-49a3-9c80-18b230fb6f98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008996564s
    STEP: Saw pod success 11/26/22 13:31:44.463
    Nov 26 13:31:44.464: INFO: Pod "security-context-3acc8471-525f-49a3-9c80-18b230fb6f98" satisfied condition "Succeeded or Failed"
    Nov 26 13:31:44.475: INFO: Trying to get logs from node ip-172-31-43-82 pod security-context-3acc8471-525f-49a3-9c80-18b230fb6f98 container test-container: <nil>
    STEP: delete the pod 11/26/22 13:31:44.489
    Nov 26 13:31:44.508: INFO: Waiting for pod security-context-3acc8471-525f-49a3-9c80-18b230fb6f98 to disappear
    Nov 26 13:31:44.513: INFO: Pod security-context-3acc8471-525f-49a3-9c80-18b230fb6f98 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov 26 13:31:44.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-5772" for this suite. 11/26/22 13:31:44.519
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:31:44.531
Nov 26 13:31:44.531: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename dns 11/26/22 13:31:44.533
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:44.561
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:44.568
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 11/26/22 13:31:44.576
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
 11/26/22 13:31:44.583
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
 11/26/22 13:31:44.583
STEP: creating a pod to probe DNS 11/26/22 13:31:44.584
STEP: submitting the pod to kubernetes 11/26/22 13:31:44.584
Nov 26 13:31:44.608: INFO: Waiting up to 15m0s for pod "dns-test-8e7c51bc-caf3-412d-9341-6a17a90bc9a6" in namespace "dns-7989" to be "running"
Nov 26 13:31:44.618: INFO: Pod "dns-test-8e7c51bc-caf3-412d-9341-6a17a90bc9a6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.876528ms
Nov 26 13:31:46.624: INFO: Pod "dns-test-8e7c51bc-caf3-412d-9341-6a17a90bc9a6": Phase="Running", Reason="", readiness=true. Elapsed: 2.015435807s
Nov 26 13:31:46.624: INFO: Pod "dns-test-8e7c51bc-caf3-412d-9341-6a17a90bc9a6" satisfied condition "running"
STEP: retrieving the pod 11/26/22 13:31:46.624
STEP: looking for the results for each expected name from probers 11/26/22 13:31:46.629
Nov 26 13:31:46.642: INFO: DNS probes using dns-test-8e7c51bc-caf3-412d-9341-6a17a90bc9a6 succeeded

STEP: deleting the pod 11/26/22 13:31:46.642
STEP: changing the externalName to bar.example.com 11/26/22 13:31:46.665
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
 11/26/22 13:31:46.679
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
 11/26/22 13:31:46.679
STEP: creating a second pod to probe DNS 11/26/22 13:31:46.68
STEP: submitting the pod to kubernetes 11/26/22 13:31:46.68
Nov 26 13:31:46.690: INFO: Waiting up to 15m0s for pod "dns-test-35c446f1-f827-47c4-977c-6150a8137dcd" in namespace "dns-7989" to be "running"
Nov 26 13:31:46.698: INFO: Pod "dns-test-35c446f1-f827-47c4-977c-6150a8137dcd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.412033ms
Nov 26 13:31:48.703: INFO: Pod "dns-test-35c446f1-f827-47c4-977c-6150a8137dcd": Phase="Running", Reason="", readiness=true. Elapsed: 2.013437089s
Nov 26 13:31:48.703: INFO: Pod "dns-test-35c446f1-f827-47c4-977c-6150a8137dcd" satisfied condition "running"
STEP: retrieving the pod 11/26/22 13:31:48.704
STEP: looking for the results for each expected name from probers 11/26/22 13:31:48.708
Nov 26 13:31:48.717: INFO: File wheezy_udp@dns-test-service-3.dns-7989.svc.cluster.local from pod  dns-7989/dns-test-35c446f1-f827-47c4-977c-6150a8137dcd contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 26 13:31:48.723: INFO: File jessie_udp@dns-test-service-3.dns-7989.svc.cluster.local from pod  dns-7989/dns-test-35c446f1-f827-47c4-977c-6150a8137dcd contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 26 13:31:48.723: INFO: Lookups using dns-7989/dns-test-35c446f1-f827-47c4-977c-6150a8137dcd failed for: [wheezy_udp@dns-test-service-3.dns-7989.svc.cluster.local jessie_udp@dns-test-service-3.dns-7989.svc.cluster.local]

Nov 26 13:31:53.740: INFO: DNS probes using dns-test-35c446f1-f827-47c4-977c-6150a8137dcd succeeded

STEP: deleting the pod 11/26/22 13:31:53.74
STEP: changing the service to type=ClusterIP 11/26/22 13:31:53.783
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
 11/26/22 13:31:53.806
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
 11/26/22 13:31:53.806
STEP: creating a third pod to probe DNS 11/26/22 13:31:53.806
STEP: submitting the pod to kubernetes 11/26/22 13:31:53.813
Nov 26 13:31:53.827: INFO: Waiting up to 15m0s for pod "dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d" in namespace "dns-7989" to be "running"
Nov 26 13:31:53.837: INFO: Pod "dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.502074ms
Nov 26 13:31:55.844: INFO: Pod "dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016887089s
Nov 26 13:31:57.842: INFO: Pod "dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d": Phase="Running", Reason="", readiness=true. Elapsed: 4.014813869s
Nov 26 13:31:57.843: INFO: Pod "dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d" satisfied condition "running"
STEP: retrieving the pod 11/26/22 13:31:57.843
STEP: looking for the results for each expected name from probers 11/26/22 13:31:57.848
Nov 26 13:31:57.874: INFO: DNS probes using dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d succeeded

STEP: deleting the pod 11/26/22 13:31:57.874
STEP: deleting the test externalName service 11/26/22 13:31:57.89
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 26 13:31:57.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7989" for this suite. 11/26/22 13:31:57.921
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":350,"skipped":6466,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.401 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:31:44.531
    Nov 26 13:31:44.531: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename dns 11/26/22 13:31:44.533
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:44.561
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:44.568
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 11/26/22 13:31:44.576
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
     11/26/22 13:31:44.583
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
     11/26/22 13:31:44.583
    STEP: creating a pod to probe DNS 11/26/22 13:31:44.584
    STEP: submitting the pod to kubernetes 11/26/22 13:31:44.584
    Nov 26 13:31:44.608: INFO: Waiting up to 15m0s for pod "dns-test-8e7c51bc-caf3-412d-9341-6a17a90bc9a6" in namespace "dns-7989" to be "running"
    Nov 26 13:31:44.618: INFO: Pod "dns-test-8e7c51bc-caf3-412d-9341-6a17a90bc9a6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.876528ms
    Nov 26 13:31:46.624: INFO: Pod "dns-test-8e7c51bc-caf3-412d-9341-6a17a90bc9a6": Phase="Running", Reason="", readiness=true. Elapsed: 2.015435807s
    Nov 26 13:31:46.624: INFO: Pod "dns-test-8e7c51bc-caf3-412d-9341-6a17a90bc9a6" satisfied condition "running"
    STEP: retrieving the pod 11/26/22 13:31:46.624
    STEP: looking for the results for each expected name from probers 11/26/22 13:31:46.629
    Nov 26 13:31:46.642: INFO: DNS probes using dns-test-8e7c51bc-caf3-412d-9341-6a17a90bc9a6 succeeded

    STEP: deleting the pod 11/26/22 13:31:46.642
    STEP: changing the externalName to bar.example.com 11/26/22 13:31:46.665
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
     11/26/22 13:31:46.679
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
     11/26/22 13:31:46.679
    STEP: creating a second pod to probe DNS 11/26/22 13:31:46.68
    STEP: submitting the pod to kubernetes 11/26/22 13:31:46.68
    Nov 26 13:31:46.690: INFO: Waiting up to 15m0s for pod "dns-test-35c446f1-f827-47c4-977c-6150a8137dcd" in namespace "dns-7989" to be "running"
    Nov 26 13:31:46.698: INFO: Pod "dns-test-35c446f1-f827-47c4-977c-6150a8137dcd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.412033ms
    Nov 26 13:31:48.703: INFO: Pod "dns-test-35c446f1-f827-47c4-977c-6150a8137dcd": Phase="Running", Reason="", readiness=true. Elapsed: 2.013437089s
    Nov 26 13:31:48.703: INFO: Pod "dns-test-35c446f1-f827-47c4-977c-6150a8137dcd" satisfied condition "running"
    STEP: retrieving the pod 11/26/22 13:31:48.704
    STEP: looking for the results for each expected name from probers 11/26/22 13:31:48.708
    Nov 26 13:31:48.717: INFO: File wheezy_udp@dns-test-service-3.dns-7989.svc.cluster.local from pod  dns-7989/dns-test-35c446f1-f827-47c4-977c-6150a8137dcd contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 26 13:31:48.723: INFO: File jessie_udp@dns-test-service-3.dns-7989.svc.cluster.local from pod  dns-7989/dns-test-35c446f1-f827-47c4-977c-6150a8137dcd contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov 26 13:31:48.723: INFO: Lookups using dns-7989/dns-test-35c446f1-f827-47c4-977c-6150a8137dcd failed for: [wheezy_udp@dns-test-service-3.dns-7989.svc.cluster.local jessie_udp@dns-test-service-3.dns-7989.svc.cluster.local]

    Nov 26 13:31:53.740: INFO: DNS probes using dns-test-35c446f1-f827-47c4-977c-6150a8137dcd succeeded

    STEP: deleting the pod 11/26/22 13:31:53.74
    STEP: changing the service to type=ClusterIP 11/26/22 13:31:53.783
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
     11/26/22 13:31:53.806
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7989.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7989.svc.cluster.local; sleep 1; done
     11/26/22 13:31:53.806
    STEP: creating a third pod to probe DNS 11/26/22 13:31:53.806
    STEP: submitting the pod to kubernetes 11/26/22 13:31:53.813
    Nov 26 13:31:53.827: INFO: Waiting up to 15m0s for pod "dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d" in namespace "dns-7989" to be "running"
    Nov 26 13:31:53.837: INFO: Pod "dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.502074ms
    Nov 26 13:31:55.844: INFO: Pod "dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016887089s
    Nov 26 13:31:57.842: INFO: Pod "dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d": Phase="Running", Reason="", readiness=true. Elapsed: 4.014813869s
    Nov 26 13:31:57.843: INFO: Pod "dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d" satisfied condition "running"
    STEP: retrieving the pod 11/26/22 13:31:57.843
    STEP: looking for the results for each expected name from probers 11/26/22 13:31:57.848
    Nov 26 13:31:57.874: INFO: DNS probes using dns-test-00490ff4-3364-4517-aa0c-0e091fa7821d succeeded

    STEP: deleting the pod 11/26/22 13:31:57.874
    STEP: deleting the test externalName service 11/26/22 13:31:57.89
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 26 13:31:57.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7989" for this suite. 11/26/22 13:31:57.921
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:31:57.94
Nov 26 13:31:57.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename projected 11/26/22 13:31:57.943
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:57.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:57.985
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-ee2f9367-bb9b-4af8-8b6e-df96a98399eb 11/26/22 13:31:57.999
STEP: Creating secret with name s-test-opt-upd-a12a4a52-2717-48cc-817a-b6faa87b3c6e 11/26/22 13:31:58.006
STEP: Creating the pod 11/26/22 13:31:58.013
Nov 26 13:31:58.029: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25" in namespace "projected-9639" to be "running and ready"
Nov 26 13:31:58.039: INFO: Pod "pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25": Phase="Pending", Reason="", readiness=false. Elapsed: 9.246952ms
Nov 26 13:31:58.039: INFO: The phase of Pod pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:32:00.049: INFO: Pod "pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019946082s
Nov 26 13:32:00.049: INFO: The phase of Pod pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:32:02.044: INFO: Pod "pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25": Phase="Running", Reason="", readiness=true. Elapsed: 4.014888103s
Nov 26 13:32:02.044: INFO: The phase of Pod pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25 is Running (Ready = true)
Nov 26 13:32:02.044: INFO: Pod "pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-ee2f9367-bb9b-4af8-8b6e-df96a98399eb 11/26/22 13:32:02.084
STEP: Updating secret s-test-opt-upd-a12a4a52-2717-48cc-817a-b6faa87b3c6e 11/26/22 13:32:02.095
STEP: Creating secret with name s-test-opt-create-d6ddd85e-ad17-427a-bc5e-c72fba54c872 11/26/22 13:32:02.103
STEP: waiting to observe update in volume 11/26/22 13:32:02.114
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov 26 13:33:22.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9639" for this suite. 11/26/22 13:33:22.661
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":351,"skipped":6483,"failed":0}
------------------------------
â€¢ [SLOW TEST] [84.732 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:31:57.94
    Nov 26 13:31:57.940: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename projected 11/26/22 13:31:57.943
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:31:57.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:31:57.985
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-ee2f9367-bb9b-4af8-8b6e-df96a98399eb 11/26/22 13:31:57.999
    STEP: Creating secret with name s-test-opt-upd-a12a4a52-2717-48cc-817a-b6faa87b3c6e 11/26/22 13:31:58.006
    STEP: Creating the pod 11/26/22 13:31:58.013
    Nov 26 13:31:58.029: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25" in namespace "projected-9639" to be "running and ready"
    Nov 26 13:31:58.039: INFO: Pod "pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25": Phase="Pending", Reason="", readiness=false. Elapsed: 9.246952ms
    Nov 26 13:31:58.039: INFO: The phase of Pod pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:32:00.049: INFO: Pod "pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019946082s
    Nov 26 13:32:00.049: INFO: The phase of Pod pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:32:02.044: INFO: Pod "pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25": Phase="Running", Reason="", readiness=true. Elapsed: 4.014888103s
    Nov 26 13:32:02.044: INFO: The phase of Pod pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25 is Running (Ready = true)
    Nov 26 13:32:02.044: INFO: Pod "pod-projected-secrets-b1d75724-96c2-4eef-a8c3-e0d9ddb9fa25" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-ee2f9367-bb9b-4af8-8b6e-df96a98399eb 11/26/22 13:32:02.084
    STEP: Updating secret s-test-opt-upd-a12a4a52-2717-48cc-817a-b6faa87b3c6e 11/26/22 13:32:02.095
    STEP: Creating secret with name s-test-opt-create-d6ddd85e-ad17-427a-bc5e-c72fba54c872 11/26/22 13:32:02.103
    STEP: waiting to observe update in volume 11/26/22 13:32:02.114
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov 26 13:33:22.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9639" for this suite. 11/26/22 13:33:22.661
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:33:22.673
Nov 26 13:33:22.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename sched-preemption 11/26/22 13:33:22.674
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:33:22.704
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:33:22.708
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov 26 13:33:22.738: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 26 13:34:22.765: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 11/26/22 13:34:22.772
Nov 26 13:34:22.804: INFO: Created pod: pod0-0-sched-preemption-low-priority
Nov 26 13:34:22.816: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Nov 26 13:34:22.851: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Nov 26 13:34:22.868: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Nov 26 13:34:22.900: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Nov 26 13:34:22.912: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 11/26/22 13:34:22.912
Nov 26 13:34:22.912: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8565" to be "running"
Nov 26 13:34:22.923: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.633746ms
Nov 26 13:34:24.928: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015807574s
Nov 26 13:34:26.929: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.016990051s
Nov 26 13:34:26.929: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Nov 26 13:34:26.929: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8565" to be "running"
Nov 26 13:34:26.934: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.003255ms
Nov 26 13:34:26.934: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 26 13:34:26.935: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8565" to be "running"
Nov 26 13:34:26.939: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.105445ms
Nov 26 13:34:26.939: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 26 13:34:26.939: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8565" to be "running"
Nov 26 13:34:26.944: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.886034ms
Nov 26 13:34:26.944: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Nov 26 13:34:26.944: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8565" to be "running"
Nov 26 13:34:26.952: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.675794ms
Nov 26 13:34:26.952: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Nov 26 13:34:26.952: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8565" to be "running"
Nov 26 13:34:26.957: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.365069ms
Nov 26 13:34:26.957: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 11/26/22 13:34:26.957
Nov 26 13:34:26.973: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Nov 26 13:34:26.978: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.862413ms
Nov 26 13:34:28.984: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011172349s
Nov 26 13:34:30.983: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.010194625s
Nov 26 13:34:30.983: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov 26 13:34:31.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-8565" for this suite. 11/26/22 13:34:31.053
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":352,"skipped":6489,"failed":0}
------------------------------
â€¢ [SLOW TEST] [68.454 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:33:22.673
    Nov 26 13:33:22.673: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename sched-preemption 11/26/22 13:33:22.674
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:33:22.704
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:33:22.708
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov 26 13:33:22.738: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov 26 13:34:22.765: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 11/26/22 13:34:22.772
    Nov 26 13:34:22.804: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Nov 26 13:34:22.816: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Nov 26 13:34:22.851: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Nov 26 13:34:22.868: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Nov 26 13:34:22.900: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Nov 26 13:34:22.912: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 11/26/22 13:34:22.912
    Nov 26 13:34:22.912: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-8565" to be "running"
    Nov 26 13:34:22.923: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.633746ms
    Nov 26 13:34:24.928: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015807574s
    Nov 26 13:34:26.929: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.016990051s
    Nov 26 13:34:26.929: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Nov 26 13:34:26.929: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-8565" to be "running"
    Nov 26 13:34:26.934: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.003255ms
    Nov 26 13:34:26.934: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 26 13:34:26.935: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-8565" to be "running"
    Nov 26 13:34:26.939: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.105445ms
    Nov 26 13:34:26.939: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 26 13:34:26.939: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-8565" to be "running"
    Nov 26 13:34:26.944: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.886034ms
    Nov 26 13:34:26.944: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov 26 13:34:26.944: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-8565" to be "running"
    Nov 26 13:34:26.952: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.675794ms
    Nov 26 13:34:26.952: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov 26 13:34:26.952: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-8565" to be "running"
    Nov 26 13:34:26.957: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.365069ms
    Nov 26 13:34:26.957: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 11/26/22 13:34:26.957
    Nov 26 13:34:26.973: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Nov 26 13:34:26.978: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.862413ms
    Nov 26 13:34:28.984: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011172349s
    Nov 26 13:34:30.983: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.010194625s
    Nov 26 13:34:30.983: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov 26 13:34:31.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-8565" for this suite. 11/26/22 13:34:31.053
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:34:31.129
Nov 26 13:34:31.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replication-controller 11/26/22 13:34:31.13
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:34:31.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:34:31.182
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 11/26/22 13:34:31.205
STEP: waiting for RC to be added 11/26/22 13:34:31.219
STEP: waiting for available Replicas 11/26/22 13:34:31.219
STEP: patching ReplicationController 11/26/22 13:34:32.353
STEP: waiting for RC to be modified 11/26/22 13:34:32.371
STEP: patching ReplicationController status 11/26/22 13:34:32.373
STEP: waiting for RC to be modified 11/26/22 13:34:32.385
STEP: waiting for available Replicas 11/26/22 13:34:32.386
STEP: fetching ReplicationController status 11/26/22 13:34:32.397
STEP: patching ReplicationController scale 11/26/22 13:34:32.403
STEP: waiting for RC to be modified 11/26/22 13:34:32.426
STEP: waiting for ReplicationController's scale to be the max amount 11/26/22 13:34:32.427
STEP: fetching ReplicationController; ensuring that it's patched 11/26/22 13:34:33.489
STEP: updating ReplicationController status 11/26/22 13:34:33.494
STEP: waiting for RC to be modified 11/26/22 13:34:33.504
STEP: listing all ReplicationControllers 11/26/22 13:34:33.504
STEP: checking that ReplicationController has expected values 11/26/22 13:34:33.555
STEP: deleting ReplicationControllers by collection 11/26/22 13:34:33.555
STEP: waiting for ReplicationController to have a DELETED watchEvent 11/26/22 13:34:33.568
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov 26 13:34:33.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1928" for this suite. 11/26/22 13:34:33.686
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":353,"skipped":6493,"failed":0}
------------------------------
â€¢ [2.569 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:34:31.129
    Nov 26 13:34:31.129: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replication-controller 11/26/22 13:34:31.13
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:34:31.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:34:31.182
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 11/26/22 13:34:31.205
    STEP: waiting for RC to be added 11/26/22 13:34:31.219
    STEP: waiting for available Replicas 11/26/22 13:34:31.219
    STEP: patching ReplicationController 11/26/22 13:34:32.353
    STEP: waiting for RC to be modified 11/26/22 13:34:32.371
    STEP: patching ReplicationController status 11/26/22 13:34:32.373
    STEP: waiting for RC to be modified 11/26/22 13:34:32.385
    STEP: waiting for available Replicas 11/26/22 13:34:32.386
    STEP: fetching ReplicationController status 11/26/22 13:34:32.397
    STEP: patching ReplicationController scale 11/26/22 13:34:32.403
    STEP: waiting for RC to be modified 11/26/22 13:34:32.426
    STEP: waiting for ReplicationController's scale to be the max amount 11/26/22 13:34:32.427
    STEP: fetching ReplicationController; ensuring that it's patched 11/26/22 13:34:33.489
    STEP: updating ReplicationController status 11/26/22 13:34:33.494
    STEP: waiting for RC to be modified 11/26/22 13:34:33.504
    STEP: listing all ReplicationControllers 11/26/22 13:34:33.504
    STEP: checking that ReplicationController has expected values 11/26/22 13:34:33.555
    STEP: deleting ReplicationControllers by collection 11/26/22 13:34:33.555
    STEP: waiting for ReplicationController to have a DELETED watchEvent 11/26/22 13:34:33.568
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov 26 13:34:33.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1928" for this suite. 11/26/22 13:34:33.686
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:34:33.709
Nov 26 13:34:33.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename replicaset 11/26/22 13:34:33.71
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:34:33.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:34:33.746
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 11/26/22 13:34:33.751
Nov 26 13:34:33.764: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-8860" to be "running and ready"
Nov 26 13:34:33.770: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 6.37ms
Nov 26 13:34:33.770: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:34:35.778: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.013777331s
Nov 26 13:34:35.778: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Nov 26 13:34:35.778: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 11/26/22 13:34:35.783
STEP: Then the orphan pod is adopted 11/26/22 13:34:35.791
STEP: When the matched label of one of its pods change 11/26/22 13:34:36.803
Nov 26 13:34:36.810: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 11/26/22 13:34:36.832
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov 26 13:34:37.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8860" for this suite. 11/26/22 13:34:37.858
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":354,"skipped":6494,"failed":0}
------------------------------
â€¢ [4.159 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:34:33.709
    Nov 26 13:34:33.709: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename replicaset 11/26/22 13:34:33.71
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:34:33.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:34:33.746
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 11/26/22 13:34:33.751
    Nov 26 13:34:33.764: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-8860" to be "running and ready"
    Nov 26 13:34:33.770: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 6.37ms
    Nov 26 13:34:33.770: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:34:35.778: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.013777331s
    Nov 26 13:34:35.778: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Nov 26 13:34:35.778: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 11/26/22 13:34:35.783
    STEP: Then the orphan pod is adopted 11/26/22 13:34:35.791
    STEP: When the matched label of one of its pods change 11/26/22 13:34:36.803
    Nov 26 13:34:36.810: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 11/26/22 13:34:36.832
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov 26 13:34:37.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-8860" for this suite. 11/26/22 13:34:37.858
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:34:37.872
Nov 26 13:34:37.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename dns 11/26/22 13:34:37.873
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:34:37.894
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:34:37.898
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9048.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9048.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 11/26/22 13:34:37.903
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9048.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9048.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 11/26/22 13:34:37.903
STEP: creating a pod to probe /etc/hosts 11/26/22 13:34:37.903
STEP: submitting the pod to kubernetes 11/26/22 13:34:37.904
Nov 26 13:34:37.920: INFO: Waiting up to 15m0s for pod "dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1" in namespace "dns-9048" to be "running"
Nov 26 13:34:37.926: INFO: Pod "dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.561521ms
Nov 26 13:34:39.932: INFO: Pod "dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011220287s
Nov 26 13:34:41.932: INFO: Pod "dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1": Phase="Running", Reason="", readiness=true. Elapsed: 4.012181672s
Nov 26 13:34:41.933: INFO: Pod "dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1" satisfied condition "running"
STEP: retrieving the pod 11/26/22 13:34:41.933
STEP: looking for the results for each expected name from probers 11/26/22 13:34:41.939
Nov 26 13:34:41.966: INFO: DNS probes using dns-9048/dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1 succeeded

STEP: deleting the pod 11/26/22 13:34:41.966
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov 26 13:34:42.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9048" for this suite. 11/26/22 13:34:42.08
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":355,"skipped":6524,"failed":0}
------------------------------
â€¢ [4.217 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:34:37.872
    Nov 26 13:34:37.872: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename dns 11/26/22 13:34:37.873
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:34:37.894
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:34:37.898
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9048.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9048.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     11/26/22 13:34:37.903
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9048.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9048.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     11/26/22 13:34:37.903
    STEP: creating a pod to probe /etc/hosts 11/26/22 13:34:37.903
    STEP: submitting the pod to kubernetes 11/26/22 13:34:37.904
    Nov 26 13:34:37.920: INFO: Waiting up to 15m0s for pod "dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1" in namespace "dns-9048" to be "running"
    Nov 26 13:34:37.926: INFO: Pod "dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1": Phase="Pending", Reason="", readiness=false. Elapsed: 5.561521ms
    Nov 26 13:34:39.932: INFO: Pod "dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011220287s
    Nov 26 13:34:41.932: INFO: Pod "dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1": Phase="Running", Reason="", readiness=true. Elapsed: 4.012181672s
    Nov 26 13:34:41.933: INFO: Pod "dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1" satisfied condition "running"
    STEP: retrieving the pod 11/26/22 13:34:41.933
    STEP: looking for the results for each expected name from probers 11/26/22 13:34:41.939
    Nov 26 13:34:41.966: INFO: DNS probes using dns-9048/dns-test-dc7e5b97-5b72-4c35-8bd9-a822472da3d1 succeeded

    STEP: deleting the pod 11/26/22 13:34:41.966
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov 26 13:34:42.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-9048" for this suite. 11/26/22 13:34:42.08
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:34:42.095
Nov 26 13:34:42.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename resourcequota 11/26/22 13:34:42.096
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:34:42.122
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:34:42.126
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 11/26/22 13:34:59.135
STEP: Creating a ResourceQuota 11/26/22 13:35:04.14
STEP: Ensuring resource quota status is calculated 11/26/22 13:35:04.151
STEP: Creating a ConfigMap 11/26/22 13:35:06.16
STEP: Ensuring resource quota status captures configMap creation 11/26/22 13:35:06.18
STEP: Deleting a ConfigMap 11/26/22 13:35:08.186
STEP: Ensuring resource quota status released usage 11/26/22 13:35:08.195
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov 26 13:35:10.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7987" for this suite. 11/26/22 13:35:10.21
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":356,"skipped":6574,"failed":0}
------------------------------
â€¢ [SLOW TEST] [28.126 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:34:42.095
    Nov 26 13:34:42.095: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename resourcequota 11/26/22 13:34:42.096
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:34:42.122
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:34:42.126
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 11/26/22 13:34:59.135
    STEP: Creating a ResourceQuota 11/26/22 13:35:04.14
    STEP: Ensuring resource quota status is calculated 11/26/22 13:35:04.151
    STEP: Creating a ConfigMap 11/26/22 13:35:06.16
    STEP: Ensuring resource quota status captures configMap creation 11/26/22 13:35:06.18
    STEP: Deleting a ConfigMap 11/26/22 13:35:08.186
    STEP: Ensuring resource quota status released usage 11/26/22 13:35:08.195
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov 26 13:35:10.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7987" for this suite. 11/26/22 13:35:10.21
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:35:10.224
Nov 26 13:35:10.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 13:35:10.226
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:35:10.253
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:35:10.258
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 11/26/22 13:35:10.266
Nov 26 13:35:10.283: INFO: Waiting up to 5m0s for pod "labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2" in namespace "downward-api-8649" to be "running and ready"
Nov 26 13:35:10.291: INFO: Pod "labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.450134ms
Nov 26 13:35:10.291: INFO: The phase of Pod labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2 is Pending, waiting for it to be Running (with Ready = true)
Nov 26 13:35:12.296: INFO: Pod "labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013504408s
Nov 26 13:35:12.296: INFO: The phase of Pod labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2 is Running (Ready = true)
Nov 26 13:35:12.296: INFO: Pod "labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2" satisfied condition "running and ready"
Nov 26 13:35:12.837: INFO: Successfully updated pod "labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 13:35:16.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8649" for this suite. 11/26/22 13:35:16.876
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":357,"skipped":6612,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.660 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:35:10.224
    Nov 26 13:35:10.225: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 13:35:10.226
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:35:10.253
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:35:10.258
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 11/26/22 13:35:10.266
    Nov 26 13:35:10.283: INFO: Waiting up to 5m0s for pod "labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2" in namespace "downward-api-8649" to be "running and ready"
    Nov 26 13:35:10.291: INFO: Pod "labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.450134ms
    Nov 26 13:35:10.291: INFO: The phase of Pod labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2 is Pending, waiting for it to be Running (with Ready = true)
    Nov 26 13:35:12.296: INFO: Pod "labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2": Phase="Running", Reason="", readiness=true. Elapsed: 2.013504408s
    Nov 26 13:35:12.296: INFO: The phase of Pod labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2 is Running (Ready = true)
    Nov 26 13:35:12.296: INFO: Pod "labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2" satisfied condition "running and ready"
    Nov 26 13:35:12.837: INFO: Successfully updated pod "labelsupdate4ff08610-a117-457d-a496-a3e7d1079fc2"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 13:35:16.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8649" for this suite. 11/26/22 13:35:16.876
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:35:16.895
Nov 26 13:35:16.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename subpath 11/26/22 13:35:16.899
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:35:16.924
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:35:16.93
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/26/22 13:35:16.934
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-bhvl 11/26/22 13:35:16.951
STEP: Creating a pod to test atomic-volume-subpath 11/26/22 13:35:16.951
Nov 26 13:35:16.963: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bhvl" in namespace "subpath-1456" to be "Succeeded or Failed"
Nov 26 13:35:16.969: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Pending", Reason="", readiness=false. Elapsed: 5.442411ms
Nov 26 13:35:18.974: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 2.011125496s
Nov 26 13:35:20.976: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 4.013252102s
Nov 26 13:35:22.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 6.011948999s
Nov 26 13:35:24.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 8.011673776s
Nov 26 13:35:26.974: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 10.011267142s
Nov 26 13:35:28.974: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 12.011331803s
Nov 26 13:35:30.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 14.011777317s
Nov 26 13:35:32.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 16.011456922s
Nov 26 13:35:34.974: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 18.011375819s
Nov 26 13:35:36.982: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 20.019126323s
Nov 26 13:35:38.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=false. Elapsed: 22.011954707s
Nov 26 13:35:40.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012022371s
STEP: Saw pod success 11/26/22 13:35:40.975
Nov 26 13:35:40.975: INFO: Pod "pod-subpath-test-configmap-bhvl" satisfied condition "Succeeded or Failed"
Nov 26 13:35:40.981: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-subpath-test-configmap-bhvl container test-container-subpath-configmap-bhvl: <nil>
STEP: delete the pod 11/26/22 13:35:40.992
Nov 26 13:35:41.015: INFO: Waiting for pod pod-subpath-test-configmap-bhvl to disappear
Nov 26 13:35:41.022: INFO: Pod pod-subpath-test-configmap-bhvl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-bhvl 11/26/22 13:35:41.022
Nov 26 13:35:41.022: INFO: Deleting pod "pod-subpath-test-configmap-bhvl" in namespace "subpath-1456"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov 26 13:35:41.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1456" for this suite. 11/26/22 13:35:41.038
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":358,"skipped":6637,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.160 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:35:16.895
    Nov 26 13:35:16.896: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename subpath 11/26/22 13:35:16.899
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:35:16.924
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:35:16.93
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/26/22 13:35:16.934
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-bhvl 11/26/22 13:35:16.951
    STEP: Creating a pod to test atomic-volume-subpath 11/26/22 13:35:16.951
    Nov 26 13:35:16.963: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bhvl" in namespace "subpath-1456" to be "Succeeded or Failed"
    Nov 26 13:35:16.969: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Pending", Reason="", readiness=false. Elapsed: 5.442411ms
    Nov 26 13:35:18.974: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 2.011125496s
    Nov 26 13:35:20.976: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 4.013252102s
    Nov 26 13:35:22.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 6.011948999s
    Nov 26 13:35:24.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 8.011673776s
    Nov 26 13:35:26.974: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 10.011267142s
    Nov 26 13:35:28.974: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 12.011331803s
    Nov 26 13:35:30.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 14.011777317s
    Nov 26 13:35:32.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 16.011456922s
    Nov 26 13:35:34.974: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 18.011375819s
    Nov 26 13:35:36.982: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=true. Elapsed: 20.019126323s
    Nov 26 13:35:38.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Running", Reason="", readiness=false. Elapsed: 22.011954707s
    Nov 26 13:35:40.975: INFO: Pod "pod-subpath-test-configmap-bhvl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012022371s
    STEP: Saw pod success 11/26/22 13:35:40.975
    Nov 26 13:35:40.975: INFO: Pod "pod-subpath-test-configmap-bhvl" satisfied condition "Succeeded or Failed"
    Nov 26 13:35:40.981: INFO: Trying to get logs from node ip-172-31-43-82 pod pod-subpath-test-configmap-bhvl container test-container-subpath-configmap-bhvl: <nil>
    STEP: delete the pod 11/26/22 13:35:40.992
    Nov 26 13:35:41.015: INFO: Waiting for pod pod-subpath-test-configmap-bhvl to disappear
    Nov 26 13:35:41.022: INFO: Pod pod-subpath-test-configmap-bhvl no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-bhvl 11/26/22 13:35:41.022
    Nov 26 13:35:41.022: INFO: Deleting pod "pod-subpath-test-configmap-bhvl" in namespace "subpath-1456"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov 26 13:35:41.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-1456" for this suite. 11/26/22 13:35:41.038
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:35:41.059
Nov 26 13:35:41.059: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename var-expansion 11/26/22 13:35:41.06
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:35:41.098
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:35:41.105
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 11/26/22 13:35:41.112
STEP: waiting for pod running 11/26/22 13:35:41.127
Nov 26 13:35:41.128: INFO: Waiting up to 2m0s for pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" in namespace "var-expansion-8032" to be "running"
Nov 26 13:35:41.136: INFO: Pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.629787ms
Nov 26 13:35:43.142: INFO: Pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a": Phase="Running", Reason="", readiness=true. Elapsed: 2.014944821s
Nov 26 13:35:43.143: INFO: Pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" satisfied condition "running"
STEP: creating a file in subpath 11/26/22 13:35:43.143
Nov 26 13:35:43.147: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-8032 PodName:var-expansion-b427d169-2df2-439d-b215-df4057660b4a ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 13:35:43.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 13:35:43.149: INFO: ExecWithOptions: Clientset creation
Nov 26 13:35:43.150: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-8032/pods/var-expansion-b427d169-2df2-439d-b215-df4057660b4a/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 11/26/22 13:35:43.246
Nov 26 13:35:43.251: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-8032 PodName:var-expansion-b427d169-2df2-439d-b215-df4057660b4a ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov 26 13:35:43.252: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
Nov 26 13:35:43.252: INFO: ExecWithOptions: Clientset creation
Nov 26 13:35:43.252: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-8032/pods/var-expansion-b427d169-2df2-439d-b215-df4057660b4a/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 11/26/22 13:35:43.326
Nov 26 13:35:43.843: INFO: Successfully updated pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a"
STEP: waiting for annotated pod running 11/26/22 13:35:43.843
Nov 26 13:35:43.843: INFO: Waiting up to 2m0s for pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" in namespace "var-expansion-8032" to be "running"
Nov 26 13:35:43.848: INFO: Pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a": Phase="Running", Reason="", readiness=true. Elapsed: 5.102898ms
Nov 26 13:35:43.848: INFO: Pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" satisfied condition "running"
STEP: deleting the pod gracefully 11/26/22 13:35:43.848
Nov 26 13:35:43.848: INFO: Deleting pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" in namespace "var-expansion-8032"
Nov 26 13:35:43.859: INFO: Wait up to 5m0s for pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov 26 13:36:17.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8032" for this suite. 11/26/22 13:36:17.878
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":359,"skipped":6661,"failed":0}
------------------------------
â€¢ [SLOW TEST] [36.830 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:35:41.059
    Nov 26 13:35:41.059: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename var-expansion 11/26/22 13:35:41.06
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:35:41.098
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:35:41.105
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 11/26/22 13:35:41.112
    STEP: waiting for pod running 11/26/22 13:35:41.127
    Nov 26 13:35:41.128: INFO: Waiting up to 2m0s for pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" in namespace "var-expansion-8032" to be "running"
    Nov 26 13:35:41.136: INFO: Pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.629787ms
    Nov 26 13:35:43.142: INFO: Pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a": Phase="Running", Reason="", readiness=true. Elapsed: 2.014944821s
    Nov 26 13:35:43.143: INFO: Pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" satisfied condition "running"
    STEP: creating a file in subpath 11/26/22 13:35:43.143
    Nov 26 13:35:43.147: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-8032 PodName:var-expansion-b427d169-2df2-439d-b215-df4057660b4a ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 13:35:43.148: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 13:35:43.149: INFO: ExecWithOptions: Clientset creation
    Nov 26 13:35:43.150: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-8032/pods/var-expansion-b427d169-2df2-439d-b215-df4057660b4a/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 11/26/22 13:35:43.246
    Nov 26 13:35:43.251: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-8032 PodName:var-expansion-b427d169-2df2-439d-b215-df4057660b4a ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov 26 13:35:43.252: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    Nov 26 13:35:43.252: INFO: ExecWithOptions: Clientset creation
    Nov 26 13:35:43.252: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-8032/pods/var-expansion-b427d169-2df2-439d-b215-df4057660b4a/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 11/26/22 13:35:43.326
    Nov 26 13:35:43.843: INFO: Successfully updated pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a"
    STEP: waiting for annotated pod running 11/26/22 13:35:43.843
    Nov 26 13:35:43.843: INFO: Waiting up to 2m0s for pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" in namespace "var-expansion-8032" to be "running"
    Nov 26 13:35:43.848: INFO: Pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a": Phase="Running", Reason="", readiness=true. Elapsed: 5.102898ms
    Nov 26 13:35:43.848: INFO: Pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" satisfied condition "running"
    STEP: deleting the pod gracefully 11/26/22 13:35:43.848
    Nov 26 13:35:43.848: INFO: Deleting pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" in namespace "var-expansion-8032"
    Nov 26 13:35:43.859: INFO: Wait up to 5m0s for pod "var-expansion-b427d169-2df2-439d-b215-df4057660b4a" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov 26 13:36:17.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-8032" for this suite. 11/26/22 13:36:17.878
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:36:17.892
Nov 26 13:36:17.892: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename lease-test 11/26/22 13:36:17.893
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:36:17.925
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:36:17.937
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Nov 26 13:36:18.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-5501" for this suite. 11/26/22 13:36:18.041
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":360,"skipped":6667,"failed":0}
------------------------------
â€¢ [0.160 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:36:17.892
    Nov 26 13:36:17.892: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename lease-test 11/26/22 13:36:17.893
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:36:17.925
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:36:17.937
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Nov 26 13:36:18.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-5501" for this suite. 11/26/22 13:36:18.041
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:36:18.055
Nov 26 13:36:18.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename downward-api 11/26/22 13:36:18.056
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:36:18.081
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:36:18.086
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 11/26/22 13:36:18.093
Nov 26 13:36:18.111: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de" in namespace "downward-api-8194" to be "Succeeded or Failed"
Nov 26 13:36:18.122: INFO: Pod "downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de": Phase="Pending", Reason="", readiness=false. Elapsed: 10.51764ms
Nov 26 13:36:20.127: INFO: Pod "downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015869421s
Nov 26 13:36:22.128: INFO: Pod "downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016931829s
STEP: Saw pod success 11/26/22 13:36:22.128
Nov 26 13:36:22.128: INFO: Pod "downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de" satisfied condition "Succeeded or Failed"
Nov 26 13:36:22.132: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de container client-container: <nil>
STEP: delete the pod 11/26/22 13:36:22.141
Nov 26 13:36:22.160: INFO: Waiting for pod downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de to disappear
Nov 26 13:36:22.165: INFO: Pod downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov 26 13:36:22.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8194" for this suite. 11/26/22 13:36:22.17
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":361,"skipped":6697,"failed":0}
------------------------------
â€¢ [4.124 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:36:18.055
    Nov 26 13:36:18.055: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename downward-api 11/26/22 13:36:18.056
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:36:18.081
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:36:18.086
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 11/26/22 13:36:18.093
    Nov 26 13:36:18.111: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de" in namespace "downward-api-8194" to be "Succeeded or Failed"
    Nov 26 13:36:18.122: INFO: Pod "downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de": Phase="Pending", Reason="", readiness=false. Elapsed: 10.51764ms
    Nov 26 13:36:20.127: INFO: Pod "downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015869421s
    Nov 26 13:36:22.128: INFO: Pod "downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016931829s
    STEP: Saw pod success 11/26/22 13:36:22.128
    Nov 26 13:36:22.128: INFO: Pod "downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de" satisfied condition "Succeeded or Failed"
    Nov 26 13:36:22.132: INFO: Trying to get logs from node ip-172-31-43-82 pod downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de container client-container: <nil>
    STEP: delete the pod 11/26/22 13:36:22.141
    Nov 26 13:36:22.160: INFO: Waiting for pod downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de to disappear
    Nov 26 13:36:22.165: INFO: Pod downwardapi-volume-4ea31ef6-1fc6-4b23-b054-9630b0d9c5de no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov 26 13:36:22.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-8194" for this suite. 11/26/22 13:36:22.17
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/26/22 13:36:22.18
Nov 26 13:36:22.180: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
STEP: Building a namespace api object, basename job 11/26/22 13:36:22.181
STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:36:22.211
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:36:22.218
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 11/26/22 13:36:22.222
STEP: Ensuring job reaches completions 11/26/22 13:36:22.23
STEP: Ensuring pods with index for job exist 11/26/22 13:36:32.236
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov 26 13:36:32.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9246" for this suite. 11/26/22 13:36:32.247
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":362,"skipped":6702,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.077 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/26/22 13:36:22.18
    Nov 26 13:36:22.180: INFO: >>> kubeConfig: /tmp/kubeconfig-2065173477
    STEP: Building a namespace api object, basename job 11/26/22 13:36:22.181
    STEP: Waiting for a default service account to be provisioned in namespace 11/26/22 13:36:22.211
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/26/22 13:36:22.218
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 11/26/22 13:36:22.222
    STEP: Ensuring job reaches completions 11/26/22 13:36:22.23
    STEP: Ensuring pods with index for job exist 11/26/22 13:36:32.236
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov 26 13:36:32.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-9246" for this suite. 11/26/22 13:36:32.247
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Nov 26 13:36:32.259: INFO: Running AfterSuite actions on all nodes
Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Nov 26 13:36:32.259: INFO: Running AfterSuite actions on node 1
Nov 26 13:36:32.259: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Nov 26 13:36:32.259: INFO: Running AfterSuite actions on all nodes
    Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Nov 26 13:36:32.259: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Nov 26 13:36:32.259: INFO: Running AfterSuite actions on node 1
    Nov 26 13:36:32.259: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.106 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 5857.960 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h37m38.821779045s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

