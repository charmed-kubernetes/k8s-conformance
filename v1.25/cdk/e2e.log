I1105 11:55:30.639816      20 e2e.go:116] Starting e2e run "3a293453-f0e8-4f41-81b6-1bd47eee4a98" on Ginkgo node 1
Nov  5 11:55:30.650: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1667649330 - will randomize all specs

Will run 362 of 7067 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Nov  5 11:55:30.800: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:55:30.801: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov  5 11:55:30.817: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov  5 11:55:30.835: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov  5 11:55:30.835: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
Nov  5 11:55:30.835: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov  5 11:55:30.839: INFO: e2e test version: v1.25.3
Nov  5 11:55:30.841: INFO: kube-apiserver version: v1.25.3
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Nov  5 11:55:30.841: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:55:30.846: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.050 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Nov  5 11:55:30.800: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:55:30.801: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Nov  5 11:55:30.817: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Nov  5 11:55:30.835: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Nov  5 11:55:30.835: INFO: expected 4 pod replicas in namespace 'kube-system', 4 are Running and Ready.
    Nov  5 11:55:30.835: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Nov  5 11:55:30.839: INFO: e2e test version: v1.25.3
    Nov  5 11:55:30.841: INFO: kube-apiserver version: v1.25.3
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Nov  5 11:55:30.841: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:55:30.846: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:55:30.875
Nov  5 11:55:30.875: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 11:55:30.876
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:55:30.903
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:55:30.909
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-5136 11/05/22 11:55:30.912
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5136 to expose endpoints map[] 11/05/22 11:55:30.932
Nov  5 11:55:30.935: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Nov  5 11:55:31.945: INFO: successfully validated that service multi-endpoint-test in namespace services-5136 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-5136 11/05/22 11:55:31.945
Nov  5 11:55:31.955: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5136" to be "running and ready"
Nov  5 11:55:31.957: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.754472ms
Nov  5 11:55:31.957: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:33.963: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008026753s
Nov  5 11:55:33.963: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:35.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00738778s
Nov  5 11:55:35.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:37.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006914674s
Nov  5 11:55:37.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:39.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.007484444s
Nov  5 11:55:39.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:41.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007063294s
Nov  5 11:55:41.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:43.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.006883176s
Nov  5 11:55:43.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:45.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007595478s
Nov  5 11:55:45.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:47.962: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 16.007316279s
Nov  5 11:55:47.962: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov  5 11:55:47.962: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5136 to expose endpoints map[pod1:[100]] 11/05/22 11:55:47.965
Nov  5 11:55:47.976: INFO: successfully validated that service multi-endpoint-test in namespace services-5136 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-5136 11/05/22 11:55:47.976
Nov  5 11:55:47.982: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5136" to be "running and ready"
Nov  5 11:55:47.985: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.230572ms
Nov  5 11:55:47.985: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:49.990: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007488676s
Nov  5 11:55:49.990: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:51.989: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006670258s
Nov  5 11:55:51.989: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:55:53.990: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 6.007734943s
Nov  5 11:55:53.990: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov  5 11:55:53.990: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5136 to expose endpoints map[pod1:[100] pod2:[101]] 11/05/22 11:55:53.993
Nov  5 11:55:54.007: INFO: successfully validated that service multi-endpoint-test in namespace services-5136 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 11/05/22 11:55:54.007
Nov  5 11:55:54.007: INFO: Creating new exec pod
Nov  5 11:55:54.012: INFO: Waiting up to 5m0s for pod "execpodlf767" in namespace "services-5136" to be "running"
Nov  5 11:55:54.015: INFO: Pod "execpodlf767": Phase="Pending", Reason="", readiness=false. Elapsed: 3.239863ms
Nov  5 11:55:56.019: INFO: Pod "execpodlf767": Phase="Running", Reason="", readiness=true. Elapsed: 2.007552525s
Nov  5 11:55:56.020: INFO: Pod "execpodlf767" satisfied condition "running"
Nov  5 11:55:57.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5136 exec execpodlf767 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Nov  5 11:55:57.196: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Nov  5 11:55:57.196: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 11:55:57.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5136 exec execpodlf767 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.38 80'
Nov  5 11:55:57.312: INFO: stderr: "+ nc -v -t -w 2 10.152.183.38 80\nConnection to 10.152.183.38 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Nov  5 11:55:57.312: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 11:55:57.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5136 exec execpodlf767 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Nov  5 11:55:57.433: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Nov  5 11:55:57.433: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 11:55:57.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5136 exec execpodlf767 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.38 81'
Nov  5 11:55:57.543: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.38 81\nConnection to 10.152.183.38 81 port [tcp/*] succeeded!\n"
Nov  5 11:55:57.543: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-5136 11/05/22 11:55:57.543
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5136 to expose endpoints map[pod2:[101]] 11/05/22 11:55:57.561
Nov  5 11:55:57.573: INFO: successfully validated that service multi-endpoint-test in namespace services-5136 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-5136 11/05/22 11:55:57.573
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5136 to expose endpoints map[] 11/05/22 11:55:57.584
Nov  5 11:55:58.602: INFO: successfully validated that service multi-endpoint-test in namespace services-5136 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 11:55:58.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5136" for this suite. 11/05/22 11:55:58.624
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":1,"skipped":9,"failed":0}
------------------------------
• [SLOW TEST] [27.756 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:55:30.875
    Nov  5 11:55:30.875: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 11:55:30.876
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:55:30.903
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:55:30.909
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-5136 11/05/22 11:55:30.912
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5136 to expose endpoints map[] 11/05/22 11:55:30.932
    Nov  5 11:55:30.935: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
    Nov  5 11:55:31.945: INFO: successfully validated that service multi-endpoint-test in namespace services-5136 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-5136 11/05/22 11:55:31.945
    Nov  5 11:55:31.955: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-5136" to be "running and ready"
    Nov  5 11:55:31.957: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.754472ms
    Nov  5 11:55:31.957: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:33.963: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008026753s
    Nov  5 11:55:33.963: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:35.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00738778s
    Nov  5 11:55:35.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:37.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.006914674s
    Nov  5 11:55:37.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:39.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.007484444s
    Nov  5 11:55:39.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:41.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007063294s
    Nov  5 11:55:41.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:43.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.006883176s
    Nov  5 11:55:43.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:45.962: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.007595478s
    Nov  5 11:55:45.962: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:47.962: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 16.007316279s
    Nov  5 11:55:47.962: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov  5 11:55:47.962: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5136 to expose endpoints map[pod1:[100]] 11/05/22 11:55:47.965
    Nov  5 11:55:47.976: INFO: successfully validated that service multi-endpoint-test in namespace services-5136 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-5136 11/05/22 11:55:47.976
    Nov  5 11:55:47.982: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-5136" to be "running and ready"
    Nov  5 11:55:47.985: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.230572ms
    Nov  5 11:55:47.985: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:49.990: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007488676s
    Nov  5 11:55:49.990: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:51.989: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006670258s
    Nov  5 11:55:51.989: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:55:53.990: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 6.007734943s
    Nov  5 11:55:53.990: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov  5 11:55:53.990: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5136 to expose endpoints map[pod1:[100] pod2:[101]] 11/05/22 11:55:53.993
    Nov  5 11:55:54.007: INFO: successfully validated that service multi-endpoint-test in namespace services-5136 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 11/05/22 11:55:54.007
    Nov  5 11:55:54.007: INFO: Creating new exec pod
    Nov  5 11:55:54.012: INFO: Waiting up to 5m0s for pod "execpodlf767" in namespace "services-5136" to be "running"
    Nov  5 11:55:54.015: INFO: Pod "execpodlf767": Phase="Pending", Reason="", readiness=false. Elapsed: 3.239863ms
    Nov  5 11:55:56.019: INFO: Pod "execpodlf767": Phase="Running", Reason="", readiness=true. Elapsed: 2.007552525s
    Nov  5 11:55:56.020: INFO: Pod "execpodlf767" satisfied condition "running"
    Nov  5 11:55:57.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5136 exec execpodlf767 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Nov  5 11:55:57.196: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Nov  5 11:55:57.196: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 11:55:57.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5136 exec execpodlf767 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.38 80'
    Nov  5 11:55:57.312: INFO: stderr: "+ nc -v -t -w 2 10.152.183.38 80\nConnection to 10.152.183.38 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Nov  5 11:55:57.312: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 11:55:57.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5136 exec execpodlf767 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Nov  5 11:55:57.433: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Nov  5 11:55:57.433: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 11:55:57.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5136 exec execpodlf767 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.38 81'
    Nov  5 11:55:57.543: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.38 81\nConnection to 10.152.183.38 81 port [tcp/*] succeeded!\n"
    Nov  5 11:55:57.543: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-5136 11/05/22 11:55:57.543
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5136 to expose endpoints map[pod2:[101]] 11/05/22 11:55:57.561
    Nov  5 11:55:57.573: INFO: successfully validated that service multi-endpoint-test in namespace services-5136 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-5136 11/05/22 11:55:57.573
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5136 to expose endpoints map[] 11/05/22 11:55:57.584
    Nov  5 11:55:58.602: INFO: successfully validated that service multi-endpoint-test in namespace services-5136 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 11:55:58.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5136" for this suite. 11/05/22 11:55:58.624
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:55:58.632
Nov  5 11:55:58.632: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 11:55:58.633
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:55:58.659
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:55:58.662
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 11:55:58.681
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 11:55:59.161
STEP: Deploying the webhook pod 11/05/22 11:55:59.169
STEP: Wait for the deployment to be ready 11/05/22 11:55:59.182
Nov  5 11:55:59.190: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 11:56:01.201
STEP: Verifying the service has paired with the endpoint 11/05/22 11:56:01.211
Nov  5 11:56:02.211: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 11/05/22 11:56:02.215
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 11/05/22 11:56:02.216
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 11/05/22 11:56:02.217
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 11/05/22 11:56:02.217
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 11/05/22 11:56:02.218
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 11/05/22 11:56:02.218
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 11/05/22 11:56:02.219
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 11:56:02.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1747" for this suite. 11/05/22 11:56:02.224
STEP: Destroying namespace "webhook-1747-markers" for this suite. 11/05/22 11:56:02.231
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":2,"skipped":31,"failed":0}
------------------------------
• [3.641 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:55:58.632
    Nov  5 11:55:58.632: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 11:55:58.633
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:55:58.659
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:55:58.662
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 11:55:58.681
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 11:55:59.161
    STEP: Deploying the webhook pod 11/05/22 11:55:59.169
    STEP: Wait for the deployment to be ready 11/05/22 11:55:59.182
    Nov  5 11:55:59.190: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 11:56:01.201
    STEP: Verifying the service has paired with the endpoint 11/05/22 11:56:01.211
    Nov  5 11:56:02.211: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 11/05/22 11:56:02.215
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 11/05/22 11:56:02.216
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 11/05/22 11:56:02.217
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 11/05/22 11:56:02.217
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 11/05/22 11:56:02.218
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 11/05/22 11:56:02.218
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 11/05/22 11:56:02.219
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 11:56:02.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1747" for this suite. 11/05/22 11:56:02.224
    STEP: Destroying namespace "webhook-1747-markers" for this suite. 11/05/22 11:56:02.231
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:56:02.275
Nov  5 11:56:02.275: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename namespaces 11/05/22 11:56:02.276
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:02.3
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:02.303
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 11/05/22 11:56:02.306
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:02.322
STEP: Creating a pod in the namespace 11/05/22 11:56:02.325
STEP: Waiting for the pod to have running status 11/05/22 11:56:02.333
Nov  5 11:56:02.333: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-8430" to be "running"
Nov  5 11:56:02.337: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.627545ms
Nov  5 11:56:04.341: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007684941s
Nov  5 11:56:04.341: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 11/05/22 11:56:04.341
STEP: Waiting for the namespace to be removed. 11/05/22 11:56:04.347
STEP: Recreating the namespace 11/05/22 11:56:15.351
STEP: Verifying there are no pods in the namespace 11/05/22 11:56:15.368
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov  5 11:56:15.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5162" for this suite. 11/05/22 11:56:15.376
STEP: Destroying namespace "nsdeletetest-8430" for this suite. 11/05/22 11:56:15.381
Nov  5 11:56:15.385: INFO: Namespace nsdeletetest-8430 was already deleted
STEP: Destroying namespace "nsdeletetest-9194" for this suite. 11/05/22 11:56:15.385
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":3,"skipped":41,"failed":0}
------------------------------
• [SLOW TEST] [13.117 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:56:02.275
    Nov  5 11:56:02.275: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename namespaces 11/05/22 11:56:02.276
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:02.3
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:02.303
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 11/05/22 11:56:02.306
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:02.322
    STEP: Creating a pod in the namespace 11/05/22 11:56:02.325
    STEP: Waiting for the pod to have running status 11/05/22 11:56:02.333
    Nov  5 11:56:02.333: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-8430" to be "running"
    Nov  5 11:56:02.337: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.627545ms
    Nov  5 11:56:04.341: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007684941s
    Nov  5 11:56:04.341: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 11/05/22 11:56:04.341
    STEP: Waiting for the namespace to be removed. 11/05/22 11:56:04.347
    STEP: Recreating the namespace 11/05/22 11:56:15.351
    STEP: Verifying there are no pods in the namespace 11/05/22 11:56:15.368
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 11:56:15.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-5162" for this suite. 11/05/22 11:56:15.376
    STEP: Destroying namespace "nsdeletetest-8430" for this suite. 11/05/22 11:56:15.381
    Nov  5 11:56:15.385: INFO: Namespace nsdeletetest-8430 was already deleted
    STEP: Destroying namespace "nsdeletetest-9194" for this suite. 11/05/22 11:56:15.385
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:56:15.394
Nov  5 11:56:15.394: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename dns 11/05/22 11:56:15.395
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:15.41
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:15.413
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 11/05/22 11:56:15.417
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1429.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1429.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 11/05/22 11:56:15.422
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1429.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1429.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 11/05/22 11:56:15.422
STEP: creating a pod to probe DNS 11/05/22 11:56:15.422
STEP: submitting the pod to kubernetes 11/05/22 11:56:15.422
Nov  5 11:56:15.443: INFO: Waiting up to 15m0s for pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc" in namespace "dns-1429" to be "running"
Nov  5 11:56:15.447: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.22214ms
Nov  5 11:56:17.451: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007738184s
Nov  5 11:56:19.452: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008756412s
Nov  5 11:56:21.451: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007413014s
Nov  5 11:56:23.451: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.007961478s
Nov  5 11:56:25.451: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007577668s
Nov  5 11:56:27.452: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.008569836s
Nov  5 11:56:29.452: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 14.008466146s
Nov  5 11:56:31.450: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 16.00672297s
Nov  5 11:56:33.452: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Running", Reason="", readiness=true. Elapsed: 18.008206084s
Nov  5 11:56:33.452: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc" satisfied condition "running"
STEP: retrieving the pod 11/05/22 11:56:33.452
STEP: looking for the results for each expected name from probers 11/05/22 11:56:33.454
Nov  5 11:56:33.469: INFO: DNS probes using dns-1429/dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc succeeded

STEP: deleting the pod 11/05/22 11:56:33.469
STEP: deleting the test headless service 11/05/22 11:56:33.486
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov  5 11:56:33.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1429" for this suite. 11/05/22 11:56:33.505
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":4,"skipped":62,"failed":0}
------------------------------
• [SLOW TEST] [18.116 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:56:15.394
    Nov  5 11:56:15.394: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename dns 11/05/22 11:56:15.395
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:15.41
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:15.413
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 11/05/22 11:56:15.417
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1429.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1429.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     11/05/22 11:56:15.422
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1429.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1429.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     11/05/22 11:56:15.422
    STEP: creating a pod to probe DNS 11/05/22 11:56:15.422
    STEP: submitting the pod to kubernetes 11/05/22 11:56:15.422
    Nov  5 11:56:15.443: INFO: Waiting up to 15m0s for pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc" in namespace "dns-1429" to be "running"
    Nov  5 11:56:15.447: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.22214ms
    Nov  5 11:56:17.451: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007738184s
    Nov  5 11:56:19.452: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008756412s
    Nov  5 11:56:21.451: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007413014s
    Nov  5 11:56:23.451: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.007961478s
    Nov  5 11:56:25.451: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.007577668s
    Nov  5 11:56:27.452: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.008569836s
    Nov  5 11:56:29.452: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 14.008466146s
    Nov  5 11:56:31.450: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Pending", Reason="", readiness=false. Elapsed: 16.00672297s
    Nov  5 11:56:33.452: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc": Phase="Running", Reason="", readiness=true. Elapsed: 18.008206084s
    Nov  5 11:56:33.452: INFO: Pod "dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc" satisfied condition "running"
    STEP: retrieving the pod 11/05/22 11:56:33.452
    STEP: looking for the results for each expected name from probers 11/05/22 11:56:33.454
    Nov  5 11:56:33.469: INFO: DNS probes using dns-1429/dns-test-83ee32da-4d79-4245-a91a-a7fb562c04bc succeeded

    STEP: deleting the pod 11/05/22 11:56:33.469
    STEP: deleting the test headless service 11/05/22 11:56:33.486
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov  5 11:56:33.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1429" for this suite. 11/05/22 11:56:33.505
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:56:33.511
Nov  5 11:56:33.511: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename var-expansion 11/05/22 11:56:33.512
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:33.527
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:33.531
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 11/05/22 11:56:33.534
Nov  5 11:56:33.540: INFO: Waiting up to 5m0s for pod "var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e" in namespace "var-expansion-3492" to be "Succeeded or Failed"
Nov  5 11:56:33.543: INFO: Pod "var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.202698ms
Nov  5 11:56:35.548: INFO: Pod "var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007894456s
Nov  5 11:56:37.549: INFO: Pod "var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00847974s
STEP: Saw pod success 11/05/22 11:56:37.549
Nov  5 11:56:37.549: INFO: Pod "var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e" satisfied condition "Succeeded or Failed"
Nov  5 11:56:37.552: INFO: Trying to get logs from node ip-172-31-0-255 pod var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e container dapi-container: <nil>
STEP: delete the pod 11/05/22 11:56:37.567
Nov  5 11:56:37.578: INFO: Waiting for pod var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e to disappear
Nov  5 11:56:37.581: INFO: Pod var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov  5 11:56:37.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3492" for this suite. 11/05/22 11:56:37.585
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":5,"skipped":68,"failed":0}
------------------------------
• [4.079 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:56:33.511
    Nov  5 11:56:33.511: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename var-expansion 11/05/22 11:56:33.512
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:33.527
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:33.531
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 11/05/22 11:56:33.534
    Nov  5 11:56:33.540: INFO: Waiting up to 5m0s for pod "var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e" in namespace "var-expansion-3492" to be "Succeeded or Failed"
    Nov  5 11:56:33.543: INFO: Pod "var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.202698ms
    Nov  5 11:56:35.548: INFO: Pod "var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007894456s
    Nov  5 11:56:37.549: INFO: Pod "var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00847974s
    STEP: Saw pod success 11/05/22 11:56:37.549
    Nov  5 11:56:37.549: INFO: Pod "var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e" satisfied condition "Succeeded or Failed"
    Nov  5 11:56:37.552: INFO: Trying to get logs from node ip-172-31-0-255 pod var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e container dapi-container: <nil>
    STEP: delete the pod 11/05/22 11:56:37.567
    Nov  5 11:56:37.578: INFO: Waiting for pod var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e to disappear
    Nov  5 11:56:37.581: INFO: Pod var-expansion-a4d7b1af-5841-4ae1-acc2-d2b3838f8a0e no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov  5 11:56:37.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3492" for this suite. 11/05/22 11:56:37.585
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:56:37.593
Nov  5 11:56:37.593: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 11:56:37.594
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:37.611
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:37.614
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 11/05/22 11:56:37.618
Nov  5 11:56:37.626: INFO: Waiting up to 5m0s for pod "downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91" in namespace "downward-api-66" to be "Succeeded or Failed"
Nov  5 11:56:37.629: INFO: Pod "downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.477825ms
Nov  5 11:56:39.633: INFO: Pod "downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006875796s
Nov  5 11:56:41.632: INFO: Pod "downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005532224s
STEP: Saw pod success 11/05/22 11:56:41.632
Nov  5 11:56:41.632: INFO: Pod "downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91" satisfied condition "Succeeded or Failed"
Nov  5 11:56:41.635: INFO: Trying to get logs from node ip-172-31-0-255 pod downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91 container dapi-container: <nil>
STEP: delete the pod 11/05/22 11:56:41.641
Nov  5 11:56:41.652: INFO: Waiting for pod downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91 to disappear
Nov  5 11:56:41.655: INFO: Pod downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov  5 11:56:41.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-66" for this suite. 11/05/22 11:56:41.658
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":6,"skipped":122,"failed":0}
------------------------------
• [4.070 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:56:37.593
    Nov  5 11:56:37.593: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 11:56:37.594
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:37.611
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:37.614
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 11/05/22 11:56:37.618
    Nov  5 11:56:37.626: INFO: Waiting up to 5m0s for pod "downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91" in namespace "downward-api-66" to be "Succeeded or Failed"
    Nov  5 11:56:37.629: INFO: Pod "downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.477825ms
    Nov  5 11:56:39.633: INFO: Pod "downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006875796s
    Nov  5 11:56:41.632: INFO: Pod "downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005532224s
    STEP: Saw pod success 11/05/22 11:56:41.632
    Nov  5 11:56:41.632: INFO: Pod "downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91" satisfied condition "Succeeded or Failed"
    Nov  5 11:56:41.635: INFO: Trying to get logs from node ip-172-31-0-255 pod downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91 container dapi-container: <nil>
    STEP: delete the pod 11/05/22 11:56:41.641
    Nov  5 11:56:41.652: INFO: Waiting for pod downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91 to disappear
    Nov  5 11:56:41.655: INFO: Pod downward-api-d61c7b7d-f136-4b7c-b97b-f316c5eafa91 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov  5 11:56:41.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-66" for this suite. 11/05/22 11:56:41.658
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:56:41.663
Nov  5 11:56:41.663: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 11:56:41.664
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:41.679
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:41.682
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 11/05/22 11:56:41.685
STEP: Creating a ResourceQuota 11/05/22 11:56:46.689
STEP: Ensuring resource quota status is calculated 11/05/22 11:56:46.696
STEP: Creating a ReplicationController 11/05/22 11:56:48.699
STEP: Ensuring resource quota status captures replication controller creation 11/05/22 11:56:48.712
STEP: Deleting a ReplicationController 11/05/22 11:56:50.716
STEP: Ensuring resource quota status released usage 11/05/22 11:56:50.723
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 11:56:52.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-125" for this suite. 11/05/22 11:56:52.73
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":7,"skipped":122,"failed":0}
------------------------------
• [SLOW TEST] [11.073 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:56:41.663
    Nov  5 11:56:41.663: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 11:56:41.664
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:41.679
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:41.682
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 11/05/22 11:56:41.685
    STEP: Creating a ResourceQuota 11/05/22 11:56:46.689
    STEP: Ensuring resource quota status is calculated 11/05/22 11:56:46.696
    STEP: Creating a ReplicationController 11/05/22 11:56:48.699
    STEP: Ensuring resource quota status captures replication controller creation 11/05/22 11:56:48.712
    STEP: Deleting a ReplicationController 11/05/22 11:56:50.716
    STEP: Ensuring resource quota status released usage 11/05/22 11:56:50.723
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 11:56:52.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-125" for this suite. 11/05/22 11:56:52.73
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:56:52.737
Nov  5 11:56:52.737: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename job 11/05/22 11:56:52.738
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:52.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:52.761
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 11/05/22 11:56:52.767
STEP: Patching the Job 11/05/22 11:56:52.773
STEP: Watching for Job to be patched 11/05/22 11:56:52.781
Nov  5 11:56:52.782: INFO: Event ADDED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr] and annotations: map[batch.kubernetes.io/job-tracking:]
Nov  5 11:56:52.782: INFO: Event MODIFIED found for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 11/05/22 11:56:52.782
STEP: Watching for Job to be updated 11/05/22 11:56:52.791
Nov  5 11:56:52.793: INFO: Event MODIFIED found for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov  5 11:56:52.793: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 11/05/22 11:56:52.793
Nov  5 11:56:52.796: INFO: Job: e2e-sgvxr as labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched]
STEP: Waiting for job to complete 11/05/22 11:56:52.796
STEP: Delete a job collection with a labelselector 11/05/22 11:57:02.802
STEP: Watching for Job to be deleted 11/05/22 11:57:02.81
Nov  5 11:57:02.812: INFO: Event MODIFIED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov  5 11:57:02.812: INFO: Event MODIFIED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov  5 11:57:02.812: INFO: Event MODIFIED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov  5 11:57:02.812: INFO: Event MODIFIED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov  5 11:57:02.812: INFO: Event MODIFIED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Nov  5 11:57:02.812: INFO: Event DELETED found for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 11/05/22 11:57:02.812
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov  5 11:57:02.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7366" for this suite. 11/05/22 11:57:02.82
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":8,"skipped":146,"failed":0}
------------------------------
• [SLOW TEST] [10.091 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:56:52.737
    Nov  5 11:56:52.737: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename job 11/05/22 11:56:52.738
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:56:52.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:56:52.761
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 11/05/22 11:56:52.767
    STEP: Patching the Job 11/05/22 11:56:52.773
    STEP: Watching for Job to be patched 11/05/22 11:56:52.781
    Nov  5 11:56:52.782: INFO: Event ADDED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr] and annotations: map[batch.kubernetes.io/job-tracking:]
    Nov  5 11:56:52.782: INFO: Event MODIFIED found for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 11/05/22 11:56:52.782
    STEP: Watching for Job to be updated 11/05/22 11:56:52.791
    Nov  5 11:56:52.793: INFO: Event MODIFIED found for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov  5 11:56:52.793: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 11/05/22 11:56:52.793
    Nov  5 11:56:52.796: INFO: Job: e2e-sgvxr as labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched]
    STEP: Waiting for job to complete 11/05/22 11:56:52.796
    STEP: Delete a job collection with a labelselector 11/05/22 11:57:02.802
    STEP: Watching for Job to be deleted 11/05/22 11:57:02.81
    Nov  5 11:57:02.812: INFO: Event MODIFIED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov  5 11:57:02.812: INFO: Event MODIFIED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov  5 11:57:02.812: INFO: Event MODIFIED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov  5 11:57:02.812: INFO: Event MODIFIED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov  5 11:57:02.812: INFO: Event MODIFIED observed for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Nov  5 11:57:02.812: INFO: Event DELETED found for Job e2e-sgvxr in namespace job-7366 with labels: map[e2e-job-label:e2e-sgvxr e2e-sgvxr:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 11/05/22 11:57:02.812
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov  5 11:57:02.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-7366" for this suite. 11/05/22 11:57:02.82
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:57:02.828
Nov  5 11:57:02.828: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename tables 11/05/22 11:57:02.829
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:57:02.862
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:57:02.867
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Nov  5 11:57:02.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9953" for this suite. 11/05/22 11:57:02.88
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":9,"skipped":148,"failed":0}
------------------------------
• [0.058 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:57:02.828
    Nov  5 11:57:02.828: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename tables 11/05/22 11:57:02.829
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:57:02.862
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:57:02.867
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Nov  5 11:57:02.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-9953" for this suite. 11/05/22 11:57:02.88
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:57:02.888
Nov  5 11:57:02.888: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename taint-multiple-pods 11/05/22 11:57:02.889
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:57:02.907
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:57:02.912
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Nov  5 11:57:02.916: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  5 11:58:02.932: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Nov  5 11:58:02.936: INFO: Starting informer...
STEP: Starting pods... 11/05/22 11:58:02.936
Nov  5 11:58:03.153: INFO: Pod1 is running on ip-172-31-0-255. Tainting Node
Nov  5 11:58:03.366: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-4517" to be "running"
Nov  5 11:58:03.369: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.64297ms
Nov  5 11:58:05.373: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.00603544s
Nov  5 11:58:05.373: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Nov  5 11:58:05.373: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-4517" to be "running"
Nov  5 11:58:05.376: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 3.854744ms
Nov  5 11:58:05.376: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Nov  5 11:58:05.376: INFO: Pod2 is running on ip-172-31-0-255. Tainting Node
STEP: Trying to apply a taint on the Node 11/05/22 11:58:05.376
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/05/22 11:58:05.386
STEP: Waiting for Pod1 and Pod2 to be deleted 11/05/22 11:58:05.39
Nov  5 11:58:11.174: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov  5 11:58:31.203: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/05/22 11:58:31.212
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Nov  5 11:58:31.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-4517" for this suite. 11/05/22 11:58:31.234
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":10,"skipped":179,"failed":0}
------------------------------
• [SLOW TEST] [88.354 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:57:02.888
    Nov  5 11:57:02.888: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename taint-multiple-pods 11/05/22 11:57:02.889
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:57:02.907
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:57:02.912
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Nov  5 11:57:02.916: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov  5 11:58:02.932: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Nov  5 11:58:02.936: INFO: Starting informer...
    STEP: Starting pods... 11/05/22 11:58:02.936
    Nov  5 11:58:03.153: INFO: Pod1 is running on ip-172-31-0-255. Tainting Node
    Nov  5 11:58:03.366: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-4517" to be "running"
    Nov  5 11:58:03.369: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.64297ms
    Nov  5 11:58:05.373: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.00603544s
    Nov  5 11:58:05.373: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Nov  5 11:58:05.373: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-4517" to be "running"
    Nov  5 11:58:05.376: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 3.854744ms
    Nov  5 11:58:05.376: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Nov  5 11:58:05.376: INFO: Pod2 is running on ip-172-31-0-255. Tainting Node
    STEP: Trying to apply a taint on the Node 11/05/22 11:58:05.376
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/05/22 11:58:05.386
    STEP: Waiting for Pod1 and Pod2 to be deleted 11/05/22 11:58:05.39
    Nov  5 11:58:11.174: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Nov  5 11:58:31.203: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/05/22 11:58:31.212
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 11:58:31.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-4517" for this suite. 11/05/22 11:58:31.234
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:58:31.244
Nov  5 11:58:31.244: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 11:58:31.244
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:31.269
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:31.273
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 11/05/22 11:58:31.276
Nov  5 11:58:31.284: INFO: Waiting up to 5m0s for pod "downward-api-fce62f58-745b-4226-9a7c-9154502fede8" in namespace "downward-api-3256" to be "Succeeded or Failed"
Nov  5 11:58:31.288: INFO: Pod "downward-api-fce62f58-745b-4226-9a7c-9154502fede8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.265223ms
Nov  5 11:58:33.292: INFO: Pod "downward-api-fce62f58-745b-4226-9a7c-9154502fede8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007380074s
Nov  5 11:58:35.292: INFO: Pod "downward-api-fce62f58-745b-4226-9a7c-9154502fede8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007382706s
STEP: Saw pod success 11/05/22 11:58:35.292
Nov  5 11:58:35.292: INFO: Pod "downward-api-fce62f58-745b-4226-9a7c-9154502fede8" satisfied condition "Succeeded or Failed"
Nov  5 11:58:35.295: INFO: Trying to get logs from node ip-172-31-0-255 pod downward-api-fce62f58-745b-4226-9a7c-9154502fede8 container dapi-container: <nil>
STEP: delete the pod 11/05/22 11:58:35.308
Nov  5 11:58:35.321: INFO: Waiting for pod downward-api-fce62f58-745b-4226-9a7c-9154502fede8 to disappear
Nov  5 11:58:35.324: INFO: Pod downward-api-fce62f58-745b-4226-9a7c-9154502fede8 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov  5 11:58:35.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3256" for this suite. 11/05/22 11:58:35.328
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":11,"skipped":188,"failed":0}
------------------------------
• [4.091 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:58:31.244
    Nov  5 11:58:31.244: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 11:58:31.244
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:31.269
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:31.273
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 11/05/22 11:58:31.276
    Nov  5 11:58:31.284: INFO: Waiting up to 5m0s for pod "downward-api-fce62f58-745b-4226-9a7c-9154502fede8" in namespace "downward-api-3256" to be "Succeeded or Failed"
    Nov  5 11:58:31.288: INFO: Pod "downward-api-fce62f58-745b-4226-9a7c-9154502fede8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.265223ms
    Nov  5 11:58:33.292: INFO: Pod "downward-api-fce62f58-745b-4226-9a7c-9154502fede8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007380074s
    Nov  5 11:58:35.292: INFO: Pod "downward-api-fce62f58-745b-4226-9a7c-9154502fede8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007382706s
    STEP: Saw pod success 11/05/22 11:58:35.292
    Nov  5 11:58:35.292: INFO: Pod "downward-api-fce62f58-745b-4226-9a7c-9154502fede8" satisfied condition "Succeeded or Failed"
    Nov  5 11:58:35.295: INFO: Trying to get logs from node ip-172-31-0-255 pod downward-api-fce62f58-745b-4226-9a7c-9154502fede8 container dapi-container: <nil>
    STEP: delete the pod 11/05/22 11:58:35.308
    Nov  5 11:58:35.321: INFO: Waiting for pod downward-api-fce62f58-745b-4226-9a7c-9154502fede8 to disappear
    Nov  5 11:58:35.324: INFO: Pod downward-api-fce62f58-745b-4226-9a7c-9154502fede8 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov  5 11:58:35.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3256" for this suite. 11/05/22 11:58:35.328
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:58:35.336
Nov  5 11:58:35.336: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 11:58:35.337
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:35.352
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:35.355
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 11/05/22 11:58:35.358
STEP: submitting the pod to kubernetes 11/05/22 11:58:35.358
STEP: verifying QOS class is set on the pod 11/05/22 11:58:35.366
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Nov  5 11:58:35.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-67" for this suite. 11/05/22 11:58:35.377
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":12,"skipped":221,"failed":0}
------------------------------
• [0.049 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:58:35.336
    Nov  5 11:58:35.336: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 11:58:35.337
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:35.352
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:35.355
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 11/05/22 11:58:35.358
    STEP: submitting the pod to kubernetes 11/05/22 11:58:35.358
    STEP: verifying QOS class is set on the pod 11/05/22 11:58:35.366
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Nov  5 11:58:35.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-67" for this suite. 11/05/22 11:58:35.377
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:58:35.385
Nov  5 11:58:35.386: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 11:58:35.386
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:35.402
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:35.405
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 11/05/22 11:58:35.408
Nov  5 11:58:35.415: INFO: Waiting up to 5m0s for pod "pod-430541fd-465d-41a7-967c-360e81c4a3ee" in namespace "emptydir-3416" to be "Succeeded or Failed"
Nov  5 11:58:35.418: INFO: Pod "pod-430541fd-465d-41a7-967c-360e81c4a3ee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.330436ms
Nov  5 11:58:37.422: INFO: Pod "pod-430541fd-465d-41a7-967c-360e81c4a3ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007090637s
Nov  5 11:58:39.424: INFO: Pod "pod-430541fd-465d-41a7-967c-360e81c4a3ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008999578s
STEP: Saw pod success 11/05/22 11:58:39.424
Nov  5 11:58:39.424: INFO: Pod "pod-430541fd-465d-41a7-967c-360e81c4a3ee" satisfied condition "Succeeded or Failed"
Nov  5 11:58:39.428: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-430541fd-465d-41a7-967c-360e81c4a3ee container test-container: <nil>
STEP: delete the pod 11/05/22 11:58:39.443
Nov  5 11:58:39.453: INFO: Waiting for pod pod-430541fd-465d-41a7-967c-360e81c4a3ee to disappear
Nov  5 11:58:39.456: INFO: Pod pod-430541fd-465d-41a7-967c-360e81c4a3ee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 11:58:39.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3416" for this suite. 11/05/22 11:58:39.46
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":13,"skipped":235,"failed":0}
------------------------------
• [4.080 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:58:35.385
    Nov  5 11:58:35.386: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 11:58:35.386
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:35.402
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:35.405
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 11/05/22 11:58:35.408
    Nov  5 11:58:35.415: INFO: Waiting up to 5m0s for pod "pod-430541fd-465d-41a7-967c-360e81c4a3ee" in namespace "emptydir-3416" to be "Succeeded or Failed"
    Nov  5 11:58:35.418: INFO: Pod "pod-430541fd-465d-41a7-967c-360e81c4a3ee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.330436ms
    Nov  5 11:58:37.422: INFO: Pod "pod-430541fd-465d-41a7-967c-360e81c4a3ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007090637s
    Nov  5 11:58:39.424: INFO: Pod "pod-430541fd-465d-41a7-967c-360e81c4a3ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008999578s
    STEP: Saw pod success 11/05/22 11:58:39.424
    Nov  5 11:58:39.424: INFO: Pod "pod-430541fd-465d-41a7-967c-360e81c4a3ee" satisfied condition "Succeeded or Failed"
    Nov  5 11:58:39.428: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-430541fd-465d-41a7-967c-360e81c4a3ee container test-container: <nil>
    STEP: delete the pod 11/05/22 11:58:39.443
    Nov  5 11:58:39.453: INFO: Waiting for pod pod-430541fd-465d-41a7-967c-360e81c4a3ee to disappear
    Nov  5 11:58:39.456: INFO: Pod pod-430541fd-465d-41a7-967c-360e81c4a3ee no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 11:58:39.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3416" for this suite. 11/05/22 11:58:39.46
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:58:39.467
Nov  5 11:58:39.467: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-runtime 11/05/22 11:58:39.468
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:39.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:39.488
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 11/05/22 11:58:39.491
STEP: wait for the container to reach Succeeded 11/05/22 11:58:39.499
STEP: get the container status 11/05/22 11:58:43.516
STEP: the container should be terminated 11/05/22 11:58:43.52
STEP: the termination message should be set 11/05/22 11:58:43.52
Nov  5 11:58:43.520: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 11/05/22 11:58:43.52
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov  5 11:58:43.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1636" for this suite. 11/05/22 11:58:43.538
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":14,"skipped":242,"failed":0}
------------------------------
• [4.077 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:58:39.467
    Nov  5 11:58:39.467: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-runtime 11/05/22 11:58:39.468
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:39.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:39.488
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 11/05/22 11:58:39.491
    STEP: wait for the container to reach Succeeded 11/05/22 11:58:39.499
    STEP: get the container status 11/05/22 11:58:43.516
    STEP: the container should be terminated 11/05/22 11:58:43.52
    STEP: the termination message should be set 11/05/22 11:58:43.52
    Nov  5 11:58:43.520: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 11/05/22 11:58:43.52
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov  5 11:58:43.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1636" for this suite. 11/05/22 11:58:43.538
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:58:43.546
Nov  5 11:58:43.546: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename deployment 11/05/22 11:58:43.546
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:43.568
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:43.571
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Nov  5 11:58:43.575: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov  5 11:58:43.585: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  5 11:58:48.590: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/05/22 11:58:48.59
Nov  5 11:58:48.590: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-mzdhk" in namespace "deployment-2423" to be "running"
Nov  5 11:58:48.594: INFO: Pod "test-rolling-update-controller-mzdhk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.727651ms
Nov  5 11:58:50.598: INFO: Pod "test-rolling-update-controller-mzdhk": Phase="Running", Reason="", readiness=true. Elapsed: 2.00801573s
Nov  5 11:58:50.598: INFO: Pod "test-rolling-update-controller-mzdhk" satisfied condition "running"
Nov  5 11:58:50.598: INFO: Creating deployment "test-rolling-update-deployment"
Nov  5 11:58:50.603: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov  5 11:58:50.609: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov  5 11:58:52.617: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov  5 11:58:52.620: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov  5 11:58:52.630: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2423  4f670425-73fa-4f4e-aaa9-e32941ee3969 3171 1 2022-11-05 11:58:50 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-11-05 11:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 11:58:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002c7d758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-05 11:58:50 +0000 UTC,LastTransitionTime:2022-11-05 11:58:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-11-05 11:58:52 +0000 UTC,LastTransitionTime:2022-11-05 11:58:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  5 11:58:52.633: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-2423  a3c89a61-d6f2-4422-aaa2-d4e876a22ff3 3161 1 2022-11-05 11:58:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 4f670425-73fa-4f4e-aaa9-e32941ee3969 0xc002c7dc57 0xc002c7dc58}] [] [{kube-controller-manager Update apps/v1 2022-11-05 11:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4f670425-73fa-4f4e-aaa9-e32941ee3969\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 11:58:52 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002c7dd08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  5 11:58:52.633: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov  5 11:58:52.634: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2423  05c9c1a0-55a1-473e-9cfa-509d46c03e65 3170 2 2022-11-05 11:58:43 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 4f670425-73fa-4f4e-aaa9-e32941ee3969 0xc002c7db2f 0xc002c7db40}] [] [{e2e.test Update apps/v1 2022-11-05 11:58:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 11:58:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4f670425-73fa-4f4e-aaa9-e32941ee3969\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-05 11:58:52 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002c7dbf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  5 11:58:52.637: INFO: Pod "test-rolling-update-deployment-78f575d8ff-z8bhw" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-z8bhw test-rolling-update-deployment-78f575d8ff- deployment-2423  91124f74-d43b-495c-9a43-44acd966a4d8 3160 0 2022-11-05 11:58:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff a3c89a61-d6f2-4422-aaa2-d4e876a22ff3 0xc002fd0ce7 0xc002fd0ce8}] [] [{kube-controller-manager Update v1 2022-11-05 11:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a3c89a61-d6f2-4422-aaa2-d4e876a22ff3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 11:58:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.143\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lx4mc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lx4mc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 11:58:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 11:58:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 11:58:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 11:58:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.143,StartTime:2022-11-05 11:58:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 11:58:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://e11e1b243c3a89b0112d8f835a92322d99fe336b9db9499a5f8620f2cd0261b6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.143,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov  5 11:58:52.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2423" for this suite. 11/05/22 11:58:52.641
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":15,"skipped":261,"failed":0}
------------------------------
• [SLOW TEST] [9.100 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:58:43.546
    Nov  5 11:58:43.546: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename deployment 11/05/22 11:58:43.546
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:43.568
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:43.571
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Nov  5 11:58:43.575: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Nov  5 11:58:43.585: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov  5 11:58:48.590: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/05/22 11:58:48.59
    Nov  5 11:58:48.590: INFO: Waiting up to 5m0s for pod "test-rolling-update-controller-mzdhk" in namespace "deployment-2423" to be "running"
    Nov  5 11:58:48.594: INFO: Pod "test-rolling-update-controller-mzdhk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.727651ms
    Nov  5 11:58:50.598: INFO: Pod "test-rolling-update-controller-mzdhk": Phase="Running", Reason="", readiness=true. Elapsed: 2.00801573s
    Nov  5 11:58:50.598: INFO: Pod "test-rolling-update-controller-mzdhk" satisfied condition "running"
    Nov  5 11:58:50.598: INFO: Creating deployment "test-rolling-update-deployment"
    Nov  5 11:58:50.603: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Nov  5 11:58:50.609: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Nov  5 11:58:52.617: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Nov  5 11:58:52.620: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov  5 11:58:52.630: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2423  4f670425-73fa-4f4e-aaa9-e32941ee3969 3171 1 2022-11-05 11:58:50 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2022-11-05 11:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 11:58:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002c7d758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-05 11:58:50 +0000 UTC,LastTransitionTime:2022-11-05 11:58:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2022-11-05 11:58:52 +0000 UTC,LastTransitionTime:2022-11-05 11:58:50 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov  5 11:58:52.633: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-2423  a3c89a61-d6f2-4422-aaa2-d4e876a22ff3 3161 1 2022-11-05 11:58:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 4f670425-73fa-4f4e-aaa9-e32941ee3969 0xc002c7dc57 0xc002c7dc58}] [] [{kube-controller-manager Update apps/v1 2022-11-05 11:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4f670425-73fa-4f4e-aaa9-e32941ee3969\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 11:58:52 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002c7dd08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 11:58:52.633: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Nov  5 11:58:52.634: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2423  05c9c1a0-55a1-473e-9cfa-509d46c03e65 3170 2 2022-11-05 11:58:43 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 4f670425-73fa-4f4e-aaa9-e32941ee3969 0xc002c7db2f 0xc002c7db40}] [] [{e2e.test Update apps/v1 2022-11-05 11:58:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 11:58:52 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4f670425-73fa-4f4e-aaa9-e32941ee3969\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-05 11:58:52 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002c7dbf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 11:58:52.637: INFO: Pod "test-rolling-update-deployment-78f575d8ff-z8bhw" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-z8bhw test-rolling-update-deployment-78f575d8ff- deployment-2423  91124f74-d43b-495c-9a43-44acd966a4d8 3160 0 2022-11-05 11:58:50 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff a3c89a61-d6f2-4422-aaa2-d4e876a22ff3 0xc002fd0ce7 0xc002fd0ce8}] [] [{kube-controller-manager Update v1 2022-11-05 11:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"a3c89a61-d6f2-4422-aaa2-d4e876a22ff3\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 11:58:52 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.143\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lx4mc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lx4mc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 11:58:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 11:58:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 11:58:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 11:58:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.143,StartTime:2022-11-05 11:58:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 11:58:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://e11e1b243c3a89b0112d8f835a92322d99fe336b9db9499a5f8620f2cd0261b6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.143,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov  5 11:58:52.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2423" for this suite. 11/05/22 11:58:52.641
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:58:52.647
Nov  5 11:58:52.647: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename init-container 11/05/22 11:58:52.648
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:52.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:52.667
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 11/05/22 11:58:52.67
Nov  5 11:58:52.671: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov  5 11:58:58.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2902" for this suite. 11/05/22 11:58:58.159
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":16,"skipped":265,"failed":0}
------------------------------
• [SLOW TEST] [5.519 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:58:52.647
    Nov  5 11:58:52.647: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename init-container 11/05/22 11:58:52.648
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:52.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:52.667
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 11/05/22 11:58:52.67
    Nov  5 11:58:52.671: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov  5 11:58:58.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-2902" for this suite. 11/05/22 11:58:58.159
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:58:58.167
Nov  5 11:58:58.167: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 11:58:58.168
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:58.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:58.187
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Nov  5 11:58:58.190: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/05/22 11:59:00.365
Nov  5 11:59:00.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-9696 --namespace=crd-publish-openapi-9696 create -f -'
Nov  5 11:59:00.927: INFO: stderr: ""
Nov  5 11:59:00.927: INFO: stdout: "e2e-test-crd-publish-openapi-3723-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  5 11:59:00.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-9696 --namespace=crd-publish-openapi-9696 delete e2e-test-crd-publish-openapi-3723-crds test-cr'
Nov  5 11:59:00.991: INFO: stderr: ""
Nov  5 11:59:00.991: INFO: stdout: "e2e-test-crd-publish-openapi-3723-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov  5 11:59:00.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-9696 --namespace=crd-publish-openapi-9696 apply -f -'
Nov  5 11:59:01.877: INFO: stderr: ""
Nov  5 11:59:01.877: INFO: stdout: "e2e-test-crd-publish-openapi-3723-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  5 11:59:01.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-9696 --namespace=crd-publish-openapi-9696 delete e2e-test-crd-publish-openapi-3723-crds test-cr'
Nov  5 11:59:01.943: INFO: stderr: ""
Nov  5 11:59:01.943: INFO: stdout: "e2e-test-crd-publish-openapi-3723-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 11/05/22 11:59:01.943
Nov  5 11:59:01.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-9696 explain e2e-test-crd-publish-openapi-3723-crds'
Nov  5 11:59:02.191: INFO: stderr: ""
Nov  5 11:59:02.191: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3723-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 11:59:04.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9696" for this suite. 11/05/22 11:59:04.383
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":17,"skipped":288,"failed":0}
------------------------------
• [SLOW TEST] [6.224 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:58:58.167
    Nov  5 11:58:58.167: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 11:58:58.168
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:58:58.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:58:58.187
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Nov  5 11:58:58.190: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/05/22 11:59:00.365
    Nov  5 11:59:00.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-9696 --namespace=crd-publish-openapi-9696 create -f -'
    Nov  5 11:59:00.927: INFO: stderr: ""
    Nov  5 11:59:00.927: INFO: stdout: "e2e-test-crd-publish-openapi-3723-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Nov  5 11:59:00.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-9696 --namespace=crd-publish-openapi-9696 delete e2e-test-crd-publish-openapi-3723-crds test-cr'
    Nov  5 11:59:00.991: INFO: stderr: ""
    Nov  5 11:59:00.991: INFO: stdout: "e2e-test-crd-publish-openapi-3723-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Nov  5 11:59:00.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-9696 --namespace=crd-publish-openapi-9696 apply -f -'
    Nov  5 11:59:01.877: INFO: stderr: ""
    Nov  5 11:59:01.877: INFO: stdout: "e2e-test-crd-publish-openapi-3723-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Nov  5 11:59:01.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-9696 --namespace=crd-publish-openapi-9696 delete e2e-test-crd-publish-openapi-3723-crds test-cr'
    Nov  5 11:59:01.943: INFO: stderr: ""
    Nov  5 11:59:01.943: INFO: stdout: "e2e-test-crd-publish-openapi-3723-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 11/05/22 11:59:01.943
    Nov  5 11:59:01.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-9696 explain e2e-test-crd-publish-openapi-3723-crds'
    Nov  5 11:59:02.191: INFO: stderr: ""
    Nov  5 11:59:02.191: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-3723-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 11:59:04.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9696" for this suite. 11/05/22 11:59:04.383
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:59:04.392
Nov  5 11:59:04.392: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 11/05/22 11:59:04.392
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:04.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:04.414
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 11/05/22 11:59:04.417
STEP: Creating hostNetwork=false pod 11/05/22 11:59:04.417
Nov  5 11:59:04.426: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-2356" to be "running and ready"
Nov  5 11:59:04.430: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.619557ms
Nov  5 11:59:04.430: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:59:06.435: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008414438s
Nov  5 11:59:06.435: INFO: The phase of Pod test-pod is Running (Ready = true)
Nov  5 11:59:06.435: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 11/05/22 11:59:06.439
Nov  5 11:59:06.444: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-2356" to be "running and ready"
Nov  5 11:59:06.448: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.46445ms
Nov  5 11:59:06.448: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Nov  5 11:59:08.453: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009196412s
Nov  5 11:59:08.453: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Nov  5 11:59:08.453: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 11/05/22 11:59:08.457
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 11/05/22 11:59:08.457
Nov  5 11:59:08.457: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 11:59:08.457: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:59:08.458: INFO: ExecWithOptions: Clientset creation
Nov  5 11:59:08.458: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov  5 11:59:08.553: INFO: Exec stderr: ""
Nov  5 11:59:08.553: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 11:59:08.553: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:59:08.554: INFO: ExecWithOptions: Clientset creation
Nov  5 11:59:08.554: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov  5 11:59:08.646: INFO: Exec stderr: ""
Nov  5 11:59:08.646: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 11:59:08.646: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:59:08.646: INFO: ExecWithOptions: Clientset creation
Nov  5 11:59:08.646: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov  5 11:59:08.709: INFO: Exec stderr: ""
Nov  5 11:59:08.709: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 11:59:08.709: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:59:08.710: INFO: ExecWithOptions: Clientset creation
Nov  5 11:59:08.710: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov  5 11:59:08.769: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 11/05/22 11:59:08.769
Nov  5 11:59:08.769: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 11:59:08.769: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:59:08.770: INFO: ExecWithOptions: Clientset creation
Nov  5 11:59:08.770: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Nov  5 11:59:08.841: INFO: Exec stderr: ""
Nov  5 11:59:08.841: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 11:59:08.841: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:59:08.841: INFO: ExecWithOptions: Clientset creation
Nov  5 11:59:08.841: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Nov  5 11:59:08.908: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 11/05/22 11:59:08.908
Nov  5 11:59:08.908: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 11:59:08.908: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:59:08.909: INFO: ExecWithOptions: Clientset creation
Nov  5 11:59:08.909: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov  5 11:59:08.999: INFO: Exec stderr: ""
Nov  5 11:59:08.999: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 11:59:08.999: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:59:09.000: INFO: ExecWithOptions: Clientset creation
Nov  5 11:59:09.000: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Nov  5 11:59:09.068: INFO: Exec stderr: ""
Nov  5 11:59:09.068: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 11:59:09.068: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:59:09.069: INFO: ExecWithOptions: Clientset creation
Nov  5 11:59:09.069: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov  5 11:59:09.125: INFO: Exec stderr: ""
Nov  5 11:59:09.125: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 11:59:09.125: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 11:59:09.126: INFO: ExecWithOptions: Clientset creation
Nov  5 11:59:09.126: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Nov  5 11:59:09.195: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Nov  5 11:59:09.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2356" for this suite. 11/05/22 11:59:09.2
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":18,"skipped":291,"failed":0}
------------------------------
• [4.815 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:59:04.392
    Nov  5 11:59:04.392: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 11/05/22 11:59:04.392
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:04.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:04.414
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 11/05/22 11:59:04.417
    STEP: Creating hostNetwork=false pod 11/05/22 11:59:04.417
    Nov  5 11:59:04.426: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-2356" to be "running and ready"
    Nov  5 11:59:04.430: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.619557ms
    Nov  5 11:59:04.430: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:59:06.435: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008414438s
    Nov  5 11:59:06.435: INFO: The phase of Pod test-pod is Running (Ready = true)
    Nov  5 11:59:06.435: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 11/05/22 11:59:06.439
    Nov  5 11:59:06.444: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-2356" to be "running and ready"
    Nov  5 11:59:06.448: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.46445ms
    Nov  5 11:59:06.448: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 11:59:08.453: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009196412s
    Nov  5 11:59:08.453: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Nov  5 11:59:08.453: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 11/05/22 11:59:08.457
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 11/05/22 11:59:08.457
    Nov  5 11:59:08.457: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 11:59:08.457: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:59:08.458: INFO: ExecWithOptions: Clientset creation
    Nov  5 11:59:08.458: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov  5 11:59:08.553: INFO: Exec stderr: ""
    Nov  5 11:59:08.553: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 11:59:08.553: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:59:08.554: INFO: ExecWithOptions: Clientset creation
    Nov  5 11:59:08.554: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov  5 11:59:08.646: INFO: Exec stderr: ""
    Nov  5 11:59:08.646: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 11:59:08.646: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:59:08.646: INFO: ExecWithOptions: Clientset creation
    Nov  5 11:59:08.646: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov  5 11:59:08.709: INFO: Exec stderr: ""
    Nov  5 11:59:08.709: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 11:59:08.709: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:59:08.710: INFO: ExecWithOptions: Clientset creation
    Nov  5 11:59:08.710: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov  5 11:59:08.769: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 11/05/22 11:59:08.769
    Nov  5 11:59:08.769: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 11:59:08.769: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:59:08.770: INFO: ExecWithOptions: Clientset creation
    Nov  5 11:59:08.770: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Nov  5 11:59:08.841: INFO: Exec stderr: ""
    Nov  5 11:59:08.841: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 11:59:08.841: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:59:08.841: INFO: ExecWithOptions: Clientset creation
    Nov  5 11:59:08.841: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Nov  5 11:59:08.908: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 11/05/22 11:59:08.908
    Nov  5 11:59:08.908: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 11:59:08.908: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:59:08.909: INFO: ExecWithOptions: Clientset creation
    Nov  5 11:59:08.909: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov  5 11:59:08.999: INFO: Exec stderr: ""
    Nov  5 11:59:08.999: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 11:59:08.999: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:59:09.000: INFO: ExecWithOptions: Clientset creation
    Nov  5 11:59:09.000: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Nov  5 11:59:09.068: INFO: Exec stderr: ""
    Nov  5 11:59:09.068: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 11:59:09.068: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:59:09.069: INFO: ExecWithOptions: Clientset creation
    Nov  5 11:59:09.069: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov  5 11:59:09.125: INFO: Exec stderr: ""
    Nov  5 11:59:09.125: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2356 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 11:59:09.125: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 11:59:09.126: INFO: ExecWithOptions: Clientset creation
    Nov  5 11:59:09.126: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/e2e-kubelet-etc-hosts-2356/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Nov  5 11:59:09.195: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Nov  5 11:59:09.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-2356" for this suite. 11/05/22 11:59:09.2
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:59:09.212
Nov  5 11:59:09.212: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 11:59:09.212
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:09.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:09.231
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 11/05/22 11:59:09.234
STEP: Getting a ResourceQuota 11/05/22 11:59:09.24
STEP: Listing all ResourceQuotas with LabelSelector 11/05/22 11:59:09.244
STEP: Patching the ResourceQuota 11/05/22 11:59:09.248
STEP: Deleting a Collection of ResourceQuotas 11/05/22 11:59:09.255
STEP: Verifying the deleted ResourceQuota 11/05/22 11:59:09.263
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 11:59:09.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1274" for this suite. 11/05/22 11:59:09.27
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":19,"skipped":352,"failed":0}
------------------------------
• [0.066 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:59:09.212
    Nov  5 11:59:09.212: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 11:59:09.212
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:09.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:09.231
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 11/05/22 11:59:09.234
    STEP: Getting a ResourceQuota 11/05/22 11:59:09.24
    STEP: Listing all ResourceQuotas with LabelSelector 11/05/22 11:59:09.244
    STEP: Patching the ResourceQuota 11/05/22 11:59:09.248
    STEP: Deleting a Collection of ResourceQuotas 11/05/22 11:59:09.255
    STEP: Verifying the deleted ResourceQuota 11/05/22 11:59:09.263
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 11:59:09.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-1274" for this suite. 11/05/22 11:59:09.27
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:59:09.278
Nov  5 11:59:09.278: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 11:59:09.279
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:09.29
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:09.294
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 11:59:09.314
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 11:59:09.49
STEP: Deploying the webhook pod 11/05/22 11:59:09.498
STEP: Wait for the deployment to be ready 11/05/22 11:59:09.511
Nov  5 11:59:09.520: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 11:59:11.533
STEP: Verifying the service has paired with the endpoint 11/05/22 11:59:11.544
Nov  5 11:59:12.545: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 11/05/22 11:59:12.55
STEP: Creating a custom resource definition that should be denied by the webhook 11/05/22 11:59:12.566
Nov  5 11:59:12.566: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 11:59:12.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4342" for this suite. 11/05/22 11:59:12.586
STEP: Destroying namespace "webhook-4342-markers" for this suite. 11/05/22 11:59:12.593
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":20,"skipped":353,"failed":0}
------------------------------
• [3.380 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:59:09.278
    Nov  5 11:59:09.278: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 11:59:09.279
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:09.29
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:09.294
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 11:59:09.314
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 11:59:09.49
    STEP: Deploying the webhook pod 11/05/22 11:59:09.498
    STEP: Wait for the deployment to be ready 11/05/22 11:59:09.511
    Nov  5 11:59:09.520: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 11:59:11.533
    STEP: Verifying the service has paired with the endpoint 11/05/22 11:59:11.544
    Nov  5 11:59:12.545: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 11/05/22 11:59:12.55
    STEP: Creating a custom resource definition that should be denied by the webhook 11/05/22 11:59:12.566
    Nov  5 11:59:12.566: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 11:59:12.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4342" for this suite. 11/05/22 11:59:12.586
    STEP: Destroying namespace "webhook-4342-markers" for this suite. 11/05/22 11:59:12.593
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:59:12.659
Nov  5 11:59:12.660: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename custom-resource-definition 11/05/22 11:59:12.66
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:12.674
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:12.679
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Nov  5 11:59:12.683: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 11:59:13.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-246" for this suite. 11/05/22 11:59:13.234
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":21,"skipped":391,"failed":0}
------------------------------
• [0.581 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:59:12.659
    Nov  5 11:59:12.660: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename custom-resource-definition 11/05/22 11:59:12.66
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:12.674
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:12.679
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Nov  5 11:59:12.683: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 11:59:13.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-246" for this suite. 11/05/22 11:59:13.234
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:59:13.242
Nov  5 11:59:13.242: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 11:59:13.243
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:13.256
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:13.26
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 11/05/22 11:59:13.264
Nov  5 11:59:13.274: INFO: Waiting up to 5m0s for pod "downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda" in namespace "downward-api-1750" to be "Succeeded or Failed"
Nov  5 11:59:13.277: INFO: Pod "downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.306805ms
Nov  5 11:59:15.281: INFO: Pod "downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007504207s
Nov  5 11:59:17.281: INFO: Pod "downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007635191s
STEP: Saw pod success 11/05/22 11:59:17.281
Nov  5 11:59:17.282: INFO: Pod "downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda" satisfied condition "Succeeded or Failed"
Nov  5 11:59:17.285: INFO: Trying to get logs from node ip-172-31-0-255 pod downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda container dapi-container: <nil>
STEP: delete the pod 11/05/22 11:59:17.298
Nov  5 11:59:17.311: INFO: Waiting for pod downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda to disappear
Nov  5 11:59:17.314: INFO: Pod downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov  5 11:59:17.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1750" for this suite. 11/05/22 11:59:17.319
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":22,"skipped":414,"failed":0}
------------------------------
• [4.083 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:59:13.242
    Nov  5 11:59:13.242: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 11:59:13.243
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:13.256
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:13.26
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 11/05/22 11:59:13.264
    Nov  5 11:59:13.274: INFO: Waiting up to 5m0s for pod "downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda" in namespace "downward-api-1750" to be "Succeeded or Failed"
    Nov  5 11:59:13.277: INFO: Pod "downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda": Phase="Pending", Reason="", readiness=false. Elapsed: 3.306805ms
    Nov  5 11:59:15.281: INFO: Pod "downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007504207s
    Nov  5 11:59:17.281: INFO: Pod "downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007635191s
    STEP: Saw pod success 11/05/22 11:59:17.281
    Nov  5 11:59:17.282: INFO: Pod "downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda" satisfied condition "Succeeded or Failed"
    Nov  5 11:59:17.285: INFO: Trying to get logs from node ip-172-31-0-255 pod downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda container dapi-container: <nil>
    STEP: delete the pod 11/05/22 11:59:17.298
    Nov  5 11:59:17.311: INFO: Waiting for pod downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda to disappear
    Nov  5 11:59:17.314: INFO: Pod downward-api-8b600afa-7aff-4d65-b97a-b7d334d86bda no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov  5 11:59:17.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-1750" for this suite. 11/05/22 11:59:17.319
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 11:59:17.326
Nov  5 11:59:17.327: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sched-preemption 11/05/22 11:59:17.327
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:17.338
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:17.344
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov  5 11:59:17.365: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  5 12:00:17.387: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:17.391
Nov  5 12:00:17.391: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sched-preemption-path 11/05/22 12:00:17.392
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:17.406
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:17.41
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Nov  5 12:00:17.427: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Nov  5 12:00:17.431: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Nov  5 12:00:17.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-4649" for this suite. 11/05/22 12:00:17.454
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:00:17.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-6119" for this suite. 11/05/22 12:00:17.476
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":23,"skipped":425,"failed":0}
------------------------------
• [SLOW TEST] [60.197 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 11:59:17.326
    Nov  5 11:59:17.327: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sched-preemption 11/05/22 11:59:17.327
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 11:59:17.338
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 11:59:17.344
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov  5 11:59:17.365: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov  5 12:00:17.387: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:17.391
    Nov  5 12:00:17.391: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sched-preemption-path 11/05/22 12:00:17.392
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:17.406
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:17.41
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Nov  5 12:00:17.427: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Nov  5 12:00:17.431: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Nov  5 12:00:17.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-4649" for this suite. 11/05/22 12:00:17.454
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:00:17.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-6119" for this suite. 11/05/22 12:00:17.476
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:17.524
Nov  5 12:00:17.524: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 12:00:17.525
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:17.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:17.543
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-121859a2-2bb4-4302-8a60-3db288b5a601 11/05/22 12:00:17.549
STEP: Creating the pod 11/05/22 12:00:17.554
Nov  5 12:00:17.562: INFO: Waiting up to 5m0s for pod "pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630" in namespace "configmap-5540" to be "running and ready"
Nov  5 12:00:17.565: INFO: Pod "pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630": Phase="Pending", Reason="", readiness=false. Elapsed: 3.478794ms
Nov  5 12:00:17.565: INFO: The phase of Pod pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:00:19.570: INFO: Pod "pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630": Phase="Running", Reason="", readiness=true. Elapsed: 2.008378706s
Nov  5 12:00:19.570: INFO: The phase of Pod pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630 is Running (Ready = true)
Nov  5 12:00:19.570: INFO: Pod "pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-121859a2-2bb4-4302-8a60-3db288b5a601 11/05/22 12:00:19.587
STEP: waiting to observe update in volume 11/05/22 12:00:19.595
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 12:00:23.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5540" for this suite. 11/05/22 12:00:23.621
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":24,"skipped":428,"failed":0}
------------------------------
• [SLOW TEST] [6.112 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:17.524
    Nov  5 12:00:17.524: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 12:00:17.525
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:17.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:17.543
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-121859a2-2bb4-4302-8a60-3db288b5a601 11/05/22 12:00:17.549
    STEP: Creating the pod 11/05/22 12:00:17.554
    Nov  5 12:00:17.562: INFO: Waiting up to 5m0s for pod "pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630" in namespace "configmap-5540" to be "running and ready"
    Nov  5 12:00:17.565: INFO: Pod "pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630": Phase="Pending", Reason="", readiness=false. Elapsed: 3.478794ms
    Nov  5 12:00:17.565: INFO: The phase of Pod pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:00:19.570: INFO: Pod "pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630": Phase="Running", Reason="", readiness=true. Elapsed: 2.008378706s
    Nov  5 12:00:19.570: INFO: The phase of Pod pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630 is Running (Ready = true)
    Nov  5 12:00:19.570: INFO: Pod "pod-configmaps-358a3b18-12f8-455e-86be-62cfcdba5630" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-121859a2-2bb4-4302-8a60-3db288b5a601 11/05/22 12:00:19.587
    STEP: waiting to observe update in volume 11/05/22 12:00:19.595
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 12:00:23.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5540" for this suite. 11/05/22 12:00:23.621
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:23.636
Nov  5 12:00:23.637: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename custom-resource-definition 11/05/22 12:00:23.637
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:23.651
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:23.656
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Nov  5 12:00:23.660: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:00:24.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3373" for this suite. 11/05/22 12:00:24.693
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":25,"skipped":439,"failed":0}
------------------------------
• [1.064 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:23.636
    Nov  5 12:00:23.637: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename custom-resource-definition 11/05/22 12:00:23.637
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:23.651
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:23.656
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Nov  5 12:00:23.660: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:00:24.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3373" for this suite. 11/05/22 12:00:24.693
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:24.701
Nov  5 12:00:24.701: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename dns 11/05/22 12:00:24.702
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:24.721
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:24.727
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 11/05/22 12:00:24.733
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 11/05/22 12:00:24.733
STEP: creating a pod to probe DNS 11/05/22 12:00:24.733
STEP: submitting the pod to kubernetes 11/05/22 12:00:24.733
Nov  5 12:00:24.747: INFO: Waiting up to 15m0s for pod "dns-test-0b54e05d-1149-4541-90f0-c0d11fbef68f" in namespace "dns-1119" to be "running"
Nov  5 12:00:24.754: INFO: Pod "dns-test-0b54e05d-1149-4541-90f0-c0d11fbef68f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.43641ms
Nov  5 12:00:26.759: INFO: Pod "dns-test-0b54e05d-1149-4541-90f0-c0d11fbef68f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01161359s
Nov  5 12:00:26.759: INFO: Pod "dns-test-0b54e05d-1149-4541-90f0-c0d11fbef68f" satisfied condition "running"
STEP: retrieving the pod 11/05/22 12:00:26.759
STEP: looking for the results for each expected name from probers 11/05/22 12:00:26.763
Nov  5 12:00:26.780: INFO: DNS probes using dns-1119/dns-test-0b54e05d-1149-4541-90f0-c0d11fbef68f succeeded

STEP: deleting the pod 11/05/22 12:00:26.78
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov  5 12:00:26.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1119" for this suite. 11/05/22 12:00:26.795
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":26,"skipped":440,"failed":0}
------------------------------
• [2.101 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:24.701
    Nov  5 12:00:24.701: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename dns 11/05/22 12:00:24.702
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:24.721
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:24.727
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     11/05/22 12:00:24.733
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     11/05/22 12:00:24.733
    STEP: creating a pod to probe DNS 11/05/22 12:00:24.733
    STEP: submitting the pod to kubernetes 11/05/22 12:00:24.733
    Nov  5 12:00:24.747: INFO: Waiting up to 15m0s for pod "dns-test-0b54e05d-1149-4541-90f0-c0d11fbef68f" in namespace "dns-1119" to be "running"
    Nov  5 12:00:24.754: INFO: Pod "dns-test-0b54e05d-1149-4541-90f0-c0d11fbef68f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.43641ms
    Nov  5 12:00:26.759: INFO: Pod "dns-test-0b54e05d-1149-4541-90f0-c0d11fbef68f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01161359s
    Nov  5 12:00:26.759: INFO: Pod "dns-test-0b54e05d-1149-4541-90f0-c0d11fbef68f" satisfied condition "running"
    STEP: retrieving the pod 11/05/22 12:00:26.759
    STEP: looking for the results for each expected name from probers 11/05/22 12:00:26.763
    Nov  5 12:00:26.780: INFO: DNS probes using dns-1119/dns-test-0b54e05d-1149-4541-90f0-c0d11fbef68f succeeded

    STEP: deleting the pod 11/05/22 12:00:26.78
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov  5 12:00:26.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1119" for this suite. 11/05/22 12:00:26.795
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:26.803
Nov  5 12:00:26.803: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 12:00:26.804
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:26.815
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:26.82
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 11/05/22 12:00:26.823
STEP: listing secrets in all namespaces to ensure that there are more than zero 11/05/22 12:00:26.829
STEP: patching the secret 11/05/22 12:00:26.832
STEP: deleting the secret using a LabelSelector 11/05/22 12:00:26.841
STEP: listing secrets in all namespaces, searching for label name and value in patch 11/05/22 12:00:26.849
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov  5 12:00:26.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6515" for this suite. 11/05/22 12:00:26.856
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":27,"skipped":443,"failed":0}
------------------------------
• [0.059 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:26.803
    Nov  5 12:00:26.803: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 12:00:26.804
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:26.815
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:26.82
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 11/05/22 12:00:26.823
    STEP: listing secrets in all namespaces to ensure that there are more than zero 11/05/22 12:00:26.829
    STEP: patching the secret 11/05/22 12:00:26.832
    STEP: deleting the secret using a LabelSelector 11/05/22 12:00:26.841
    STEP: listing secrets in all namespaces, searching for label name and value in patch 11/05/22 12:00:26.849
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 12:00:26.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6515" for this suite. 11/05/22 12:00:26.856
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:26.864
Nov  5 12:00:26.864: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename job 11/05/22 12:00:26.864
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:26.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:26.884
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 11/05/22 12:00:26.887
STEP: Ensuring active pods == parallelism 11/05/22 12:00:26.894
STEP: Orphaning one of the Job's Pods 11/05/22 12:00:28.898
Nov  5 12:00:29.414: INFO: Successfully updated pod "adopt-release-6mc96"
STEP: Checking that the Job readopts the Pod 11/05/22 12:00:29.414
Nov  5 12:00:29.414: INFO: Waiting up to 15m0s for pod "adopt-release-6mc96" in namespace "job-5022" to be "adopted"
Nov  5 12:00:29.417: INFO: Pod "adopt-release-6mc96": Phase="Running", Reason="", readiness=true. Elapsed: 3.40531ms
Nov  5 12:00:31.421: INFO: Pod "adopt-release-6mc96": Phase="Running", Reason="", readiness=true. Elapsed: 2.007306361s
Nov  5 12:00:31.421: INFO: Pod "adopt-release-6mc96" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 11/05/22 12:00:31.421
Nov  5 12:00:31.936: INFO: Successfully updated pod "adopt-release-6mc96"
STEP: Checking that the Job releases the Pod 11/05/22 12:00:31.936
Nov  5 12:00:31.936: INFO: Waiting up to 15m0s for pod "adopt-release-6mc96" in namespace "job-5022" to be "released"
Nov  5 12:00:31.940: INFO: Pod "adopt-release-6mc96": Phase="Running", Reason="", readiness=true. Elapsed: 3.921495ms
Nov  5 12:00:33.944: INFO: Pod "adopt-release-6mc96": Phase="Running", Reason="", readiness=true. Elapsed: 2.008334026s
Nov  5 12:00:33.944: INFO: Pod "adopt-release-6mc96" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov  5 12:00:33.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5022" for this suite. 11/05/22 12:00:33.948
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":28,"skipped":478,"failed":0}
------------------------------
• [SLOW TEST] [7.092 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:26.864
    Nov  5 12:00:26.864: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename job 11/05/22 12:00:26.864
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:26.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:26.884
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 11/05/22 12:00:26.887
    STEP: Ensuring active pods == parallelism 11/05/22 12:00:26.894
    STEP: Orphaning one of the Job's Pods 11/05/22 12:00:28.898
    Nov  5 12:00:29.414: INFO: Successfully updated pod "adopt-release-6mc96"
    STEP: Checking that the Job readopts the Pod 11/05/22 12:00:29.414
    Nov  5 12:00:29.414: INFO: Waiting up to 15m0s for pod "adopt-release-6mc96" in namespace "job-5022" to be "adopted"
    Nov  5 12:00:29.417: INFO: Pod "adopt-release-6mc96": Phase="Running", Reason="", readiness=true. Elapsed: 3.40531ms
    Nov  5 12:00:31.421: INFO: Pod "adopt-release-6mc96": Phase="Running", Reason="", readiness=true. Elapsed: 2.007306361s
    Nov  5 12:00:31.421: INFO: Pod "adopt-release-6mc96" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 11/05/22 12:00:31.421
    Nov  5 12:00:31.936: INFO: Successfully updated pod "adopt-release-6mc96"
    STEP: Checking that the Job releases the Pod 11/05/22 12:00:31.936
    Nov  5 12:00:31.936: INFO: Waiting up to 15m0s for pod "adopt-release-6mc96" in namespace "job-5022" to be "released"
    Nov  5 12:00:31.940: INFO: Pod "adopt-release-6mc96": Phase="Running", Reason="", readiness=true. Elapsed: 3.921495ms
    Nov  5 12:00:33.944: INFO: Pod "adopt-release-6mc96": Phase="Running", Reason="", readiness=true. Elapsed: 2.008334026s
    Nov  5 12:00:33.944: INFO: Pod "adopt-release-6mc96" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov  5 12:00:33.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5022" for this suite. 11/05/22 12:00:33.948
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:33.956
Nov  5 12:00:33.956: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-webhook 11/05/22 12:00:33.957
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:33.971
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:33.975
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 11/05/22 12:00:33.979
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/05/22 12:00:34.269
STEP: Deploying the custom resource conversion webhook pod 11/05/22 12:00:34.277
STEP: Wait for the deployment to be ready 11/05/22 12:00:34.29
Nov  5 12:00:34.299: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 12:00:36.311
STEP: Verifying the service has paired with the endpoint 11/05/22 12:00:36.323
Nov  5 12:00:37.324: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Nov  5 12:00:37.329: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Creating a v1 custom resource 11/05/22 12:00:39.912
STEP: v2 custom resource should be converted 11/05/22 12:00:39.918
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:00:40.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-389" for this suite. 11/05/22 12:00:40.441
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":29,"skipped":494,"failed":0}
------------------------------
• [SLOW TEST] [6.545 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:33.956
    Nov  5 12:00:33.956: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-webhook 11/05/22 12:00:33.957
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:33.971
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:33.975
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 11/05/22 12:00:33.979
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/05/22 12:00:34.269
    STEP: Deploying the custom resource conversion webhook pod 11/05/22 12:00:34.277
    STEP: Wait for the deployment to be ready 11/05/22 12:00:34.29
    Nov  5 12:00:34.299: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 12:00:36.311
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:00:36.323
    Nov  5 12:00:37.324: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Nov  5 12:00:37.329: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Creating a v1 custom resource 11/05/22 12:00:39.912
    STEP: v2 custom resource should be converted 11/05/22 12:00:39.918
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:00:40.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-389" for this suite. 11/05/22 12:00:40.441
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:40.505
Nov  5 12:00:40.505: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:00:40.505
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:40.532
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:40.537
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Nov  5 12:00:40.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 create -f -'
Nov  5 12:00:41.266: INFO: stderr: ""
Nov  5 12:00:41.266: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Nov  5 12:00:41.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 create -f -'
Nov  5 12:00:41.540: INFO: stderr: ""
Nov  5 12:00:41.540: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/05/22 12:00:41.54
Nov  5 12:00:42.544: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  5 12:00:42.544: INFO: Found 1 / 1
Nov  5 12:00:42.544: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  5 12:00:42.548: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  5 12:00:42.548: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  5 12:00:42.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 describe pod agnhost-primary-ntdmt'
Nov  5 12:00:42.615: INFO: stderr: ""
Nov  5 12:00:42.615: INFO: stdout: "Name:             agnhost-primary-ntdmt\nNamespace:        kubectl-9813\nPriority:         0\nService Account:  default\nNode:             ip-172-31-0-255/172.31.0.255\nStart Time:       Sat, 05 Nov 2022 12:00:41 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.206.149\nIPs:\n  IP:           192.168.206.149\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://e6aa545bb55e86a40f8394607b13e1f7c57ac53d30945a0ab24989cb9db448dc\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 05 Nov 2022 12:00:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-rzzvr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-rzzvr:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-9813/agnhost-primary-ntdmt to ip-172-31-0-255\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    0s    kubelet            Created container agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
Nov  5 12:00:42.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 describe rc agnhost-primary'
Nov  5 12:00:42.686: INFO: stderr: ""
Nov  5 12:00:42.686: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-9813\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-ntdmt\n"
Nov  5 12:00:42.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 describe service agnhost-primary'
Nov  5 12:00:42.756: INFO: stderr: ""
Nov  5 12:00:42.756: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-9813\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.144\nIPs:               10.152.183.144\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.206.149:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov  5 12:00:42.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 describe node ip-172-31-0-255'
Nov  5 12:00:42.851: INFO: stderr: ""
Nov  5 12:00:42.851: INFO: stdout: "Name:               ip-172-31-0-255\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-0-255\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 05 Nov 2022 11:49:00 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-0-255\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 05 Nov 2022 12:00:41 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 05 Nov 2022 11:58:20 +0000   Sat, 05 Nov 2022 11:49:00 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 05 Nov 2022 11:58:20 +0000   Sat, 05 Nov 2022 11:49:00 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 05 Nov 2022 11:58:20 +0000   Sat, 05 Nov 2022 11:49:00 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 05 Nov 2022 11:58:20 +0000   Sat, 05 Nov 2022 11:53:54 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.0.255\n  Hostname:    ip-172-31-0-255\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16082940Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             15980540Ki\n  pods:               110\nSystem Info:\n  Machine ID:                      ec2962563c3e2488f6334d9f3c692443\n  System UUID:                     ec296256-3c3e-2488-f633-4d9f3c692443\n  Boot ID:                         5d56697e-fb70-4357-88b3-4d46804dee88\n  Kernel Version:                  5.15.0-1022-aws\n  OS Image:                        Ubuntu 20.04.5 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.5.9\n  Kubelet Version:                 v1.25.3\n  Kube-Proxy Version:              v1.25.3\nNon-terminated Pods:               (5 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-hdhmc           0 (0%)        0 (0%)      0 (0%)           0 (0%)         2m11s\n  job-5022                         adopt-release-7dbzq                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         16s\n  kubectl-9813                     agnhost-primary-ntdmt                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         1s\n  sonobuoy                         sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         5m29s\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl    0 (0%)        0 (0%)      0 (0%)           0 (0%)         5m26s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests  Limits\n  --------           --------  ------\n  cpu                0 (0%)    0 (0%)\n  memory             0 (0%)    0 (0%)\n  ephemeral-storage  0 (0%)    0 (0%)\n  hugepages-1Gi      0 (0%)    0 (0%)\n  hugepages-2Mi      0 (0%)    0 (0%)\nEvents:\n  Type     Reason                   Age    From             Message\n  ----     ------                   ----   ----             -------\n  Normal   Starting                 10m    kube-proxy       \n  Normal   Starting                 6m58s  kube-proxy       \n  Normal   Starting                 11m    kube-proxy       \n  Normal   Starting                 11m    kube-proxy       \n  Normal   NodeHasNoDiskPressure    11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasNoDiskPressure\n  Warning  InvalidDiskCapacity      11m    kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  11m    kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 11m    kubelet          Starting kubelet.\n  Normal   NodeHasSufficientMemory  11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientPID\n  Normal   RegisteredNode           11m    node-controller  Node ip-172-31-0-255 event: Registered Node ip-172-31-0-255 in Controller\n  Normal   NodeHasSufficientMemory  11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  11m    kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 11m    kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      11m    kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeReady                11m    kubelet          Node ip-172-31-0-255 status is now: NodeReady\n  Normal   NodeNotReady             10m    kubelet          Node ip-172-31-0-255 status is now: NodeNotReady\n  Warning  InvalidDiskCapacity      10m    kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasNoDiskPressure    10m    kubelet          Node ip-172-31-0-255 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     10m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  10m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  10m    kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 10m    kubelet          Starting kubelet.\n  Normal   NodeReady                9m52s  kubelet          Node ip-172-31-0-255 status is now: NodeReady\n  Normal   NodeHasSufficientMemory  6m58s  kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientMemory\n  Warning  InvalidDiskCapacity      6m58s  kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 6m58s  kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    6m58s  kubelet          Node ip-172-31-0-255 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     6m58s  kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientPID\n  Normal   NodeNotReady             6m58s  kubelet          Node ip-172-31-0-255 status is now: NodeNotReady\n  Normal   NodeAllocatableEnforced  6m58s  kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                6m48s  kubelet          Node ip-172-31-0-255 status is now: NodeReady\n"
Nov  5 12:00:42.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 describe namespace kubectl-9813'
Nov  5 12:00:42.927: INFO: stderr: ""
Nov  5 12:00:42.927: INFO: stdout: "Name:         kubectl-9813\nLabels:       e2e-framework=kubectl\n              e2e-run=3a293453-f0e8-4f41-81b6-1bd47eee4a98\n              kubernetes.io/metadata.name=kubectl-9813\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:00:42.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9813" for this suite. 11/05/22 12:00:42.932
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":30,"skipped":544,"failed":0}
------------------------------
• [2.434 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:40.505
    Nov  5 12:00:40.505: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:00:40.505
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:40.532
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:40.537
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Nov  5 12:00:40.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 create -f -'
    Nov  5 12:00:41.266: INFO: stderr: ""
    Nov  5 12:00:41.266: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Nov  5 12:00:41.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 create -f -'
    Nov  5 12:00:41.540: INFO: stderr: ""
    Nov  5 12:00:41.540: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/05/22 12:00:41.54
    Nov  5 12:00:42.544: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov  5 12:00:42.544: INFO: Found 1 / 1
    Nov  5 12:00:42.544: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Nov  5 12:00:42.548: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov  5 12:00:42.548: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov  5 12:00:42.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 describe pod agnhost-primary-ntdmt'
    Nov  5 12:00:42.615: INFO: stderr: ""
    Nov  5 12:00:42.615: INFO: stdout: "Name:             agnhost-primary-ntdmt\nNamespace:        kubectl-9813\nPriority:         0\nService Account:  default\nNode:             ip-172-31-0-255/172.31.0.255\nStart Time:       Sat, 05 Nov 2022 12:00:41 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      <none>\nStatus:           Running\nIP:               192.168.206.149\nIPs:\n  IP:           192.168.206.149\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://e6aa545bb55e86a40f8394607b13e1f7c57ac53d30945a0ab24989cb9db448dc\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 05 Nov 2022 12:00:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-rzzvr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-rzzvr:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  1s    default-scheduler  Successfully assigned kubectl-9813/agnhost-primary-ntdmt to ip-172-31-0-255\n  Normal  Pulled     1s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    0s    kubelet            Created container agnhost-primary\n  Normal  Started    0s    kubelet            Started container agnhost-primary\n"
    Nov  5 12:00:42.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 describe rc agnhost-primary'
    Nov  5 12:00:42.686: INFO: stderr: ""
    Nov  5 12:00:42.686: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-9813\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: agnhost-primary-ntdmt\n"
    Nov  5 12:00:42.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 describe service agnhost-primary'
    Nov  5 12:00:42.756: INFO: stderr: ""
    Nov  5 12:00:42.756: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-9813\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                10.152.183.144\nIPs:               10.152.183.144\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         192.168.206.149:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Nov  5 12:00:42.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 describe node ip-172-31-0-255'
    Nov  5 12:00:42.851: INFO: stderr: ""
    Nov  5 12:00:42.851: INFO: stdout: "Name:               ip-172-31-0-255\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    juju-application=kubernetes-worker\n                    juju-charm=kubernetes-worker\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-172-31-0-255\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 05 Nov 2022 11:49:00 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-172-31-0-255\n  AcquireTime:     <unset>\n  RenewTime:       Sat, 05 Nov 2022 12:00:41 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 05 Nov 2022 11:58:20 +0000   Sat, 05 Nov 2022 11:49:00 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 05 Nov 2022 11:58:20 +0000   Sat, 05 Nov 2022 11:49:00 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 05 Nov 2022 11:58:20 +0000   Sat, 05 Nov 2022 11:49:00 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 05 Nov 2022 11:58:20 +0000   Sat, 05 Nov 2022 11:53:54 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.0.255\n  Hostname:    ip-172-31-0-255\nCapacity:\n  cpu:                2\n  ephemeral-storage:  16069568Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16082940Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  14809713845\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             15980540Ki\n  pods:               110\nSystem Info:\n  Machine ID:                      ec2962563c3e2488f6334d9f3c692443\n  System UUID:                     ec296256-3c3e-2488-f633-4d9f3c692443\n  Boot ID:                         5d56697e-fb70-4357-88b3-4d46804dee88\n  Kernel Version:                  5.15.0-1022-aws\n  OS Image:                        Ubuntu 20.04.5 LTS\n  Operating System:                linux\n  Architecture:                    amd64\n  Container Runtime Version:       containerd://1.5.9\n  Kubelet Version:                 v1.25.3\n  Kube-Proxy Version:              v1.25.3\nNon-terminated Pods:               (5 in total)\n  Namespace                        Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                        ----                                                       ------------  ----------  ---------------  -------------  ---\n  ingress-nginx-kubernetes-worker  nginx-ingress-controller-kubernetes-worker-hdhmc           0 (0%)        0 (0%)      0 (0%)           0 (0%)         2m11s\n  job-5022                         adopt-release-7dbzq                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         16s\n  kubectl-9813                     agnhost-primary-ntdmt                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         1s\n  sonobuoy                         sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         5m29s\n  sonobuoy                         sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl    0 (0%)        0 (0%)      0 (0%)           0 (0%)         5m26s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests  Limits\n  --------           --------  ------\n  cpu                0 (0%)    0 (0%)\n  memory             0 (0%)    0 (0%)\n  ephemeral-storage  0 (0%)    0 (0%)\n  hugepages-1Gi      0 (0%)    0 (0%)\n  hugepages-2Mi      0 (0%)    0 (0%)\nEvents:\n  Type     Reason                   Age    From             Message\n  ----     ------                   ----   ----             -------\n  Normal   Starting                 10m    kube-proxy       \n  Normal   Starting                 6m58s  kube-proxy       \n  Normal   Starting                 11m    kube-proxy       \n  Normal   Starting                 11m    kube-proxy       \n  Normal   NodeHasNoDiskPressure    11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasNoDiskPressure\n  Warning  InvalidDiskCapacity      11m    kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeAllocatableEnforced  11m    kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 11m    kubelet          Starting kubelet.\n  Normal   NodeHasSufficientMemory  11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientMemory\n  Normal   NodeHasSufficientPID     11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientPID\n  Normal   RegisteredNode           11m    node-controller  Node ip-172-31-0-255 event: Registered Node ip-172-31-0-255 in Controller\n  Normal   NodeHasSufficientMemory  11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     11m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  11m    kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 11m    kubelet          Starting kubelet.\n  Warning  InvalidDiskCapacity      11m    kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeReady                11m    kubelet          Node ip-172-31-0-255 status is now: NodeReady\n  Normal   NodeNotReady             10m    kubelet          Node ip-172-31-0-255 status is now: NodeNotReady\n  Warning  InvalidDiskCapacity      10m    kubelet          invalid capacity 0 on image filesystem\n  Normal   NodeHasNoDiskPressure    10m    kubelet          Node ip-172-31-0-255 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     10m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientPID\n  Normal   NodeHasSufficientMemory  10m    kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientMemory\n  Normal   NodeAllocatableEnforced  10m    kubelet          Updated Node Allocatable limit across pods\n  Normal   Starting                 10m    kubelet          Starting kubelet.\n  Normal   NodeReady                9m52s  kubelet          Node ip-172-31-0-255 status is now: NodeReady\n  Normal   NodeHasSufficientMemory  6m58s  kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientMemory\n  Warning  InvalidDiskCapacity      6m58s  kubelet          invalid capacity 0 on image filesystem\n  Normal   Starting                 6m58s  kubelet          Starting kubelet.\n  Normal   NodeHasNoDiskPressure    6m58s  kubelet          Node ip-172-31-0-255 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     6m58s  kubelet          Node ip-172-31-0-255 status is now: NodeHasSufficientPID\n  Normal   NodeNotReady             6m58s  kubelet          Node ip-172-31-0-255 status is now: NodeNotReady\n  Normal   NodeAllocatableEnforced  6m58s  kubelet          Updated Node Allocatable limit across pods\n  Normal   NodeReady                6m48s  kubelet          Node ip-172-31-0-255 status is now: NodeReady\n"
    Nov  5 12:00:42.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9813 describe namespace kubectl-9813'
    Nov  5 12:00:42.927: INFO: stderr: ""
    Nov  5 12:00:42.927: INFO: stdout: "Name:         kubectl-9813\nLabels:       e2e-framework=kubectl\n              e2e-run=3a293453-f0e8-4f41-81b6-1bd47eee4a98\n              kubernetes.io/metadata.name=kubectl-9813\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:00:42.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9813" for this suite. 11/05/22 12:00:42.932
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:42.939
Nov  5 12:00:42.939: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename security-context 11/05/22 12:00:42.94
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:42.955
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:42.958
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/05/22 12:00:42.962
Nov  5 12:00:42.971: INFO: Waiting up to 5m0s for pod "security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445" in namespace "security-context-9209" to be "Succeeded or Failed"
Nov  5 12:00:42.977: INFO: Pod "security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445": Phase="Pending", Reason="", readiness=false. Elapsed: 5.946866ms
Nov  5 12:00:44.982: INFO: Pod "security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010940452s
Nov  5 12:00:46.981: INFO: Pod "security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009851723s
STEP: Saw pod success 11/05/22 12:00:46.981
Nov  5 12:00:46.981: INFO: Pod "security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445" satisfied condition "Succeeded or Failed"
Nov  5 12:00:46.985: INFO: Trying to get logs from node ip-172-31-0-255 pod security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445 container test-container: <nil>
STEP: delete the pod 11/05/22 12:00:46.992
Nov  5 12:00:47.002: INFO: Waiting for pod security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445 to disappear
Nov  5 12:00:47.005: INFO: Pod security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov  5 12:00:47.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-9209" for this suite. 11/05/22 12:00:47.009
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":31,"skipped":544,"failed":0}
------------------------------
• [4.076 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:42.939
    Nov  5 12:00:42.939: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename security-context 11/05/22 12:00:42.94
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:42.955
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:42.958
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/05/22 12:00:42.962
    Nov  5 12:00:42.971: INFO: Waiting up to 5m0s for pod "security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445" in namespace "security-context-9209" to be "Succeeded or Failed"
    Nov  5 12:00:42.977: INFO: Pod "security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445": Phase="Pending", Reason="", readiness=false. Elapsed: 5.946866ms
    Nov  5 12:00:44.982: INFO: Pod "security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010940452s
    Nov  5 12:00:46.981: INFO: Pod "security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009851723s
    STEP: Saw pod success 11/05/22 12:00:46.981
    Nov  5 12:00:46.981: INFO: Pod "security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445" satisfied condition "Succeeded or Failed"
    Nov  5 12:00:46.985: INFO: Trying to get logs from node ip-172-31-0-255 pod security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445 container test-container: <nil>
    STEP: delete the pod 11/05/22 12:00:46.992
    Nov  5 12:00:47.002: INFO: Waiting for pod security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445 to disappear
    Nov  5 12:00:47.005: INFO: Pod security-context-ebf643ff-a6ba-4230-a1df-8c2984a96445 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov  5 12:00:47.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-9209" for this suite. 11/05/22 12:00:47.009
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:47.017
Nov  5 12:00:47.017: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 12:00:47.017
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:47.033
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:47.036
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 11/05/22 12:00:47.04
Nov  5 12:00:47.048: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563" in namespace "downward-api-3857" to be "Succeeded or Failed"
Nov  5 12:00:47.052: INFO: Pod "downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563": Phase="Pending", Reason="", readiness=false. Elapsed: 3.376923ms
Nov  5 12:00:49.056: INFO: Pod "downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008251607s
Nov  5 12:00:51.057: INFO: Pod "downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008450541s
STEP: Saw pod success 11/05/22 12:00:51.057
Nov  5 12:00:51.057: INFO: Pod "downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563" satisfied condition "Succeeded or Failed"
Nov  5 12:00:51.061: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563 container client-container: <nil>
STEP: delete the pod 11/05/22 12:00:51.067
Nov  5 12:00:51.080: INFO: Waiting for pod downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563 to disappear
Nov  5 12:00:51.084: INFO: Pod downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 12:00:51.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3857" for this suite. 11/05/22 12:00:51.087
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":32,"skipped":553,"failed":0}
------------------------------
• [4.077 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:47.017
    Nov  5 12:00:47.017: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 12:00:47.017
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:47.033
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:47.036
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 11/05/22 12:00:47.04
    Nov  5 12:00:47.048: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563" in namespace "downward-api-3857" to be "Succeeded or Failed"
    Nov  5 12:00:47.052: INFO: Pod "downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563": Phase="Pending", Reason="", readiness=false. Elapsed: 3.376923ms
    Nov  5 12:00:49.056: INFO: Pod "downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008251607s
    Nov  5 12:00:51.057: INFO: Pod "downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008450541s
    STEP: Saw pod success 11/05/22 12:00:51.057
    Nov  5 12:00:51.057: INFO: Pod "downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563" satisfied condition "Succeeded or Failed"
    Nov  5 12:00:51.061: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563 container client-container: <nil>
    STEP: delete the pod 11/05/22 12:00:51.067
    Nov  5 12:00:51.080: INFO: Waiting for pod downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563 to disappear
    Nov  5 12:00:51.084: INFO: Pod downwardapi-volume-7bd3afec-1728-47e4-890f-6d3953943563 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 12:00:51.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3857" for this suite. 11/05/22 12:00:51.087
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:51.095
Nov  5 12:00:51.095: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 12:00:51.096
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:51.112
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:51.117
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 12:00:51.133
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:00:51.617
STEP: Deploying the webhook pod 11/05/22 12:00:51.623
STEP: Wait for the deployment to be ready 11/05/22 12:00:51.637
Nov  5 12:00:51.644: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/05/22 12:00:53.655
STEP: Verifying the service has paired with the endpoint 11/05/22 12:00:53.664
Nov  5 12:00:54.665: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 11/05/22 12:00:54.669
STEP: create a configmap that should be updated by the webhook 11/05/22 12:00:54.685
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:00:54.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9106" for this suite. 11/05/22 12:00:54.708
STEP: Destroying namespace "webhook-9106-markers" for this suite. 11/05/22 12:00:54.715
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":33,"skipped":593,"failed":0}
------------------------------
• [3.676 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:51.095
    Nov  5 12:00:51.095: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 12:00:51.096
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:51.112
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:51.117
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 12:00:51.133
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:00:51.617
    STEP: Deploying the webhook pod 11/05/22 12:00:51.623
    STEP: Wait for the deployment to be ready 11/05/22 12:00:51.637
    Nov  5 12:00:51.644: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/05/22 12:00:53.655
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:00:53.664
    Nov  5 12:00:54.665: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 11/05/22 12:00:54.669
    STEP: create a configmap that should be updated by the webhook 11/05/22 12:00:54.685
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:00:54.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9106" for this suite. 11/05/22 12:00:54.708
    STEP: Destroying namespace "webhook-9106-markers" for this suite. 11/05/22 12:00:54.715
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:54.773
Nov  5 12:00:54.773: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 12:00:54.774
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:54.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:54.793
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-85091a25-7d10-4559-9fec-62baeed6b23f 11/05/22 12:00:54.797
STEP: Creating a pod to test consume configMaps 11/05/22 12:00:54.802
Nov  5 12:00:54.812: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8" in namespace "configmap-302" to be "Succeeded or Failed"
Nov  5 12:00:54.817: INFO: Pod "pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.685848ms
Nov  5 12:00:56.821: INFO: Pod "pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009508375s
Nov  5 12:00:58.823: INFO: Pod "pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011037182s
STEP: Saw pod success 11/05/22 12:00:58.823
Nov  5 12:00:58.823: INFO: Pod "pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8" satisfied condition "Succeeded or Failed"
Nov  5 12:00:58.826: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8 container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:00:58.833
Nov  5 12:00:58.846: INFO: Waiting for pod pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8 to disappear
Nov  5 12:00:58.850: INFO: Pod pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 12:00:58.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-302" for this suite. 11/05/22 12:00:58.853
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":34,"skipped":661,"failed":0}
------------------------------
• [4.087 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:54.773
    Nov  5 12:00:54.773: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 12:00:54.774
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:54.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:54.793
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-85091a25-7d10-4559-9fec-62baeed6b23f 11/05/22 12:00:54.797
    STEP: Creating a pod to test consume configMaps 11/05/22 12:00:54.802
    Nov  5 12:00:54.812: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8" in namespace "configmap-302" to be "Succeeded or Failed"
    Nov  5 12:00:54.817: INFO: Pod "pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.685848ms
    Nov  5 12:00:56.821: INFO: Pod "pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009508375s
    Nov  5 12:00:58.823: INFO: Pod "pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011037182s
    STEP: Saw pod success 11/05/22 12:00:58.823
    Nov  5 12:00:58.823: INFO: Pod "pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8" satisfied condition "Succeeded or Failed"
    Nov  5 12:00:58.826: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8 container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:00:58.833
    Nov  5 12:00:58.846: INFO: Waiting for pod pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8 to disappear
    Nov  5 12:00:58.850: INFO: Pod pod-configmaps-c1c38623-f33f-417e-a445-7473609ca7d8 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 12:00:58.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-302" for this suite. 11/05/22 12:00:58.853
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:00:58.861
Nov  5 12:00:58.861: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir-wrapper 11/05/22 12:00:58.862
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:58.876
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:58.88
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Nov  5 12:00:58.915: INFO: Waiting up to 5m0s for pod "pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18" in namespace "emptydir-wrapper-3251" to be "running and ready"
Nov  5 12:00:58.921: INFO: Pod "pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18": Phase="Pending", Reason="", readiness=false. Elapsed: 6.535333ms
Nov  5 12:00:58.921: INFO: The phase of Pod pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:01:00.926: INFO: Pod "pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18": Phase="Running", Reason="", readiness=true. Elapsed: 2.011936446s
Nov  5 12:01:00.927: INFO: The phase of Pod pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18 is Running (Ready = true)
Nov  5 12:01:00.927: INFO: Pod "pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18" satisfied condition "running and ready"
STEP: Cleaning up the secret 11/05/22 12:01:00.931
STEP: Cleaning up the configmap 11/05/22 12:01:00.938
STEP: Cleaning up the pod 11/05/22 12:01:00.945
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Nov  5 12:01:00.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3251" for this suite. 11/05/22 12:01:00.964
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":35,"skipped":667,"failed":0}
------------------------------
• [2.111 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:00:58.861
    Nov  5 12:00:58.861: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir-wrapper 11/05/22 12:00:58.862
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:00:58.876
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:00:58.88
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Nov  5 12:00:58.915: INFO: Waiting up to 5m0s for pod "pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18" in namespace "emptydir-wrapper-3251" to be "running and ready"
    Nov  5 12:00:58.921: INFO: Pod "pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18": Phase="Pending", Reason="", readiness=false. Elapsed: 6.535333ms
    Nov  5 12:00:58.921: INFO: The phase of Pod pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:01:00.926: INFO: Pod "pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18": Phase="Running", Reason="", readiness=true. Elapsed: 2.011936446s
    Nov  5 12:01:00.927: INFO: The phase of Pod pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18 is Running (Ready = true)
    Nov  5 12:01:00.927: INFO: Pod "pod-secrets-5a42fbbd-dd1b-46e2-a8e3-b5a4f7efec18" satisfied condition "running and ready"
    STEP: Cleaning up the secret 11/05/22 12:01:00.931
    STEP: Cleaning up the configmap 11/05/22 12:01:00.938
    STEP: Cleaning up the pod 11/05/22 12:01:00.945
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Nov  5 12:01:00.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-3251" for this suite. 11/05/22 12:01:00.964
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:01:00.976
Nov  5 12:01:00.976: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-probe 11/05/22 12:01:00.976
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:01:00.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:01:01.004
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a in namespace container-probe-6899 11/05/22 12:01:01.008
Nov  5 12:01:01.019: INFO: Waiting up to 5m0s for pod "liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a" in namespace "container-probe-6899" to be "not pending"
Nov  5 12:01:01.023: INFO: Pod "liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.846978ms
Nov  5 12:01:03.029: INFO: Pod "liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a": Phase="Running", Reason="", readiness=true. Elapsed: 2.010147625s
Nov  5 12:01:03.029: INFO: Pod "liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a" satisfied condition "not pending"
Nov  5 12:01:03.029: INFO: Started pod liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a in namespace container-probe-6899
STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 12:01:03.029
Nov  5 12:01:03.033: INFO: Initial restart count of pod liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is 0
Nov  5 12:01:23.086: INFO: Restart count of pod container-probe-6899/liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is now 1 (20.052890223s elapsed)
Nov  5 12:01:43.130: INFO: Restart count of pod container-probe-6899/liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is now 2 (40.096114398s elapsed)
Nov  5 12:02:03.175: INFO: Restart count of pod container-probe-6899/liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is now 3 (1m0.141604856s elapsed)
Nov  5 12:02:23.220: INFO: Restart count of pod container-probe-6899/liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is now 4 (1m20.186962186s elapsed)
Nov  5 12:03:35.392: INFO: Restart count of pod container-probe-6899/liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is now 5 (2m32.35866308s elapsed)
STEP: deleting the pod 11/05/22 12:03:35.392
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov  5 12:03:35.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6899" for this suite. 11/05/22 12:03:35.413
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":36,"skipped":703,"failed":0}
------------------------------
• [SLOW TEST] [154.444 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:01:00.976
    Nov  5 12:01:00.976: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-probe 11/05/22 12:01:00.976
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:01:00.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:01:01.004
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a in namespace container-probe-6899 11/05/22 12:01:01.008
    Nov  5 12:01:01.019: INFO: Waiting up to 5m0s for pod "liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a" in namespace "container-probe-6899" to be "not pending"
    Nov  5 12:01:01.023: INFO: Pod "liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.846978ms
    Nov  5 12:01:03.029: INFO: Pod "liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a": Phase="Running", Reason="", readiness=true. Elapsed: 2.010147625s
    Nov  5 12:01:03.029: INFO: Pod "liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a" satisfied condition "not pending"
    Nov  5 12:01:03.029: INFO: Started pod liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a in namespace container-probe-6899
    STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 12:01:03.029
    Nov  5 12:01:03.033: INFO: Initial restart count of pod liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is 0
    Nov  5 12:01:23.086: INFO: Restart count of pod container-probe-6899/liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is now 1 (20.052890223s elapsed)
    Nov  5 12:01:43.130: INFO: Restart count of pod container-probe-6899/liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is now 2 (40.096114398s elapsed)
    Nov  5 12:02:03.175: INFO: Restart count of pod container-probe-6899/liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is now 3 (1m0.141604856s elapsed)
    Nov  5 12:02:23.220: INFO: Restart count of pod container-probe-6899/liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is now 4 (1m20.186962186s elapsed)
    Nov  5 12:03:35.392: INFO: Restart count of pod container-probe-6899/liveness-93342ba9-8ac1-45a5-9a41-ae3a8663875a is now 5 (2m32.35866308s elapsed)
    STEP: deleting the pod 11/05/22 12:03:35.392
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov  5 12:03:35.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6899" for this suite. 11/05/22 12:03:35.413
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:03:35.422
Nov  5 12:03:35.422: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 12:03:35.423
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:03:35.435
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:03:35.439
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-7977/configmap-test-a88525d5-0840-4286-a3a4-e6906ffded98 11/05/22 12:03:35.448
STEP: Creating a pod to test consume configMaps 11/05/22 12:03:35.454
Nov  5 12:03:35.473: INFO: Waiting up to 5m0s for pod "pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db" in namespace "configmap-7977" to be "Succeeded or Failed"
Nov  5 12:03:35.479: INFO: Pod "pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007925ms
Nov  5 12:03:37.483: INFO: Pod "pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01047419s
Nov  5 12:03:39.485: INFO: Pod "pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011802557s
STEP: Saw pod success 11/05/22 12:03:39.485
Nov  5 12:03:39.485: INFO: Pod "pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db" satisfied condition "Succeeded or Failed"
Nov  5 12:03:39.488: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db container env-test: <nil>
STEP: delete the pod 11/05/22 12:03:39.505
Nov  5 12:03:39.520: INFO: Waiting for pod pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db to disappear
Nov  5 12:03:39.523: INFO: Pod pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 12:03:39.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7977" for this suite. 11/05/22 12:03:39.527
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":37,"skipped":721,"failed":0}
------------------------------
• [4.112 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:03:35.422
    Nov  5 12:03:35.422: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 12:03:35.423
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:03:35.435
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:03:35.439
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-7977/configmap-test-a88525d5-0840-4286-a3a4-e6906ffded98 11/05/22 12:03:35.448
    STEP: Creating a pod to test consume configMaps 11/05/22 12:03:35.454
    Nov  5 12:03:35.473: INFO: Waiting up to 5m0s for pod "pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db" in namespace "configmap-7977" to be "Succeeded or Failed"
    Nov  5 12:03:35.479: INFO: Pod "pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007925ms
    Nov  5 12:03:37.483: INFO: Pod "pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01047419s
    Nov  5 12:03:39.485: INFO: Pod "pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011802557s
    STEP: Saw pod success 11/05/22 12:03:39.485
    Nov  5 12:03:39.485: INFO: Pod "pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db" satisfied condition "Succeeded or Failed"
    Nov  5 12:03:39.488: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db container env-test: <nil>
    STEP: delete the pod 11/05/22 12:03:39.505
    Nov  5 12:03:39.520: INFO: Waiting for pod pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db to disappear
    Nov  5 12:03:39.523: INFO: Pod pod-configmaps-8aa945f5-a3ad-466b-88d1-a34b696631db no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 12:03:39.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-7977" for this suite. 11/05/22 12:03:39.527
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:03:39.536
Nov  5 12:03:39.536: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename daemonsets 11/05/22 12:03:39.537
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:03:39.554
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:03:39.558
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 11/05/22 12:03:39.581
STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 12:03:39.587
Nov  5 12:03:39.591: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:39.591: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:39.595: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:03:39.595: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:03:40.602: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:40.602: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:40.607: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov  5 12:03:40.607: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:03:41.601: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:41.601: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:41.605: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov  5 12:03:41.605: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:03:42.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:42.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:42.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov  5 12:03:42.604: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:03:43.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:43.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:43.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov  5 12:03:43.604: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:03:44.601: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:44.601: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:44.607: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov  5 12:03:44.607: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:03:45.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:45.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:45.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov  5 12:03:45.604: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:03:46.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:46.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:46.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov  5 12:03:46.604: INFO: Node ip-172-31-27-199 is running 0 daemon pod, expected 1
Nov  5 12:03:47.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:47.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:47.603: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov  5 12:03:47.603: INFO: Node ip-172-31-27-199 is running 0 daemon pod, expected 1
Nov  5 12:03:48.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:48.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:48.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov  5 12:03:48.604: INFO: Node ip-172-31-27-199 is running 0 daemon pod, expected 1
Nov  5 12:03:49.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:49.601: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:49.605: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov  5 12:03:49.605: INFO: Node ip-172-31-27-199 is running 0 daemon pod, expected 1
Nov  5 12:03:50.599: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:50.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:50.603: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov  5 12:03:50.604: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 11/05/22 12:03:50.607
Nov  5 12:03:50.623: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:50.623: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:50.627: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov  5 12:03:50.627: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
Nov  5 12:03:51.632: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:51.632: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:51.636: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov  5 12:03:51.636: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
Nov  5 12:03:52.632: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:52.632: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:03:52.636: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov  5 12:03:52.636: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/05/22 12:03:52.639
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3212, will wait for the garbage collector to delete the pods 11/05/22 12:03:52.639
Nov  5 12:03:52.701: INFO: Deleting DaemonSet.extensions daemon-set took: 7.477003ms
Nov  5 12:03:52.801: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.504457ms
Nov  5 12:03:55.707: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:03:55.707: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov  5 12:03:55.712: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4851"},"items":null}

Nov  5 12:03:55.715: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4851"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:03:55.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3212" for this suite. 11/05/22 12:03:55.733
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":38,"skipped":736,"failed":0}
------------------------------
• [SLOW TEST] [16.205 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:03:39.536
    Nov  5 12:03:39.536: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename daemonsets 11/05/22 12:03:39.537
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:03:39.554
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:03:39.558
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 11/05/22 12:03:39.581
    STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 12:03:39.587
    Nov  5 12:03:39.591: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:39.591: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:39.595: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:03:39.595: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:03:40.602: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:40.602: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:40.607: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov  5 12:03:40.607: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:03:41.601: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:41.601: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:41.605: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov  5 12:03:41.605: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:03:42.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:42.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:42.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov  5 12:03:42.604: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:03:43.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:43.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:43.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov  5 12:03:43.604: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:03:44.601: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:44.601: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:44.607: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov  5 12:03:44.607: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:03:45.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:45.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:45.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov  5 12:03:45.604: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:03:46.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:46.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:46.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov  5 12:03:46.604: INFO: Node ip-172-31-27-199 is running 0 daemon pod, expected 1
    Nov  5 12:03:47.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:47.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:47.603: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov  5 12:03:47.603: INFO: Node ip-172-31-27-199 is running 0 daemon pod, expected 1
    Nov  5 12:03:48.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:48.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:48.604: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov  5 12:03:48.604: INFO: Node ip-172-31-27-199 is running 0 daemon pod, expected 1
    Nov  5 12:03:49.600: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:49.601: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:49.605: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov  5 12:03:49.605: INFO: Node ip-172-31-27-199 is running 0 daemon pod, expected 1
    Nov  5 12:03:50.599: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:50.600: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:50.603: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov  5 12:03:50.604: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 11/05/22 12:03:50.607
    Nov  5 12:03:50.623: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:50.623: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:50.627: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov  5 12:03:50.627: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
    Nov  5 12:03:51.632: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:51.632: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:51.636: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov  5 12:03:51.636: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
    Nov  5 12:03:52.632: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:52.632: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:03:52.636: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov  5 12:03:52.636: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/05/22 12:03:52.639
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3212, will wait for the garbage collector to delete the pods 11/05/22 12:03:52.639
    Nov  5 12:03:52.701: INFO: Deleting DaemonSet.extensions daemon-set took: 7.477003ms
    Nov  5 12:03:52.801: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.504457ms
    Nov  5 12:03:55.707: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:03:55.707: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov  5 12:03:55.712: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"4851"},"items":null}

    Nov  5 12:03:55.715: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"4851"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:03:55.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-3212" for this suite. 11/05/22 12:03:55.733
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:03:55.742
Nov  5 12:03:55.742: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-lifecycle-hook 11/05/22 12:03:55.742
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:03:55.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:03:55.76
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/05/22 12:03:55.774
Nov  5 12:03:55.783: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5679" to be "running and ready"
Nov  5 12:03:55.789: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.234356ms
Nov  5 12:03:55.789: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:03:57.793: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.010412868s
Nov  5 12:03:57.793: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov  5 12:03:57.793: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 11/05/22 12:03:57.797
Nov  5 12:03:57.805: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-5679" to be "running and ready"
Nov  5 12:03:57.812: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.422652ms
Nov  5 12:03:57.812: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:03:59.817: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011397083s
Nov  5 12:03:59.817: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Nov  5 12:03:59.817: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 11/05/22 12:03:59.82
STEP: delete the pod with lifecycle hook 11/05/22 12:03:59.838
Nov  5 12:03:59.847: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  5 12:03:59.851: INFO: Pod pod-with-poststart-http-hook still exists
Nov  5 12:04:01.851: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  5 12:04:01.855: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov  5 12:04:01.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5679" for this suite. 11/05/22 12:04:01.859
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":39,"skipped":754,"failed":0}
------------------------------
• [SLOW TEST] [6.124 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:03:55.742
    Nov  5 12:03:55.742: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/05/22 12:03:55.742
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:03:55.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:03:55.76
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/05/22 12:03:55.774
    Nov  5 12:03:55.783: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-5679" to be "running and ready"
    Nov  5 12:03:55.789: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.234356ms
    Nov  5 12:03:55.789: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:03:57.793: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.010412868s
    Nov  5 12:03:57.793: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov  5 12:03:57.793: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 11/05/22 12:03:57.797
    Nov  5 12:03:57.805: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-5679" to be "running and ready"
    Nov  5 12:03:57.812: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.422652ms
    Nov  5 12:03:57.812: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:03:59.817: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011397083s
    Nov  5 12:03:59.817: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Nov  5 12:03:59.817: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 11/05/22 12:03:59.82
    STEP: delete the pod with lifecycle hook 11/05/22 12:03:59.838
    Nov  5 12:03:59.847: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov  5 12:03:59.851: INFO: Pod pod-with-poststart-http-hook still exists
    Nov  5 12:04:01.851: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Nov  5 12:04:01.855: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov  5 12:04:01.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-5679" for this suite. 11/05/22 12:04:01.859
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:04:01.87
Nov  5 12:04:01.870: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:04:01.871
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:04:01.885
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:04:01.889
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 11/05/22 12:04:01.893
Nov  5 12:04:01.901: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06" in namespace "projected-3709" to be "Succeeded or Failed"
Nov  5 12:04:01.904: INFO: Pod "downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06": Phase="Pending", Reason="", readiness=false. Elapsed: 3.167403ms
Nov  5 12:04:03.909: INFO: Pod "downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00788824s
Nov  5 12:04:05.908: INFO: Pod "downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007737412s
STEP: Saw pod success 11/05/22 12:04:05.908
Nov  5 12:04:05.909: INFO: Pod "downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06" satisfied condition "Succeeded or Failed"
Nov  5 12:04:05.912: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06 container client-container: <nil>
STEP: delete the pod 11/05/22 12:04:05.919
Nov  5 12:04:05.932: INFO: Waiting for pod downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06 to disappear
Nov  5 12:04:05.936: INFO: Pod downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 12:04:05.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3709" for this suite. 11/05/22 12:04:05.94
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":40,"skipped":809,"failed":0}
------------------------------
• [4.076 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:04:01.87
    Nov  5 12:04:01.870: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:04:01.871
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:04:01.885
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:04:01.889
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 11/05/22 12:04:01.893
    Nov  5 12:04:01.901: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06" in namespace "projected-3709" to be "Succeeded or Failed"
    Nov  5 12:04:01.904: INFO: Pod "downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06": Phase="Pending", Reason="", readiness=false. Elapsed: 3.167403ms
    Nov  5 12:04:03.909: INFO: Pod "downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00788824s
    Nov  5 12:04:05.908: INFO: Pod "downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007737412s
    STEP: Saw pod success 11/05/22 12:04:05.908
    Nov  5 12:04:05.909: INFO: Pod "downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06" satisfied condition "Succeeded or Failed"
    Nov  5 12:04:05.912: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06 container client-container: <nil>
    STEP: delete the pod 11/05/22 12:04:05.919
    Nov  5 12:04:05.932: INFO: Waiting for pod downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06 to disappear
    Nov  5 12:04:05.936: INFO: Pod downwardapi-volume-ed8c456e-ae1c-4532-ad54-d4952075bd06 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 12:04:05.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3709" for this suite. 11/05/22 12:04:05.94
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:04:05.947
Nov  5 12:04:05.948: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sched-pred 11/05/22 12:04:05.948
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:04:05.961
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:04:05.965
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov  5 12:04:05.969: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  5 12:04:05.976: INFO: Waiting for terminating namespaces to be deleted...
Nov  5 12:04:05.980: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-0-255 before test
Nov  5 12:04:05.985: INFO: nginx-ingress-controller-kubernetes-worker-hdhmc from ingress-nginx-kubernetes-worker started at 2022-11-05 11:58:31 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.985: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 12:04:05.985: INFO: sonobuoy from sonobuoy started at 2022-11-05 11:55:13 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.985: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  5 12:04:05.985: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 12:04:05.985: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:04:05.985: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 12:04:05.985: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-27-199 before test
Nov  5 12:04:05.989: INFO: default-http-backend-kubernetes-worker-6546b9855c-tdc5h from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.989: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov  5 12:04:05.989: INFO: nginx-ingress-controller-kubernetes-worker-l6972 from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.990: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 12:04:05.990: INFO: calico-kube-controllers-b5bd6849d-zg9jq from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.990: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  5 12:04:05.990: INFO: coredns-6bcf44f4cc-ddkx4 from kube-system started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.990: INFO: 	Container coredns ready: true, restart count 0
Nov  5 12:04:05.990: INFO: kube-state-metrics-74f5d549cc-cc4bl from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.990: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov  5 12:04:05.990: INFO: metrics-server-v0.5.2-6b48dc6f97-cp95w from kube-system started at 2022-11-05 11:49:10 +0000 UTC (2 container statuses recorded)
Nov  5 12:04:05.990: INFO: 	Container metrics-server ready: true, restart count 1
Nov  5 12:04:05.990: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov  5 12:04:05.990: INFO: dashboard-metrics-scraper-85d45476c6-4v4zk from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.990: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  5 12:04:05.990: INFO: kubernetes-dashboard-7fb574cb-6lhg6 from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.990: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Nov  5 12:04:05.990: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-w6fxs from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 12:04:05.990: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:04:05.990: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 12:04:05.990: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-41-19 before test
Nov  5 12:04:05.995: INFO: pod-handle-http-request from container-lifecycle-hook-5679 started at 2022-11-05 12:03:55 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.995: INFO: 	Container agnhost-container ready: true, restart count 0
Nov  5 12:04:05.995: INFO: nginx-ingress-controller-kubernetes-worker-879hx from ingress-nginx-kubernetes-worker started at 2022-11-05 11:50:52 +0000 UTC (1 container statuses recorded)
Nov  5 12:04:05.995: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 12:04:05.995: INFO: sonobuoy-e2e-job-b878a59025e244cf from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 12:04:05.995: INFO: 	Container e2e ready: true, restart count 0
Nov  5 12:04:05.995: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:04:05.995: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-zjsjg from sonobuoy started at 2022-11-05 11:55:17 +0000 UTC (2 container statuses recorded)
Nov  5 12:04:05.995: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:04:05.995: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 11/05/22 12:04:05.995
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1724aeb309bfbb9d], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 11/05/22 12:04:06.021
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:04:07.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8192" for this suite. 11/05/22 12:04:07.022
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":41,"skipped":818,"failed":0}
------------------------------
• [1.082 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:04:05.947
    Nov  5 12:04:05.948: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sched-pred 11/05/22 12:04:05.948
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:04:05.961
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:04:05.965
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov  5 12:04:05.969: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov  5 12:04:05.976: INFO: Waiting for terminating namespaces to be deleted...
    Nov  5 12:04:05.980: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-0-255 before test
    Nov  5 12:04:05.985: INFO: nginx-ingress-controller-kubernetes-worker-hdhmc from ingress-nginx-kubernetes-worker started at 2022-11-05 11:58:31 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.985: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 12:04:05.985: INFO: sonobuoy from sonobuoy started at 2022-11-05 11:55:13 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.985: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov  5 12:04:05.985: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 12:04:05.985: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:04:05.985: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov  5 12:04:05.985: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-27-199 before test
    Nov  5 12:04:05.989: INFO: default-http-backend-kubernetes-worker-6546b9855c-tdc5h from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.989: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov  5 12:04:05.989: INFO: nginx-ingress-controller-kubernetes-worker-l6972 from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.990: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 12:04:05.990: INFO: calico-kube-controllers-b5bd6849d-zg9jq from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.990: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov  5 12:04:05.990: INFO: coredns-6bcf44f4cc-ddkx4 from kube-system started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.990: INFO: 	Container coredns ready: true, restart count 0
    Nov  5 12:04:05.990: INFO: kube-state-metrics-74f5d549cc-cc4bl from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.990: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov  5 12:04:05.990: INFO: metrics-server-v0.5.2-6b48dc6f97-cp95w from kube-system started at 2022-11-05 11:49:10 +0000 UTC (2 container statuses recorded)
    Nov  5 12:04:05.990: INFO: 	Container metrics-server ready: true, restart count 1
    Nov  5 12:04:05.990: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov  5 12:04:05.990: INFO: dashboard-metrics-scraper-85d45476c6-4v4zk from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.990: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov  5 12:04:05.990: INFO: kubernetes-dashboard-7fb574cb-6lhg6 from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.990: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
    Nov  5 12:04:05.990: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-w6fxs from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 12:04:05.990: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:04:05.990: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov  5 12:04:05.990: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-41-19 before test
    Nov  5 12:04:05.995: INFO: pod-handle-http-request from container-lifecycle-hook-5679 started at 2022-11-05 12:03:55 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.995: INFO: 	Container agnhost-container ready: true, restart count 0
    Nov  5 12:04:05.995: INFO: nginx-ingress-controller-kubernetes-worker-879hx from ingress-nginx-kubernetes-worker started at 2022-11-05 11:50:52 +0000 UTC (1 container statuses recorded)
    Nov  5 12:04:05.995: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 12:04:05.995: INFO: sonobuoy-e2e-job-b878a59025e244cf from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 12:04:05.995: INFO: 	Container e2e ready: true, restart count 0
    Nov  5 12:04:05.995: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:04:05.995: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-zjsjg from sonobuoy started at 2022-11-05 11:55:17 +0000 UTC (2 container statuses recorded)
    Nov  5 12:04:05.995: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:04:05.995: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 11/05/22 12:04:05.995
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.1724aeb309bfbb9d], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 11/05/22 12:04:06.021
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:04:07.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-8192" for this suite. 11/05/22 12:04:07.022
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:04:07.03
Nov  5 12:04:07.031: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 12:04:07.031
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:04:07.046
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:04:07.053
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 11/05/22 12:04:07.058
Nov  5 12:04:07.075: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6" in namespace "downward-api-226" to be "Succeeded or Failed"
Nov  5 12:04:07.083: INFO: Pod "downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.178706ms
Nov  5 12:04:09.088: INFO: Pod "downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012820262s
Nov  5 12:04:11.088: INFO: Pod "downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012742481s
STEP: Saw pod success 11/05/22 12:04:11.088
Nov  5 12:04:11.088: INFO: Pod "downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6" satisfied condition "Succeeded or Failed"
Nov  5 12:04:11.091: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6 container client-container: <nil>
STEP: delete the pod 11/05/22 12:04:11.098
Nov  5 12:04:11.113: INFO: Waiting for pod downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6 to disappear
Nov  5 12:04:11.117: INFO: Pod downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 12:04:11.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-226" for this suite. 11/05/22 12:04:11.121
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":42,"skipped":831,"failed":0}
------------------------------
• [4.097 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:04:07.03
    Nov  5 12:04:07.031: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 12:04:07.031
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:04:07.046
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:04:07.053
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 11/05/22 12:04:07.058
    Nov  5 12:04:07.075: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6" in namespace "downward-api-226" to be "Succeeded or Failed"
    Nov  5 12:04:07.083: INFO: Pod "downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.178706ms
    Nov  5 12:04:09.088: INFO: Pod "downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012820262s
    Nov  5 12:04:11.088: INFO: Pod "downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012742481s
    STEP: Saw pod success 11/05/22 12:04:11.088
    Nov  5 12:04:11.088: INFO: Pod "downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6" satisfied condition "Succeeded or Failed"
    Nov  5 12:04:11.091: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6 container client-container: <nil>
    STEP: delete the pod 11/05/22 12:04:11.098
    Nov  5 12:04:11.113: INFO: Waiting for pod downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6 to disappear
    Nov  5 12:04:11.117: INFO: Pod downwardapi-volume-c024c4b7-93f0-499d-aecc-149d213bd7a6 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 12:04:11.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-226" for this suite. 11/05/22 12:04:11.121
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:04:11.128
Nov  5 12:04:11.128: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename job 11/05/22 12:04:11.129
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:04:11.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:04:11.148
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 11/05/22 12:04:11.152
STEP: Ensure pods equal to paralellism count is attached to the job 11/05/22 12:04:11.161
STEP: patching /status 11/05/22 12:04:13.166
STEP: updating /status 11/05/22 12:04:13.174
STEP: get /status 11/05/22 12:04:13.203
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov  5 12:04:13.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2620" for this suite. 11/05/22 12:04:13.212
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":43,"skipped":832,"failed":0}
------------------------------
• [2.091 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:04:11.128
    Nov  5 12:04:11.128: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename job 11/05/22 12:04:11.129
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:04:11.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:04:11.148
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 11/05/22 12:04:11.152
    STEP: Ensure pods equal to paralellism count is attached to the job 11/05/22 12:04:11.161
    STEP: patching /status 11/05/22 12:04:13.166
    STEP: updating /status 11/05/22 12:04:13.174
    STEP: get /status 11/05/22 12:04:13.203
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov  5 12:04:13.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2620" for this suite. 11/05/22 12:04:13.212
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:04:13.22
Nov  5 12:04:13.220: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename statefulset 11/05/22 12:04:13.221
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:04:13.233
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:04:13.238
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-473 11/05/22 12:04:13.241
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-473 11/05/22 12:04:13.246
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-473 11/05/22 12:04:13.256
Nov  5 12:04:13.260: INFO: Found 0 stateful pods, waiting for 1
Nov  5 12:04:23.265: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 11/05/22 12:04:23.265
Nov  5 12:04:23.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  5 12:04:23.417: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  5 12:04:23.417: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  5 12:04:23.417: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  5 12:04:23.421: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  5 12:04:33.425: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 12:04:33.425: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 12:04:33.442: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Nov  5 12:04:33.442: INFO: ss-0  ip-172-31-41-19  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  }]
Nov  5 12:04:33.442: INFO: 
Nov  5 12:04:33.442: INFO: StatefulSet ss has not reached scale 3, at 1
Nov  5 12:04:34.447: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995555255s
Nov  5 12:04:35.451: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990823887s
Nov  5 12:04:36.456: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985703721s
Nov  5 12:04:37.461: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981869379s
Nov  5 12:04:38.465: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976750528s
Nov  5 12:04:39.470: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972469752s
Nov  5 12:04:40.474: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968051519s
Nov  5 12:04:41.479: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963576391s
Nov  5 12:04:42.483: INFO: Verifying statefulset ss doesn't scale past 3 for another 959.150533ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-473 11/05/22 12:04:43.484
Nov  5 12:04:43.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  5 12:04:43.648: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  5 12:04:43.648: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  5 12:04:43.648: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  5 12:04:43.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  5 12:04:43.797: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  5 12:04:43.797: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  5 12:04:43.797: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  5 12:04:43.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  5 12:04:43.954: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  5 12:04:43.954: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  5 12:04:43.954: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  5 12:04:43.959: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Nov  5 12:04:53.965: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 12:04:53.965: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 12:04:53.965: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 11/05/22 12:04:53.965
Nov  5 12:04:53.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  5 12:04:54.117: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  5 12:04:54.117: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  5 12:04:54.117: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  5 12:04:54.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  5 12:04:54.258: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  5 12:04:54.258: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  5 12:04:54.258: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  5 12:04:54.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  5 12:04:54.396: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  5 12:04:54.396: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  5 12:04:54.396: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  5 12:04:54.396: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 12:04:54.400: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov  5 12:05:04.413: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 12:05:04.413: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 12:05:04.413: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 12:05:04.428: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
Nov  5 12:05:04.428: INFO: ss-0  ip-172-31-41-19   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  }]
Nov  5 12:05:04.428: INFO: ss-1  ip-172-31-0-255   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:33 +0000 UTC  }]
Nov  5 12:05:04.428: INFO: ss-2  ip-172-31-27-199  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:33 +0000 UTC  }]
Nov  5 12:05:04.428: INFO: 
Nov  5 12:05:04.428: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  5 12:05:05.432: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Nov  5 12:05:05.432: INFO: ss-0  ip-172-31-41-19  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  }]
Nov  5 12:05:05.432: INFO: 
Nov  5 12:05:05.432: INFO: StatefulSet ss has not reached scale 0, at 1
Nov  5 12:05:06.436: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.991452576s
Nov  5 12:05:07.440: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.987457956s
Nov  5 12:05:08.445: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.982261214s
Nov  5 12:05:09.450: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.977497382s
Nov  5 12:05:10.455: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.972712921s
Nov  5 12:05:11.459: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.96811015s
Nov  5 12:05:12.463: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.964129185s
Nov  5 12:05:13.467: INFO: Verifying statefulset ss doesn't scale past 0 for another 960.36807ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-473 11/05/22 12:05:14.467
Nov  5 12:05:14.472: INFO: Scaling statefulset ss to 0
Nov  5 12:05:14.485: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov  5 12:05:14.488: INFO: Deleting all statefulset in ns statefulset-473
Nov  5 12:05:14.492: INFO: Scaling statefulset ss to 0
Nov  5 12:05:14.503: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 12:05:14.506: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov  5 12:05:14.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-473" for this suite. 11/05/22 12:05:14.531
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":44,"skipped":846,"failed":0}
------------------------------
• [SLOW TEST] [61.318 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:04:13.22
    Nov  5 12:04:13.220: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename statefulset 11/05/22 12:04:13.221
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:04:13.233
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:04:13.238
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-473 11/05/22 12:04:13.241
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-473 11/05/22 12:04:13.246
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-473 11/05/22 12:04:13.256
    Nov  5 12:04:13.260: INFO: Found 0 stateful pods, waiting for 1
    Nov  5 12:04:23.265: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 11/05/22 12:04:23.265
    Nov  5 12:04:23.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov  5 12:04:23.417: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov  5 12:04:23.417: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov  5 12:04:23.417: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov  5 12:04:23.421: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Nov  5 12:04:33.425: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov  5 12:04:33.425: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 12:04:33.442: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
    Nov  5 12:04:33.442: INFO: ss-0  ip-172-31-41-19  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:23 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  }]
    Nov  5 12:04:33.442: INFO: 
    Nov  5 12:04:33.442: INFO: StatefulSet ss has not reached scale 3, at 1
    Nov  5 12:04:34.447: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995555255s
    Nov  5 12:04:35.451: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990823887s
    Nov  5 12:04:36.456: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985703721s
    Nov  5 12:04:37.461: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981869379s
    Nov  5 12:04:38.465: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976750528s
    Nov  5 12:04:39.470: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972469752s
    Nov  5 12:04:40.474: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968051519s
    Nov  5 12:04:41.479: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963576391s
    Nov  5 12:04:42.483: INFO: Verifying statefulset ss doesn't scale past 3 for another 959.150533ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-473 11/05/22 12:04:43.484
    Nov  5 12:04:43.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov  5 12:04:43.648: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov  5 12:04:43.648: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov  5 12:04:43.648: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov  5 12:04:43.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov  5 12:04:43.797: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Nov  5 12:04:43.797: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov  5 12:04:43.797: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov  5 12:04:43.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov  5 12:04:43.954: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Nov  5 12:04:43.954: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov  5 12:04:43.954: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov  5 12:04:43.959: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
    Nov  5 12:04:53.965: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 12:04:53.965: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 12:04:53.965: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 11/05/22 12:04:53.965
    Nov  5 12:04:53.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov  5 12:04:54.117: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov  5 12:04:54.117: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov  5 12:04:54.117: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov  5 12:04:54.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov  5 12:04:54.258: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov  5 12:04:54.258: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov  5 12:04:54.258: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov  5 12:04:54.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-473 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov  5 12:04:54.396: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov  5 12:04:54.396: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov  5 12:04:54.396: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov  5 12:04:54.396: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 12:04:54.400: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
    Nov  5 12:05:04.413: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov  5 12:05:04.413: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Nov  5 12:05:04.413: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Nov  5 12:05:04.428: INFO: POD   NODE              PHASE    GRACE  CONDITIONS
    Nov  5 12:05:04.428: INFO: ss-0  ip-172-31-41-19   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  }]
    Nov  5 12:05:04.428: INFO: ss-1  ip-172-31-0-255   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:33 +0000 UTC  }]
    Nov  5 12:05:04.428: INFO: ss-2  ip-172-31-27-199  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:33 +0000 UTC  }]
    Nov  5 12:05:04.428: INFO: 
    Nov  5 12:05:04.428: INFO: StatefulSet ss has not reached scale 0, at 3
    Nov  5 12:05:05.432: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
    Nov  5 12:05:05.432: INFO: ss-0  ip-172-31-41-19  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:04:13 +0000 UTC  }]
    Nov  5 12:05:05.432: INFO: 
    Nov  5 12:05:05.432: INFO: StatefulSet ss has not reached scale 0, at 1
    Nov  5 12:05:06.436: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.991452576s
    Nov  5 12:05:07.440: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.987457956s
    Nov  5 12:05:08.445: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.982261214s
    Nov  5 12:05:09.450: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.977497382s
    Nov  5 12:05:10.455: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.972712921s
    Nov  5 12:05:11.459: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.96811015s
    Nov  5 12:05:12.463: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.964129185s
    Nov  5 12:05:13.467: INFO: Verifying statefulset ss doesn't scale past 0 for another 960.36807ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-473 11/05/22 12:05:14.467
    Nov  5 12:05:14.472: INFO: Scaling statefulset ss to 0
    Nov  5 12:05:14.485: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov  5 12:05:14.488: INFO: Deleting all statefulset in ns statefulset-473
    Nov  5 12:05:14.492: INFO: Scaling statefulset ss to 0
    Nov  5 12:05:14.503: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 12:05:14.506: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov  5 12:05:14.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-473" for this suite. 11/05/22 12:05:14.531
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:05:14.538
Nov  5 12:05:14.539: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 12:05:14.539
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:05:14.553
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:05:14.558
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 12:05:14.573
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:05:14.998
STEP: Deploying the webhook pod 11/05/22 12:05:15.006
STEP: Wait for the deployment to be ready 11/05/22 12:05:15.018
Nov  5 12:05:15.026: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 12:05:17.037
STEP: Verifying the service has paired with the endpoint 11/05/22 12:05:17.051
Nov  5 12:05:18.051: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 11/05/22 12:05:18.117
STEP: Creating a configMap that should be mutated 11/05/22 12:05:18.129
STEP: Deleting the collection of validation webhooks 11/05/22 12:05:18.155
STEP: Creating a configMap that should not be mutated 11/05/22 12:05:18.203
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:05:18.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7991" for this suite. 11/05/22 12:05:18.218
STEP: Destroying namespace "webhook-7991-markers" for this suite. 11/05/22 12:05:18.225
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":45,"skipped":848,"failed":0}
------------------------------
• [3.743 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:05:14.538
    Nov  5 12:05:14.539: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 12:05:14.539
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:05:14.553
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:05:14.558
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 12:05:14.573
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:05:14.998
    STEP: Deploying the webhook pod 11/05/22 12:05:15.006
    STEP: Wait for the deployment to be ready 11/05/22 12:05:15.018
    Nov  5 12:05:15.026: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 12:05:17.037
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:05:17.051
    Nov  5 12:05:18.051: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 11/05/22 12:05:18.117
    STEP: Creating a configMap that should be mutated 11/05/22 12:05:18.129
    STEP: Deleting the collection of validation webhooks 11/05/22 12:05:18.155
    STEP: Creating a configMap that should not be mutated 11/05/22 12:05:18.203
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:05:18.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7991" for this suite. 11/05/22 12:05:18.218
    STEP: Destroying namespace "webhook-7991-markers" for this suite. 11/05/22 12:05:18.225
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:05:18.283
Nov  5 12:05:18.283: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:05:18.284
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:05:18.297
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:05:18.301
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-19842ea1-c268-443e-9924-cb983bd90eba 11/05/22 12:05:18.305
STEP: Creating a pod to test consume configMaps 11/05/22 12:05:18.311
Nov  5 12:05:18.319: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80" in namespace "projected-6221" to be "Succeeded or Failed"
Nov  5 12:05:18.325: INFO: Pod "pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.406207ms
Nov  5 12:05:20.329: INFO: Pod "pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010651132s
Nov  5 12:05:22.329: INFO: Pod "pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010644119s
STEP: Saw pod success 11/05/22 12:05:22.329
Nov  5 12:05:22.329: INFO: Pod "pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80" satisfied condition "Succeeded or Failed"
Nov  5 12:05:22.333: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80 container projected-configmap-volume-test: <nil>
STEP: delete the pod 11/05/22 12:05:22.339
Nov  5 12:05:22.350: INFO: Waiting for pod pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80 to disappear
Nov  5 12:05:22.353: INFO: Pod pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov  5 12:05:22.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6221" for this suite. 11/05/22 12:05:22.357
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":46,"skipped":885,"failed":0}
------------------------------
• [4.080 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:05:18.283
    Nov  5 12:05:18.283: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:05:18.284
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:05:18.297
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:05:18.301
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-19842ea1-c268-443e-9924-cb983bd90eba 11/05/22 12:05:18.305
    STEP: Creating a pod to test consume configMaps 11/05/22 12:05:18.311
    Nov  5 12:05:18.319: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80" in namespace "projected-6221" to be "Succeeded or Failed"
    Nov  5 12:05:18.325: INFO: Pod "pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.406207ms
    Nov  5 12:05:20.329: INFO: Pod "pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010651132s
    Nov  5 12:05:22.329: INFO: Pod "pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010644119s
    STEP: Saw pod success 11/05/22 12:05:22.329
    Nov  5 12:05:22.329: INFO: Pod "pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80" satisfied condition "Succeeded or Failed"
    Nov  5 12:05:22.333: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 11/05/22 12:05:22.339
    Nov  5 12:05:22.350: INFO: Waiting for pod pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80 to disappear
    Nov  5 12:05:22.353: INFO: Pod pod-projected-configmaps-9d683a12-b113-4b89-900a-422eedd05c80 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov  5 12:05:22.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6221" for this suite. 11/05/22 12:05:22.357
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:05:22.364
Nov  5 12:05:22.364: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubelet-test 11/05/22 12:05:22.365
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:05:22.379
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:05:22.382
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Nov  5 12:05:22.394: INFO: Waiting up to 5m0s for pod "busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb" in namespace "kubelet-test-914" to be "running and ready"
Nov  5 12:05:22.519: INFO: Pod "busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb": Phase="Pending", Reason="", readiness=false. Elapsed: 125.504408ms
Nov  5 12:05:22.519: INFO: The phase of Pod busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:05:24.524: INFO: Pod "busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb": Phase="Running", Reason="", readiness=true. Elapsed: 2.130794608s
Nov  5 12:05:24.524: INFO: The phase of Pod busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb is Running (Ready = true)
Nov  5 12:05:24.524: INFO: Pod "busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov  5 12:05:24.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-914" for this suite. 11/05/22 12:05:24.538
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":47,"skipped":890,"failed":0}
------------------------------
• [2.181 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:05:22.364
    Nov  5 12:05:22.364: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubelet-test 11/05/22 12:05:22.365
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:05:22.379
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:05:22.382
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Nov  5 12:05:22.394: INFO: Waiting up to 5m0s for pod "busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb" in namespace "kubelet-test-914" to be "running and ready"
    Nov  5 12:05:22.519: INFO: Pod "busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb": Phase="Pending", Reason="", readiness=false. Elapsed: 125.504408ms
    Nov  5 12:05:22.519: INFO: The phase of Pod busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:05:24.524: INFO: Pod "busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb": Phase="Running", Reason="", readiness=true. Elapsed: 2.130794608s
    Nov  5 12:05:24.524: INFO: The phase of Pod busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb is Running (Ready = true)
    Nov  5 12:05:24.524: INFO: Pod "busybox-scheduling-1749ae6e-41e4-47bf-aa25-a3c40f8df4bb" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov  5 12:05:24.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-914" for this suite. 11/05/22 12:05:24.538
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:05:24.546
Nov  5 12:05:24.546: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sched-preemption 11/05/22 12:05:24.546
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:05:24.563
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:05:24.567
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov  5 12:05:24.587: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  5 12:06:24.607: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 11/05/22 12:06:24.611
Nov  5 12:06:24.697: INFO: Created pod: pod0-0-sched-preemption-low-priority
Nov  5 12:06:24.705: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Nov  5 12:06:24.724: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Nov  5 12:06:24.736: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Nov  5 12:06:24.754: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Nov  5 12:06:24.761: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 11/05/22 12:06:24.761
Nov  5 12:06:24.761: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4653" to be "running"
Nov  5 12:06:24.765: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.353346ms
Nov  5 12:06:26.769: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00841477s
Nov  5 12:06:28.770: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009159116s
Nov  5 12:06:30.769: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008173079s
Nov  5 12:06:32.772: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01081303s
Nov  5 12:06:34.770: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.009578994s
Nov  5 12:06:34.770: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Nov  5 12:06:34.770: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4653" to be "running"
Nov  5 12:06:34.774: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.541302ms
Nov  5 12:06:34.774: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Nov  5 12:06:34.774: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4653" to be "running"
Nov  5 12:06:34.778: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.870704ms
Nov  5 12:06:34.778: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Nov  5 12:06:34.778: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4653" to be "running"
Nov  5 12:06:34.781: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.015188ms
Nov  5 12:06:34.781: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Nov  5 12:06:34.781: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-4653" to be "running"
Nov  5 12:06:34.784: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.295737ms
Nov  5 12:06:34.784: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Nov  5 12:06:34.784: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-4653" to be "running"
Nov  5 12:06:34.788: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.546021ms
Nov  5 12:06:34.788: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 11/05/22 12:06:34.788
Nov  5 12:06:34.793: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-4653" to be "running"
Nov  5 12:06:34.797: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.798134ms
Nov  5 12:06:36.802: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008521914s
Nov  5 12:06:38.801: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.008434638s
Nov  5 12:06:38.801: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:06:38.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-4653" for this suite. 11/05/22 12:06:38.828
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":48,"skipped":902,"failed":0}
------------------------------
• [SLOW TEST] [74.328 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:05:24.546
    Nov  5 12:05:24.546: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sched-preemption 11/05/22 12:05:24.546
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:05:24.563
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:05:24.567
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov  5 12:05:24.587: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov  5 12:06:24.607: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 11/05/22 12:06:24.611
    Nov  5 12:06:24.697: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Nov  5 12:06:24.705: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Nov  5 12:06:24.724: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Nov  5 12:06:24.736: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Nov  5 12:06:24.754: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Nov  5 12:06:24.761: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 11/05/22 12:06:24.761
    Nov  5 12:06:24.761: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-4653" to be "running"
    Nov  5 12:06:24.765: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.353346ms
    Nov  5 12:06:26.769: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00841477s
    Nov  5 12:06:28.770: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009159116s
    Nov  5 12:06:30.769: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008173079s
    Nov  5 12:06:32.772: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01081303s
    Nov  5 12:06:34.770: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.009578994s
    Nov  5 12:06:34.770: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Nov  5 12:06:34.770: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-4653" to be "running"
    Nov  5 12:06:34.774: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.541302ms
    Nov  5 12:06:34.774: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov  5 12:06:34.774: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-4653" to be "running"
    Nov  5 12:06:34.778: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.870704ms
    Nov  5 12:06:34.778: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov  5 12:06:34.778: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-4653" to be "running"
    Nov  5 12:06:34.781: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.015188ms
    Nov  5 12:06:34.781: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov  5 12:06:34.781: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-4653" to be "running"
    Nov  5 12:06:34.784: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.295737ms
    Nov  5 12:06:34.784: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov  5 12:06:34.784: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-4653" to be "running"
    Nov  5 12:06:34.788: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.546021ms
    Nov  5 12:06:34.788: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 11/05/22 12:06:34.788
    Nov  5 12:06:34.793: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-4653" to be "running"
    Nov  5 12:06:34.797: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.798134ms
    Nov  5 12:06:36.802: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008521914s
    Nov  5 12:06:38.801: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.008434638s
    Nov  5 12:06:38.801: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:06:38.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-4653" for this suite. 11/05/22 12:06:38.828
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:06:38.876
Nov  5 12:06:38.876: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename taint-single-pod 11/05/22 12:06:38.877
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:06:38.892
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:06:38.896
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Nov  5 12:06:38.899: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  5 12:07:38.917: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Nov  5 12:07:38.920: INFO: Starting informer...
STEP: Starting pod... 11/05/22 12:07:38.92
Nov  5 12:07:39.136: INFO: Pod is running on ip-172-31-0-255. Tainting Node
STEP: Trying to apply a taint on the Node 11/05/22 12:07:39.136
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/05/22 12:07:39.152
STEP: Waiting short time to make sure Pod is queued for deletion 11/05/22 12:07:39.156
Nov  5 12:07:39.156: INFO: Pod wasn't evicted. Proceeding
Nov  5 12:07:39.156: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/05/22 12:07:39.171
STEP: Waiting some time to make sure that toleration time passed. 11/05/22 12:07:39.273
Nov  5 12:08:54.277: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:08:54.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-3940" for this suite. 11/05/22 12:08:54.281
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":49,"skipped":920,"failed":0}
------------------------------
• [SLOW TEST] [135.413 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:06:38.876
    Nov  5 12:06:38.876: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename taint-single-pod 11/05/22 12:06:38.877
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:06:38.892
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:06:38.896
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Nov  5 12:06:38.899: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov  5 12:07:38.917: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Nov  5 12:07:38.920: INFO: Starting informer...
    STEP: Starting pod... 11/05/22 12:07:38.92
    Nov  5 12:07:39.136: INFO: Pod is running on ip-172-31-0-255. Tainting Node
    STEP: Trying to apply a taint on the Node 11/05/22 12:07:39.136
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/05/22 12:07:39.152
    STEP: Waiting short time to make sure Pod is queued for deletion 11/05/22 12:07:39.156
    Nov  5 12:07:39.156: INFO: Pod wasn't evicted. Proceeding
    Nov  5 12:07:39.156: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 11/05/22 12:07:39.171
    STEP: Waiting some time to make sure that toleration time passed. 11/05/22 12:07:39.273
    Nov  5 12:08:54.277: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:08:54.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-3940" for this suite. 11/05/22 12:08:54.281
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:08:54.291
Nov  5 12:08:54.291: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 12:08:54.292
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:08:54.307
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:08:54.311
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 11/05/22 12:08:54.315
Nov  5 12:08:54.323: INFO: Waiting up to 5m0s for pod "pod-26825f54-c319-4e18-a13f-4a7d16d43ab5" in namespace "emptydir-7215" to be "Succeeded or Failed"
Nov  5 12:08:54.330: INFO: Pod "pod-26825f54-c319-4e18-a13f-4a7d16d43ab5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.066007ms
Nov  5 12:08:56.334: INFO: Pod "pod-26825f54-c319-4e18-a13f-4a7d16d43ab5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011100044s
Nov  5 12:08:58.335: INFO: Pod "pod-26825f54-c319-4e18-a13f-4a7d16d43ab5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011467062s
STEP: Saw pod success 11/05/22 12:08:58.335
Nov  5 12:08:58.335: INFO: Pod "pod-26825f54-c319-4e18-a13f-4a7d16d43ab5" satisfied condition "Succeeded or Failed"
Nov  5 12:08:58.339: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-26825f54-c319-4e18-a13f-4a7d16d43ab5 container test-container: <nil>
STEP: delete the pod 11/05/22 12:08:58.356
Nov  5 12:08:58.368: INFO: Waiting for pod pod-26825f54-c319-4e18-a13f-4a7d16d43ab5 to disappear
Nov  5 12:08:58.372: INFO: Pod pod-26825f54-c319-4e18-a13f-4a7d16d43ab5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 12:08:58.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7215" for this suite. 11/05/22 12:08:58.375
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":50,"skipped":976,"failed":0}
------------------------------
• [4.091 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:08:54.291
    Nov  5 12:08:54.291: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 12:08:54.292
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:08:54.307
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:08:54.311
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 11/05/22 12:08:54.315
    Nov  5 12:08:54.323: INFO: Waiting up to 5m0s for pod "pod-26825f54-c319-4e18-a13f-4a7d16d43ab5" in namespace "emptydir-7215" to be "Succeeded or Failed"
    Nov  5 12:08:54.330: INFO: Pod "pod-26825f54-c319-4e18-a13f-4a7d16d43ab5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.066007ms
    Nov  5 12:08:56.334: INFO: Pod "pod-26825f54-c319-4e18-a13f-4a7d16d43ab5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011100044s
    Nov  5 12:08:58.335: INFO: Pod "pod-26825f54-c319-4e18-a13f-4a7d16d43ab5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011467062s
    STEP: Saw pod success 11/05/22 12:08:58.335
    Nov  5 12:08:58.335: INFO: Pod "pod-26825f54-c319-4e18-a13f-4a7d16d43ab5" satisfied condition "Succeeded or Failed"
    Nov  5 12:08:58.339: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-26825f54-c319-4e18-a13f-4a7d16d43ab5 container test-container: <nil>
    STEP: delete the pod 11/05/22 12:08:58.356
    Nov  5 12:08:58.368: INFO: Waiting for pod pod-26825f54-c319-4e18-a13f-4a7d16d43ab5 to disappear
    Nov  5 12:08:58.372: INFO: Pod pod-26825f54-c319-4e18-a13f-4a7d16d43ab5 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 12:08:58.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-7215" for this suite. 11/05/22 12:08:58.375
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:08:58.384
Nov  5 12:08:58.384: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:08:58.385
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:08:58.396
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:08:58.401
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 11/05/22 12:08:58.405
Nov  5 12:08:58.412: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255" in namespace "projected-5989" to be "Succeeded or Failed"
Nov  5 12:08:58.419: INFO: Pod "downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255": Phase="Pending", Reason="", readiness=false. Elapsed: 6.576332ms
Nov  5 12:09:00.424: INFO: Pod "downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0116022s
Nov  5 12:09:02.424: INFO: Pod "downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012004612s
STEP: Saw pod success 11/05/22 12:09:02.425
Nov  5 12:09:02.425: INFO: Pod "downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255" satisfied condition "Succeeded or Failed"
Nov  5 12:09:02.428: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255 container client-container: <nil>
STEP: delete the pod 11/05/22 12:09:02.435
Nov  5 12:09:02.450: INFO: Waiting for pod downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255 to disappear
Nov  5 12:09:02.453: INFO: Pod downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 12:09:02.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5989" for this suite. 11/05/22 12:09:02.459
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":51,"skipped":983,"failed":0}
------------------------------
• [4.082 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:08:58.384
    Nov  5 12:08:58.384: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:08:58.385
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:08:58.396
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:08:58.401
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 11/05/22 12:08:58.405
    Nov  5 12:08:58.412: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255" in namespace "projected-5989" to be "Succeeded or Failed"
    Nov  5 12:08:58.419: INFO: Pod "downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255": Phase="Pending", Reason="", readiness=false. Elapsed: 6.576332ms
    Nov  5 12:09:00.424: INFO: Pod "downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0116022s
    Nov  5 12:09:02.424: INFO: Pod "downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012004612s
    STEP: Saw pod success 11/05/22 12:09:02.425
    Nov  5 12:09:02.425: INFO: Pod "downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255" satisfied condition "Succeeded or Failed"
    Nov  5 12:09:02.428: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255 container client-container: <nil>
    STEP: delete the pod 11/05/22 12:09:02.435
    Nov  5 12:09:02.450: INFO: Waiting for pod downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255 to disappear
    Nov  5 12:09:02.453: INFO: Pod downwardapi-volume-b2893b20-d57d-4e12-8972-7e8b5e6a5255 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 12:09:02.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5989" for this suite. 11/05/22 12:09:02.459
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:09:02.466
Nov  5 12:09:02.466: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 12:09:02.467
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:09:02.483
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:09:02.486
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 11/05/22 12:09:02.491
Nov  5 12:09:02.498: INFO: Waiting up to 5m0s for pod "pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655" in namespace "emptydir-1938" to be "Succeeded or Failed"
Nov  5 12:09:02.504: INFO: Pod "pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655": Phase="Pending", Reason="", readiness=false. Elapsed: 5.888357ms
Nov  5 12:09:04.511: INFO: Pod "pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013244102s
Nov  5 12:09:06.508: INFO: Pod "pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010163594s
STEP: Saw pod success 11/05/22 12:09:06.508
Nov  5 12:09:06.509: INFO: Pod "pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655" satisfied condition "Succeeded or Failed"
Nov  5 12:09:06.512: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655 container test-container: <nil>
STEP: delete the pod 11/05/22 12:09:06.519
Nov  5 12:09:06.534: INFO: Waiting for pod pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655 to disappear
Nov  5 12:09:06.537: INFO: Pod pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 12:09:06.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1938" for this suite. 11/05/22 12:09:06.541
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":52,"skipped":983,"failed":0}
------------------------------
• [4.083 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:09:02.466
    Nov  5 12:09:02.466: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 12:09:02.467
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:09:02.483
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:09:02.486
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 11/05/22 12:09:02.491
    Nov  5 12:09:02.498: INFO: Waiting up to 5m0s for pod "pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655" in namespace "emptydir-1938" to be "Succeeded or Failed"
    Nov  5 12:09:02.504: INFO: Pod "pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655": Phase="Pending", Reason="", readiness=false. Elapsed: 5.888357ms
    Nov  5 12:09:04.511: INFO: Pod "pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013244102s
    Nov  5 12:09:06.508: INFO: Pod "pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010163594s
    STEP: Saw pod success 11/05/22 12:09:06.508
    Nov  5 12:09:06.509: INFO: Pod "pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655" satisfied condition "Succeeded or Failed"
    Nov  5 12:09:06.512: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655 container test-container: <nil>
    STEP: delete the pod 11/05/22 12:09:06.519
    Nov  5 12:09:06.534: INFO: Waiting for pod pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655 to disappear
    Nov  5 12:09:06.537: INFO: Pod pod-2c0d6401-3b93-48d4-84ab-b4f057ba5655 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 12:09:06.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1938" for this suite. 11/05/22 12:09:06.541
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:09:06.549
Nov  5 12:09:06.549: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:09:06.55
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:09:06.562
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:09:06.569
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 11/05/22 12:09:06.573
Nov  5 12:09:06.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 create -f -'
Nov  5 12:09:06.757: INFO: stderr: ""
Nov  5 12:09:06.757: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/05/22 12:09:06.757
Nov  5 12:09:06.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov  5 12:09:06.822: INFO: stderr: ""
Nov  5 12:09:06.823: INFO: stdout: "update-demo-nautilus-892xj update-demo-nautilus-wqcmp "
Nov  5 12:09:06.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-892xj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov  5 12:09:06.881: INFO: stderr: ""
Nov  5 12:09:06.881: INFO: stdout: ""
Nov  5 12:09:06.881: INFO: update-demo-nautilus-892xj is created but not running
Nov  5 12:09:11.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov  5 12:09:11.940: INFO: stderr: ""
Nov  5 12:09:11.940: INFO: stdout: "update-demo-nautilus-892xj update-demo-nautilus-wqcmp "
Nov  5 12:09:11.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-892xj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov  5 12:09:11.998: INFO: stderr: ""
Nov  5 12:09:11.998: INFO: stdout: "true"
Nov  5 12:09:11.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-892xj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov  5 12:09:12.058: INFO: stderr: ""
Nov  5 12:09:12.058: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov  5 12:09:12.058: INFO: validating pod update-demo-nautilus-892xj
Nov  5 12:09:12.064: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 12:09:12.064: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 12:09:12.064: INFO: update-demo-nautilus-892xj is verified up and running
Nov  5 12:09:12.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov  5 12:09:12.128: INFO: stderr: ""
Nov  5 12:09:12.128: INFO: stdout: "true"
Nov  5 12:09:12.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov  5 12:09:12.186: INFO: stderr: ""
Nov  5 12:09:12.186: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov  5 12:09:12.186: INFO: validating pod update-demo-nautilus-wqcmp
Nov  5 12:09:12.193: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 12:09:12.193: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 12:09:12.193: INFO: update-demo-nautilus-wqcmp is verified up and running
STEP: scaling down the replication controller 11/05/22 12:09:12.193
Nov  5 12:09:12.194: INFO: scanned /root for discovery docs: <nil>
Nov  5 12:09:12.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Nov  5 12:09:13.269: INFO: stderr: ""
Nov  5 12:09:13.269: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/05/22 12:09:13.269
Nov  5 12:09:13.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov  5 12:09:13.331: INFO: stderr: ""
Nov  5 12:09:13.331: INFO: stdout: "update-demo-nautilus-892xj update-demo-nautilus-wqcmp "
STEP: Replicas for name=update-demo: expected=1 actual=2 11/05/22 12:09:13.331
Nov  5 12:09:18.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov  5 12:09:18.392: INFO: stderr: ""
Nov  5 12:09:18.392: INFO: stdout: "update-demo-nautilus-wqcmp "
Nov  5 12:09:18.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov  5 12:09:18.449: INFO: stderr: ""
Nov  5 12:09:18.449: INFO: stdout: "true"
Nov  5 12:09:18.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov  5 12:09:18.506: INFO: stderr: ""
Nov  5 12:09:18.506: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov  5 12:09:18.507: INFO: validating pod update-demo-nautilus-wqcmp
Nov  5 12:09:18.513: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 12:09:18.513: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 12:09:18.513: INFO: update-demo-nautilus-wqcmp is verified up and running
STEP: scaling up the replication controller 11/05/22 12:09:18.513
Nov  5 12:09:18.514: INFO: scanned /root for discovery docs: <nil>
Nov  5 12:09:18.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Nov  5 12:09:19.592: INFO: stderr: ""
Nov  5 12:09:19.592: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/05/22 12:09:19.592
Nov  5 12:09:19.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov  5 12:09:19.652: INFO: stderr: ""
Nov  5 12:09:19.652: INFO: stdout: "update-demo-nautilus-wljss update-demo-nautilus-wqcmp "
Nov  5 12:09:19.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wljss -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov  5 12:09:19.710: INFO: stderr: ""
Nov  5 12:09:19.710: INFO: stdout: ""
Nov  5 12:09:19.710: INFO: update-demo-nautilus-wljss is created but not running
Nov  5 12:09:24.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov  5 12:09:24.772: INFO: stderr: ""
Nov  5 12:09:24.772: INFO: stdout: "update-demo-nautilus-wljss update-demo-nautilus-wqcmp "
Nov  5 12:09:24.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wljss -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov  5 12:09:24.829: INFO: stderr: ""
Nov  5 12:09:24.829: INFO: stdout: "true"
Nov  5 12:09:24.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wljss -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov  5 12:09:24.887: INFO: stderr: ""
Nov  5 12:09:24.887: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov  5 12:09:24.887: INFO: validating pod update-demo-nautilus-wljss
Nov  5 12:09:24.893: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 12:09:24.893: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 12:09:24.893: INFO: update-demo-nautilus-wljss is verified up and running
Nov  5 12:09:24.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov  5 12:09:24.952: INFO: stderr: ""
Nov  5 12:09:24.952: INFO: stdout: "true"
Nov  5 12:09:24.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov  5 12:09:25.024: INFO: stderr: ""
Nov  5 12:09:25.024: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov  5 12:09:25.024: INFO: validating pod update-demo-nautilus-wqcmp
Nov  5 12:09:25.030: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 12:09:25.030: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 12:09:25.030: INFO: update-demo-nautilus-wqcmp is verified up and running
STEP: using delete to clean up resources 11/05/22 12:09:25.03
Nov  5 12:09:25.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 delete --grace-period=0 --force -f -'
Nov  5 12:09:25.094: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 12:09:25.094: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  5 12:09:25.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get rc,svc -l name=update-demo --no-headers'
Nov  5 12:09:25.176: INFO: stderr: "No resources found in kubectl-972 namespace.\n"
Nov  5 12:09:25.176: INFO: stdout: ""
Nov  5 12:09:25.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  5 12:09:25.266: INFO: stderr: ""
Nov  5 12:09:25.266: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:09:25.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-972" for this suite. 11/05/22 12:09:25.271
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":53,"skipped":991,"failed":0}
------------------------------
• [SLOW TEST] [18.730 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:09:06.549
    Nov  5 12:09:06.549: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:09:06.55
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:09:06.562
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:09:06.569
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 11/05/22 12:09:06.573
    Nov  5 12:09:06.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 create -f -'
    Nov  5 12:09:06.757: INFO: stderr: ""
    Nov  5 12:09:06.757: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/05/22 12:09:06.757
    Nov  5 12:09:06.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov  5 12:09:06.822: INFO: stderr: ""
    Nov  5 12:09:06.823: INFO: stdout: "update-demo-nautilus-892xj update-demo-nautilus-wqcmp "
    Nov  5 12:09:06.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-892xj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov  5 12:09:06.881: INFO: stderr: ""
    Nov  5 12:09:06.881: INFO: stdout: ""
    Nov  5 12:09:06.881: INFO: update-demo-nautilus-892xj is created but not running
    Nov  5 12:09:11.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov  5 12:09:11.940: INFO: stderr: ""
    Nov  5 12:09:11.940: INFO: stdout: "update-demo-nautilus-892xj update-demo-nautilus-wqcmp "
    Nov  5 12:09:11.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-892xj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov  5 12:09:11.998: INFO: stderr: ""
    Nov  5 12:09:11.998: INFO: stdout: "true"
    Nov  5 12:09:11.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-892xj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov  5 12:09:12.058: INFO: stderr: ""
    Nov  5 12:09:12.058: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov  5 12:09:12.058: INFO: validating pod update-demo-nautilus-892xj
    Nov  5 12:09:12.064: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov  5 12:09:12.064: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov  5 12:09:12.064: INFO: update-demo-nautilus-892xj is verified up and running
    Nov  5 12:09:12.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov  5 12:09:12.128: INFO: stderr: ""
    Nov  5 12:09:12.128: INFO: stdout: "true"
    Nov  5 12:09:12.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov  5 12:09:12.186: INFO: stderr: ""
    Nov  5 12:09:12.186: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov  5 12:09:12.186: INFO: validating pod update-demo-nautilus-wqcmp
    Nov  5 12:09:12.193: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov  5 12:09:12.193: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov  5 12:09:12.193: INFO: update-demo-nautilus-wqcmp is verified up and running
    STEP: scaling down the replication controller 11/05/22 12:09:12.193
    Nov  5 12:09:12.194: INFO: scanned /root for discovery docs: <nil>
    Nov  5 12:09:12.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Nov  5 12:09:13.269: INFO: stderr: ""
    Nov  5 12:09:13.269: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/05/22 12:09:13.269
    Nov  5 12:09:13.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov  5 12:09:13.331: INFO: stderr: ""
    Nov  5 12:09:13.331: INFO: stdout: "update-demo-nautilus-892xj update-demo-nautilus-wqcmp "
    STEP: Replicas for name=update-demo: expected=1 actual=2 11/05/22 12:09:13.331
    Nov  5 12:09:18.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov  5 12:09:18.392: INFO: stderr: ""
    Nov  5 12:09:18.392: INFO: stdout: "update-demo-nautilus-wqcmp "
    Nov  5 12:09:18.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov  5 12:09:18.449: INFO: stderr: ""
    Nov  5 12:09:18.449: INFO: stdout: "true"
    Nov  5 12:09:18.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov  5 12:09:18.506: INFO: stderr: ""
    Nov  5 12:09:18.506: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov  5 12:09:18.507: INFO: validating pod update-demo-nautilus-wqcmp
    Nov  5 12:09:18.513: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov  5 12:09:18.513: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov  5 12:09:18.513: INFO: update-demo-nautilus-wqcmp is verified up and running
    STEP: scaling up the replication controller 11/05/22 12:09:18.513
    Nov  5 12:09:18.514: INFO: scanned /root for discovery docs: <nil>
    Nov  5 12:09:18.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Nov  5 12:09:19.592: INFO: stderr: ""
    Nov  5 12:09:19.592: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/05/22 12:09:19.592
    Nov  5 12:09:19.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov  5 12:09:19.652: INFO: stderr: ""
    Nov  5 12:09:19.652: INFO: stdout: "update-demo-nautilus-wljss update-demo-nautilus-wqcmp "
    Nov  5 12:09:19.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wljss -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov  5 12:09:19.710: INFO: stderr: ""
    Nov  5 12:09:19.710: INFO: stdout: ""
    Nov  5 12:09:19.710: INFO: update-demo-nautilus-wljss is created but not running
    Nov  5 12:09:24.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov  5 12:09:24.772: INFO: stderr: ""
    Nov  5 12:09:24.772: INFO: stdout: "update-demo-nautilus-wljss update-demo-nautilus-wqcmp "
    Nov  5 12:09:24.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wljss -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov  5 12:09:24.829: INFO: stderr: ""
    Nov  5 12:09:24.829: INFO: stdout: "true"
    Nov  5 12:09:24.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wljss -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov  5 12:09:24.887: INFO: stderr: ""
    Nov  5 12:09:24.887: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov  5 12:09:24.887: INFO: validating pod update-demo-nautilus-wljss
    Nov  5 12:09:24.893: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov  5 12:09:24.893: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov  5 12:09:24.893: INFO: update-demo-nautilus-wljss is verified up and running
    Nov  5 12:09:24.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov  5 12:09:24.952: INFO: stderr: ""
    Nov  5 12:09:24.952: INFO: stdout: "true"
    Nov  5 12:09:24.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods update-demo-nautilus-wqcmp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov  5 12:09:25.024: INFO: stderr: ""
    Nov  5 12:09:25.024: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov  5 12:09:25.024: INFO: validating pod update-demo-nautilus-wqcmp
    Nov  5 12:09:25.030: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov  5 12:09:25.030: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov  5 12:09:25.030: INFO: update-demo-nautilus-wqcmp is verified up and running
    STEP: using delete to clean up resources 11/05/22 12:09:25.03
    Nov  5 12:09:25.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 delete --grace-period=0 --force -f -'
    Nov  5 12:09:25.094: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov  5 12:09:25.094: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Nov  5 12:09:25.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get rc,svc -l name=update-demo --no-headers'
    Nov  5 12:09:25.176: INFO: stderr: "No resources found in kubectl-972 namespace.\n"
    Nov  5 12:09:25.176: INFO: stdout: ""
    Nov  5 12:09:25.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-972 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov  5 12:09:25.266: INFO: stderr: ""
    Nov  5 12:09:25.266: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:09:25.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-972" for this suite. 11/05/22 12:09:25.271
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:09:25.279
Nov  5 12:09:25.279: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename statefulset 11/05/22 12:09:25.28
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:09:25.292
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:09:25.295
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-3372 11/05/22 12:09:25.299
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-3372 11/05/22 12:09:25.313
Nov  5 12:09:25.333: INFO: Found 0 stateful pods, waiting for 1
Nov  5 12:09:35.340: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 11/05/22 12:09:35.347
STEP: Getting /status 11/05/22 12:09:35.358
Nov  5 12:09:35.363: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 11/05/22 12:09:35.363
Nov  5 12:09:35.374: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 11/05/22 12:09:35.374
Nov  5 12:09:35.376: INFO: Observed &StatefulSet event: ADDED
Nov  5 12:09:35.376: INFO: Found Statefulset ss in namespace statefulset-3372 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov  5 12:09:35.376: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 11/05/22 12:09:35.376
Nov  5 12:09:35.376: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov  5 12:09:35.388: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 11/05/22 12:09:35.388
Nov  5 12:09:35.390: INFO: Observed &StatefulSet event: ADDED
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov  5 12:09:35.390: INFO: Deleting all statefulset in ns statefulset-3372
Nov  5 12:09:35.393: INFO: Scaling statefulset ss to 0
Nov  5 12:09:45.416: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 12:09:45.420: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov  5 12:09:45.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3372" for this suite. 11/05/22 12:09:45.446
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":54,"skipped":993,"failed":0}
------------------------------
• [SLOW TEST] [20.176 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:09:25.279
    Nov  5 12:09:25.279: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename statefulset 11/05/22 12:09:25.28
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:09:25.292
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:09:25.295
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-3372 11/05/22 12:09:25.299
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-3372 11/05/22 12:09:25.313
    Nov  5 12:09:25.333: INFO: Found 0 stateful pods, waiting for 1
    Nov  5 12:09:35.340: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 11/05/22 12:09:35.347
    STEP: Getting /status 11/05/22 12:09:35.358
    Nov  5 12:09:35.363: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 11/05/22 12:09:35.363
    Nov  5 12:09:35.374: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 11/05/22 12:09:35.374
    Nov  5 12:09:35.376: INFO: Observed &StatefulSet event: ADDED
    Nov  5 12:09:35.376: INFO: Found Statefulset ss in namespace statefulset-3372 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov  5 12:09:35.376: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 11/05/22 12:09:35.376
    Nov  5 12:09:35.376: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov  5 12:09:35.388: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 11/05/22 12:09:35.388
    Nov  5 12:09:35.390: INFO: Observed &StatefulSet event: ADDED
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov  5 12:09:35.390: INFO: Deleting all statefulset in ns statefulset-3372
    Nov  5 12:09:35.393: INFO: Scaling statefulset ss to 0
    Nov  5 12:09:45.416: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 12:09:45.420: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov  5 12:09:45.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-3372" for this suite. 11/05/22 12:09:45.446
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:09:45.457
Nov  5 12:09:45.457: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 12:09:45.458
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:09:45.471
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:09:45.475
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-5803/secret-test-eb63d969-a2b1-4c83-910c-3d050de2d322 11/05/22 12:09:45.478
STEP: Creating a pod to test consume secrets 11/05/22 12:09:45.483
Nov  5 12:09:45.492: INFO: Waiting up to 5m0s for pod "pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a" in namespace "secrets-5803" to be "Succeeded or Failed"
Nov  5 12:09:45.500: INFO: Pod "pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.258824ms
Nov  5 12:09:47.504: INFO: Pod "pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01170762s
Nov  5 12:09:49.504: INFO: Pod "pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011505312s
STEP: Saw pod success 11/05/22 12:09:49.504
Nov  5 12:09:49.504: INFO: Pod "pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a" satisfied condition "Succeeded or Failed"
Nov  5 12:09:49.508: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a container env-test: <nil>
STEP: delete the pod 11/05/22 12:09:49.515
Nov  5 12:09:49.529: INFO: Waiting for pod pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a to disappear
Nov  5 12:09:49.532: INFO: Pod pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov  5 12:09:49.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5803" for this suite. 11/05/22 12:09:49.536
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":55,"skipped":1008,"failed":0}
------------------------------
• [4.086 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:09:45.457
    Nov  5 12:09:45.457: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 12:09:45.458
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:09:45.471
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:09:45.475
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-5803/secret-test-eb63d969-a2b1-4c83-910c-3d050de2d322 11/05/22 12:09:45.478
    STEP: Creating a pod to test consume secrets 11/05/22 12:09:45.483
    Nov  5 12:09:45.492: INFO: Waiting up to 5m0s for pod "pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a" in namespace "secrets-5803" to be "Succeeded or Failed"
    Nov  5 12:09:45.500: INFO: Pod "pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.258824ms
    Nov  5 12:09:47.504: INFO: Pod "pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01170762s
    Nov  5 12:09:49.504: INFO: Pod "pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011505312s
    STEP: Saw pod success 11/05/22 12:09:49.504
    Nov  5 12:09:49.504: INFO: Pod "pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a" satisfied condition "Succeeded or Failed"
    Nov  5 12:09:49.508: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a container env-test: <nil>
    STEP: delete the pod 11/05/22 12:09:49.515
    Nov  5 12:09:49.529: INFO: Waiting for pod pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a to disappear
    Nov  5 12:09:49.532: INFO: Pod pod-configmaps-cfbaed0d-7542-4bef-9637-1fc381152f0a no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 12:09:49.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5803" for this suite. 11/05/22 12:09:49.536
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:09:49.544
Nov  5 12:09:49.544: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename dns 11/05/22 12:09:49.544
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:09:49.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:09:49.562
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 11/05/22 12:09:49.566
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4732 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4732;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4732 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4732;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4732.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4732.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4732.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4732.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4732.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4732.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4732.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4732.svc;check="$$(dig +notcp +noall +answer +search 59.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.59_udp@PTR;check="$$(dig +tcp +noall +answer +search 59.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.59_tcp@PTR;sleep 1; done
 11/05/22 12:09:49.583
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4732 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4732;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4732 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4732;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4732.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4732.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4732.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4732.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4732.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4732.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4732.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4732.svc;check="$$(dig +notcp +noall +answer +search 59.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.59_udp@PTR;check="$$(dig +tcp +noall +answer +search 59.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.59_tcp@PTR;sleep 1; done
 11/05/22 12:09:49.584
STEP: creating a pod to probe DNS 11/05/22 12:09:49.584
STEP: submitting the pod to kubernetes 11/05/22 12:09:49.584
Nov  5 12:09:49.608: INFO: Waiting up to 15m0s for pod "dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781" in namespace "dns-4732" to be "running"
Nov  5 12:09:49.613: INFO: Pod "dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781": Phase="Pending", Reason="", readiness=false. Elapsed: 5.34872ms
Nov  5 12:09:51.617: INFO: Pod "dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781": Phase="Running", Reason="", readiness=true. Elapsed: 2.009675697s
Nov  5 12:09:51.617: INFO: Pod "dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781" satisfied condition "running"
STEP: retrieving the pod 11/05/22 12:09:51.617
STEP: looking for the results for each expected name from probers 11/05/22 12:09:51.621
Nov  5 12:09:51.626: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.632: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.635: INFO: Unable to read wheezy_udp@dns-test-service.dns-4732 from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.639: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4732 from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.645: INFO: Unable to read wheezy_udp@dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.648: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.652: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.657: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.675: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.679: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.683: INFO: Unable to read jessie_udp@dns-test-service.dns-4732 from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.687: INFO: Unable to read jessie_tcp@dns-test-service.dns-4732 from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.691: INFO: Unable to read jessie_udp@dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.695: INFO: Unable to read jessie_tcp@dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.698: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.702: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:51.717: INFO: Lookups using dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4732 wheezy_tcp@dns-test-service.dns-4732 wheezy_udp@dns-test-service.dns-4732.svc wheezy_tcp@dns-test-service.dns-4732.svc wheezy_udp@_http._tcp.dns-test-service.dns-4732.svc wheezy_tcp@_http._tcp.dns-test-service.dns-4732.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4732 jessie_tcp@dns-test-service.dns-4732 jessie_udp@dns-test-service.dns-4732.svc jessie_tcp@dns-test-service.dns-4732.svc jessie_udp@_http._tcp.dns-test-service.dns-4732.svc jessie_tcp@_http._tcp.dns-test-service.dns-4732.svc]

Nov  5 12:09:56.747: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
Nov  5 12:09:56.811: INFO: Lookups using dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-4732.svc]

Nov  5 12:10:01.815: INFO: DNS probes using dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781 succeeded

STEP: deleting the pod 11/05/22 12:10:01.815
STEP: deleting the test service 11/05/22 12:10:01.833
STEP: deleting the test headless service 11/05/22 12:10:01.856
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov  5 12:10:01.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4732" for this suite. 11/05/22 12:10:01.876
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":56,"skipped":1026,"failed":0}
------------------------------
• [SLOW TEST] [12.342 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:09:49.544
    Nov  5 12:09:49.544: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename dns 11/05/22 12:09:49.544
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:09:49.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:09:49.562
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 11/05/22 12:09:49.566
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4732 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4732;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4732 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4732;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4732.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4732.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4732.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4732.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4732.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4732.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4732.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4732.svc;check="$$(dig +notcp +noall +answer +search 59.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.59_udp@PTR;check="$$(dig +tcp +noall +answer +search 59.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.59_tcp@PTR;sleep 1; done
     11/05/22 12:09:49.583
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4732 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4732;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4732 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4732;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4732.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4732.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4732.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4732.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4732.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4732.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4732.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4732.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4732.svc;check="$$(dig +notcp +noall +answer +search 59.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.59_udp@PTR;check="$$(dig +tcp +noall +answer +search 59.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.59_tcp@PTR;sleep 1; done
     11/05/22 12:09:49.584
    STEP: creating a pod to probe DNS 11/05/22 12:09:49.584
    STEP: submitting the pod to kubernetes 11/05/22 12:09:49.584
    Nov  5 12:09:49.608: INFO: Waiting up to 15m0s for pod "dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781" in namespace "dns-4732" to be "running"
    Nov  5 12:09:49.613: INFO: Pod "dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781": Phase="Pending", Reason="", readiness=false. Elapsed: 5.34872ms
    Nov  5 12:09:51.617: INFO: Pod "dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781": Phase="Running", Reason="", readiness=true. Elapsed: 2.009675697s
    Nov  5 12:09:51.617: INFO: Pod "dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781" satisfied condition "running"
    STEP: retrieving the pod 11/05/22 12:09:51.617
    STEP: looking for the results for each expected name from probers 11/05/22 12:09:51.621
    Nov  5 12:09:51.626: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.632: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.635: INFO: Unable to read wheezy_udp@dns-test-service.dns-4732 from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.639: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4732 from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.645: INFO: Unable to read wheezy_udp@dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.648: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.652: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.657: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.675: INFO: Unable to read jessie_udp@dns-test-service from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.679: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.683: INFO: Unable to read jessie_udp@dns-test-service.dns-4732 from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.687: INFO: Unable to read jessie_tcp@dns-test-service.dns-4732 from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.691: INFO: Unable to read jessie_udp@dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.695: INFO: Unable to read jessie_tcp@dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.698: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.702: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:51.717: INFO: Lookups using dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-4732 wheezy_tcp@dns-test-service.dns-4732 wheezy_udp@dns-test-service.dns-4732.svc wheezy_tcp@dns-test-service.dns-4732.svc wheezy_udp@_http._tcp.dns-test-service.dns-4732.svc wheezy_tcp@_http._tcp.dns-test-service.dns-4732.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-4732 jessie_tcp@dns-test-service.dns-4732 jessie_udp@dns-test-service.dns-4732.svc jessie_tcp@dns-test-service.dns-4732.svc jessie_udp@_http._tcp.dns-test-service.dns-4732.svc jessie_tcp@_http._tcp.dns-test-service.dns-4732.svc]

    Nov  5 12:09:56.747: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4732.svc from pod dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781: the server could not find the requested resource (get pods dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781)
    Nov  5 12:09:56.811: INFO: Lookups using dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-4732.svc]

    Nov  5 12:10:01.815: INFO: DNS probes using dns-4732/dns-test-9c2de9df-b807-41c0-8ba9-957bbe5d0781 succeeded

    STEP: deleting the pod 11/05/22 12:10:01.815
    STEP: deleting the test service 11/05/22 12:10:01.833
    STEP: deleting the test headless service 11/05/22 12:10:01.856
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov  5 12:10:01.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-4732" for this suite. 11/05/22 12:10:01.876
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:10:01.888
Nov  5 12:10:01.888: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename subpath 11/05/22 12:10:01.889
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:01.91
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:01.915
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/05/22 12:10:01.92
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-lntp 11/05/22 12:10:01.931
STEP: Creating a pod to test atomic-volume-subpath 11/05/22 12:10:01.931
Nov  5 12:10:01.941: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-lntp" in namespace "subpath-4040" to be "Succeeded or Failed"
Nov  5 12:10:01.946: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.522413ms
Nov  5 12:10:03.950: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 2.00893985s
Nov  5 12:10:05.950: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 4.00855137s
Nov  5 12:10:07.953: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 6.010997696s
Nov  5 12:10:09.951: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 8.009006073s
Nov  5 12:10:11.951: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 10.009553914s
Nov  5 12:10:13.953: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 12.011457729s
Nov  5 12:10:15.950: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 14.008549426s
Nov  5 12:10:17.953: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 16.0115536s
Nov  5 12:10:19.952: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 18.010758652s
Nov  5 12:10:21.952: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 20.010114747s
Nov  5 12:10:23.952: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=false. Elapsed: 22.010367489s
Nov  5 12:10:25.950: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.008914174s
STEP: Saw pod success 11/05/22 12:10:25.95
Nov  5 12:10:25.951: INFO: Pod "pod-subpath-test-downwardapi-lntp" satisfied condition "Succeeded or Failed"
Nov  5 12:10:25.954: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-subpath-test-downwardapi-lntp container test-container-subpath-downwardapi-lntp: <nil>
STEP: delete the pod 11/05/22 12:10:25.961
Nov  5 12:10:25.972: INFO: Waiting for pod pod-subpath-test-downwardapi-lntp to disappear
Nov  5 12:10:25.975: INFO: Pod pod-subpath-test-downwardapi-lntp no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-lntp 11/05/22 12:10:25.975
Nov  5 12:10:25.975: INFO: Deleting pod "pod-subpath-test-downwardapi-lntp" in namespace "subpath-4040"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov  5 12:10:25.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4040" for this suite. 11/05/22 12:10:25.983
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":57,"skipped":1064,"failed":0}
------------------------------
• [SLOW TEST] [24.102 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:10:01.888
    Nov  5 12:10:01.888: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename subpath 11/05/22 12:10:01.889
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:01.91
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:01.915
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/05/22 12:10:01.92
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-lntp 11/05/22 12:10:01.931
    STEP: Creating a pod to test atomic-volume-subpath 11/05/22 12:10:01.931
    Nov  5 12:10:01.941: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-lntp" in namespace "subpath-4040" to be "Succeeded or Failed"
    Nov  5 12:10:01.946: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.522413ms
    Nov  5 12:10:03.950: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 2.00893985s
    Nov  5 12:10:05.950: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 4.00855137s
    Nov  5 12:10:07.953: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 6.010997696s
    Nov  5 12:10:09.951: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 8.009006073s
    Nov  5 12:10:11.951: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 10.009553914s
    Nov  5 12:10:13.953: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 12.011457729s
    Nov  5 12:10:15.950: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 14.008549426s
    Nov  5 12:10:17.953: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 16.0115536s
    Nov  5 12:10:19.952: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 18.010758652s
    Nov  5 12:10:21.952: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=true. Elapsed: 20.010114747s
    Nov  5 12:10:23.952: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Running", Reason="", readiness=false. Elapsed: 22.010367489s
    Nov  5 12:10:25.950: INFO: Pod "pod-subpath-test-downwardapi-lntp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.008914174s
    STEP: Saw pod success 11/05/22 12:10:25.95
    Nov  5 12:10:25.951: INFO: Pod "pod-subpath-test-downwardapi-lntp" satisfied condition "Succeeded or Failed"
    Nov  5 12:10:25.954: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-subpath-test-downwardapi-lntp container test-container-subpath-downwardapi-lntp: <nil>
    STEP: delete the pod 11/05/22 12:10:25.961
    Nov  5 12:10:25.972: INFO: Waiting for pod pod-subpath-test-downwardapi-lntp to disappear
    Nov  5 12:10:25.975: INFO: Pod pod-subpath-test-downwardapi-lntp no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-lntp 11/05/22 12:10:25.975
    Nov  5 12:10:25.975: INFO: Deleting pod "pod-subpath-test-downwardapi-lntp" in namespace "subpath-4040"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov  5 12:10:25.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-4040" for this suite. 11/05/22 12:10:25.983
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:10:25.992
Nov  5 12:10:25.992: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename endpointslice 11/05/22 12:10:25.993
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:26.006
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:26.01
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Nov  5 12:10:26.026: INFO: Endpoints addresses: [172.31.23.198 172.31.83.205] , ports: [6443]
Nov  5 12:10:26.026: INFO: EndpointSlices addresses: [172.31.23.198 172.31.83.205] , ports: [6443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov  5 12:10:26.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-3885" for this suite. 11/05/22 12:10:26.03
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":58,"skipped":1104,"failed":0}
------------------------------
• [0.046 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:10:25.992
    Nov  5 12:10:25.992: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename endpointslice 11/05/22 12:10:25.993
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:26.006
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:26.01
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Nov  5 12:10:26.026: INFO: Endpoints addresses: [172.31.23.198 172.31.83.205] , ports: [6443]
    Nov  5 12:10:26.026: INFO: EndpointSlices addresses: [172.31.23.198 172.31.83.205] , ports: [6443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov  5 12:10:26.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-3885" for this suite. 11/05/22 12:10:26.03
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:10:26.04
Nov  5 12:10:26.040: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 12:10:26.041
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:26.056
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:26.066
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5567 11/05/22 12:10:26.07
STEP: changing the ExternalName service to type=NodePort 11/05/22 12:10:26.078
STEP: creating replication controller externalname-service in namespace services-5567 11/05/22 12:10:26.11
I1105 12:10:26.129817      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5567, replica count: 2
I1105 12:10:29.180725      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 12:10:29.180: INFO: Creating new exec pod
Nov  5 12:10:29.189: INFO: Waiting up to 5m0s for pod "execpod5947l" in namespace "services-5567" to be "running"
Nov  5 12:10:29.194: INFO: Pod "execpod5947l": Phase="Pending", Reason="", readiness=false. Elapsed: 5.19882ms
Nov  5 12:10:31.198: INFO: Pod "execpod5947l": Phase="Running", Reason="", readiness=true. Elapsed: 2.009193841s
Nov  5 12:10:31.198: INFO: Pod "execpod5947l" satisfied condition "running"
Nov  5 12:10:32.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5567 exec execpod5947l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov  5 12:10:32.352: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  5 12:10:32.352: INFO: stdout: "externalname-service-pbwv5"
Nov  5 12:10:32.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5567 exec execpod5947l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.83 80'
Nov  5 12:10:32.497: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.83 80\nConnection to 10.152.183.83 80 port [tcp/http] succeeded!\n"
Nov  5 12:10:32.497: INFO: stdout: ""
Nov  5 12:10:33.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5567 exec execpod5947l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.83 80'
Nov  5 12:10:33.642: INFO: stderr: "+ nc -v -t -w 2 10.152.183.83 80\n+ echo hostName\nConnection to 10.152.183.83 80 port [tcp/http] succeeded!\n"
Nov  5 12:10:33.642: INFO: stdout: "externalname-service-pbwv5"
Nov  5 12:10:33.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5567 exec execpod5947l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 31748'
Nov  5 12:10:33.779: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.41.19 31748\nConnection to 172.31.41.19 31748 port [tcp/*] succeeded!\n"
Nov  5 12:10:33.779: INFO: stdout: "externalname-service-fph6t"
Nov  5 12:10:33.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5567 exec execpod5947l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.255 31748'
Nov  5 12:10:33.900: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.0.255 31748\nConnection to 172.31.0.255 31748 port [tcp/*] succeeded!\n"
Nov  5 12:10:33.900: INFO: stdout: "externalname-service-pbwv5"
Nov  5 12:10:33.900: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 12:10:33.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5567" for this suite. 11/05/22 12:10:33.949
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":59,"skipped":1146,"failed":0}
------------------------------
• [SLOW TEST] [7.917 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:10:26.04
    Nov  5 12:10:26.040: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 12:10:26.041
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:26.056
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:26.066
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-5567 11/05/22 12:10:26.07
    STEP: changing the ExternalName service to type=NodePort 11/05/22 12:10:26.078
    STEP: creating replication controller externalname-service in namespace services-5567 11/05/22 12:10:26.11
    I1105 12:10:26.129817      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-5567, replica count: 2
    I1105 12:10:29.180725      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 12:10:29.180: INFO: Creating new exec pod
    Nov  5 12:10:29.189: INFO: Waiting up to 5m0s for pod "execpod5947l" in namespace "services-5567" to be "running"
    Nov  5 12:10:29.194: INFO: Pod "execpod5947l": Phase="Pending", Reason="", readiness=false. Elapsed: 5.19882ms
    Nov  5 12:10:31.198: INFO: Pod "execpod5947l": Phase="Running", Reason="", readiness=true. Elapsed: 2.009193841s
    Nov  5 12:10:31.198: INFO: Pod "execpod5947l" satisfied condition "running"
    Nov  5 12:10:32.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5567 exec execpod5947l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov  5 12:10:32.352: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov  5 12:10:32.352: INFO: stdout: "externalname-service-pbwv5"
    Nov  5 12:10:32.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5567 exec execpod5947l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.83 80'
    Nov  5 12:10:32.497: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.83 80\nConnection to 10.152.183.83 80 port [tcp/http] succeeded!\n"
    Nov  5 12:10:32.497: INFO: stdout: ""
    Nov  5 12:10:33.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5567 exec execpod5947l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.83 80'
    Nov  5 12:10:33.642: INFO: stderr: "+ nc -v -t -w 2 10.152.183.83 80\n+ echo hostName\nConnection to 10.152.183.83 80 port [tcp/http] succeeded!\n"
    Nov  5 12:10:33.642: INFO: stdout: "externalname-service-pbwv5"
    Nov  5 12:10:33.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5567 exec execpod5947l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 31748'
    Nov  5 12:10:33.779: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.41.19 31748\nConnection to 172.31.41.19 31748 port [tcp/*] succeeded!\n"
    Nov  5 12:10:33.779: INFO: stdout: "externalname-service-fph6t"
    Nov  5 12:10:33.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-5567 exec execpod5947l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.255 31748'
    Nov  5 12:10:33.900: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.0.255 31748\nConnection to 172.31.0.255 31748 port [tcp/*] succeeded!\n"
    Nov  5 12:10:33.900: INFO: stdout: "externalname-service-pbwv5"
    Nov  5 12:10:33.900: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 12:10:33.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5567" for this suite. 11/05/22 12:10:33.949
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:10:33.958
Nov  5 12:10:33.958: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename runtimeclass 11/05/22 12:10:33.959
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:33.98
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:33.985
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-9349-delete-me 11/05/22 12:10:33.995
STEP: Waiting for the RuntimeClass to disappear 11/05/22 12:10:34.002
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov  5 12:10:34.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9349" for this suite. 11/05/22 12:10:34.018
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":60,"skipped":1155,"failed":0}
------------------------------
• [0.067 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:10:33.958
    Nov  5 12:10:33.958: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename runtimeclass 11/05/22 12:10:33.959
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:33.98
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:33.985
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-9349-delete-me 11/05/22 12:10:33.995
    STEP: Waiting for the RuntimeClass to disappear 11/05/22 12:10:34.002
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov  5 12:10:34.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-9349" for this suite. 11/05/22 12:10:34.018
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:10:34.025
Nov  5 12:10:34.025: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replication-controller 11/05/22 12:10:34.025
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:34.038
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:34.042
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 11/05/22 12:10:34.054
STEP: waiting for RC to be added 11/05/22 12:10:34.059
STEP: waiting for available Replicas 11/05/22 12:10:34.061
STEP: patching ReplicationController 11/05/22 12:10:36.567
STEP: waiting for RC to be modified 11/05/22 12:10:36.574
STEP: patching ReplicationController status 11/05/22 12:10:36.574
STEP: waiting for RC to be modified 11/05/22 12:10:36.583
STEP: waiting for available Replicas 11/05/22 12:10:36.583
STEP: fetching ReplicationController status 11/05/22 12:10:36.587
STEP: patching ReplicationController scale 11/05/22 12:10:36.591
STEP: waiting for RC to be modified 11/05/22 12:10:36.597
STEP: waiting for ReplicationController's scale to be the max amount 11/05/22 12:10:36.597
STEP: fetching ReplicationController; ensuring that it's patched 11/05/22 12:10:39.289
STEP: updating ReplicationController status 11/05/22 12:10:39.293
STEP: waiting for RC to be modified 11/05/22 12:10:39.308
STEP: listing all ReplicationControllers 11/05/22 12:10:39.308
STEP: checking that ReplicationController has expected values 11/05/22 12:10:39.314
STEP: deleting ReplicationControllers by collection 11/05/22 12:10:39.314
STEP: waiting for ReplicationController to have a DELETED watchEvent 11/05/22 12:10:39.325
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov  5 12:10:39.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4889" for this suite. 11/05/22 12:10:39.37
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":61,"skipped":1158,"failed":0}
------------------------------
• [SLOW TEST] [5.352 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:10:34.025
    Nov  5 12:10:34.025: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replication-controller 11/05/22 12:10:34.025
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:34.038
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:34.042
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 11/05/22 12:10:34.054
    STEP: waiting for RC to be added 11/05/22 12:10:34.059
    STEP: waiting for available Replicas 11/05/22 12:10:34.061
    STEP: patching ReplicationController 11/05/22 12:10:36.567
    STEP: waiting for RC to be modified 11/05/22 12:10:36.574
    STEP: patching ReplicationController status 11/05/22 12:10:36.574
    STEP: waiting for RC to be modified 11/05/22 12:10:36.583
    STEP: waiting for available Replicas 11/05/22 12:10:36.583
    STEP: fetching ReplicationController status 11/05/22 12:10:36.587
    STEP: patching ReplicationController scale 11/05/22 12:10:36.591
    STEP: waiting for RC to be modified 11/05/22 12:10:36.597
    STEP: waiting for ReplicationController's scale to be the max amount 11/05/22 12:10:36.597
    STEP: fetching ReplicationController; ensuring that it's patched 11/05/22 12:10:39.289
    STEP: updating ReplicationController status 11/05/22 12:10:39.293
    STEP: waiting for RC to be modified 11/05/22 12:10:39.308
    STEP: listing all ReplicationControllers 11/05/22 12:10:39.308
    STEP: checking that ReplicationController has expected values 11/05/22 12:10:39.314
    STEP: deleting ReplicationControllers by collection 11/05/22 12:10:39.314
    STEP: waiting for ReplicationController to have a DELETED watchEvent 11/05/22 12:10:39.325
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov  5 12:10:39.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-4889" for this suite. 11/05/22 12:10:39.37
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:10:39.379
Nov  5 12:10:39.379: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename podtemplate 11/05/22 12:10:39.379
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:39.396
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:39.4
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov  5 12:10:39.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-1498" for this suite. 11/05/22 12:10:39.442
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":62,"skipped":1205,"failed":0}
------------------------------
• [0.070 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:10:39.379
    Nov  5 12:10:39.379: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename podtemplate 11/05/22 12:10:39.379
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:39.396
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:39.4
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov  5 12:10:39.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-1498" for this suite. 11/05/22 12:10:39.442
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:10:39.449
Nov  5 12:10:39.449: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 12:10:39.449
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:39.462
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:39.467
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 11/05/22 12:10:39.471
Nov  5 12:10:39.480: INFO: Waiting up to 5m0s for pod "pod-7121b44d-cd1a-4d73-a6e8-8291b025a181" in namespace "emptydir-5388" to be "Succeeded or Failed"
Nov  5 12:10:39.486: INFO: Pod "pod-7121b44d-cd1a-4d73-a6e8-8291b025a181": Phase="Pending", Reason="", readiness=false. Elapsed: 5.459332ms
Nov  5 12:10:41.490: INFO: Pod "pod-7121b44d-cd1a-4d73-a6e8-8291b025a181": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009615067s
Nov  5 12:10:43.490: INFO: Pod "pod-7121b44d-cd1a-4d73-a6e8-8291b025a181": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009971571s
STEP: Saw pod success 11/05/22 12:10:43.49
Nov  5 12:10:43.490: INFO: Pod "pod-7121b44d-cd1a-4d73-a6e8-8291b025a181" satisfied condition "Succeeded or Failed"
Nov  5 12:10:43.494: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-7121b44d-cd1a-4d73-a6e8-8291b025a181 container test-container: <nil>
STEP: delete the pod 11/05/22 12:10:43.5
Nov  5 12:10:43.510: INFO: Waiting for pod pod-7121b44d-cd1a-4d73-a6e8-8291b025a181 to disappear
Nov  5 12:10:43.513: INFO: Pod pod-7121b44d-cd1a-4d73-a6e8-8291b025a181 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 12:10:43.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5388" for this suite. 11/05/22 12:10:43.517
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":63,"skipped":1206,"failed":0}
------------------------------
• [4.075 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:10:39.449
    Nov  5 12:10:39.449: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 12:10:39.449
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:39.462
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:39.467
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 11/05/22 12:10:39.471
    Nov  5 12:10:39.480: INFO: Waiting up to 5m0s for pod "pod-7121b44d-cd1a-4d73-a6e8-8291b025a181" in namespace "emptydir-5388" to be "Succeeded or Failed"
    Nov  5 12:10:39.486: INFO: Pod "pod-7121b44d-cd1a-4d73-a6e8-8291b025a181": Phase="Pending", Reason="", readiness=false. Elapsed: 5.459332ms
    Nov  5 12:10:41.490: INFO: Pod "pod-7121b44d-cd1a-4d73-a6e8-8291b025a181": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009615067s
    Nov  5 12:10:43.490: INFO: Pod "pod-7121b44d-cd1a-4d73-a6e8-8291b025a181": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009971571s
    STEP: Saw pod success 11/05/22 12:10:43.49
    Nov  5 12:10:43.490: INFO: Pod "pod-7121b44d-cd1a-4d73-a6e8-8291b025a181" satisfied condition "Succeeded or Failed"
    Nov  5 12:10:43.494: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-7121b44d-cd1a-4d73-a6e8-8291b025a181 container test-container: <nil>
    STEP: delete the pod 11/05/22 12:10:43.5
    Nov  5 12:10:43.510: INFO: Waiting for pod pod-7121b44d-cd1a-4d73-a6e8-8291b025a181 to disappear
    Nov  5 12:10:43.513: INFO: Pod pod-7121b44d-cd1a-4d73-a6e8-8291b025a181 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 12:10:43.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5388" for this suite. 11/05/22 12:10:43.517
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:10:43.525
Nov  5 12:10:43.525: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename controllerrevisions 11/05/22 12:10:43.525
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:43.537
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:43.542
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-z5d8j-daemon-set" 11/05/22 12:10:43.564
STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 12:10:43.572
Nov  5 12:10:43.575: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:10:43.576: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:10:43.579: INFO: Number of nodes with available pods controlled by daemonset e2e-z5d8j-daemon-set: 0
Nov  5 12:10:43.579: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:10:44.584: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:10:44.585: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:10:44.593: INFO: Number of nodes with available pods controlled by daemonset e2e-z5d8j-daemon-set: 2
Nov  5 12:10:44.593: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
Nov  5 12:10:45.584: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:10:45.584: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:10:45.589: INFO: Number of nodes with available pods controlled by daemonset e2e-z5d8j-daemon-set: 3
Nov  5 12:10:45.589: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-z5d8j-daemon-set
STEP: Confirm DaemonSet "e2e-z5d8j-daemon-set" successfully created with "daemonset-name=e2e-z5d8j-daemon-set" label 11/05/22 12:10:45.592
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-z5d8j-daemon-set" 11/05/22 12:10:45.602
Nov  5 12:10:45.606: INFO: Located ControllerRevision: "e2e-z5d8j-daemon-set-6d9845869d"
STEP: Patching ControllerRevision "e2e-z5d8j-daemon-set-6d9845869d" 11/05/22 12:10:45.609
Nov  5 12:10:45.616: INFO: e2e-z5d8j-daemon-set-6d9845869d has been patched
STEP: Create a new ControllerRevision 11/05/22 12:10:45.616
Nov  5 12:10:45.623: INFO: Created ControllerRevision: e2e-z5d8j-daemon-set-658f7dd756
STEP: Confirm that there are two ControllerRevisions 11/05/22 12:10:45.623
Nov  5 12:10:45.623: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov  5 12:10:45.627: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-z5d8j-daemon-set-6d9845869d" 11/05/22 12:10:45.627
STEP: Confirm that there is only one ControllerRevision 11/05/22 12:10:45.633
Nov  5 12:10:45.633: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov  5 12:10:45.636: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-z5d8j-daemon-set-658f7dd756" 11/05/22 12:10:45.646
Nov  5 12:10:45.655: INFO: e2e-z5d8j-daemon-set-658f7dd756 has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 11/05/22 12:10:45.656
W1105 12:10:45.666357      20 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 11/05/22 12:10:45.666
Nov  5 12:10:45.666: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov  5 12:10:46.671: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov  5 12:10:46.675: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-z5d8j-daemon-set-658f7dd756=updated" 11/05/22 12:10:46.675
STEP: Confirm that there is only one ControllerRevision 11/05/22 12:10:46.683
Nov  5 12:10:46.683: INFO: Requesting list of ControllerRevisions to confirm quantity
Nov  5 12:10:46.686: INFO: Found 1 ControllerRevisions
Nov  5 12:10:46.690: INFO: ControllerRevision "e2e-z5d8j-daemon-set-64bbd75f6f" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-z5d8j-daemon-set" 11/05/22 12:10:46.693
STEP: deleting DaemonSet.extensions e2e-z5d8j-daemon-set in namespace controllerrevisions-1476, will wait for the garbage collector to delete the pods 11/05/22 12:10:46.693
Nov  5 12:10:46.754: INFO: Deleting DaemonSet.extensions e2e-z5d8j-daemon-set took: 6.565922ms
Nov  5 12:10:46.854: INFO: Terminating DaemonSet.extensions e2e-z5d8j-daemon-set pods took: 100.223246ms
Nov  5 12:10:48.359: INFO: Number of nodes with available pods controlled by daemonset e2e-z5d8j-daemon-set: 0
Nov  5 12:10:48.359: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-z5d8j-daemon-set
Nov  5 12:10:48.362: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7275"},"items":null}

Nov  5 12:10:48.366: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7275"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:10:48.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-1476" for this suite. 11/05/22 12:10:48.383
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":64,"skipped":1215,"failed":0}
------------------------------
• [4.865 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:10:43.525
    Nov  5 12:10:43.525: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename controllerrevisions 11/05/22 12:10:43.525
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:43.537
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:43.542
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-z5d8j-daemon-set" 11/05/22 12:10:43.564
    STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 12:10:43.572
    Nov  5 12:10:43.575: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:10:43.576: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:10:43.579: INFO: Number of nodes with available pods controlled by daemonset e2e-z5d8j-daemon-set: 0
    Nov  5 12:10:43.579: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:10:44.584: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:10:44.585: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:10:44.593: INFO: Number of nodes with available pods controlled by daemonset e2e-z5d8j-daemon-set: 2
    Nov  5 12:10:44.593: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
    Nov  5 12:10:45.584: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:10:45.584: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:10:45.589: INFO: Number of nodes with available pods controlled by daemonset e2e-z5d8j-daemon-set: 3
    Nov  5 12:10:45.589: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset e2e-z5d8j-daemon-set
    STEP: Confirm DaemonSet "e2e-z5d8j-daemon-set" successfully created with "daemonset-name=e2e-z5d8j-daemon-set" label 11/05/22 12:10:45.592
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-z5d8j-daemon-set" 11/05/22 12:10:45.602
    Nov  5 12:10:45.606: INFO: Located ControllerRevision: "e2e-z5d8j-daemon-set-6d9845869d"
    STEP: Patching ControllerRevision "e2e-z5d8j-daemon-set-6d9845869d" 11/05/22 12:10:45.609
    Nov  5 12:10:45.616: INFO: e2e-z5d8j-daemon-set-6d9845869d has been patched
    STEP: Create a new ControllerRevision 11/05/22 12:10:45.616
    Nov  5 12:10:45.623: INFO: Created ControllerRevision: e2e-z5d8j-daemon-set-658f7dd756
    STEP: Confirm that there are two ControllerRevisions 11/05/22 12:10:45.623
    Nov  5 12:10:45.623: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov  5 12:10:45.627: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-z5d8j-daemon-set-6d9845869d" 11/05/22 12:10:45.627
    STEP: Confirm that there is only one ControllerRevision 11/05/22 12:10:45.633
    Nov  5 12:10:45.633: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov  5 12:10:45.636: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-z5d8j-daemon-set-658f7dd756" 11/05/22 12:10:45.646
    Nov  5 12:10:45.655: INFO: e2e-z5d8j-daemon-set-658f7dd756 has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 11/05/22 12:10:45.656
    W1105 12:10:45.666357      20 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 11/05/22 12:10:45.666
    Nov  5 12:10:45.666: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov  5 12:10:46.671: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov  5 12:10:46.675: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-z5d8j-daemon-set-658f7dd756=updated" 11/05/22 12:10:46.675
    STEP: Confirm that there is only one ControllerRevision 11/05/22 12:10:46.683
    Nov  5 12:10:46.683: INFO: Requesting list of ControllerRevisions to confirm quantity
    Nov  5 12:10:46.686: INFO: Found 1 ControllerRevisions
    Nov  5 12:10:46.690: INFO: ControllerRevision "e2e-z5d8j-daemon-set-64bbd75f6f" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-z5d8j-daemon-set" 11/05/22 12:10:46.693
    STEP: deleting DaemonSet.extensions e2e-z5d8j-daemon-set in namespace controllerrevisions-1476, will wait for the garbage collector to delete the pods 11/05/22 12:10:46.693
    Nov  5 12:10:46.754: INFO: Deleting DaemonSet.extensions e2e-z5d8j-daemon-set took: 6.565922ms
    Nov  5 12:10:46.854: INFO: Terminating DaemonSet.extensions e2e-z5d8j-daemon-set pods took: 100.223246ms
    Nov  5 12:10:48.359: INFO: Number of nodes with available pods controlled by daemonset e2e-z5d8j-daemon-set: 0
    Nov  5 12:10:48.359: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-z5d8j-daemon-set
    Nov  5 12:10:48.362: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"7275"},"items":null}

    Nov  5 12:10:48.366: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"7275"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:10:48.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-1476" for this suite. 11/05/22 12:10:48.383
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:10:48.39
Nov  5 12:10:48.390: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename disruption 11/05/22 12:10:48.391
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:48.409
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:48.414
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 11/05/22 12:10:48.418
STEP: Waiting for the pdb to be processed 11/05/22 12:10:48.423
STEP: First trying to evict a pod which shouldn't be evictable 11/05/22 12:10:50.439
STEP: Waiting for all pods to be running 11/05/22 12:10:50.439
Nov  5 12:10:50.443: INFO: pods: 0 < 3
STEP: locating a running pod 11/05/22 12:10:52.447
STEP: Updating the pdb to allow a pod to be evicted 11/05/22 12:10:52.457
STEP: Waiting for the pdb to be processed 11/05/22 12:10:52.465
STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/05/22 12:10:54.478
STEP: Waiting for all pods to be running 11/05/22 12:10:54.478
STEP: Waiting for the pdb to observed all healthy pods 11/05/22 12:10:54.482
STEP: Patching the pdb to disallow a pod to be evicted 11/05/22 12:10:54.504
STEP: Waiting for the pdb to be processed 11/05/22 12:10:54.525
STEP: Waiting for all pods to be running 11/05/22 12:10:56.539
STEP: locating a running pod 11/05/22 12:10:56.543
STEP: Deleting the pdb to allow a pod to be evicted 11/05/22 12:10:56.553
STEP: Waiting for the pdb to be deleted 11/05/22 12:10:56.559
STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/05/22 12:10:56.562
STEP: Waiting for all pods to be running 11/05/22 12:10:56.562
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov  5 12:10:56.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-9545" for this suite. 11/05/22 12:10:56.582
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":65,"skipped":1220,"failed":0}
------------------------------
• [SLOW TEST] [8.204 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:10:48.39
    Nov  5 12:10:48.390: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename disruption 11/05/22 12:10:48.391
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:48.409
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:48.414
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 11/05/22 12:10:48.418
    STEP: Waiting for the pdb to be processed 11/05/22 12:10:48.423
    STEP: First trying to evict a pod which shouldn't be evictable 11/05/22 12:10:50.439
    STEP: Waiting for all pods to be running 11/05/22 12:10:50.439
    Nov  5 12:10:50.443: INFO: pods: 0 < 3
    STEP: locating a running pod 11/05/22 12:10:52.447
    STEP: Updating the pdb to allow a pod to be evicted 11/05/22 12:10:52.457
    STEP: Waiting for the pdb to be processed 11/05/22 12:10:52.465
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/05/22 12:10:54.478
    STEP: Waiting for all pods to be running 11/05/22 12:10:54.478
    STEP: Waiting for the pdb to observed all healthy pods 11/05/22 12:10:54.482
    STEP: Patching the pdb to disallow a pod to be evicted 11/05/22 12:10:54.504
    STEP: Waiting for the pdb to be processed 11/05/22 12:10:54.525
    STEP: Waiting for all pods to be running 11/05/22 12:10:56.539
    STEP: locating a running pod 11/05/22 12:10:56.543
    STEP: Deleting the pdb to allow a pod to be evicted 11/05/22 12:10:56.553
    STEP: Waiting for the pdb to be deleted 11/05/22 12:10:56.559
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 11/05/22 12:10:56.562
    STEP: Waiting for all pods to be running 11/05/22 12:10:56.562
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov  5 12:10:56.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-9545" for this suite. 11/05/22 12:10:56.582
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:10:56.597
Nov  5 12:10:56.597: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename var-expansion 11/05/22 12:10:56.598
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:56.612
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:56.616
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 11/05/22 12:10:56.62
Nov  5 12:10:56.628: INFO: Waiting up to 5m0s for pod "var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc" in namespace "var-expansion-4430" to be "Succeeded or Failed"
Nov  5 12:10:56.634: INFO: Pod "var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.566381ms
Nov  5 12:10:58.638: INFO: Pod "var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009861546s
Nov  5 12:11:00.639: INFO: Pod "var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010365316s
STEP: Saw pod success 11/05/22 12:11:00.639
Nov  5 12:11:00.639: INFO: Pod "var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc" satisfied condition "Succeeded or Failed"
Nov  5 12:11:00.642: INFO: Trying to get logs from node ip-172-31-0-255 pod var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc container dapi-container: <nil>
STEP: delete the pod 11/05/22 12:11:00.648
Nov  5 12:11:00.663: INFO: Waiting for pod var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc to disappear
Nov  5 12:11:00.666: INFO: Pod var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov  5 12:11:00.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4430" for this suite. 11/05/22 12:11:00.673
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":66,"skipped":1242,"failed":0}
------------------------------
• [4.085 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:10:56.597
    Nov  5 12:10:56.597: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename var-expansion 11/05/22 12:10:56.598
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:10:56.612
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:10:56.616
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 11/05/22 12:10:56.62
    Nov  5 12:10:56.628: INFO: Waiting up to 5m0s for pod "var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc" in namespace "var-expansion-4430" to be "Succeeded or Failed"
    Nov  5 12:10:56.634: INFO: Pod "var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.566381ms
    Nov  5 12:10:58.638: INFO: Pod "var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009861546s
    Nov  5 12:11:00.639: INFO: Pod "var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010365316s
    STEP: Saw pod success 11/05/22 12:11:00.639
    Nov  5 12:11:00.639: INFO: Pod "var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc" satisfied condition "Succeeded or Failed"
    Nov  5 12:11:00.642: INFO: Trying to get logs from node ip-172-31-0-255 pod var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc container dapi-container: <nil>
    STEP: delete the pod 11/05/22 12:11:00.648
    Nov  5 12:11:00.663: INFO: Waiting for pod var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc to disappear
    Nov  5 12:11:00.666: INFO: Pod var-expansion-be44a177-a2e4-4238-90b9-3313392a69bc no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov  5 12:11:00.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-4430" for this suite. 11/05/22 12:11:00.673
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:11:00.683
Nov  5 12:11:00.683: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 12:11:00.684
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:00.696
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:00.7
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204
STEP: creating service in namespace services-1458 11/05/22 12:11:00.704
STEP: creating service affinity-nodeport in namespace services-1458 11/05/22 12:11:00.704
STEP: creating replication controller affinity-nodeport in namespace services-1458 11/05/22 12:11:00.727
I1105 12:11:00.737898      20 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-1458, replica count: 3
I1105 12:11:03.789069      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1105 12:11:06.789575      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1105 12:11:09.789777      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 12:11:09.801: INFO: Creating new exec pod
Nov  5 12:11:09.808: INFO: Waiting up to 5m0s for pod "execpod-affinityphgk5" in namespace "services-1458" to be "running"
Nov  5 12:11:09.813: INFO: Pod "execpod-affinityphgk5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.42465ms
Nov  5 12:11:11.818: INFO: Pod "execpod-affinityphgk5": Phase="Running", Reason="", readiness=true. Elapsed: 2.009465648s
Nov  5 12:11:11.818: INFO: Pod "execpod-affinityphgk5" satisfied condition "running"
Nov  5 12:11:12.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1458 exec execpod-affinityphgk5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Nov  5 12:11:12.965: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Nov  5 12:11:12.965: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 12:11:12.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1458 exec execpod-affinityphgk5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.66 80'
Nov  5 12:11:13.097: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.66 80\nConnection to 10.152.183.66 80 port [tcp/http] succeeded!\n"
Nov  5 12:11:13.097: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 12:11:13.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1458 exec execpod-affinityphgk5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.255 31763'
Nov  5 12:11:13.213: INFO: stderr: "+ nc -v -t -w 2 172.31.0.255 31763\n+ echo hostName\nConnection to 172.31.0.255 31763 port [tcp/*] succeeded!\n"
Nov  5 12:11:13.213: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 12:11:13.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1458 exec execpod-affinityphgk5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.27.199 31763'
Nov  5 12:11:13.331: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.27.199 31763\nConnection to 172.31.27.199 31763 port [tcp/*] succeeded!\n"
Nov  5 12:11:13.331: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 12:11:13.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1458 exec execpod-affinityphgk5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.255:31763/ ; done'
Nov  5 12:11:13.530: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n"
Nov  5 12:11:13.530: INFO: stdout: "\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4"
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
Nov  5 12:11:13.530: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-1458, will wait for the garbage collector to delete the pods 11/05/22 12:11:13.544
Nov  5 12:11:13.607: INFO: Deleting ReplicationController affinity-nodeport took: 8.379173ms
Nov  5 12:11:13.707: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.431407ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 12:11:15.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1458" for this suite. 11/05/22 12:11:15.736
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":67,"skipped":1250,"failed":0}
------------------------------
• [SLOW TEST] [15.060 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:11:00.683
    Nov  5 12:11:00.683: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 12:11:00.684
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:00.696
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:00.7
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2204
    STEP: creating service in namespace services-1458 11/05/22 12:11:00.704
    STEP: creating service affinity-nodeport in namespace services-1458 11/05/22 12:11:00.704
    STEP: creating replication controller affinity-nodeport in namespace services-1458 11/05/22 12:11:00.727
    I1105 12:11:00.737898      20 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-1458, replica count: 3
    I1105 12:11:03.789069      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1105 12:11:06.789575      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 2 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1105 12:11:09.789777      20 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 12:11:09.801: INFO: Creating new exec pod
    Nov  5 12:11:09.808: INFO: Waiting up to 5m0s for pod "execpod-affinityphgk5" in namespace "services-1458" to be "running"
    Nov  5 12:11:09.813: INFO: Pod "execpod-affinityphgk5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.42465ms
    Nov  5 12:11:11.818: INFO: Pod "execpod-affinityphgk5": Phase="Running", Reason="", readiness=true. Elapsed: 2.009465648s
    Nov  5 12:11:11.818: INFO: Pod "execpod-affinityphgk5" satisfied condition "running"
    Nov  5 12:11:12.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1458 exec execpod-affinityphgk5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Nov  5 12:11:12.965: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Nov  5 12:11:12.965: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 12:11:12.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1458 exec execpod-affinityphgk5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.66 80'
    Nov  5 12:11:13.097: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.66 80\nConnection to 10.152.183.66 80 port [tcp/http] succeeded!\n"
    Nov  5 12:11:13.097: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 12:11:13.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1458 exec execpod-affinityphgk5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.255 31763'
    Nov  5 12:11:13.213: INFO: stderr: "+ nc -v -t -w 2 172.31.0.255 31763\n+ echo hostName\nConnection to 172.31.0.255 31763 port [tcp/*] succeeded!\n"
    Nov  5 12:11:13.213: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 12:11:13.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1458 exec execpod-affinityphgk5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.27.199 31763'
    Nov  5 12:11:13.331: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.27.199 31763\nConnection to 172.31.27.199 31763 port [tcp/*] succeeded!\n"
    Nov  5 12:11:13.331: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 12:11:13.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1458 exec execpod-affinityphgk5 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.255:31763/ ; done'
    Nov  5 12:11:13.530: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31763/\n"
    Nov  5 12:11:13.530: INFO: stdout: "\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4\naffinity-nodeport-lkzh4"
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Received response from host: affinity-nodeport-lkzh4
    Nov  5 12:11:13.530: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-1458, will wait for the garbage collector to delete the pods 11/05/22 12:11:13.544
    Nov  5 12:11:13.607: INFO: Deleting ReplicationController affinity-nodeport took: 8.379173ms
    Nov  5 12:11:13.707: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.431407ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 12:11:15.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1458" for this suite. 11/05/22 12:11:15.736
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:11:15.744
Nov  5 12:11:15.744: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 12:11:15.745
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:15.758
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:15.767
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 11/05/22 12:11:15.771
Nov  5 12:11:15.781: INFO: created test-pod-1
Nov  5 12:11:15.789: INFO: created test-pod-2
Nov  5 12:11:15.798: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 11/05/22 12:11:15.798
Nov  5 12:11:15.798: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-7981' to be running and ready
Nov  5 12:11:15.812: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov  5 12:11:15.812: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov  5 12:11:15.812: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Nov  5 12:11:15.812: INFO: 0 / 3 pods in namespace 'pods-7981' are running and ready (0 seconds elapsed)
Nov  5 12:11:15.812: INFO: expected 0 pod replicas in namespace 'pods-7981', 0 are Running and Ready.
Nov  5 12:11:15.812: INFO: POD         NODE             PHASE    GRACE  CONDITIONS
Nov  5 12:11:15.812: INFO: test-pod-1  ip-172-31-0-255  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC  }]
Nov  5 12:11:15.812: INFO: test-pod-2  ip-172-31-0-255  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC  }]
Nov  5 12:11:15.812: INFO: test-pod-3  ip-172-31-41-19  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC  }]
Nov  5 12:11:15.812: INFO: 
Nov  5 12:11:17.823: INFO: 3 / 3 pods in namespace 'pods-7981' are running and ready (2 seconds elapsed)
Nov  5 12:11:17.823: INFO: expected 0 pod replicas in namespace 'pods-7981', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 11/05/22 12:11:17.843
Nov  5 12:11:17.847: INFO: Pod quantity 3 is different from expected quantity 0
Nov  5 12:11:18.851: INFO: Pod quantity 3 is different from expected quantity 0
Nov  5 12:11:19.851: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov  5 12:11:20.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7981" for this suite. 11/05/22 12:11:20.855
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":68,"skipped":1256,"failed":0}
------------------------------
• [SLOW TEST] [5.118 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:11:15.744
    Nov  5 12:11:15.744: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 12:11:15.745
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:15.758
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:15.767
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 11/05/22 12:11:15.771
    Nov  5 12:11:15.781: INFO: created test-pod-1
    Nov  5 12:11:15.789: INFO: created test-pod-2
    Nov  5 12:11:15.798: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 11/05/22 12:11:15.798
    Nov  5 12:11:15.798: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-7981' to be running and ready
    Nov  5 12:11:15.812: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov  5 12:11:15.812: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov  5 12:11:15.812: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Nov  5 12:11:15.812: INFO: 0 / 3 pods in namespace 'pods-7981' are running and ready (0 seconds elapsed)
    Nov  5 12:11:15.812: INFO: expected 0 pod replicas in namespace 'pods-7981', 0 are Running and Ready.
    Nov  5 12:11:15.812: INFO: POD         NODE             PHASE    GRACE  CONDITIONS
    Nov  5 12:11:15.812: INFO: test-pod-1  ip-172-31-0-255  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC  }]
    Nov  5 12:11:15.812: INFO: test-pod-2  ip-172-31-0-255  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC  }]
    Nov  5 12:11:15.812: INFO: test-pod-3  ip-172-31-41-19  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:11:15 +0000 UTC  }]
    Nov  5 12:11:15.812: INFO: 
    Nov  5 12:11:17.823: INFO: 3 / 3 pods in namespace 'pods-7981' are running and ready (2 seconds elapsed)
    Nov  5 12:11:17.823: INFO: expected 0 pod replicas in namespace 'pods-7981', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 11/05/22 12:11:17.843
    Nov  5 12:11:17.847: INFO: Pod quantity 3 is different from expected quantity 0
    Nov  5 12:11:18.851: INFO: Pod quantity 3 is different from expected quantity 0
    Nov  5 12:11:19.851: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov  5 12:11:20.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7981" for this suite. 11/05/22 12:11:20.855
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:11:20.863
Nov  5 12:11:20.863: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 12:11:20.864
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:20.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:20.882
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 11/05/22 12:11:20.886
Nov  5 12:11:20.895: INFO: Waiting up to 5m0s for pod "downward-api-55ec0638-84f4-43c2-990b-4ee331395646" in namespace "downward-api-7511" to be "Succeeded or Failed"
Nov  5 12:11:20.900: INFO: Pod "downward-api-55ec0638-84f4-43c2-990b-4ee331395646": Phase="Pending", Reason="", readiness=false. Elapsed: 4.933365ms
Nov  5 12:11:22.906: INFO: Pod "downward-api-55ec0638-84f4-43c2-990b-4ee331395646": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010422111s
Nov  5 12:11:24.904: INFO: Pod "downward-api-55ec0638-84f4-43c2-990b-4ee331395646": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009206662s
STEP: Saw pod success 11/05/22 12:11:24.904
Nov  5 12:11:24.905: INFO: Pod "downward-api-55ec0638-84f4-43c2-990b-4ee331395646" satisfied condition "Succeeded or Failed"
Nov  5 12:11:24.909: INFO: Trying to get logs from node ip-172-31-0-255 pod downward-api-55ec0638-84f4-43c2-990b-4ee331395646 container dapi-container: <nil>
STEP: delete the pod 11/05/22 12:11:24.916
Nov  5 12:11:24.926: INFO: Waiting for pod downward-api-55ec0638-84f4-43c2-990b-4ee331395646 to disappear
Nov  5 12:11:24.929: INFO: Pod downward-api-55ec0638-84f4-43c2-990b-4ee331395646 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov  5 12:11:24.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7511" for this suite. 11/05/22 12:11:24.933
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":69,"skipped":1266,"failed":0}
------------------------------
• [4.079 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:11:20.863
    Nov  5 12:11:20.863: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 12:11:20.864
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:20.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:20.882
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 11/05/22 12:11:20.886
    Nov  5 12:11:20.895: INFO: Waiting up to 5m0s for pod "downward-api-55ec0638-84f4-43c2-990b-4ee331395646" in namespace "downward-api-7511" to be "Succeeded or Failed"
    Nov  5 12:11:20.900: INFO: Pod "downward-api-55ec0638-84f4-43c2-990b-4ee331395646": Phase="Pending", Reason="", readiness=false. Elapsed: 4.933365ms
    Nov  5 12:11:22.906: INFO: Pod "downward-api-55ec0638-84f4-43c2-990b-4ee331395646": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010422111s
    Nov  5 12:11:24.904: INFO: Pod "downward-api-55ec0638-84f4-43c2-990b-4ee331395646": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009206662s
    STEP: Saw pod success 11/05/22 12:11:24.904
    Nov  5 12:11:24.905: INFO: Pod "downward-api-55ec0638-84f4-43c2-990b-4ee331395646" satisfied condition "Succeeded or Failed"
    Nov  5 12:11:24.909: INFO: Trying to get logs from node ip-172-31-0-255 pod downward-api-55ec0638-84f4-43c2-990b-4ee331395646 container dapi-container: <nil>
    STEP: delete the pod 11/05/22 12:11:24.916
    Nov  5 12:11:24.926: INFO: Waiting for pod downward-api-55ec0638-84f4-43c2-990b-4ee331395646 to disappear
    Nov  5 12:11:24.929: INFO: Pod downward-api-55ec0638-84f4-43c2-990b-4ee331395646 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov  5 12:11:24.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7511" for this suite. 11/05/22 12:11:24.933
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:11:24.944
Nov  5 12:11:24.944: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-runtime 11/05/22 12:11:24.944
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:24.955
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:24.959
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 11/05/22 12:11:24.962
STEP: wait for the container to reach Failed 11/05/22 12:11:24.974
STEP: get the container status 11/05/22 12:11:28.995
STEP: the container should be terminated 11/05/22 12:11:28.999
STEP: the termination message should be set 11/05/22 12:11:28.999
Nov  5 12:11:28.999: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 11/05/22 12:11:28.999
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov  5 12:11:29.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8211" for this suite. 11/05/22 12:11:29.018
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":70,"skipped":1281,"failed":0}
------------------------------
• [4.084 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:11:24.944
    Nov  5 12:11:24.944: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-runtime 11/05/22 12:11:24.944
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:24.955
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:24.959
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 11/05/22 12:11:24.962
    STEP: wait for the container to reach Failed 11/05/22 12:11:24.974
    STEP: get the container status 11/05/22 12:11:28.995
    STEP: the container should be terminated 11/05/22 12:11:28.999
    STEP: the termination message should be set 11/05/22 12:11:28.999
    Nov  5 12:11:28.999: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 11/05/22 12:11:28.999
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov  5 12:11:29.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-8211" for this suite. 11/05/22 12:11:29.018
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:11:29.03
Nov  5 12:11:29.030: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename security-context 11/05/22 12:11:29.031
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:29.048
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:29.052
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/05/22 12:11:29.058
Nov  5 12:11:29.069: INFO: Waiting up to 5m0s for pod "security-context-d977bb05-4db3-4b12-a8f1-badbceac9393" in namespace "security-context-8393" to be "Succeeded or Failed"
Nov  5 12:11:29.073: INFO: Pod "security-context-d977bb05-4db3-4b12-a8f1-badbceac9393": Phase="Pending", Reason="", readiness=false. Elapsed: 4.548975ms
Nov  5 12:11:31.077: INFO: Pod "security-context-d977bb05-4db3-4b12-a8f1-badbceac9393": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008452878s
Nov  5 12:11:33.078: INFO: Pod "security-context-d977bb05-4db3-4b12-a8f1-badbceac9393": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009635911s
STEP: Saw pod success 11/05/22 12:11:33.078
Nov  5 12:11:33.079: INFO: Pod "security-context-d977bb05-4db3-4b12-a8f1-badbceac9393" satisfied condition "Succeeded or Failed"
Nov  5 12:11:33.082: INFO: Trying to get logs from node ip-172-31-0-255 pod security-context-d977bb05-4db3-4b12-a8f1-badbceac9393 container test-container: <nil>
STEP: delete the pod 11/05/22 12:11:33.089
Nov  5 12:11:33.102: INFO: Waiting for pod security-context-d977bb05-4db3-4b12-a8f1-badbceac9393 to disappear
Nov  5 12:11:33.105: INFO: Pod security-context-d977bb05-4db3-4b12-a8f1-badbceac9393 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov  5 12:11:33.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-8393" for this suite. 11/05/22 12:11:33.109
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":71,"skipped":1309,"failed":0}
------------------------------
• [4.086 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:11:29.03
    Nov  5 12:11:29.030: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename security-context 11/05/22 12:11:29.031
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:29.048
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:29.052
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 11/05/22 12:11:29.058
    Nov  5 12:11:29.069: INFO: Waiting up to 5m0s for pod "security-context-d977bb05-4db3-4b12-a8f1-badbceac9393" in namespace "security-context-8393" to be "Succeeded or Failed"
    Nov  5 12:11:29.073: INFO: Pod "security-context-d977bb05-4db3-4b12-a8f1-badbceac9393": Phase="Pending", Reason="", readiness=false. Elapsed: 4.548975ms
    Nov  5 12:11:31.077: INFO: Pod "security-context-d977bb05-4db3-4b12-a8f1-badbceac9393": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008452878s
    Nov  5 12:11:33.078: INFO: Pod "security-context-d977bb05-4db3-4b12-a8f1-badbceac9393": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009635911s
    STEP: Saw pod success 11/05/22 12:11:33.078
    Nov  5 12:11:33.079: INFO: Pod "security-context-d977bb05-4db3-4b12-a8f1-badbceac9393" satisfied condition "Succeeded or Failed"
    Nov  5 12:11:33.082: INFO: Trying to get logs from node ip-172-31-0-255 pod security-context-d977bb05-4db3-4b12-a8f1-badbceac9393 container test-container: <nil>
    STEP: delete the pod 11/05/22 12:11:33.089
    Nov  5 12:11:33.102: INFO: Waiting for pod security-context-d977bb05-4db3-4b12-a8f1-badbceac9393 to disappear
    Nov  5 12:11:33.105: INFO: Pod security-context-d977bb05-4db3-4b12-a8f1-badbceac9393 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov  5 12:11:33.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-8393" for this suite. 11/05/22 12:11:33.109
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:11:33.118
Nov  5 12:11:33.118: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:11:33.119
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:33.131
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:33.136
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-506c940c-122b-4914-adbf-393f8a27cfc2 11/05/22 12:11:33.139
STEP: Creating a pod to test consume secrets 11/05/22 12:11:33.145
Nov  5 12:11:33.153: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0" in namespace "projected-7023" to be "Succeeded or Failed"
Nov  5 12:11:33.161: INFO: Pod "pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.047522ms
Nov  5 12:11:35.165: INFO: Pod "pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011764999s
Nov  5 12:11:37.165: INFO: Pod "pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012388065s
STEP: Saw pod success 11/05/22 12:11:37.165
Nov  5 12:11:37.166: INFO: Pod "pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0" satisfied condition "Succeeded or Failed"
Nov  5 12:11:37.170: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/05/22 12:11:37.176
Nov  5 12:11:37.191: INFO: Waiting for pod pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0 to disappear
Nov  5 12:11:37.194: INFO: Pod pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov  5 12:11:37.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7023" for this suite. 11/05/22 12:11:37.198
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":72,"skipped":1328,"failed":0}
------------------------------
• [4.087 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:11:33.118
    Nov  5 12:11:33.118: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:11:33.119
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:33.131
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:33.136
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-506c940c-122b-4914-adbf-393f8a27cfc2 11/05/22 12:11:33.139
    STEP: Creating a pod to test consume secrets 11/05/22 12:11:33.145
    Nov  5 12:11:33.153: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0" in namespace "projected-7023" to be "Succeeded or Failed"
    Nov  5 12:11:33.161: INFO: Pod "pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.047522ms
    Nov  5 12:11:35.165: INFO: Pod "pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011764999s
    Nov  5 12:11:37.165: INFO: Pod "pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012388065s
    STEP: Saw pod success 11/05/22 12:11:37.165
    Nov  5 12:11:37.166: INFO: Pod "pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0" satisfied condition "Succeeded or Failed"
    Nov  5 12:11:37.170: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 12:11:37.176
    Nov  5 12:11:37.191: INFO: Waiting for pod pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0 to disappear
    Nov  5 12:11:37.194: INFO: Pod pod-projected-secrets-9007c701-33f7-4033-a5ee-68d0160158a0 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov  5 12:11:37.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7023" for this suite. 11/05/22 12:11:37.198
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:11:37.206
Nov  5 12:11:37.206: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 12:11:37.207
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:37.22
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:37.224
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 12:11:37.242
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:11:37.485
STEP: Deploying the webhook pod 11/05/22 12:11:37.495
STEP: Wait for the deployment to be ready 11/05/22 12:11:37.517
Nov  5 12:11:37.530: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 12:11:39.54
STEP: Verifying the service has paired with the endpoint 11/05/22 12:11:39.55
Nov  5 12:11:40.551: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Nov  5 12:11:40.555: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5068-crds.webhook.example.com via the AdmissionRegistration API 11/05/22 12:11:41.068
STEP: Creating a custom resource while v1 is storage version 11/05/22 12:11:41.082
STEP: Patching Custom Resource Definition to set v2 as storage 11/05/22 12:11:43.137
STEP: Patching the custom resource while v2 is storage version 11/05/22 12:11:43.153
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:11:43.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1332" for this suite. 11/05/22 12:11:43.711
STEP: Destroying namespace "webhook-1332-markers" for this suite. 11/05/22 12:11:43.718
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":73,"skipped":1343,"failed":0}
------------------------------
• [SLOW TEST] [6.578 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:11:37.206
    Nov  5 12:11:37.206: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 12:11:37.207
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:37.22
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:37.224
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 12:11:37.242
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:11:37.485
    STEP: Deploying the webhook pod 11/05/22 12:11:37.495
    STEP: Wait for the deployment to be ready 11/05/22 12:11:37.517
    Nov  5 12:11:37.530: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 12:11:39.54
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:11:39.55
    Nov  5 12:11:40.551: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Nov  5 12:11:40.555: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5068-crds.webhook.example.com via the AdmissionRegistration API 11/05/22 12:11:41.068
    STEP: Creating a custom resource while v1 is storage version 11/05/22 12:11:41.082
    STEP: Patching Custom Resource Definition to set v2 as storage 11/05/22 12:11:43.137
    STEP: Patching the custom resource while v2 is storage version 11/05/22 12:11:43.153
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:11:43.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1332" for this suite. 11/05/22 12:11:43.711
    STEP: Destroying namespace "webhook-1332-markers" for this suite. 11/05/22 12:11:43.718
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:11:43.785
Nov  5 12:11:43.786: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 12:11:43.786
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:43.808
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:43.813
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 12:11:43.834
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:11:44.346
STEP: Deploying the webhook pod 11/05/22 12:11:44.352
STEP: Wait for the deployment to be ready 11/05/22 12:11:44.365
Nov  5 12:11:44.384: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 12:11:46.396
STEP: Verifying the service has paired with the endpoint 11/05/22 12:11:46.406
Nov  5 12:11:47.406: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 11/05/22 12:11:47.479
STEP: Creating a configMap that does not comply to the validation webhook rules 11/05/22 12:11:47.515
STEP: Deleting the collection of validation webhooks 11/05/22 12:11:47.549
STEP: Creating a configMap that does not comply to the validation webhook rules 11/05/22 12:11:47.596
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:11:47.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7331" for this suite. 11/05/22 12:11:47.611
STEP: Destroying namespace "webhook-7331-markers" for this suite. 11/05/22 12:11:47.617
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":74,"skipped":1352,"failed":0}
------------------------------
• [3.888 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:11:43.785
    Nov  5 12:11:43.786: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 12:11:43.786
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:43.808
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:43.813
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 12:11:43.834
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:11:44.346
    STEP: Deploying the webhook pod 11/05/22 12:11:44.352
    STEP: Wait for the deployment to be ready 11/05/22 12:11:44.365
    Nov  5 12:11:44.384: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 12:11:46.396
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:11:46.406
    Nov  5 12:11:47.406: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 11/05/22 12:11:47.479
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/05/22 12:11:47.515
    STEP: Deleting the collection of validation webhooks 11/05/22 12:11:47.549
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/05/22 12:11:47.596
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:11:47.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7331" for this suite. 11/05/22 12:11:47.611
    STEP: Destroying namespace "webhook-7331-markers" for this suite. 11/05/22 12:11:47.617
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:11:47.675
Nov  5 12:11:47.675: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename var-expansion 11/05/22 12:11:47.676
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:47.704
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:47.708
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Nov  5 12:11:47.724: INFO: Waiting up to 2m0s for pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621" in namespace "var-expansion-3727" to be "container 0 failed with reason CreateContainerConfigError"
Nov  5 12:11:47.727: INFO: Pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621": Phase="Pending", Reason="", readiness=false. Elapsed: 3.869522ms
Nov  5 12:11:49.732: INFO: Pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008526459s
Nov  5 12:11:49.732: INFO: Pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Nov  5 12:11:49.732: INFO: Deleting pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621" in namespace "var-expansion-3727"
Nov  5 12:11:49.742: INFO: Wait up to 5m0s for pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov  5 12:11:51.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3727" for this suite. 11/05/22 12:11:51.755
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":75,"skipped":1364,"failed":0}
------------------------------
• [4.088 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:11:47.675
    Nov  5 12:11:47.675: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename var-expansion 11/05/22 12:11:47.676
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:47.704
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:47.708
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Nov  5 12:11:47.724: INFO: Waiting up to 2m0s for pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621" in namespace "var-expansion-3727" to be "container 0 failed with reason CreateContainerConfigError"
    Nov  5 12:11:47.727: INFO: Pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621": Phase="Pending", Reason="", readiness=false. Elapsed: 3.869522ms
    Nov  5 12:11:49.732: INFO: Pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008526459s
    Nov  5 12:11:49.732: INFO: Pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Nov  5 12:11:49.732: INFO: Deleting pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621" in namespace "var-expansion-3727"
    Nov  5 12:11:49.742: INFO: Wait up to 5m0s for pod "var-expansion-b010f967-8cfd-4c0e-a9de-24d690737621" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov  5 12:11:51.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3727" for this suite. 11/05/22 12:11:51.755
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:11:51.764
Nov  5 12:11:51.764: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 12:11:51.765
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:51.78
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:51.784
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 11/05/22 12:11:51.788
STEP: Ensuring ResourceQuota status is calculated 11/05/22 12:11:51.793
STEP: Creating a ResourceQuota with not terminating scope 11/05/22 12:11:53.798
STEP: Ensuring ResourceQuota status is calculated 11/05/22 12:11:53.804
STEP: Creating a long running pod 11/05/22 12:11:55.809
STEP: Ensuring resource quota with not terminating scope captures the pod usage 11/05/22 12:11:55.825
STEP: Ensuring resource quota with terminating scope ignored the pod usage 11/05/22 12:11:57.83
STEP: Deleting the pod 11/05/22 12:11:59.834
STEP: Ensuring resource quota status released the pod usage 11/05/22 12:11:59.848
STEP: Creating a terminating pod 11/05/22 12:12:01.852
STEP: Ensuring resource quota with terminating scope captures the pod usage 11/05/22 12:12:01.864
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 11/05/22 12:12:03.87
STEP: Deleting the pod 11/05/22 12:12:05.874
STEP: Ensuring resource quota status released the pod usage 11/05/22 12:12:05.894
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 12:12:07.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9328" for this suite. 11/05/22 12:12:07.902
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":76,"skipped":1392,"failed":0}
------------------------------
• [SLOW TEST] [16.146 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:11:51.764
    Nov  5 12:11:51.764: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 12:11:51.765
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:11:51.78
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:11:51.784
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 11/05/22 12:11:51.788
    STEP: Ensuring ResourceQuota status is calculated 11/05/22 12:11:51.793
    STEP: Creating a ResourceQuota with not terminating scope 11/05/22 12:11:53.798
    STEP: Ensuring ResourceQuota status is calculated 11/05/22 12:11:53.804
    STEP: Creating a long running pod 11/05/22 12:11:55.809
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 11/05/22 12:11:55.825
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 11/05/22 12:11:57.83
    STEP: Deleting the pod 11/05/22 12:11:59.834
    STEP: Ensuring resource quota status released the pod usage 11/05/22 12:11:59.848
    STEP: Creating a terminating pod 11/05/22 12:12:01.852
    STEP: Ensuring resource quota with terminating scope captures the pod usage 11/05/22 12:12:01.864
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 11/05/22 12:12:03.87
    STEP: Deleting the pod 11/05/22 12:12:05.874
    STEP: Ensuring resource quota status released the pod usage 11/05/22 12:12:05.894
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 12:12:07.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9328" for this suite. 11/05/22 12:12:07.902
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:12:07.911
Nov  5 12:12:07.911: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 12:12:07.912
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:07.923
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:07.927
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 12:12:07.945
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:12:08.234
STEP: Deploying the webhook pod 11/05/22 12:12:08.242
STEP: Wait for the deployment to be ready 11/05/22 12:12:08.256
Nov  5 12:12:08.279: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 12:12:10.292
STEP: Verifying the service has paired with the endpoint 11/05/22 12:12:10.302
Nov  5 12:12:11.302: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 11/05/22 12:12:11.306
STEP: create a pod 11/05/22 12:12:11.321
Nov  5 12:12:11.326: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-6431" to be "running"
Nov  5 12:12:11.331: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.617682ms
Nov  5 12:12:13.335: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009165635s
Nov  5 12:12:13.336: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 11/05/22 12:12:13.336
Nov  5 12:12:13.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=webhook-6431 attach --namespace=webhook-6431 to-be-attached-pod -i -c=container1'
Nov  5 12:12:13.407: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:12:13.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6431" for this suite. 11/05/22 12:12:13.419
STEP: Destroying namespace "webhook-6431-markers" for this suite. 11/05/22 12:12:13.426
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":77,"skipped":1393,"failed":0}
------------------------------
• [SLOW TEST] [5.595 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:12:07.911
    Nov  5 12:12:07.911: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 12:12:07.912
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:07.923
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:07.927
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 12:12:07.945
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:12:08.234
    STEP: Deploying the webhook pod 11/05/22 12:12:08.242
    STEP: Wait for the deployment to be ready 11/05/22 12:12:08.256
    Nov  5 12:12:08.279: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 12:12:10.292
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:12:10.302
    Nov  5 12:12:11.302: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 11/05/22 12:12:11.306
    STEP: create a pod 11/05/22 12:12:11.321
    Nov  5 12:12:11.326: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-6431" to be "running"
    Nov  5 12:12:11.331: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.617682ms
    Nov  5 12:12:13.335: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009165635s
    Nov  5 12:12:13.336: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 11/05/22 12:12:13.336
    Nov  5 12:12:13.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=webhook-6431 attach --namespace=webhook-6431 to-be-attached-pod -i -c=container1'
    Nov  5 12:12:13.407: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:12:13.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6431" for this suite. 11/05/22 12:12:13.419
    STEP: Destroying namespace "webhook-6431-markers" for this suite. 11/05/22 12:12:13.426
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:12:13.508
Nov  5 12:12:13.508: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename discovery 11/05/22 12:12:13.508
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:13.533
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:13.537
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 11/05/22 12:12:13.543
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Nov  5 12:12:14.115: INFO: Checking APIGroup: apiregistration.k8s.io
Nov  5 12:12:14.116: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Nov  5 12:12:14.116: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Nov  5 12:12:14.116: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Nov  5 12:12:14.116: INFO: Checking APIGroup: apps
Nov  5 12:12:14.118: INFO: PreferredVersion.GroupVersion: apps/v1
Nov  5 12:12:14.118: INFO: Versions found [{apps/v1 v1}]
Nov  5 12:12:14.118: INFO: apps/v1 matches apps/v1
Nov  5 12:12:14.118: INFO: Checking APIGroup: events.k8s.io
Nov  5 12:12:14.119: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Nov  5 12:12:14.119: INFO: Versions found [{events.k8s.io/v1 v1}]
Nov  5 12:12:14.119: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Nov  5 12:12:14.119: INFO: Checking APIGroup: authentication.k8s.io
Nov  5 12:12:14.120: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Nov  5 12:12:14.120: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Nov  5 12:12:14.120: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Nov  5 12:12:14.120: INFO: Checking APIGroup: authorization.k8s.io
Nov  5 12:12:14.122: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Nov  5 12:12:14.122: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Nov  5 12:12:14.122: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Nov  5 12:12:14.122: INFO: Checking APIGroup: autoscaling
Nov  5 12:12:14.123: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Nov  5 12:12:14.123: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Nov  5 12:12:14.123: INFO: autoscaling/v2 matches autoscaling/v2
Nov  5 12:12:14.123: INFO: Checking APIGroup: batch
Nov  5 12:12:14.125: INFO: PreferredVersion.GroupVersion: batch/v1
Nov  5 12:12:14.125: INFO: Versions found [{batch/v1 v1}]
Nov  5 12:12:14.125: INFO: batch/v1 matches batch/v1
Nov  5 12:12:14.125: INFO: Checking APIGroup: certificates.k8s.io
Nov  5 12:12:14.126: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Nov  5 12:12:14.126: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Nov  5 12:12:14.126: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Nov  5 12:12:14.126: INFO: Checking APIGroup: networking.k8s.io
Nov  5 12:12:14.128: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Nov  5 12:12:14.128: INFO: Versions found [{networking.k8s.io/v1 v1}]
Nov  5 12:12:14.128: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Nov  5 12:12:14.128: INFO: Checking APIGroup: policy
Nov  5 12:12:14.129: INFO: PreferredVersion.GroupVersion: policy/v1
Nov  5 12:12:14.129: INFO: Versions found [{policy/v1 v1}]
Nov  5 12:12:14.129: INFO: policy/v1 matches policy/v1
Nov  5 12:12:14.129: INFO: Checking APIGroup: rbac.authorization.k8s.io
Nov  5 12:12:14.131: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Nov  5 12:12:14.131: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Nov  5 12:12:14.131: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Nov  5 12:12:14.131: INFO: Checking APIGroup: storage.k8s.io
Nov  5 12:12:14.132: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Nov  5 12:12:14.132: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Nov  5 12:12:14.132: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Nov  5 12:12:14.132: INFO: Checking APIGroup: admissionregistration.k8s.io
Nov  5 12:12:14.133: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Nov  5 12:12:14.133: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Nov  5 12:12:14.133: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Nov  5 12:12:14.133: INFO: Checking APIGroup: apiextensions.k8s.io
Nov  5 12:12:14.135: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Nov  5 12:12:14.135: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Nov  5 12:12:14.135: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Nov  5 12:12:14.135: INFO: Checking APIGroup: scheduling.k8s.io
Nov  5 12:12:14.136: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Nov  5 12:12:14.136: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Nov  5 12:12:14.136: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Nov  5 12:12:14.136: INFO: Checking APIGroup: coordination.k8s.io
Nov  5 12:12:14.138: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Nov  5 12:12:14.138: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Nov  5 12:12:14.138: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Nov  5 12:12:14.138: INFO: Checking APIGroup: node.k8s.io
Nov  5 12:12:14.139: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Nov  5 12:12:14.139: INFO: Versions found [{node.k8s.io/v1 v1}]
Nov  5 12:12:14.139: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Nov  5 12:12:14.139: INFO: Checking APIGroup: discovery.k8s.io
Nov  5 12:12:14.141: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Nov  5 12:12:14.141: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Nov  5 12:12:14.141: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Nov  5 12:12:14.141: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Nov  5 12:12:14.142: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Nov  5 12:12:14.142: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Nov  5 12:12:14.142: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Nov  5 12:12:14.142: INFO: Checking APIGroup: metrics.k8s.io
Nov  5 12:12:14.143: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Nov  5 12:12:14.143: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Nov  5 12:12:14.144: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Nov  5 12:12:14.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-2389" for this suite. 11/05/22 12:12:14.148
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":78,"skipped":1426,"failed":0}
------------------------------
• [0.647 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:12:13.508
    Nov  5 12:12:13.508: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename discovery 11/05/22 12:12:13.508
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:13.533
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:13.537
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 11/05/22 12:12:13.543
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Nov  5 12:12:14.115: INFO: Checking APIGroup: apiregistration.k8s.io
    Nov  5 12:12:14.116: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Nov  5 12:12:14.116: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Nov  5 12:12:14.116: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Nov  5 12:12:14.116: INFO: Checking APIGroup: apps
    Nov  5 12:12:14.118: INFO: PreferredVersion.GroupVersion: apps/v1
    Nov  5 12:12:14.118: INFO: Versions found [{apps/v1 v1}]
    Nov  5 12:12:14.118: INFO: apps/v1 matches apps/v1
    Nov  5 12:12:14.118: INFO: Checking APIGroup: events.k8s.io
    Nov  5 12:12:14.119: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Nov  5 12:12:14.119: INFO: Versions found [{events.k8s.io/v1 v1}]
    Nov  5 12:12:14.119: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Nov  5 12:12:14.119: INFO: Checking APIGroup: authentication.k8s.io
    Nov  5 12:12:14.120: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Nov  5 12:12:14.120: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Nov  5 12:12:14.120: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Nov  5 12:12:14.120: INFO: Checking APIGroup: authorization.k8s.io
    Nov  5 12:12:14.122: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Nov  5 12:12:14.122: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Nov  5 12:12:14.122: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Nov  5 12:12:14.122: INFO: Checking APIGroup: autoscaling
    Nov  5 12:12:14.123: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Nov  5 12:12:14.123: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Nov  5 12:12:14.123: INFO: autoscaling/v2 matches autoscaling/v2
    Nov  5 12:12:14.123: INFO: Checking APIGroup: batch
    Nov  5 12:12:14.125: INFO: PreferredVersion.GroupVersion: batch/v1
    Nov  5 12:12:14.125: INFO: Versions found [{batch/v1 v1}]
    Nov  5 12:12:14.125: INFO: batch/v1 matches batch/v1
    Nov  5 12:12:14.125: INFO: Checking APIGroup: certificates.k8s.io
    Nov  5 12:12:14.126: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Nov  5 12:12:14.126: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Nov  5 12:12:14.126: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Nov  5 12:12:14.126: INFO: Checking APIGroup: networking.k8s.io
    Nov  5 12:12:14.128: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Nov  5 12:12:14.128: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Nov  5 12:12:14.128: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Nov  5 12:12:14.128: INFO: Checking APIGroup: policy
    Nov  5 12:12:14.129: INFO: PreferredVersion.GroupVersion: policy/v1
    Nov  5 12:12:14.129: INFO: Versions found [{policy/v1 v1}]
    Nov  5 12:12:14.129: INFO: policy/v1 matches policy/v1
    Nov  5 12:12:14.129: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Nov  5 12:12:14.131: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Nov  5 12:12:14.131: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Nov  5 12:12:14.131: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Nov  5 12:12:14.131: INFO: Checking APIGroup: storage.k8s.io
    Nov  5 12:12:14.132: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Nov  5 12:12:14.132: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Nov  5 12:12:14.132: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Nov  5 12:12:14.132: INFO: Checking APIGroup: admissionregistration.k8s.io
    Nov  5 12:12:14.133: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Nov  5 12:12:14.133: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Nov  5 12:12:14.133: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Nov  5 12:12:14.133: INFO: Checking APIGroup: apiextensions.k8s.io
    Nov  5 12:12:14.135: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Nov  5 12:12:14.135: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Nov  5 12:12:14.135: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Nov  5 12:12:14.135: INFO: Checking APIGroup: scheduling.k8s.io
    Nov  5 12:12:14.136: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Nov  5 12:12:14.136: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Nov  5 12:12:14.136: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Nov  5 12:12:14.136: INFO: Checking APIGroup: coordination.k8s.io
    Nov  5 12:12:14.138: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Nov  5 12:12:14.138: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Nov  5 12:12:14.138: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Nov  5 12:12:14.138: INFO: Checking APIGroup: node.k8s.io
    Nov  5 12:12:14.139: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Nov  5 12:12:14.139: INFO: Versions found [{node.k8s.io/v1 v1}]
    Nov  5 12:12:14.139: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Nov  5 12:12:14.139: INFO: Checking APIGroup: discovery.k8s.io
    Nov  5 12:12:14.141: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Nov  5 12:12:14.141: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Nov  5 12:12:14.141: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Nov  5 12:12:14.141: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Nov  5 12:12:14.142: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Nov  5 12:12:14.142: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Nov  5 12:12:14.142: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Nov  5 12:12:14.142: INFO: Checking APIGroup: metrics.k8s.io
    Nov  5 12:12:14.143: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Nov  5 12:12:14.143: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Nov  5 12:12:14.144: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Nov  5 12:12:14.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-2389" for this suite. 11/05/22 12:12:14.148
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:12:14.156
Nov  5 12:12:14.157: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:12:14.157
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:14.17
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:14.174
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-215971c1-e604-4700-8a43-cfe099a0a973 11/05/22 12:12:14.178
STEP: Creating a pod to test consume configMaps 11/05/22 12:12:14.182
Nov  5 12:12:14.192: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c" in namespace "projected-8119" to be "Succeeded or Failed"
Nov  5 12:12:14.196: INFO: Pod "pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.306475ms
Nov  5 12:12:16.200: INFO: Pod "pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008770009s
Nov  5 12:12:18.201: INFO: Pod "pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009233171s
STEP: Saw pod success 11/05/22 12:12:18.201
Nov  5 12:12:18.201: INFO: Pod "pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c" satisfied condition "Succeeded or Failed"
Nov  5 12:12:18.205: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:12:18.211
Nov  5 12:12:18.221: INFO: Waiting for pod pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c to disappear
Nov  5 12:12:18.225: INFO: Pod pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov  5 12:12:18.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8119" for this suite. 11/05/22 12:12:18.228
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":79,"skipped":1455,"failed":0}
------------------------------
• [4.078 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:12:14.156
    Nov  5 12:12:14.157: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:12:14.157
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:14.17
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:14.174
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-215971c1-e604-4700-8a43-cfe099a0a973 11/05/22 12:12:14.178
    STEP: Creating a pod to test consume configMaps 11/05/22 12:12:14.182
    Nov  5 12:12:14.192: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c" in namespace "projected-8119" to be "Succeeded or Failed"
    Nov  5 12:12:14.196: INFO: Pod "pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.306475ms
    Nov  5 12:12:16.200: INFO: Pod "pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008770009s
    Nov  5 12:12:18.201: INFO: Pod "pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009233171s
    STEP: Saw pod success 11/05/22 12:12:18.201
    Nov  5 12:12:18.201: INFO: Pod "pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c" satisfied condition "Succeeded or Failed"
    Nov  5 12:12:18.205: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:12:18.211
    Nov  5 12:12:18.221: INFO: Waiting for pod pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c to disappear
    Nov  5 12:12:18.225: INFO: Pod pod-projected-configmaps-c8fe877e-8fa8-4abc-beaa-12595aee994c no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov  5 12:12:18.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8119" for this suite. 11/05/22 12:12:18.228
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:12:18.236
Nov  5 12:12:18.236: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename init-container 11/05/22 12:12:18.236
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:18.249
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:18.253
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 11/05/22 12:12:18.257
Nov  5 12:12:18.257: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov  5 12:12:22.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4424" for this suite. 11/05/22 12:12:22.857
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":80,"skipped":1456,"failed":0}
------------------------------
• [4.628 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:12:18.236
    Nov  5 12:12:18.236: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename init-container 11/05/22 12:12:18.236
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:18.249
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:18.253
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 11/05/22 12:12:18.257
    Nov  5 12:12:18.257: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov  5 12:12:22.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-4424" for this suite. 11/05/22 12:12:22.857
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:12:22.864
Nov  5 12:12:22.864: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename subpath 11/05/22 12:12:22.865
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:22.885
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:22.89
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/05/22 12:12:22.894
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-klqz 11/05/22 12:12:22.906
STEP: Creating a pod to test atomic-volume-subpath 11/05/22 12:12:22.906
Nov  5 12:12:22.914: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-klqz" in namespace "subpath-5986" to be "Succeeded or Failed"
Nov  5 12:12:22.918: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Pending", Reason="", readiness=false. Elapsed: 3.442808ms
Nov  5 12:12:24.923: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 2.008790658s
Nov  5 12:12:26.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 4.007314884s
Nov  5 12:12:28.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 6.007400703s
Nov  5 12:12:30.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 8.008046853s
Nov  5 12:12:32.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 10.007386053s
Nov  5 12:12:34.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 12.007923811s
Nov  5 12:12:36.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 14.007323179s
Nov  5 12:12:38.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 16.007749392s
Nov  5 12:12:40.923: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 18.008449839s
Nov  5 12:12:42.924: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 20.009284159s
Nov  5 12:12:44.923: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=false. Elapsed: 22.009082191s
Nov  5 12:12:46.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.007619007s
STEP: Saw pod success 11/05/22 12:12:46.922
Nov  5 12:12:46.922: INFO: Pod "pod-subpath-test-projected-klqz" satisfied condition "Succeeded or Failed"
Nov  5 12:12:46.926: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-subpath-test-projected-klqz container test-container-subpath-projected-klqz: <nil>
STEP: delete the pod 11/05/22 12:12:46.933
Nov  5 12:12:46.943: INFO: Waiting for pod pod-subpath-test-projected-klqz to disappear
Nov  5 12:12:46.947: INFO: Pod pod-subpath-test-projected-klqz no longer exists
STEP: Deleting pod pod-subpath-test-projected-klqz 11/05/22 12:12:46.947
Nov  5 12:12:46.947: INFO: Deleting pod "pod-subpath-test-projected-klqz" in namespace "subpath-5986"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov  5 12:12:46.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5986" for this suite. 11/05/22 12:12:46.954
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":81,"skipped":1457,"failed":0}
------------------------------
• [SLOW TEST] [24.095 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:12:22.864
    Nov  5 12:12:22.864: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename subpath 11/05/22 12:12:22.865
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:22.885
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:22.89
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/05/22 12:12:22.894
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-klqz 11/05/22 12:12:22.906
    STEP: Creating a pod to test atomic-volume-subpath 11/05/22 12:12:22.906
    Nov  5 12:12:22.914: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-klqz" in namespace "subpath-5986" to be "Succeeded or Failed"
    Nov  5 12:12:22.918: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Pending", Reason="", readiness=false. Elapsed: 3.442808ms
    Nov  5 12:12:24.923: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 2.008790658s
    Nov  5 12:12:26.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 4.007314884s
    Nov  5 12:12:28.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 6.007400703s
    Nov  5 12:12:30.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 8.008046853s
    Nov  5 12:12:32.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 10.007386053s
    Nov  5 12:12:34.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 12.007923811s
    Nov  5 12:12:36.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 14.007323179s
    Nov  5 12:12:38.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 16.007749392s
    Nov  5 12:12:40.923: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 18.008449839s
    Nov  5 12:12:42.924: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=true. Elapsed: 20.009284159s
    Nov  5 12:12:44.923: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Running", Reason="", readiness=false. Elapsed: 22.009082191s
    Nov  5 12:12:46.922: INFO: Pod "pod-subpath-test-projected-klqz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.007619007s
    STEP: Saw pod success 11/05/22 12:12:46.922
    Nov  5 12:12:46.922: INFO: Pod "pod-subpath-test-projected-klqz" satisfied condition "Succeeded or Failed"
    Nov  5 12:12:46.926: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-subpath-test-projected-klqz container test-container-subpath-projected-klqz: <nil>
    STEP: delete the pod 11/05/22 12:12:46.933
    Nov  5 12:12:46.943: INFO: Waiting for pod pod-subpath-test-projected-klqz to disappear
    Nov  5 12:12:46.947: INFO: Pod pod-subpath-test-projected-klqz no longer exists
    STEP: Deleting pod pod-subpath-test-projected-klqz 11/05/22 12:12:46.947
    Nov  5 12:12:46.947: INFO: Deleting pod "pod-subpath-test-projected-klqz" in namespace "subpath-5986"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov  5 12:12:46.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5986" for this suite. 11/05/22 12:12:46.954
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:12:46.96
Nov  5 12:12:46.960: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename podtemplate 11/05/22 12:12:46.961
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:47.024
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:47.028
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 11/05/22 12:12:47.032
Nov  5 12:12:47.037: INFO: created test-podtemplate-1
Nov  5 12:12:47.042: INFO: created test-podtemplate-2
Nov  5 12:12:47.046: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 11/05/22 12:12:47.046
STEP: delete collection of pod templates 11/05/22 12:12:47.05
Nov  5 12:12:47.050: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 11/05/22 12:12:47.068
Nov  5 12:12:47.068: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov  5 12:12:47.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-8225" for this suite. 11/05/22 12:12:47.076
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":82,"skipped":1462,"failed":0}
------------------------------
• [0.123 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:12:46.96
    Nov  5 12:12:46.960: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename podtemplate 11/05/22 12:12:46.961
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:47.024
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:47.028
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 11/05/22 12:12:47.032
    Nov  5 12:12:47.037: INFO: created test-podtemplate-1
    Nov  5 12:12:47.042: INFO: created test-podtemplate-2
    Nov  5 12:12:47.046: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 11/05/22 12:12:47.046
    STEP: delete collection of pod templates 11/05/22 12:12:47.05
    Nov  5 12:12:47.050: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 11/05/22 12:12:47.068
    Nov  5 12:12:47.068: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov  5 12:12:47.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-8225" for this suite. 11/05/22 12:12:47.076
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:12:47.083
Nov  5 12:12:47.083: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename daemonsets 11/05/22 12:12:47.084
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:47.102
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:47.106
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 11/05/22 12:12:47.132
STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 12:12:47.137
Nov  5 12:12:47.141: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:12:47.141: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:12:47.145: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:12:47.145: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:12:48.149: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:12:48.150: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:12:48.153: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:12:48.153: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:12:49.150: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:12:49.150: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:12:49.154: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov  5 12:12:49.154: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Getting /status 11/05/22 12:12:49.157
Nov  5 12:12:49.161: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 11/05/22 12:12:49.161
Nov  5 12:12:49.170: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 11/05/22 12:12:49.17
Nov  5 12:12:49.172: INFO: Observed &DaemonSet event: ADDED
Nov  5 12:12:49.172: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.173: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.173: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.173: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.173: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.173: INFO: Found daemon set daemon-set in namespace daemonsets-800 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov  5 12:12:49.173: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 11/05/22 12:12:49.173
STEP: watching for the daemon set status to be patched 11/05/22 12:12:49.181
Nov  5 12:12:49.183: INFO: Observed &DaemonSet event: ADDED
Nov  5 12:12:49.183: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.183: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.183: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.183: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.184: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.184: INFO: Observed daemon set daemon-set in namespace daemonsets-800 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov  5 12:12:49.184: INFO: Observed &DaemonSet event: MODIFIED
Nov  5 12:12:49.184: INFO: Found daemon set daemon-set in namespace daemonsets-800 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Nov  5 12:12:49.184: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/05/22 12:12:49.188
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-800, will wait for the garbage collector to delete the pods 11/05/22 12:12:49.188
Nov  5 12:12:49.248: INFO: Deleting DaemonSet.extensions daemon-set took: 5.942922ms
Nov  5 12:12:49.349: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.21166ms
Nov  5 12:12:51.954: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:12:51.954: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov  5 12:12:51.958: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8654"},"items":null}

Nov  5 12:12:51.961: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8654"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:12:51.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-800" for this suite. 11/05/22 12:12:51.986
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":83,"skipped":1463,"failed":0}
------------------------------
• [4.909 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:12:47.083
    Nov  5 12:12:47.083: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename daemonsets 11/05/22 12:12:47.084
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:47.102
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:47.106
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 11/05/22 12:12:47.132
    STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 12:12:47.137
    Nov  5 12:12:47.141: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:12:47.141: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:12:47.145: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:12:47.145: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:12:48.149: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:12:48.150: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:12:48.153: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:12:48.153: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:12:49.150: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:12:49.150: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:12:49.154: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov  5 12:12:49.154: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Getting /status 11/05/22 12:12:49.157
    Nov  5 12:12:49.161: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 11/05/22 12:12:49.161
    Nov  5 12:12:49.170: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 11/05/22 12:12:49.17
    Nov  5 12:12:49.172: INFO: Observed &DaemonSet event: ADDED
    Nov  5 12:12:49.172: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.173: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.173: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.173: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.173: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.173: INFO: Found daemon set daemon-set in namespace daemonsets-800 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov  5 12:12:49.173: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 11/05/22 12:12:49.173
    STEP: watching for the daemon set status to be patched 11/05/22 12:12:49.181
    Nov  5 12:12:49.183: INFO: Observed &DaemonSet event: ADDED
    Nov  5 12:12:49.183: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.183: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.183: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.183: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.184: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.184: INFO: Observed daemon set daemon-set in namespace daemonsets-800 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov  5 12:12:49.184: INFO: Observed &DaemonSet event: MODIFIED
    Nov  5 12:12:49.184: INFO: Found daemon set daemon-set in namespace daemonsets-800 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Nov  5 12:12:49.184: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/05/22 12:12:49.188
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-800, will wait for the garbage collector to delete the pods 11/05/22 12:12:49.188
    Nov  5 12:12:49.248: INFO: Deleting DaemonSet.extensions daemon-set took: 5.942922ms
    Nov  5 12:12:49.349: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.21166ms
    Nov  5 12:12:51.954: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:12:51.954: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov  5 12:12:51.958: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"8654"},"items":null}

    Nov  5 12:12:51.961: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"8654"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:12:51.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-800" for this suite. 11/05/22 12:12:51.986
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:12:51.994
Nov  5 12:12:51.994: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename svcaccounts 11/05/22 12:12:51.995
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:52.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:52.014
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Nov  5 12:12:52.021: INFO: Got root ca configmap in namespace "svcaccounts-536"
Nov  5 12:12:52.028: INFO: Deleted root ca configmap in namespace "svcaccounts-536"
STEP: waiting for a new root ca configmap created 11/05/22 12:12:52.528
Nov  5 12:12:52.532: INFO: Recreated root ca configmap in namespace "svcaccounts-536"
Nov  5 12:12:52.538: INFO: Updated root ca configmap in namespace "svcaccounts-536"
STEP: waiting for the root ca configmap reconciled 11/05/22 12:12:53.039
Nov  5 12:12:53.043: INFO: Reconciled root ca configmap in namespace "svcaccounts-536"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov  5 12:12:53.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-536" for this suite. 11/05/22 12:12:53.047
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":84,"skipped":1480,"failed":0}
------------------------------
• [1.060 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:12:51.994
    Nov  5 12:12:51.994: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename svcaccounts 11/05/22 12:12:51.995
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:52.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:52.014
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Nov  5 12:12:52.021: INFO: Got root ca configmap in namespace "svcaccounts-536"
    Nov  5 12:12:52.028: INFO: Deleted root ca configmap in namespace "svcaccounts-536"
    STEP: waiting for a new root ca configmap created 11/05/22 12:12:52.528
    Nov  5 12:12:52.532: INFO: Recreated root ca configmap in namespace "svcaccounts-536"
    Nov  5 12:12:52.538: INFO: Updated root ca configmap in namespace "svcaccounts-536"
    STEP: waiting for the root ca configmap reconciled 11/05/22 12:12:53.039
    Nov  5 12:12:53.043: INFO: Reconciled root ca configmap in namespace "svcaccounts-536"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov  5 12:12:53.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-536" for this suite. 11/05/22 12:12:53.047
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:12:53.054
Nov  5 12:12:53.054: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 12:12:53.055
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:53.071
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:53.079
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 11/05/22 12:12:53.083
STEP: Getting a ResourceQuota 11/05/22 12:12:53.088
STEP: Updating a ResourceQuota 11/05/22 12:12:53.093
STEP: Verifying a ResourceQuota was modified 11/05/22 12:12:53.099
STEP: Deleting a ResourceQuota 11/05/22 12:12:53.102
STEP: Verifying the deleted ResourceQuota 11/05/22 12:12:53.109
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 12:12:53.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9601" for this suite. 11/05/22 12:12:53.115
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":85,"skipped":1487,"failed":0}
------------------------------
• [0.067 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:12:53.054
    Nov  5 12:12:53.054: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 12:12:53.055
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:53.071
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:53.079
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 11/05/22 12:12:53.083
    STEP: Getting a ResourceQuota 11/05/22 12:12:53.088
    STEP: Updating a ResourceQuota 11/05/22 12:12:53.093
    STEP: Verifying a ResourceQuota was modified 11/05/22 12:12:53.099
    STEP: Deleting a ResourceQuota 11/05/22 12:12:53.102
    STEP: Verifying the deleted ResourceQuota 11/05/22 12:12:53.109
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 12:12:53.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-9601" for this suite. 11/05/22 12:12:53.115
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:12:53.125
Nov  5 12:12:53.126: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pod-network-test 11/05/22 12:12:53.126
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:53.14
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:53.143
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-7054 11/05/22 12:12:53.147
STEP: creating a selector 11/05/22 12:12:53.147
STEP: Creating the service pods in kubernetes 11/05/22 12:12:53.147
Nov  5 12:12:53.147: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov  5 12:12:53.179: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7054" to be "running and ready"
Nov  5 12:12:53.183: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.69451ms
Nov  5 12:12:53.183: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:12:55.188: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.008542581s
Nov  5 12:12:55.188: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 12:12:57.187: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.007928129s
Nov  5 12:12:57.187: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 12:12:59.188: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.009072058s
Nov  5 12:12:59.188: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 12:13:01.188: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.008955822s
Nov  5 12:13:01.188: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 12:13:03.188: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.009092897s
Nov  5 12:13:03.188: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 12:13:05.188: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.008427825s
Nov  5 12:13:05.188: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov  5 12:13:05.188: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov  5 12:13:05.191: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7054" to be "running and ready"
Nov  5 12:13:05.195: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.662311ms
Nov  5 12:13:05.195: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov  5 12:13:05.195: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov  5 12:13:05.198: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7054" to be "running and ready"
Nov  5 12:13:05.201: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.263879ms
Nov  5 12:13:05.201: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov  5 12:13:05.201: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/05/22 12:13:05.205
Nov  5 12:13:05.211: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7054" to be "running"
Nov  5 12:13:05.216: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.549585ms
Nov  5 12:13:07.220: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008990987s
Nov  5 12:13:07.220: INFO: Pod "test-container-pod" satisfied condition "running"
Nov  5 12:13:07.224: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov  5 12:13:07.224: INFO: Breadth first check of 192.168.206.142 on host 172.31.0.255...
Nov  5 12:13:07.227: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.143:9080/dial?request=hostname&protocol=http&host=192.168.206.142&port=8083&tries=1'] Namespace:pod-network-test-7054 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 12:13:07.227: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 12:13:07.228: INFO: ExecWithOptions: Clientset creation
Nov  5 12:13:07.228: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7054/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.143%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.206.142%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov  5 12:13:07.307: INFO: Waiting for responses: map[]
Nov  5 12:13:07.307: INFO: reached 192.168.206.142 after 0/1 tries
Nov  5 12:13:07.307: INFO: Breadth first check of 192.168.242.15 on host 172.31.27.199...
Nov  5 12:13:07.310: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.143:9080/dial?request=hostname&protocol=http&host=192.168.242.15&port=8083&tries=1'] Namespace:pod-network-test-7054 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 12:13:07.310: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 12:13:07.311: INFO: ExecWithOptions: Clientset creation
Nov  5 12:13:07.311: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7054/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.143%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.242.15%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov  5 12:13:07.372: INFO: Waiting for responses: map[]
Nov  5 12:13:07.373: INFO: reached 192.168.242.15 after 0/1 tries
Nov  5 12:13:07.373: INFO: Breadth first check of 192.168.90.93 on host 172.31.41.19...
Nov  5 12:13:07.377: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.143:9080/dial?request=hostname&protocol=http&host=192.168.90.93&port=8083&tries=1'] Namespace:pod-network-test-7054 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 12:13:07.377: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 12:13:07.377: INFO: ExecWithOptions: Clientset creation
Nov  5 12:13:07.377: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7054/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.143%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.90.93%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov  5 12:13:07.450: INFO: Waiting for responses: map[]
Nov  5 12:13:07.451: INFO: reached 192.168.90.93 after 0/1 tries
Nov  5 12:13:07.451: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov  5 12:13:07.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7054" for this suite. 11/05/22 12:13:07.455
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":86,"skipped":1526,"failed":0}
------------------------------
• [SLOW TEST] [14.337 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:12:53.125
    Nov  5 12:12:53.126: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pod-network-test 11/05/22 12:12:53.126
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:12:53.14
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:12:53.143
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-7054 11/05/22 12:12:53.147
    STEP: creating a selector 11/05/22 12:12:53.147
    STEP: Creating the service pods in kubernetes 11/05/22 12:12:53.147
    Nov  5 12:12:53.147: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov  5 12:12:53.179: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-7054" to be "running and ready"
    Nov  5 12:12:53.183: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.69451ms
    Nov  5 12:12:53.183: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:12:55.188: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.008542581s
    Nov  5 12:12:55.188: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 12:12:57.187: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.007928129s
    Nov  5 12:12:57.187: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 12:12:59.188: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.009072058s
    Nov  5 12:12:59.188: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 12:13:01.188: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.008955822s
    Nov  5 12:13:01.188: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 12:13:03.188: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.009092897s
    Nov  5 12:13:03.188: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 12:13:05.188: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.008427825s
    Nov  5 12:13:05.188: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov  5 12:13:05.188: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov  5 12:13:05.191: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-7054" to be "running and ready"
    Nov  5 12:13:05.195: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.662311ms
    Nov  5 12:13:05.195: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov  5 12:13:05.195: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov  5 12:13:05.198: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-7054" to be "running and ready"
    Nov  5 12:13:05.201: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.263879ms
    Nov  5 12:13:05.201: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov  5 12:13:05.201: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/05/22 12:13:05.205
    Nov  5 12:13:05.211: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-7054" to be "running"
    Nov  5 12:13:05.216: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.549585ms
    Nov  5 12:13:07.220: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008990987s
    Nov  5 12:13:07.220: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov  5 12:13:07.224: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov  5 12:13:07.224: INFO: Breadth first check of 192.168.206.142 on host 172.31.0.255...
    Nov  5 12:13:07.227: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.143:9080/dial?request=hostname&protocol=http&host=192.168.206.142&port=8083&tries=1'] Namespace:pod-network-test-7054 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 12:13:07.227: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 12:13:07.228: INFO: ExecWithOptions: Clientset creation
    Nov  5 12:13:07.228: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7054/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.143%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.206.142%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov  5 12:13:07.307: INFO: Waiting for responses: map[]
    Nov  5 12:13:07.307: INFO: reached 192.168.206.142 after 0/1 tries
    Nov  5 12:13:07.307: INFO: Breadth first check of 192.168.242.15 on host 172.31.27.199...
    Nov  5 12:13:07.310: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.143:9080/dial?request=hostname&protocol=http&host=192.168.242.15&port=8083&tries=1'] Namespace:pod-network-test-7054 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 12:13:07.310: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 12:13:07.311: INFO: ExecWithOptions: Clientset creation
    Nov  5 12:13:07.311: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7054/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.143%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.242.15%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov  5 12:13:07.372: INFO: Waiting for responses: map[]
    Nov  5 12:13:07.373: INFO: reached 192.168.242.15 after 0/1 tries
    Nov  5 12:13:07.373: INFO: Breadth first check of 192.168.90.93 on host 172.31.41.19...
    Nov  5 12:13:07.377: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.143:9080/dial?request=hostname&protocol=http&host=192.168.90.93&port=8083&tries=1'] Namespace:pod-network-test-7054 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 12:13:07.377: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 12:13:07.377: INFO: ExecWithOptions: Clientset creation
    Nov  5 12:13:07.377: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-7054/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.143%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D192.168.90.93%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov  5 12:13:07.450: INFO: Waiting for responses: map[]
    Nov  5 12:13:07.451: INFO: reached 192.168.90.93 after 0/1 tries
    Nov  5 12:13:07.451: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov  5 12:13:07.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-7054" for this suite. 11/05/22 12:13:07.455
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:13:07.464
Nov  5 12:13:07.464: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 12:13:07.465
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:13:07.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:13:07.488
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 12:13:07.508
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:13:07.901
STEP: Deploying the webhook pod 11/05/22 12:13:07.91
STEP: Wait for the deployment to be ready 11/05/22 12:13:07.924
Nov  5 12:13:07.935: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 12:13:09.946
STEP: Verifying the service has paired with the endpoint 11/05/22 12:13:09.956
Nov  5 12:13:10.956: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 11/05/22 12:13:10.96
STEP: Updating a mutating webhook configuration's rules to not include the create operation 11/05/22 12:13:10.979
STEP: Creating a configMap that should not be mutated 11/05/22 12:13:10.986
STEP: Patching a mutating webhook configuration's rules to include the create operation 11/05/22 12:13:10.997
STEP: Creating a configMap that should be mutated 11/05/22 12:13:11.004
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:13:11.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2984" for this suite. 11/05/22 12:13:11.03
STEP: Destroying namespace "webhook-2984-markers" for this suite. 11/05/22 12:13:11.037
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":87,"skipped":1548,"failed":0}
------------------------------
• [3.647 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:13:07.464
    Nov  5 12:13:07.464: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 12:13:07.465
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:13:07.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:13:07.488
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 12:13:07.508
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:13:07.901
    STEP: Deploying the webhook pod 11/05/22 12:13:07.91
    STEP: Wait for the deployment to be ready 11/05/22 12:13:07.924
    Nov  5 12:13:07.935: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 12:13:09.946
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:13:09.956
    Nov  5 12:13:10.956: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 11/05/22 12:13:10.96
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 11/05/22 12:13:10.979
    STEP: Creating a configMap that should not be mutated 11/05/22 12:13:10.986
    STEP: Patching a mutating webhook configuration's rules to include the create operation 11/05/22 12:13:10.997
    STEP: Creating a configMap that should be mutated 11/05/22 12:13:11.004
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:13:11.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2984" for this suite. 11/05/22 12:13:11.03
    STEP: Destroying namespace "webhook-2984-markers" for this suite. 11/05/22 12:13:11.037
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:13:11.111
Nov  5 12:13:11.111: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir-wrapper 11/05/22 12:13:11.112
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:13:11.127
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:13:11.132
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 11/05/22 12:13:11.136
STEP: Creating RC which spawns configmap-volume pods 11/05/22 12:13:11.406
Nov  5 12:13:11.538: INFO: Pod name wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/05/22 12:13:11.538
Nov  5 12:13:11.538: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:11.549: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.638625ms
Nov  5 12:13:13.554: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015470741s
Nov  5 12:13:15.554: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016075957s
Nov  5 12:13:17.554: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016051521s
Nov  5 12:13:19.554: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01578913s
Nov  5 12:13:21.553: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.015004329s
Nov  5 12:13:23.554: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016308939s
Nov  5 12:13:25.555: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016547279s
Nov  5 12:13:27.555: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Running", Reason="", readiness=true. Elapsed: 16.017121492s
Nov  5 12:13:27.555: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8" satisfied condition "running"
Nov  5 12:13:27.555: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-h48lq" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:27.559: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-h48lq": Phase="Running", Reason="", readiness=true. Elapsed: 4.014158ms
Nov  5 12:13:27.559: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-h48lq" satisfied condition "running"
Nov  5 12:13:27.559: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-l75c7" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:27.563: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-l75c7": Phase="Running", Reason="", readiness=true. Elapsed: 3.522492ms
Nov  5 12:13:27.563: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-l75c7" satisfied condition "running"
Nov  5 12:13:27.563: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-rpqk4" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:27.566: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-rpqk4": Phase="Running", Reason="", readiness=true. Elapsed: 3.52938ms
Nov  5 12:13:27.566: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-rpqk4" satisfied condition "running"
Nov  5 12:13:27.566: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-stl95" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:27.570: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-stl95": Phase="Running", Reason="", readiness=true. Elapsed: 3.854838ms
Nov  5 12:13:27.570: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-stl95" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb in namespace emptydir-wrapper-3812, will wait for the garbage collector to delete the pods 11/05/22 12:13:27.57
Nov  5 12:13:27.632: INFO: Deleting ReplicationController wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb took: 6.993759ms
Nov  5 12:13:27.733: INFO: Terminating ReplicationController wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb pods took: 101.082674ms
STEP: Creating RC which spawns configmap-volume pods 11/05/22 12:13:30.238
Nov  5 12:13:30.251: INFO: Pod name wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5: Found 0 pods out of 5
Nov  5 12:13:35.257: INFO: Pod name wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/05/22 12:13:35.257
Nov  5 12:13:35.257: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:35.261: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.963203ms
Nov  5 12:13:37.266: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009074797s
Nov  5 12:13:39.267: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009484208s
Nov  5 12:13:41.266: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008564444s
Nov  5 12:13:43.265: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008019393s
Nov  5 12:13:45.266: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Running", Reason="", readiness=true. Elapsed: 10.008197465s
Nov  5 12:13:45.266: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf" satisfied condition "running"
Nov  5 12:13:45.266: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-bg4d2" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:45.269: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-bg4d2": Phase="Running", Reason="", readiness=true. Elapsed: 3.800416ms
Nov  5 12:13:45.269: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-bg4d2" satisfied condition "running"
Nov  5 12:13:45.269: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-mvkt2" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:45.273: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-mvkt2": Phase="Running", Reason="", readiness=true. Elapsed: 3.973002ms
Nov  5 12:13:45.273: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-mvkt2" satisfied condition "running"
Nov  5 12:13:45.273: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-qghh8" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:45.277: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-qghh8": Phase="Running", Reason="", readiness=true. Elapsed: 3.364869ms
Nov  5 12:13:45.277: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-qghh8" satisfied condition "running"
Nov  5 12:13:45.277: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-z7j2r" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:45.280: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-z7j2r": Phase="Running", Reason="", readiness=true. Elapsed: 3.470635ms
Nov  5 12:13:45.280: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-z7j2r" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5 in namespace emptydir-wrapper-3812, will wait for the garbage collector to delete the pods 11/05/22 12:13:45.28
Nov  5 12:13:45.342: INFO: Deleting ReplicationController wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5 took: 6.830129ms
Nov  5 12:13:45.442: INFO: Terminating ReplicationController wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5 pods took: 100.599669ms
STEP: Creating RC which spawns configmap-volume pods 11/05/22 12:13:49.648
Nov  5 12:13:49.670: INFO: Pod name wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f: Found 0 pods out of 5
Nov  5 12:13:54.679: INFO: Pod name wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f: Found 5 pods out of 5
STEP: Ensuring each pod is running 11/05/22 12:13:54.679
Nov  5 12:13:54.679: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:13:54.682: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 3.68312ms
Nov  5 12:13:56.688: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008866233s
Nov  5 12:13:58.687: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008679199s
Nov  5 12:14:00.688: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008819531s
Nov  5 12:14:02.688: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009212356s
Nov  5 12:14:04.687: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 10.008230445s
Nov  5 12:14:06.688: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Running", Reason="", readiness=true. Elapsed: 12.008975659s
Nov  5 12:14:06.688: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl" satisfied condition "running"
Nov  5 12:14:06.688: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-94vvm" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:14:06.691: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-94vvm": Phase="Running", Reason="", readiness=true. Elapsed: 3.507472ms
Nov  5 12:14:06.691: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-94vvm" satisfied condition "running"
Nov  5 12:14:06.691: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-f5ht7" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:14:06.695: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-f5ht7": Phase="Running", Reason="", readiness=true. Elapsed: 3.497435ms
Nov  5 12:14:06.695: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-f5ht7" satisfied condition "running"
Nov  5 12:14:06.695: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-mfpxw" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:14:06.699: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-mfpxw": Phase="Running", Reason="", readiness=true. Elapsed: 4.030995ms
Nov  5 12:14:06.699: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-mfpxw" satisfied condition "running"
Nov  5 12:14:06.699: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-wg4t5" in namespace "emptydir-wrapper-3812" to be "running"
Nov  5 12:14:06.702: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-wg4t5": Phase="Running", Reason="", readiness=true. Elapsed: 3.359313ms
Nov  5 12:14:06.702: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-wg4t5" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f in namespace emptydir-wrapper-3812, will wait for the garbage collector to delete the pods 11/05/22 12:14:06.702
Nov  5 12:14:06.765: INFO: Deleting ReplicationController wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f took: 7.931669ms
Nov  5 12:14:06.865: INFO: Terminating ReplicationController wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f pods took: 100.974989ms
STEP: Cleaning up the configMaps 11/05/22 12:14:09.766
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Nov  5 12:14:10.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3812" for this suite. 11/05/22 12:14:10.156
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":88,"skipped":1551,"failed":0}
------------------------------
• [SLOW TEST] [59.052 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:13:11.111
    Nov  5 12:13:11.111: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir-wrapper 11/05/22 12:13:11.112
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:13:11.127
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:13:11.132
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 11/05/22 12:13:11.136
    STEP: Creating RC which spawns configmap-volume pods 11/05/22 12:13:11.406
    Nov  5 12:13:11.538: INFO: Pod name wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/05/22 12:13:11.538
    Nov  5 12:13:11.538: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:11.549: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.638625ms
    Nov  5 12:13:13.554: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015470741s
    Nov  5 12:13:15.554: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016075957s
    Nov  5 12:13:17.554: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016051521s
    Nov  5 12:13:19.554: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01578913s
    Nov  5 12:13:21.553: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.015004329s
    Nov  5 12:13:23.554: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016308939s
    Nov  5 12:13:25.555: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016547279s
    Nov  5 12:13:27.555: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8": Phase="Running", Reason="", readiness=true. Elapsed: 16.017121492s
    Nov  5 12:13:27.555: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-bdxg8" satisfied condition "running"
    Nov  5 12:13:27.555: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-h48lq" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:27.559: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-h48lq": Phase="Running", Reason="", readiness=true. Elapsed: 4.014158ms
    Nov  5 12:13:27.559: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-h48lq" satisfied condition "running"
    Nov  5 12:13:27.559: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-l75c7" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:27.563: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-l75c7": Phase="Running", Reason="", readiness=true. Elapsed: 3.522492ms
    Nov  5 12:13:27.563: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-l75c7" satisfied condition "running"
    Nov  5 12:13:27.563: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-rpqk4" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:27.566: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-rpqk4": Phase="Running", Reason="", readiness=true. Elapsed: 3.52938ms
    Nov  5 12:13:27.566: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-rpqk4" satisfied condition "running"
    Nov  5 12:13:27.566: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-stl95" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:27.570: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-stl95": Phase="Running", Reason="", readiness=true. Elapsed: 3.854838ms
    Nov  5 12:13:27.570: INFO: Pod "wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb-stl95" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb in namespace emptydir-wrapper-3812, will wait for the garbage collector to delete the pods 11/05/22 12:13:27.57
    Nov  5 12:13:27.632: INFO: Deleting ReplicationController wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb took: 6.993759ms
    Nov  5 12:13:27.733: INFO: Terminating ReplicationController wrapped-volume-race-92ba636e-e1d6-417b-96a1-ce155dbd7cdb pods took: 101.082674ms
    STEP: Creating RC which spawns configmap-volume pods 11/05/22 12:13:30.238
    Nov  5 12:13:30.251: INFO: Pod name wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5: Found 0 pods out of 5
    Nov  5 12:13:35.257: INFO: Pod name wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/05/22 12:13:35.257
    Nov  5 12:13:35.257: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:35.261: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.963203ms
    Nov  5 12:13:37.266: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009074797s
    Nov  5 12:13:39.267: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009484208s
    Nov  5 12:13:41.266: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008564444s
    Nov  5 12:13:43.265: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.008019393s
    Nov  5 12:13:45.266: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf": Phase="Running", Reason="", readiness=true. Elapsed: 10.008197465s
    Nov  5 12:13:45.266: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-9rcqf" satisfied condition "running"
    Nov  5 12:13:45.266: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-bg4d2" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:45.269: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-bg4d2": Phase="Running", Reason="", readiness=true. Elapsed: 3.800416ms
    Nov  5 12:13:45.269: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-bg4d2" satisfied condition "running"
    Nov  5 12:13:45.269: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-mvkt2" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:45.273: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-mvkt2": Phase="Running", Reason="", readiness=true. Elapsed: 3.973002ms
    Nov  5 12:13:45.273: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-mvkt2" satisfied condition "running"
    Nov  5 12:13:45.273: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-qghh8" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:45.277: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-qghh8": Phase="Running", Reason="", readiness=true. Elapsed: 3.364869ms
    Nov  5 12:13:45.277: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-qghh8" satisfied condition "running"
    Nov  5 12:13:45.277: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-z7j2r" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:45.280: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-z7j2r": Phase="Running", Reason="", readiness=true. Elapsed: 3.470635ms
    Nov  5 12:13:45.280: INFO: Pod "wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5-z7j2r" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5 in namespace emptydir-wrapper-3812, will wait for the garbage collector to delete the pods 11/05/22 12:13:45.28
    Nov  5 12:13:45.342: INFO: Deleting ReplicationController wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5 took: 6.830129ms
    Nov  5 12:13:45.442: INFO: Terminating ReplicationController wrapped-volume-race-1b04d266-467f-4b7d-a66e-9835257903c5 pods took: 100.599669ms
    STEP: Creating RC which spawns configmap-volume pods 11/05/22 12:13:49.648
    Nov  5 12:13:49.670: INFO: Pod name wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f: Found 0 pods out of 5
    Nov  5 12:13:54.679: INFO: Pod name wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f: Found 5 pods out of 5
    STEP: Ensuring each pod is running 11/05/22 12:13:54.679
    Nov  5 12:13:54.679: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:13:54.682: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 3.68312ms
    Nov  5 12:13:56.688: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008866233s
    Nov  5 12:13:58.687: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008679199s
    Nov  5 12:14:00.688: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008819531s
    Nov  5 12:14:02.688: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009212356s
    Nov  5 12:14:04.687: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Pending", Reason="", readiness=false. Elapsed: 10.008230445s
    Nov  5 12:14:06.688: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl": Phase="Running", Reason="", readiness=true. Elapsed: 12.008975659s
    Nov  5 12:14:06.688: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-66cdl" satisfied condition "running"
    Nov  5 12:14:06.688: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-94vvm" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:14:06.691: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-94vvm": Phase="Running", Reason="", readiness=true. Elapsed: 3.507472ms
    Nov  5 12:14:06.691: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-94vvm" satisfied condition "running"
    Nov  5 12:14:06.691: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-f5ht7" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:14:06.695: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-f5ht7": Phase="Running", Reason="", readiness=true. Elapsed: 3.497435ms
    Nov  5 12:14:06.695: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-f5ht7" satisfied condition "running"
    Nov  5 12:14:06.695: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-mfpxw" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:14:06.699: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-mfpxw": Phase="Running", Reason="", readiness=true. Elapsed: 4.030995ms
    Nov  5 12:14:06.699: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-mfpxw" satisfied condition "running"
    Nov  5 12:14:06.699: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-wg4t5" in namespace "emptydir-wrapper-3812" to be "running"
    Nov  5 12:14:06.702: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-wg4t5": Phase="Running", Reason="", readiness=true. Elapsed: 3.359313ms
    Nov  5 12:14:06.702: INFO: Pod "wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f-wg4t5" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f in namespace emptydir-wrapper-3812, will wait for the garbage collector to delete the pods 11/05/22 12:14:06.702
    Nov  5 12:14:06.765: INFO: Deleting ReplicationController wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f took: 7.931669ms
    Nov  5 12:14:06.865: INFO: Terminating ReplicationController wrapped-volume-race-c8c0dce9-c60b-4edc-abe0-599ad00f3a7f pods took: 100.974989ms
    STEP: Cleaning up the configMaps 11/05/22 12:14:09.766
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Nov  5 12:14:10.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-3812" for this suite. 11/05/22 12:14:10.156
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:14:10.165
Nov  5 12:14:10.165: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sched-preemption 11/05/22 12:14:10.166
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:14:10.181
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:14:10.185
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov  5 12:14:10.202: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  5 12:15:10.224: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:15:10.227
Nov  5 12:15:10.227: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sched-preemption-path 11/05/22 12:15:10.228
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:10.241
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:10.246
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 11/05/22 12:15:10.249
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/05/22 12:15:10.249
Nov  5 12:15:10.257: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-2957" to be "running"
Nov  5 12:15:10.260: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.227516ms
Nov  5 12:15:12.265: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.007812342s
Nov  5 12:15:12.265: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/05/22 12:15:12.268
Nov  5 12:15:12.278: INFO: found a healthy node: ip-172-31-0-255
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Nov  5 12:15:28.363: INFO: pods created so far: [1 1 1]
Nov  5 12:15:28.363: INFO: length of pods created so far: 3
Nov  5 12:15:30.376: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Nov  5 12:15:37.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-2957" for this suite. 11/05/22 12:15:37.382
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:15:37.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3271" for this suite. 11/05/22 12:15:37.429
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":89,"skipped":1565,"failed":0}
------------------------------
• [SLOW TEST] [87.329 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:14:10.165
    Nov  5 12:14:10.165: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sched-preemption 11/05/22 12:14:10.166
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:14:10.181
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:14:10.185
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov  5 12:14:10.202: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov  5 12:15:10.224: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:15:10.227
    Nov  5 12:15:10.227: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sched-preemption-path 11/05/22 12:15:10.228
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:10.241
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:10.246
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 11/05/22 12:15:10.249
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/05/22 12:15:10.249
    Nov  5 12:15:10.257: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-2957" to be "running"
    Nov  5 12:15:10.260: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.227516ms
    Nov  5 12:15:12.265: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.007812342s
    Nov  5 12:15:12.265: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/05/22 12:15:12.268
    Nov  5 12:15:12.278: INFO: found a healthy node: ip-172-31-0-255
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Nov  5 12:15:28.363: INFO: pods created so far: [1 1 1]
    Nov  5 12:15:28.363: INFO: length of pods created so far: 3
    Nov  5 12:15:30.376: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Nov  5 12:15:37.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-2957" for this suite. 11/05/22 12:15:37.382
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:15:37.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-3271" for this suite. 11/05/22 12:15:37.429
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:15:37.495
Nov  5 12:15:37.495: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename endpointslice 11/05/22 12:15:37.496
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:37.517
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:37.523
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 11/05/22 12:15:37.527
STEP: getting /apis/discovery.k8s.io 11/05/22 12:15:37.531
STEP: getting /apis/discovery.k8s.iov1 11/05/22 12:15:37.533
STEP: creating 11/05/22 12:15:37.535
STEP: getting 11/05/22 12:15:37.559
STEP: listing 11/05/22 12:15:37.562
STEP: watching 11/05/22 12:15:37.566
Nov  5 12:15:37.566: INFO: starting watch
STEP: cluster-wide listing 11/05/22 12:15:37.568
STEP: cluster-wide watching 11/05/22 12:15:37.572
Nov  5 12:15:37.572: INFO: starting watch
STEP: patching 11/05/22 12:15:37.574
STEP: updating 11/05/22 12:15:37.58
Nov  5 12:15:37.589: INFO: waiting for watch events with expected annotations
Nov  5 12:15:37.589: INFO: saw patched and updated annotations
STEP: deleting 11/05/22 12:15:37.59
STEP: deleting a collection 11/05/22 12:15:37.605
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov  5 12:15:37.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-7798" for this suite. 11/05/22 12:15:37.627
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":90,"skipped":1571,"failed":0}
------------------------------
• [0.143 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:15:37.495
    Nov  5 12:15:37.495: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename endpointslice 11/05/22 12:15:37.496
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:37.517
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:37.523
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 11/05/22 12:15:37.527
    STEP: getting /apis/discovery.k8s.io 11/05/22 12:15:37.531
    STEP: getting /apis/discovery.k8s.iov1 11/05/22 12:15:37.533
    STEP: creating 11/05/22 12:15:37.535
    STEP: getting 11/05/22 12:15:37.559
    STEP: listing 11/05/22 12:15:37.562
    STEP: watching 11/05/22 12:15:37.566
    Nov  5 12:15:37.566: INFO: starting watch
    STEP: cluster-wide listing 11/05/22 12:15:37.568
    STEP: cluster-wide watching 11/05/22 12:15:37.572
    Nov  5 12:15:37.572: INFO: starting watch
    STEP: patching 11/05/22 12:15:37.574
    STEP: updating 11/05/22 12:15:37.58
    Nov  5 12:15:37.589: INFO: waiting for watch events with expected annotations
    Nov  5 12:15:37.589: INFO: saw patched and updated annotations
    STEP: deleting 11/05/22 12:15:37.59
    STEP: deleting a collection 11/05/22 12:15:37.605
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov  5 12:15:37.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-7798" for this suite. 11/05/22 12:15:37.627
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:15:37.642
Nov  5 12:15:37.642: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-lifecycle-hook 11/05/22 12:15:37.643
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:37.661
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:37.68
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/05/22 12:15:37.69
Nov  5 12:15:37.702: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4894" to be "running and ready"
Nov  5 12:15:37.711: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 8.626186ms
Nov  5 12:15:37.711: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:15:39.716: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.013572608s
Nov  5 12:15:39.716: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov  5 12:15:39.716: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 11/05/22 12:15:39.72
Nov  5 12:15:39.729: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-4894" to be "running and ready"
Nov  5 12:15:39.736: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.439274ms
Nov  5 12:15:39.736: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:15:41.741: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.012299719s
Nov  5 12:15:41.741: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Nov  5 12:15:41.741: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 11/05/22 12:15:41.745
STEP: delete the pod with lifecycle hook 11/05/22 12:15:41.764
Nov  5 12:15:41.776: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 12:15:41.780: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 12:15:43.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 12:15:43.784: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  5 12:15:45.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  5 12:15:45.785: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov  5 12:15:45.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4894" for this suite. 11/05/22 12:15:45.79
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":91,"skipped":1577,"failed":0}
------------------------------
• [SLOW TEST] [8.157 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:15:37.642
    Nov  5 12:15:37.642: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/05/22 12:15:37.643
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:37.661
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:37.68
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/05/22 12:15:37.69
    Nov  5 12:15:37.702: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-4894" to be "running and ready"
    Nov  5 12:15:37.711: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 8.626186ms
    Nov  5 12:15:37.711: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:15:39.716: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.013572608s
    Nov  5 12:15:39.716: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov  5 12:15:39.716: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 11/05/22 12:15:39.72
    Nov  5 12:15:39.729: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-4894" to be "running and ready"
    Nov  5 12:15:39.736: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.439274ms
    Nov  5 12:15:39.736: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:15:41.741: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.012299719s
    Nov  5 12:15:41.741: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Nov  5 12:15:41.741: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 11/05/22 12:15:41.745
    STEP: delete the pod with lifecycle hook 11/05/22 12:15:41.764
    Nov  5 12:15:41.776: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov  5 12:15:41.780: INFO: Pod pod-with-poststart-exec-hook still exists
    Nov  5 12:15:43.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov  5 12:15:43.784: INFO: Pod pod-with-poststart-exec-hook still exists
    Nov  5 12:15:45.780: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Nov  5 12:15:45.785: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov  5 12:15:45.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-4894" for this suite. 11/05/22 12:15:45.79
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:15:45.801
Nov  5 12:15:45.801: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:15:45.802
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:45.819
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:45.826
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-c4d36b95-e2a1-4d6d-b93c-20abbd6bb90a 11/05/22 12:15:45.829
STEP: Creating secret with name secret-projected-all-test-volume-fd931fea-e451-4467-817a-53e9971706d1 11/05/22 12:15:45.835
STEP: Creating a pod to test Check all projections for projected volume plugin 11/05/22 12:15:45.841
Nov  5 12:15:45.854: INFO: Waiting up to 5m0s for pod "projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac" in namespace "projected-5449" to be "Succeeded or Failed"
Nov  5 12:15:45.861: INFO: Pod "projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac": Phase="Pending", Reason="", readiness=false. Elapsed: 6.395893ms
Nov  5 12:15:47.865: INFO: Pod "projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010803911s
Nov  5 12:15:49.866: INFO: Pod "projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011458055s
STEP: Saw pod success 11/05/22 12:15:49.866
Nov  5 12:15:49.866: INFO: Pod "projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac" satisfied condition "Succeeded or Failed"
Nov  5 12:15:49.870: INFO: Trying to get logs from node ip-172-31-41-19 pod projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac container projected-all-volume-test: <nil>
STEP: delete the pod 11/05/22 12:15:49.886
Nov  5 12:15:49.899: INFO: Waiting for pod projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac to disappear
Nov  5 12:15:49.903: INFO: Pod projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Nov  5 12:15:49.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5449" for this suite. 11/05/22 12:15:49.907
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":92,"skipped":1615,"failed":0}
------------------------------
• [4.113 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:15:45.801
    Nov  5 12:15:45.801: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:15:45.802
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:45.819
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:45.826
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-c4d36b95-e2a1-4d6d-b93c-20abbd6bb90a 11/05/22 12:15:45.829
    STEP: Creating secret with name secret-projected-all-test-volume-fd931fea-e451-4467-817a-53e9971706d1 11/05/22 12:15:45.835
    STEP: Creating a pod to test Check all projections for projected volume plugin 11/05/22 12:15:45.841
    Nov  5 12:15:45.854: INFO: Waiting up to 5m0s for pod "projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac" in namespace "projected-5449" to be "Succeeded or Failed"
    Nov  5 12:15:45.861: INFO: Pod "projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac": Phase="Pending", Reason="", readiness=false. Elapsed: 6.395893ms
    Nov  5 12:15:47.865: INFO: Pod "projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010803911s
    Nov  5 12:15:49.866: INFO: Pod "projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011458055s
    STEP: Saw pod success 11/05/22 12:15:49.866
    Nov  5 12:15:49.866: INFO: Pod "projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac" satisfied condition "Succeeded or Failed"
    Nov  5 12:15:49.870: INFO: Trying to get logs from node ip-172-31-41-19 pod projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac container projected-all-volume-test: <nil>
    STEP: delete the pod 11/05/22 12:15:49.886
    Nov  5 12:15:49.899: INFO: Waiting for pod projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac to disappear
    Nov  5 12:15:49.903: INFO: Pod projected-volume-ac2a1bfd-2382-43ea-8b3b-15eb07f24eac no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Nov  5 12:15:49.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5449" for this suite. 11/05/22 12:15:49.907
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:15:49.915
Nov  5 12:15:49.915: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 12:15:49.915
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:49.928
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:49.933
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 11/05/22 12:15:49.937
Nov  5 12:15:49.946: INFO: Waiting up to 5m0s for pod "annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f" in namespace "downward-api-7250" to be "running and ready"
Nov  5 12:15:49.949: INFO: Pod "annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.68332ms
Nov  5 12:15:49.949: INFO: The phase of Pod annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:15:51.954: INFO: Pod "annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f": Phase="Running", Reason="", readiness=true. Elapsed: 2.007927343s
Nov  5 12:15:51.954: INFO: The phase of Pod annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f is Running (Ready = true)
Nov  5 12:15:51.954: INFO: Pod "annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f" satisfied condition "running and ready"
Nov  5 12:15:52.480: INFO: Successfully updated pod "annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 12:15:56.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7250" for this suite. 11/05/22 12:15:56.507
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":93,"skipped":1628,"failed":0}
------------------------------
• [SLOW TEST] [6.600 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:15:49.915
    Nov  5 12:15:49.915: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 12:15:49.915
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:49.928
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:49.933
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 11/05/22 12:15:49.937
    Nov  5 12:15:49.946: INFO: Waiting up to 5m0s for pod "annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f" in namespace "downward-api-7250" to be "running and ready"
    Nov  5 12:15:49.949: INFO: Pod "annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.68332ms
    Nov  5 12:15:49.949: INFO: The phase of Pod annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:15:51.954: INFO: Pod "annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f": Phase="Running", Reason="", readiness=true. Elapsed: 2.007927343s
    Nov  5 12:15:51.954: INFO: The phase of Pod annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f is Running (Ready = true)
    Nov  5 12:15:51.954: INFO: Pod "annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f" satisfied condition "running and ready"
    Nov  5 12:15:52.480: INFO: Successfully updated pod "annotationupdate5cd32962-213f-45d6-a167-9ba58a4e3d3f"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 12:15:56.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-7250" for this suite. 11/05/22 12:15:56.507
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:15:56.516
Nov  5 12:15:56.516: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename disruption 11/05/22 12:15:56.517
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:56.531
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:56.535
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 11/05/22 12:15:56.546
STEP: Updating PodDisruptionBudget status 11/05/22 12:15:58.554
STEP: Waiting for all pods to be running 11/05/22 12:15:58.562
Nov  5 12:15:58.566: INFO: running pods: 0 < 1
STEP: locating a running pod 11/05/22 12:16:00.571
STEP: Waiting for the pdb to be processed 11/05/22 12:16:00.585
STEP: Patching PodDisruptionBudget status 11/05/22 12:16:00.592
STEP: Waiting for the pdb to be processed 11/05/22 12:16:00.601
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov  5 12:16:00.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6641" for this suite. 11/05/22 12:16:00.609
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":94,"skipped":1651,"failed":0}
------------------------------
• [4.100 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:15:56.516
    Nov  5 12:15:56.516: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename disruption 11/05/22 12:15:56.517
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:15:56.531
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:15:56.535
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 11/05/22 12:15:56.546
    STEP: Updating PodDisruptionBudget status 11/05/22 12:15:58.554
    STEP: Waiting for all pods to be running 11/05/22 12:15:58.562
    Nov  5 12:15:58.566: INFO: running pods: 0 < 1
    STEP: locating a running pod 11/05/22 12:16:00.571
    STEP: Waiting for the pdb to be processed 11/05/22 12:16:00.585
    STEP: Patching PodDisruptionBudget status 11/05/22 12:16:00.592
    STEP: Waiting for the pdb to be processed 11/05/22 12:16:00.601
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov  5 12:16:00.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6641" for this suite. 11/05/22 12:16:00.609
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:16:00.617
Nov  5 12:16:00.617: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename containers 11/05/22 12:16:00.617
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:00.629
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:00.632
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 11/05/22 12:16:00.637
Nov  5 12:16:00.644: INFO: Waiting up to 5m0s for pod "client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5" in namespace "containers-9552" to be "Succeeded or Failed"
Nov  5 12:16:00.649: INFO: Pod "client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.182376ms
Nov  5 12:16:02.655: INFO: Pod "client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010357392s
Nov  5 12:16:04.653: INFO: Pod "client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00890714s
STEP: Saw pod success 11/05/22 12:16:04.653
Nov  5 12:16:04.653: INFO: Pod "client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5" satisfied condition "Succeeded or Failed"
Nov  5 12:16:04.657: INFO: Trying to get logs from node ip-172-31-0-255 pod client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5 container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:16:04.663
Nov  5 12:16:04.677: INFO: Waiting for pod client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5 to disappear
Nov  5 12:16:04.682: INFO: Pod client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov  5 12:16:04.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9552" for this suite. 11/05/22 12:16:04.686
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":95,"skipped":1659,"failed":0}
------------------------------
• [4.075 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:16:00.617
    Nov  5 12:16:00.617: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename containers 11/05/22 12:16:00.617
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:00.629
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:00.632
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 11/05/22 12:16:00.637
    Nov  5 12:16:00.644: INFO: Waiting up to 5m0s for pod "client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5" in namespace "containers-9552" to be "Succeeded or Failed"
    Nov  5 12:16:00.649: INFO: Pod "client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.182376ms
    Nov  5 12:16:02.655: INFO: Pod "client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010357392s
    Nov  5 12:16:04.653: INFO: Pod "client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00890714s
    STEP: Saw pod success 11/05/22 12:16:04.653
    Nov  5 12:16:04.653: INFO: Pod "client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5" satisfied condition "Succeeded or Failed"
    Nov  5 12:16:04.657: INFO: Trying to get logs from node ip-172-31-0-255 pod client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5 container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:16:04.663
    Nov  5 12:16:04.677: INFO: Waiting for pod client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5 to disappear
    Nov  5 12:16:04.682: INFO: Pod client-containers-4d5ecc72-b653-4f71-ba2f-5586d28e7ff5 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov  5 12:16:04.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-9552" for this suite. 11/05/22 12:16:04.686
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:16:04.694
Nov  5 12:16:04.694: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 12:16:04.695
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:04.706
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:04.71
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 11/05/22 12:16:21.718
STEP: Creating a ResourceQuota 11/05/22 12:16:26.722
STEP: Ensuring resource quota status is calculated 11/05/22 12:16:26.728
STEP: Creating a ConfigMap 11/05/22 12:16:28.733
STEP: Ensuring resource quota status captures configMap creation 11/05/22 12:16:28.745
STEP: Deleting a ConfigMap 11/05/22 12:16:30.75
STEP: Ensuring resource quota status released usage 11/05/22 12:16:30.757
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 12:16:32.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4167" for this suite. 11/05/22 12:16:32.766
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":96,"skipped":1671,"failed":0}
------------------------------
• [SLOW TEST] [28.079 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:16:04.694
    Nov  5 12:16:04.694: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 12:16:04.695
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:04.706
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:04.71
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 11/05/22 12:16:21.718
    STEP: Creating a ResourceQuota 11/05/22 12:16:26.722
    STEP: Ensuring resource quota status is calculated 11/05/22 12:16:26.728
    STEP: Creating a ConfigMap 11/05/22 12:16:28.733
    STEP: Ensuring resource quota status captures configMap creation 11/05/22 12:16:28.745
    STEP: Deleting a ConfigMap 11/05/22 12:16:30.75
    STEP: Ensuring resource quota status released usage 11/05/22 12:16:30.757
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 12:16:32.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4167" for this suite. 11/05/22 12:16:32.766
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:16:32.774
Nov  5 12:16:32.774: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:16:32.775
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:32.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:32.792
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/05/22 12:16:32.796
Nov  5 12:16:32.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9010 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Nov  5 12:16:32.860: INFO: stderr: ""
Nov  5 12:16:32.860: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 11/05/22 12:16:32.86
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Nov  5 12:16:32.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9010 delete pods e2e-test-httpd-pod'
Nov  5 12:16:35.317: INFO: stderr: ""
Nov  5 12:16:35.317: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:16:35.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9010" for this suite. 11/05/22 12:16:35.321
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":97,"skipped":1681,"failed":0}
------------------------------
• [2.553 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:16:32.774
    Nov  5 12:16:32.774: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:16:32.775
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:32.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:32.792
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/05/22 12:16:32.796
    Nov  5 12:16:32.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9010 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Nov  5 12:16:32.860: INFO: stderr: ""
    Nov  5 12:16:32.860: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 11/05/22 12:16:32.86
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Nov  5 12:16:32.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9010 delete pods e2e-test-httpd-pod'
    Nov  5 12:16:35.317: INFO: stderr: ""
    Nov  5 12:16:35.317: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:16:35.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9010" for this suite. 11/05/22 12:16:35.321
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:16:35.329
Nov  5 12:16:35.329: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename namespaces 11/05/22 12:16:35.33
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:35.341
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:35.347
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 11/05/22 12:16:35.35
STEP: patching the Namespace 11/05/22 12:16:35.361
STEP: get the Namespace and ensuring it has the label 11/05/22 12:16:35.368
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:16:35.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3531" for this suite. 11/05/22 12:16:35.377
STEP: Destroying namespace "nspatchtest-1a8d31a0-74d2-4dca-90d5-c8f48ca55278-7187" for this suite. 11/05/22 12:16:35.384
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":98,"skipped":1718,"failed":0}
------------------------------
• [0.061 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:16:35.329
    Nov  5 12:16:35.329: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename namespaces 11/05/22 12:16:35.33
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:35.341
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:35.347
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 11/05/22 12:16:35.35
    STEP: patching the Namespace 11/05/22 12:16:35.361
    STEP: get the Namespace and ensuring it has the label 11/05/22 12:16:35.368
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:16:35.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-3531" for this suite. 11/05/22 12:16:35.377
    STEP: Destroying namespace "nspatchtest-1a8d31a0-74d2-4dca-90d5-c8f48ca55278-7187" for this suite. 11/05/22 12:16:35.384
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:16:35.391
Nov  5 12:16:35.391: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 12:16:35.391
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:35.404
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:35.407
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 11/05/22 12:16:35.411
Nov  5 12:16:35.419: INFO: Waiting up to 5m0s for pod "pod-3f0c71d3-1a55-4180-af35-11d54485187a" in namespace "emptydir-4330" to be "Succeeded or Failed"
Nov  5 12:16:35.424: INFO: Pod "pod-3f0c71d3-1a55-4180-af35-11d54485187a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.929121ms
Nov  5 12:16:37.430: INFO: Pod "pod-3f0c71d3-1a55-4180-af35-11d54485187a": Phase="Running", Reason="", readiness=false. Elapsed: 2.01009777s
Nov  5 12:16:39.429: INFO: Pod "pod-3f0c71d3-1a55-4180-af35-11d54485187a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0096014s
STEP: Saw pod success 11/05/22 12:16:39.429
Nov  5 12:16:39.429: INFO: Pod "pod-3f0c71d3-1a55-4180-af35-11d54485187a" satisfied condition "Succeeded or Failed"
Nov  5 12:16:39.433: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-3f0c71d3-1a55-4180-af35-11d54485187a container test-container: <nil>
STEP: delete the pod 11/05/22 12:16:39.439
Nov  5 12:16:39.450: INFO: Waiting for pod pod-3f0c71d3-1a55-4180-af35-11d54485187a to disappear
Nov  5 12:16:39.453: INFO: Pod pod-3f0c71d3-1a55-4180-af35-11d54485187a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 12:16:39.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4330" for this suite. 11/05/22 12:16:39.458
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":99,"skipped":1724,"failed":0}
------------------------------
• [4.073 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:16:35.391
    Nov  5 12:16:35.391: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 12:16:35.391
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:35.404
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:35.407
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 11/05/22 12:16:35.411
    Nov  5 12:16:35.419: INFO: Waiting up to 5m0s for pod "pod-3f0c71d3-1a55-4180-af35-11d54485187a" in namespace "emptydir-4330" to be "Succeeded or Failed"
    Nov  5 12:16:35.424: INFO: Pod "pod-3f0c71d3-1a55-4180-af35-11d54485187a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.929121ms
    Nov  5 12:16:37.430: INFO: Pod "pod-3f0c71d3-1a55-4180-af35-11d54485187a": Phase="Running", Reason="", readiness=false. Elapsed: 2.01009777s
    Nov  5 12:16:39.429: INFO: Pod "pod-3f0c71d3-1a55-4180-af35-11d54485187a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0096014s
    STEP: Saw pod success 11/05/22 12:16:39.429
    Nov  5 12:16:39.429: INFO: Pod "pod-3f0c71d3-1a55-4180-af35-11d54485187a" satisfied condition "Succeeded or Failed"
    Nov  5 12:16:39.433: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-3f0c71d3-1a55-4180-af35-11d54485187a container test-container: <nil>
    STEP: delete the pod 11/05/22 12:16:39.439
    Nov  5 12:16:39.450: INFO: Waiting for pod pod-3f0c71d3-1a55-4180-af35-11d54485187a to disappear
    Nov  5 12:16:39.453: INFO: Pod pod-3f0c71d3-1a55-4180-af35-11d54485187a no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 12:16:39.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4330" for this suite. 11/05/22 12:16:39.458
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:16:39.465
Nov  5 12:16:39.465: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 12:16:39.466
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:39.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:39.483
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 11/05/22 12:16:39.491
STEP: watching for Pod to be ready 11/05/22 12:16:39.499
Nov  5 12:16:39.501: INFO: observed Pod pod-test in namespace pods-8646 in phase Pending with labels: map[test-pod-static:true] & conditions []
Nov  5 12:16:39.504: INFO: observed Pod pod-test in namespace pods-8646 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC  }]
Nov  5 12:16:39.520: INFO: observed Pod pod-test in namespace pods-8646 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC  }]
Nov  5 12:16:41.317: INFO: Found Pod pod-test in namespace pods-8646 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 11/05/22 12:16:41.321
STEP: getting the Pod and ensuring that it's patched 11/05/22 12:16:41.331
STEP: replacing the Pod's status Ready condition to False 11/05/22 12:16:41.334
STEP: check the Pod again to ensure its Ready conditions are False 11/05/22 12:16:41.346
STEP: deleting the Pod via a Collection with a LabelSelector 11/05/22 12:16:41.346
STEP: watching for the Pod to be deleted 11/05/22 12:16:41.356
Nov  5 12:16:41.358: INFO: observed event type MODIFIED
Nov  5 12:16:43.335: INFO: observed event type MODIFIED
Nov  5 12:16:44.323: INFO: observed event type MODIFIED
Nov  5 12:16:44.333: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov  5 12:16:44.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8646" for this suite. 11/05/22 12:16:44.347
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":100,"skipped":1756,"failed":0}
------------------------------
• [4.889 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:16:39.465
    Nov  5 12:16:39.465: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 12:16:39.466
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:39.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:39.483
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 11/05/22 12:16:39.491
    STEP: watching for Pod to be ready 11/05/22 12:16:39.499
    Nov  5 12:16:39.501: INFO: observed Pod pod-test in namespace pods-8646 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Nov  5 12:16:39.504: INFO: observed Pod pod-test in namespace pods-8646 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC  }]
    Nov  5 12:16:39.520: INFO: observed Pod pod-test in namespace pods-8646 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC  }]
    Nov  5 12:16:41.317: INFO: Found Pod pod-test in namespace pods-8646 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:41 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:41 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2022-11-05 12:16:39 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 11/05/22 12:16:41.321
    STEP: getting the Pod and ensuring that it's patched 11/05/22 12:16:41.331
    STEP: replacing the Pod's status Ready condition to False 11/05/22 12:16:41.334
    STEP: check the Pod again to ensure its Ready conditions are False 11/05/22 12:16:41.346
    STEP: deleting the Pod via a Collection with a LabelSelector 11/05/22 12:16:41.346
    STEP: watching for the Pod to be deleted 11/05/22 12:16:41.356
    Nov  5 12:16:41.358: INFO: observed event type MODIFIED
    Nov  5 12:16:43.335: INFO: observed event type MODIFIED
    Nov  5 12:16:44.323: INFO: observed event type MODIFIED
    Nov  5 12:16:44.333: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov  5 12:16:44.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-8646" for this suite. 11/05/22 12:16:44.347
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:16:44.356
Nov  5 12:16:44.356: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 12:16:44.357
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:44.374
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:44.377
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 11/05/22 12:16:44.384
Nov  5 12:16:44.393: INFO: Waiting up to 5m0s for pod "pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f" in namespace "emptydir-3753" to be "Succeeded or Failed"
Nov  5 12:16:44.399: INFO: Pod "pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.21997ms
Nov  5 12:16:46.404: INFO: Pod "pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010998953s
Nov  5 12:16:48.403: INFO: Pod "pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01077504s
STEP: Saw pod success 11/05/22 12:16:48.403
Nov  5 12:16:48.403: INFO: Pod "pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f" satisfied condition "Succeeded or Failed"
Nov  5 12:16:48.409: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f container test-container: <nil>
STEP: delete the pod 11/05/22 12:16:48.415
Nov  5 12:16:48.429: INFO: Waiting for pod pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f to disappear
Nov  5 12:16:48.433: INFO: Pod pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 12:16:48.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3753" for this suite. 11/05/22 12:16:48.437
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":101,"skipped":1800,"failed":0}
------------------------------
• [4.089 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:16:44.356
    Nov  5 12:16:44.356: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 12:16:44.357
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:44.374
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:44.377
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 11/05/22 12:16:44.384
    Nov  5 12:16:44.393: INFO: Waiting up to 5m0s for pod "pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f" in namespace "emptydir-3753" to be "Succeeded or Failed"
    Nov  5 12:16:44.399: INFO: Pod "pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.21997ms
    Nov  5 12:16:46.404: INFO: Pod "pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010998953s
    Nov  5 12:16:48.403: INFO: Pod "pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01077504s
    STEP: Saw pod success 11/05/22 12:16:48.403
    Nov  5 12:16:48.403: INFO: Pod "pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f" satisfied condition "Succeeded or Failed"
    Nov  5 12:16:48.409: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f container test-container: <nil>
    STEP: delete the pod 11/05/22 12:16:48.415
    Nov  5 12:16:48.429: INFO: Waiting for pod pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f to disappear
    Nov  5 12:16:48.433: INFO: Pod pod-55f65c38-eeed-49c5-80e1-4f3826df1d1f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 12:16:48.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3753" for this suite. 11/05/22 12:16:48.437
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:16:48.446
Nov  5 12:16:48.446: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename gc 11/05/22 12:16:48.446
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:48.458
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:48.46
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 11/05/22 12:16:48.464
STEP: Wait for the Deployment to create new ReplicaSet 11/05/22 12:16:48.47
STEP: delete the deployment 11/05/22 12:16:48.978
STEP: wait for all rs to be garbage collected 11/05/22 12:16:48.984
STEP: expected 0 pods, got 2 pods 11/05/22 12:16:48.99
STEP: expected 0 rs, got 1 rs 11/05/22 12:16:49.002
STEP: Gathering metrics 11/05/22 12:16:49.515
W1105 12:16:49.519520      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov  5 12:16:49.519: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov  5 12:16:49.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7498" for this suite. 11/05/22 12:16:49.523
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":102,"skipped":1803,"failed":0}
------------------------------
• [1.085 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:16:48.446
    Nov  5 12:16:48.446: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename gc 11/05/22 12:16:48.446
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:48.458
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:48.46
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 11/05/22 12:16:48.464
    STEP: Wait for the Deployment to create new ReplicaSet 11/05/22 12:16:48.47
    STEP: delete the deployment 11/05/22 12:16:48.978
    STEP: wait for all rs to be garbage collected 11/05/22 12:16:48.984
    STEP: expected 0 pods, got 2 pods 11/05/22 12:16:48.99
    STEP: expected 0 rs, got 1 rs 11/05/22 12:16:49.002
    STEP: Gathering metrics 11/05/22 12:16:49.515
    W1105 12:16:49.519520      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov  5 12:16:49.519: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov  5 12:16:49.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7498" for this suite. 11/05/22 12:16:49.523
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:16:49.532
Nov  5 12:16:49.532: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-watch 11/05/22 12:16:49.533
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:49.548
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:49.552
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Nov  5 12:16:49.557: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Creating first CR  11/05/22 12:16:52.109
Nov  5 12:16:52.114: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:16:52Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:16:52Z]] name:name1 resourceVersion:10937 uid:bc4e8215-3956-42b3-be8d-43f7db49464f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 11/05/22 12:17:02.114
Nov  5 12:17:02.120: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:17:02Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:17:02Z]] name:name2 resourceVersion:10984 uid:6272a0f0-9534-4655-8434-c1a1cdadbf39] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 11/05/22 12:17:12.121
Nov  5 12:17:12.127: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:16:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:17:12Z]] name:name1 resourceVersion:11003 uid:bc4e8215-3956-42b3-be8d-43f7db49464f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 11/05/22 12:17:22.127
Nov  5 12:17:22.133: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:17:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:17:22Z]] name:name2 resourceVersion:11023 uid:6272a0f0-9534-4655-8434-c1a1cdadbf39] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 11/05/22 12:17:32.134
Nov  5 12:17:32.143: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:16:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:17:12Z]] name:name1 resourceVersion:11039 uid:bc4e8215-3956-42b3-be8d-43f7db49464f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 11/05/22 12:17:42.144
Nov  5 12:17:42.152: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:17:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:17:22Z]] name:name2 resourceVersion:11058 uid:6272a0f0-9534-4655-8434-c1a1cdadbf39] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:17:52.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-1957" for this suite. 11/05/22 12:17:52.673
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":103,"skipped":1825,"failed":0}
------------------------------
• [SLOW TEST] [63.150 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:16:49.532
    Nov  5 12:16:49.532: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-watch 11/05/22 12:16:49.533
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:16:49.548
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:16:49.552
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Nov  5 12:16:49.557: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Creating first CR  11/05/22 12:16:52.109
    Nov  5 12:16:52.114: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:16:52Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:16:52Z]] name:name1 resourceVersion:10937 uid:bc4e8215-3956-42b3-be8d-43f7db49464f] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 11/05/22 12:17:02.114
    Nov  5 12:17:02.120: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:17:02Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:17:02Z]] name:name2 resourceVersion:10984 uid:6272a0f0-9534-4655-8434-c1a1cdadbf39] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 11/05/22 12:17:12.121
    Nov  5 12:17:12.127: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:16:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:17:12Z]] name:name1 resourceVersion:11003 uid:bc4e8215-3956-42b3-be8d-43f7db49464f] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 11/05/22 12:17:22.127
    Nov  5 12:17:22.133: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:17:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:17:22Z]] name:name2 resourceVersion:11023 uid:6272a0f0-9534-4655-8434-c1a1cdadbf39] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 11/05/22 12:17:32.134
    Nov  5 12:17:32.143: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:16:52Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:17:12Z]] name:name1 resourceVersion:11039 uid:bc4e8215-3956-42b3-be8d-43f7db49464f] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 11/05/22 12:17:42.144
    Nov  5 12:17:42.152: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2022-11-05T12:17:02Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2022-11-05T12:17:22Z]] name:name2 resourceVersion:11058 uid:6272a0f0-9534-4655-8434-c1a1cdadbf39] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:17:52.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-1957" for this suite. 11/05/22 12:17:52.673
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:17:52.684
Nov  5 12:17:52.685: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename svcaccounts 11/05/22 12:17:52.685
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:17:52.699
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:17:52.704
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Nov  5 12:17:52.727: INFO: created pod pod-service-account-defaultsa
Nov  5 12:17:52.727: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov  5 12:17:52.734: INFO: created pod pod-service-account-mountsa
Nov  5 12:17:52.734: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov  5 12:17:52.742: INFO: created pod pod-service-account-nomountsa
Nov  5 12:17:52.742: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov  5 12:17:52.753: INFO: created pod pod-service-account-defaultsa-mountspec
Nov  5 12:17:52.753: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov  5 12:17:52.761: INFO: created pod pod-service-account-mountsa-mountspec
Nov  5 12:17:52.761: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov  5 12:17:52.770: INFO: created pod pod-service-account-nomountsa-mountspec
Nov  5 12:17:52.770: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov  5 12:17:52.783: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov  5 12:17:52.783: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov  5 12:17:52.789: INFO: created pod pod-service-account-mountsa-nomountspec
Nov  5 12:17:52.789: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov  5 12:17:52.802: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov  5 12:17:52.802: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov  5 12:17:52.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6226" for this suite. 11/05/22 12:17:52.807
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":104,"skipped":1872,"failed":0}
------------------------------
• [0.129 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:17:52.684
    Nov  5 12:17:52.685: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename svcaccounts 11/05/22 12:17:52.685
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:17:52.699
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:17:52.704
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Nov  5 12:17:52.727: INFO: created pod pod-service-account-defaultsa
    Nov  5 12:17:52.727: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Nov  5 12:17:52.734: INFO: created pod pod-service-account-mountsa
    Nov  5 12:17:52.734: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Nov  5 12:17:52.742: INFO: created pod pod-service-account-nomountsa
    Nov  5 12:17:52.742: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Nov  5 12:17:52.753: INFO: created pod pod-service-account-defaultsa-mountspec
    Nov  5 12:17:52.753: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Nov  5 12:17:52.761: INFO: created pod pod-service-account-mountsa-mountspec
    Nov  5 12:17:52.761: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Nov  5 12:17:52.770: INFO: created pod pod-service-account-nomountsa-mountspec
    Nov  5 12:17:52.770: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Nov  5 12:17:52.783: INFO: created pod pod-service-account-defaultsa-nomountspec
    Nov  5 12:17:52.783: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Nov  5 12:17:52.789: INFO: created pod pod-service-account-mountsa-nomountspec
    Nov  5 12:17:52.789: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Nov  5 12:17:52.802: INFO: created pod pod-service-account-nomountsa-nomountspec
    Nov  5 12:17:52.802: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov  5 12:17:52.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-6226" for this suite. 11/05/22 12:17:52.807
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:17:52.816
Nov  5 12:17:52.816: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename watch 11/05/22 12:17:52.817
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:17:52.829
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:17:52.833
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 11/05/22 12:17:52.84
STEP: starting a background goroutine to produce watch events 11/05/22 12:17:52.844
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 11/05/22 12:17:52.844
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov  5 12:17:55.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1889" for this suite. 11/05/22 12:17:55.671
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":105,"skipped":1915,"failed":0}
------------------------------
• [2.910 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:17:52.816
    Nov  5 12:17:52.816: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename watch 11/05/22 12:17:52.817
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:17:52.829
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:17:52.833
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 11/05/22 12:17:52.84
    STEP: starting a background goroutine to produce watch events 11/05/22 12:17:52.844
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 11/05/22 12:17:52.844
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov  5 12:17:55.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-1889" for this suite. 11/05/22 12:17:55.671
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:17:55.726
Nov  5 12:17:55.727: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename gc 11/05/22 12:17:55.727
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:17:55.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:17:55.745
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 11/05/22 12:17:55.752
STEP: create the rc2 11/05/22 12:17:55.757
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 11/05/22 12:18:00.768
STEP: delete the rc simpletest-rc-to-be-deleted 11/05/22 12:18:01.264
STEP: wait for the rc to be deleted 11/05/22 12:18:01.271
Nov  5 12:18:06.287: INFO: 69 pods remaining
Nov  5 12:18:06.287: INFO: 69 pods has nil DeletionTimestamp
Nov  5 12:18:06.287: INFO: 
STEP: Gathering metrics 11/05/22 12:18:11.283
W1105 12:18:11.288728      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov  5 12:18:11.288: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Nov  5 12:18:11.288: INFO: Deleting pod "simpletest-rc-to-be-deleted-26srj" in namespace "gc-7932"
Nov  5 12:18:11.300: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bwn6" in namespace "gc-7932"
Nov  5 12:18:11.311: INFO: Deleting pod "simpletest-rc-to-be-deleted-2f4nj" in namespace "gc-7932"
Nov  5 12:18:11.321: INFO: Deleting pod "simpletest-rc-to-be-deleted-2q7cj" in namespace "gc-7932"
Nov  5 12:18:11.341: INFO: Deleting pod "simpletest-rc-to-be-deleted-2xqkd" in namespace "gc-7932"
Nov  5 12:18:11.356: INFO: Deleting pod "simpletest-rc-to-be-deleted-2xrp4" in namespace "gc-7932"
Nov  5 12:18:11.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-46ppq" in namespace "gc-7932"
Nov  5 12:18:11.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-4k99d" in namespace "gc-7932"
Nov  5 12:18:11.413: INFO: Deleting pod "simpletest-rc-to-be-deleted-4r29n" in namespace "gc-7932"
Nov  5 12:18:11.428: INFO: Deleting pod "simpletest-rc-to-be-deleted-4r4mv" in namespace "gc-7932"
Nov  5 12:18:11.442: INFO: Deleting pod "simpletest-rc-to-be-deleted-4rxwz" in namespace "gc-7932"
Nov  5 12:18:11.467: INFO: Deleting pod "simpletest-rc-to-be-deleted-4s4cv" in namespace "gc-7932"
Nov  5 12:18:11.478: INFO: Deleting pod "simpletest-rc-to-be-deleted-5qrjw" in namespace "gc-7932"
Nov  5 12:18:11.489: INFO: Deleting pod "simpletest-rc-to-be-deleted-5sdg6" in namespace "gc-7932"
Nov  5 12:18:11.502: INFO: Deleting pod "simpletest-rc-to-be-deleted-5swcx" in namespace "gc-7932"
Nov  5 12:18:11.513: INFO: Deleting pod "simpletest-rc-to-be-deleted-647bh" in namespace "gc-7932"
Nov  5 12:18:11.528: INFO: Deleting pod "simpletest-rc-to-be-deleted-69zj8" in namespace "gc-7932"
Nov  5 12:18:11.540: INFO: Deleting pod "simpletest-rc-to-be-deleted-6f49s" in namespace "gc-7932"
Nov  5 12:18:11.558: INFO: Deleting pod "simpletest-rc-to-be-deleted-6k68l" in namespace "gc-7932"
Nov  5 12:18:11.581: INFO: Deleting pod "simpletest-rc-to-be-deleted-6qnmd" in namespace "gc-7932"
Nov  5 12:18:11.594: INFO: Deleting pod "simpletest-rc-to-be-deleted-7d5gj" in namespace "gc-7932"
Nov  5 12:18:11.609: INFO: Deleting pod "simpletest-rc-to-be-deleted-7r8pk" in namespace "gc-7932"
Nov  5 12:18:11.621: INFO: Deleting pod "simpletest-rc-to-be-deleted-84mdw" in namespace "gc-7932"
Nov  5 12:18:11.633: INFO: Deleting pod "simpletest-rc-to-be-deleted-85blb" in namespace "gc-7932"
Nov  5 12:18:11.647: INFO: Deleting pod "simpletest-rc-to-be-deleted-8mc8d" in namespace "gc-7932"
Nov  5 12:18:11.661: INFO: Deleting pod "simpletest-rc-to-be-deleted-8nwct" in namespace "gc-7932"
Nov  5 12:18:11.673: INFO: Deleting pod "simpletest-rc-to-be-deleted-8sz8r" in namespace "gc-7932"
Nov  5 12:18:11.794: INFO: Deleting pod "simpletest-rc-to-be-deleted-8xvns" in namespace "gc-7932"
Nov  5 12:18:11.807: INFO: Deleting pod "simpletest-rc-to-be-deleted-98l2v" in namespace "gc-7932"
Nov  5 12:18:11.816: INFO: Deleting pod "simpletest-rc-to-be-deleted-99qrk" in namespace "gc-7932"
Nov  5 12:18:11.828: INFO: Deleting pod "simpletest-rc-to-be-deleted-9c5zr" in namespace "gc-7932"
Nov  5 12:18:11.840: INFO: Deleting pod "simpletest-rc-to-be-deleted-9cqwx" in namespace "gc-7932"
Nov  5 12:18:11.855: INFO: Deleting pod "simpletest-rc-to-be-deleted-9fpnw" in namespace "gc-7932"
Nov  5 12:18:11.872: INFO: Deleting pod "simpletest-rc-to-be-deleted-9hjst" in namespace "gc-7932"
Nov  5 12:18:11.887: INFO: Deleting pod "simpletest-rc-to-be-deleted-9nh4t" in namespace "gc-7932"
Nov  5 12:18:11.899: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9zr2" in namespace "gc-7932"
Nov  5 12:18:11.911: INFO: Deleting pod "simpletest-rc-to-be-deleted-btchz" in namespace "gc-7932"
Nov  5 12:18:11.925: INFO: Deleting pod "simpletest-rc-to-be-deleted-cfpc4" in namespace "gc-7932"
Nov  5 12:18:11.939: INFO: Deleting pod "simpletest-rc-to-be-deleted-cnlc9" in namespace "gc-7932"
Nov  5 12:18:11.950: INFO: Deleting pod "simpletest-rc-to-be-deleted-cnxrv" in namespace "gc-7932"
Nov  5 12:18:11.960: INFO: Deleting pod "simpletest-rc-to-be-deleted-czgjd" in namespace "gc-7932"
Nov  5 12:18:12.046: INFO: Deleting pod "simpletest-rc-to-be-deleted-d4t5t" in namespace "gc-7932"
Nov  5 12:18:12.058: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6d9m" in namespace "gc-7932"
Nov  5 12:18:12.069: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnh2z" in namespace "gc-7932"
Nov  5 12:18:12.079: INFO: Deleting pod "simpletest-rc-to-be-deleted-dsclc" in namespace "gc-7932"
Nov  5 12:18:12.092: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvqww" in namespace "gc-7932"
Nov  5 12:18:12.116: INFO: Deleting pod "simpletest-rc-to-be-deleted-f54qt" in namespace "gc-7932"
Nov  5 12:18:12.128: INFO: Deleting pod "simpletest-rc-to-be-deleted-f5vq9" in namespace "gc-7932"
Nov  5 12:18:12.139: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7lwd" in namespace "gc-7932"
Nov  5 12:18:12.150: INFO: Deleting pod "simpletest-rc-to-be-deleted-fhddk" in namespace "gc-7932"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov  5 12:18:12.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7932" for this suite. 11/05/22 12:18:12.165
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":106,"skipped":1918,"failed":0}
------------------------------
• [SLOW TEST] [16.445 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:17:55.726
    Nov  5 12:17:55.727: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename gc 11/05/22 12:17:55.727
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:17:55.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:17:55.745
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 11/05/22 12:17:55.752
    STEP: create the rc2 11/05/22 12:17:55.757
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 11/05/22 12:18:00.768
    STEP: delete the rc simpletest-rc-to-be-deleted 11/05/22 12:18:01.264
    STEP: wait for the rc to be deleted 11/05/22 12:18:01.271
    Nov  5 12:18:06.287: INFO: 69 pods remaining
    Nov  5 12:18:06.287: INFO: 69 pods has nil DeletionTimestamp
    Nov  5 12:18:06.287: INFO: 
    STEP: Gathering metrics 11/05/22 12:18:11.283
    W1105 12:18:11.288728      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov  5 12:18:11.288: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Nov  5 12:18:11.288: INFO: Deleting pod "simpletest-rc-to-be-deleted-26srj" in namespace "gc-7932"
    Nov  5 12:18:11.300: INFO: Deleting pod "simpletest-rc-to-be-deleted-2bwn6" in namespace "gc-7932"
    Nov  5 12:18:11.311: INFO: Deleting pod "simpletest-rc-to-be-deleted-2f4nj" in namespace "gc-7932"
    Nov  5 12:18:11.321: INFO: Deleting pod "simpletest-rc-to-be-deleted-2q7cj" in namespace "gc-7932"
    Nov  5 12:18:11.341: INFO: Deleting pod "simpletest-rc-to-be-deleted-2xqkd" in namespace "gc-7932"
    Nov  5 12:18:11.356: INFO: Deleting pod "simpletest-rc-to-be-deleted-2xrp4" in namespace "gc-7932"
    Nov  5 12:18:11.375: INFO: Deleting pod "simpletest-rc-to-be-deleted-46ppq" in namespace "gc-7932"
    Nov  5 12:18:11.388: INFO: Deleting pod "simpletest-rc-to-be-deleted-4k99d" in namespace "gc-7932"
    Nov  5 12:18:11.413: INFO: Deleting pod "simpletest-rc-to-be-deleted-4r29n" in namespace "gc-7932"
    Nov  5 12:18:11.428: INFO: Deleting pod "simpletest-rc-to-be-deleted-4r4mv" in namespace "gc-7932"
    Nov  5 12:18:11.442: INFO: Deleting pod "simpletest-rc-to-be-deleted-4rxwz" in namespace "gc-7932"
    Nov  5 12:18:11.467: INFO: Deleting pod "simpletest-rc-to-be-deleted-4s4cv" in namespace "gc-7932"
    Nov  5 12:18:11.478: INFO: Deleting pod "simpletest-rc-to-be-deleted-5qrjw" in namespace "gc-7932"
    Nov  5 12:18:11.489: INFO: Deleting pod "simpletest-rc-to-be-deleted-5sdg6" in namespace "gc-7932"
    Nov  5 12:18:11.502: INFO: Deleting pod "simpletest-rc-to-be-deleted-5swcx" in namespace "gc-7932"
    Nov  5 12:18:11.513: INFO: Deleting pod "simpletest-rc-to-be-deleted-647bh" in namespace "gc-7932"
    Nov  5 12:18:11.528: INFO: Deleting pod "simpletest-rc-to-be-deleted-69zj8" in namespace "gc-7932"
    Nov  5 12:18:11.540: INFO: Deleting pod "simpletest-rc-to-be-deleted-6f49s" in namespace "gc-7932"
    Nov  5 12:18:11.558: INFO: Deleting pod "simpletest-rc-to-be-deleted-6k68l" in namespace "gc-7932"
    Nov  5 12:18:11.581: INFO: Deleting pod "simpletest-rc-to-be-deleted-6qnmd" in namespace "gc-7932"
    Nov  5 12:18:11.594: INFO: Deleting pod "simpletest-rc-to-be-deleted-7d5gj" in namespace "gc-7932"
    Nov  5 12:18:11.609: INFO: Deleting pod "simpletest-rc-to-be-deleted-7r8pk" in namespace "gc-7932"
    Nov  5 12:18:11.621: INFO: Deleting pod "simpletest-rc-to-be-deleted-84mdw" in namespace "gc-7932"
    Nov  5 12:18:11.633: INFO: Deleting pod "simpletest-rc-to-be-deleted-85blb" in namespace "gc-7932"
    Nov  5 12:18:11.647: INFO: Deleting pod "simpletest-rc-to-be-deleted-8mc8d" in namespace "gc-7932"
    Nov  5 12:18:11.661: INFO: Deleting pod "simpletest-rc-to-be-deleted-8nwct" in namespace "gc-7932"
    Nov  5 12:18:11.673: INFO: Deleting pod "simpletest-rc-to-be-deleted-8sz8r" in namespace "gc-7932"
    Nov  5 12:18:11.794: INFO: Deleting pod "simpletest-rc-to-be-deleted-8xvns" in namespace "gc-7932"
    Nov  5 12:18:11.807: INFO: Deleting pod "simpletest-rc-to-be-deleted-98l2v" in namespace "gc-7932"
    Nov  5 12:18:11.816: INFO: Deleting pod "simpletest-rc-to-be-deleted-99qrk" in namespace "gc-7932"
    Nov  5 12:18:11.828: INFO: Deleting pod "simpletest-rc-to-be-deleted-9c5zr" in namespace "gc-7932"
    Nov  5 12:18:11.840: INFO: Deleting pod "simpletest-rc-to-be-deleted-9cqwx" in namespace "gc-7932"
    Nov  5 12:18:11.855: INFO: Deleting pod "simpletest-rc-to-be-deleted-9fpnw" in namespace "gc-7932"
    Nov  5 12:18:11.872: INFO: Deleting pod "simpletest-rc-to-be-deleted-9hjst" in namespace "gc-7932"
    Nov  5 12:18:11.887: INFO: Deleting pod "simpletest-rc-to-be-deleted-9nh4t" in namespace "gc-7932"
    Nov  5 12:18:11.899: INFO: Deleting pod "simpletest-rc-to-be-deleted-b9zr2" in namespace "gc-7932"
    Nov  5 12:18:11.911: INFO: Deleting pod "simpletest-rc-to-be-deleted-btchz" in namespace "gc-7932"
    Nov  5 12:18:11.925: INFO: Deleting pod "simpletest-rc-to-be-deleted-cfpc4" in namespace "gc-7932"
    Nov  5 12:18:11.939: INFO: Deleting pod "simpletest-rc-to-be-deleted-cnlc9" in namespace "gc-7932"
    Nov  5 12:18:11.950: INFO: Deleting pod "simpletest-rc-to-be-deleted-cnxrv" in namespace "gc-7932"
    Nov  5 12:18:11.960: INFO: Deleting pod "simpletest-rc-to-be-deleted-czgjd" in namespace "gc-7932"
    Nov  5 12:18:12.046: INFO: Deleting pod "simpletest-rc-to-be-deleted-d4t5t" in namespace "gc-7932"
    Nov  5 12:18:12.058: INFO: Deleting pod "simpletest-rc-to-be-deleted-d6d9m" in namespace "gc-7932"
    Nov  5 12:18:12.069: INFO: Deleting pod "simpletest-rc-to-be-deleted-dnh2z" in namespace "gc-7932"
    Nov  5 12:18:12.079: INFO: Deleting pod "simpletest-rc-to-be-deleted-dsclc" in namespace "gc-7932"
    Nov  5 12:18:12.092: INFO: Deleting pod "simpletest-rc-to-be-deleted-dvqww" in namespace "gc-7932"
    Nov  5 12:18:12.116: INFO: Deleting pod "simpletest-rc-to-be-deleted-f54qt" in namespace "gc-7932"
    Nov  5 12:18:12.128: INFO: Deleting pod "simpletest-rc-to-be-deleted-f5vq9" in namespace "gc-7932"
    Nov  5 12:18:12.139: INFO: Deleting pod "simpletest-rc-to-be-deleted-f7lwd" in namespace "gc-7932"
    Nov  5 12:18:12.150: INFO: Deleting pod "simpletest-rc-to-be-deleted-fhddk" in namespace "gc-7932"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov  5 12:18:12.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7932" for this suite. 11/05/22 12:18:12.165
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:18:12.172
Nov  5 12:18:12.172: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename server-version 11/05/22 12:18:12.173
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:12.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:12.191
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 11/05/22 12:18:12.194
STEP: Confirm major version 11/05/22 12:18:12.196
Nov  5 12:18:12.196: INFO: Major version: 1
STEP: Confirm minor version 11/05/22 12:18:12.196
Nov  5 12:18:12.196: INFO: cleanMinorVersion: 25
Nov  5 12:18:12.196: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Nov  5 12:18:12.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-7555" for this suite. 11/05/22 12:18:12.2
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":107,"skipped":1920,"failed":0}
------------------------------
• [0.035 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:18:12.172
    Nov  5 12:18:12.172: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename server-version 11/05/22 12:18:12.173
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:12.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:12.191
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 11/05/22 12:18:12.194
    STEP: Confirm major version 11/05/22 12:18:12.196
    Nov  5 12:18:12.196: INFO: Major version: 1
    STEP: Confirm minor version 11/05/22 12:18:12.196
    Nov  5 12:18:12.196: INFO: cleanMinorVersion: 25
    Nov  5 12:18:12.196: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Nov  5 12:18:12.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-7555" for this suite. 11/05/22 12:18:12.2
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:18:12.207
Nov  5 12:18:12.207: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replicaset 11/05/22 12:18:12.208
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:12.227
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:12.236
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Nov  5 12:18:12.254: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  5 12:18:17.259: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/05/22 12:18:17.259
STEP: Scaling up "test-rs" replicaset  11/05/22 12:18:17.259
Nov  5 12:18:17.270: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 11/05/22 12:18:17.27
W1105 12:18:17.283646      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov  5 12:18:17.286: INFO: observed ReplicaSet test-rs in namespace replicaset-290 with ReadyReplicas 1, AvailableReplicas 1
Nov  5 12:18:17.302: INFO: observed ReplicaSet test-rs in namespace replicaset-290 with ReadyReplicas 1, AvailableReplicas 1
Nov  5 12:18:17.327: INFO: observed ReplicaSet test-rs in namespace replicaset-290 with ReadyReplicas 1, AvailableReplicas 1
Nov  5 12:18:17.334: INFO: observed ReplicaSet test-rs in namespace replicaset-290 with ReadyReplicas 1, AvailableReplicas 1
Nov  5 12:18:22.762: INFO: observed ReplicaSet test-rs in namespace replicaset-290 with ReadyReplicas 2, AvailableReplicas 2
Nov  5 12:18:23.614: INFO: observed Replicaset test-rs in namespace replicaset-290 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov  5 12:18:23.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-290" for this suite. 11/05/22 12:18:23.618
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":108,"skipped":1920,"failed":0}
------------------------------
• [SLOW TEST] [11.417 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:18:12.207
    Nov  5 12:18:12.207: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replicaset 11/05/22 12:18:12.208
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:12.227
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:12.236
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Nov  5 12:18:12.254: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov  5 12:18:17.259: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/05/22 12:18:17.259
    STEP: Scaling up "test-rs" replicaset  11/05/22 12:18:17.259
    Nov  5 12:18:17.270: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 11/05/22 12:18:17.27
    W1105 12:18:17.283646      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov  5 12:18:17.286: INFO: observed ReplicaSet test-rs in namespace replicaset-290 with ReadyReplicas 1, AvailableReplicas 1
    Nov  5 12:18:17.302: INFO: observed ReplicaSet test-rs in namespace replicaset-290 with ReadyReplicas 1, AvailableReplicas 1
    Nov  5 12:18:17.327: INFO: observed ReplicaSet test-rs in namespace replicaset-290 with ReadyReplicas 1, AvailableReplicas 1
    Nov  5 12:18:17.334: INFO: observed ReplicaSet test-rs in namespace replicaset-290 with ReadyReplicas 1, AvailableReplicas 1
    Nov  5 12:18:22.762: INFO: observed ReplicaSet test-rs in namespace replicaset-290 with ReadyReplicas 2, AvailableReplicas 2
    Nov  5 12:18:23.614: INFO: observed Replicaset test-rs in namespace replicaset-290 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov  5 12:18:23.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-290" for this suite. 11/05/22 12:18:23.618
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:18:23.626
Nov  5 12:18:23.626: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 12:18:23.627
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:23.639
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:23.643
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 12:18:23.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7709" for this suite. 11/05/22 12:18:23.654
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":109,"skipped":1928,"failed":0}
------------------------------
• [0.035 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:18:23.626
    Nov  5 12:18:23.626: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 12:18:23.627
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:23.639
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:23.643
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 12:18:23.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7709" for this suite. 11/05/22 12:18:23.654
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:18:23.664
Nov  5 12:18:23.664: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replication-controller 11/05/22 12:18:23.665
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:23.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:23.685
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Nov  5 12:18:23.690: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 11/05/22 12:18:24.706
STEP: Checking rc "condition-test" has the desired failure condition set 11/05/22 12:18:24.712
STEP: Scaling down rc "condition-test" to satisfy pod quota 11/05/22 12:18:25.721
Nov  5 12:18:25.730: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 11/05/22 12:18:25.73
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov  5 12:18:26.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1861" for this suite. 11/05/22 12:18:26.749
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":110,"skipped":1964,"failed":0}
------------------------------
• [3.095 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:18:23.664
    Nov  5 12:18:23.664: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replication-controller 11/05/22 12:18:23.665
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:23.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:23.685
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Nov  5 12:18:23.690: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 11/05/22 12:18:24.706
    STEP: Checking rc "condition-test" has the desired failure condition set 11/05/22 12:18:24.712
    STEP: Scaling down rc "condition-test" to satisfy pod quota 11/05/22 12:18:25.721
    Nov  5 12:18:25.730: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 11/05/22 12:18:25.73
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov  5 12:18:26.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1861" for this suite. 11/05/22 12:18:26.749
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:18:26.759
Nov  5 12:18:26.759: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename daemonsets 11/05/22 12:18:26.76
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:26.779
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:26.785
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 11/05/22 12:18:26.814
STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 12:18:26.82
Nov  5 12:18:26.827: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:18:26.827: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:18:26.831: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:18:26.831: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:18:27.836: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:18:27.836: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:18:27.839: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:18:27.839: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:18:28.835: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:18:28.835: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:18:28.840: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov  5 12:18:28.841: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: listing all DeamonSets 11/05/22 12:18:28.845
STEP: DeleteCollection of the DaemonSets 11/05/22 12:18:28.85
STEP: Verify that ReplicaSets have been deleted 11/05/22 12:18:28.86
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Nov  5 12:18:28.895: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"13485"},"items":null}

Nov  5 12:18:28.905: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"13486"},"items":[{"metadata":{"name":"daemon-set-4qz4l","generateName":"daemon-set-","namespace":"daemonsets-7231","uid":"7c6d7aaf-584d-44f9-94b9-a499923c575f","resourceVersion":"13464","creationTimestamp":"2022-11-05T12:18:26Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f4d9c3b0-8131-45cd-9405-8d3786f27edf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f4d9c3b0-8131-45cd-9405-8d3786f27edf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.75\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-7p9hd","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-7p9hd","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-41-19","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-41-19"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"}],"hostIP":"172.31.41.19","podIP":"192.168.90.75","podIPs":[{"ip":"192.168.90.75"}],"startTime":"2022-11-05T12:18:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-05T12:18:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://a8347bca6928c3354c09090a2489f8b0d3c105b03deb449fd1c3d039bf7c1c6e","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-cnvc4","generateName":"daemon-set-","namespace":"daemonsets-7231","uid":"1a811d38-93fe-4a5f-a153-a383cce078f0","resourceVersion":"13466","creationTimestamp":"2022-11-05T12:18:26Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f4d9c3b0-8131-45cd-9405-8d3786f27edf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f4d9c3b0-8131-45cd-9405-8d3786f27edf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.242.59\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vdwdr","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vdwdr","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-27-199","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-27-199"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"}],"hostIP":"172.31.27.199","podIP":"192.168.242.59","podIPs":[{"ip":"192.168.242.59"}],"startTime":"2022-11-05T12:18:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-05T12:18:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://621dbaff26d4b107cc8b1fa28b9160b22907680d7762dc220cc5d827ea996c71","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-z4tqg","generateName":"daemon-set-","namespace":"daemonsets-7231","uid":"03be6dac-0fc1-4dab-8fd5-62387dc700a5","resourceVersion":"13468","creationTimestamp":"2022-11-05T12:18:26Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f4d9c3b0-8131-45cd-9405-8d3786f27edf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f4d9c3b0-8131-45cd-9405-8d3786f27edf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.128\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-kzq7v","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-kzq7v","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-0-255","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-0-255"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"}],"hostIP":"172.31.0.255","podIP":"192.168.206.128","podIPs":[{"ip":"192.168.206.128"}],"startTime":"2022-11-05T12:18:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-05T12:18:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://961a0c83ed71824fc6ec08c8acc924067f854871e77e9d28399650a05e38039d","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:18:28.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7231" for this suite. 11/05/22 12:18:28.968
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":111,"skipped":1969,"failed":0}
------------------------------
• [2.216 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:18:26.759
    Nov  5 12:18:26.759: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename daemonsets 11/05/22 12:18:26.76
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:26.779
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:26.785
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 11/05/22 12:18:26.814
    STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 12:18:26.82
    Nov  5 12:18:26.827: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:18:26.827: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:18:26.831: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:18:26.831: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:18:27.836: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:18:27.836: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:18:27.839: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:18:27.839: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:18:28.835: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:18:28.835: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:18:28.840: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov  5 12:18:28.841: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: listing all DeamonSets 11/05/22 12:18:28.845
    STEP: DeleteCollection of the DaemonSets 11/05/22 12:18:28.85
    STEP: Verify that ReplicaSets have been deleted 11/05/22 12:18:28.86
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Nov  5 12:18:28.895: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"13485"},"items":null}

    Nov  5 12:18:28.905: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"13486"},"items":[{"metadata":{"name":"daemon-set-4qz4l","generateName":"daemon-set-","namespace":"daemonsets-7231","uid":"7c6d7aaf-584d-44f9-94b9-a499923c575f","resourceVersion":"13464","creationTimestamp":"2022-11-05T12:18:26Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f4d9c3b0-8131-45cd-9405-8d3786f27edf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f4d9c3b0-8131-45cd-9405-8d3786f27edf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.75\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-7p9hd","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-7p9hd","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-41-19","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-41-19"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"}],"hostIP":"172.31.41.19","podIP":"192.168.90.75","podIPs":[{"ip":"192.168.90.75"}],"startTime":"2022-11-05T12:18:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-05T12:18:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://a8347bca6928c3354c09090a2489f8b0d3c105b03deb449fd1c3d039bf7c1c6e","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-cnvc4","generateName":"daemon-set-","namespace":"daemonsets-7231","uid":"1a811d38-93fe-4a5f-a153-a383cce078f0","resourceVersion":"13466","creationTimestamp":"2022-11-05T12:18:26Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f4d9c3b0-8131-45cd-9405-8d3786f27edf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f4d9c3b0-8131-45cd-9405-8d3786f27edf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.242.59\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-vdwdr","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-vdwdr","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-27-199","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-27-199"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"}],"hostIP":"172.31.27.199","podIP":"192.168.242.59","podIPs":[{"ip":"192.168.242.59"}],"startTime":"2022-11-05T12:18:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-05T12:18:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://621dbaff26d4b107cc8b1fa28b9160b22907680d7762dc220cc5d827ea996c71","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-z4tqg","generateName":"daemon-set-","namespace":"daemonsets-7231","uid":"03be6dac-0fc1-4dab-8fd5-62387dc700a5","resourceVersion":"13468","creationTimestamp":"2022-11-05T12:18:26Z","labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"f4d9c3b0-8131-45cd-9405-8d3786f27edf","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:26Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f4d9c3b0-8131-45cd-9405-8d3786f27edf\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2022-11-05T12:18:28Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.128\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-kzq7v","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-kzq7v","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"ip-172-31-0-255","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["ip-172-31-0-255"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:28Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2022-11-05T12:18:26Z"}],"hostIP":"172.31.0.255","podIP":"192.168.206.128","podIPs":[{"ip":"192.168.206.128"}],"startTime":"2022-11-05T12:18:26Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2022-11-05T12:18:27Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://961a0c83ed71824fc6ec08c8acc924067f854871e77e9d28399650a05e38039d","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:18:28.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7231" for this suite. 11/05/22 12:18:28.968
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:18:28.977
Nov  5 12:18:28.977: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:18:28.978
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:29.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:29.006
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 11/05/22 12:18:29.011
Nov  5 12:18:29.011: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7968 proxy --unix-socket=/tmp/kubectl-proxy-unix3681996491/test'
STEP: retrieving proxy /api/ output 11/05/22 12:18:29.115
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:18:29.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7968" for this suite. 11/05/22 12:18:29.124
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":112,"skipped":1983,"failed":0}
------------------------------
• [0.154 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:18:28.977
    Nov  5 12:18:28.977: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:18:28.978
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:29.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:29.006
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 11/05/22 12:18:29.011
    Nov  5 12:18:29.011: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7968 proxy --unix-socket=/tmp/kubectl-proxy-unix3681996491/test'
    STEP: retrieving proxy /api/ output 11/05/22 12:18:29.115
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:18:29.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7968" for this suite. 11/05/22 12:18:29.124
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:18:29.131
Nov  5 12:18:29.131: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replicaset 11/05/22 12:18:29.132
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:29.147
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:29.151
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Nov  5 12:18:29.154: INFO: Creating ReplicaSet my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c
Nov  5 12:18:29.168: INFO: Pod name my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c: Found 0 pods out of 1
Nov  5 12:18:34.173: INFO: Pod name my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c: Found 1 pods out of 1
Nov  5 12:18:34.173: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c" is running
Nov  5 12:18:34.173: INFO: Waiting up to 5m0s for pod "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6" in namespace "replicaset-1274" to be "running"
Nov  5 12:18:34.177: INFO: Pod "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6": Phase="Running", Reason="", readiness=true. Elapsed: 3.925575ms
Nov  5 12:18:34.177: INFO: Pod "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6" satisfied condition "running"
Nov  5 12:18:34.177: INFO: Pod "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:18:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:18:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:18:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:18:29 +0000 UTC Reason: Message:}])
Nov  5 12:18:34.177: INFO: Trying to dial the pod
Nov  5 12:18:39.193: INFO: Controller my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c: Got expected result from replica 1 [my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6]: "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov  5 12:18:39.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1274" for this suite. 11/05/22 12:18:39.197
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":113,"skipped":1983,"failed":0}
------------------------------
• [SLOW TEST] [10.072 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:18:29.131
    Nov  5 12:18:29.131: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replicaset 11/05/22 12:18:29.132
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:29.147
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:29.151
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Nov  5 12:18:29.154: INFO: Creating ReplicaSet my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c
    Nov  5 12:18:29.168: INFO: Pod name my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c: Found 0 pods out of 1
    Nov  5 12:18:34.173: INFO: Pod name my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c: Found 1 pods out of 1
    Nov  5 12:18:34.173: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c" is running
    Nov  5 12:18:34.173: INFO: Waiting up to 5m0s for pod "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6" in namespace "replicaset-1274" to be "running"
    Nov  5 12:18:34.177: INFO: Pod "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6": Phase="Running", Reason="", readiness=true. Elapsed: 3.925575ms
    Nov  5 12:18:34.177: INFO: Pod "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6" satisfied condition "running"
    Nov  5 12:18:34.177: INFO: Pod "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:18:29 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:18:30 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:18:30 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:18:29 +0000 UTC Reason: Message:}])
    Nov  5 12:18:34.177: INFO: Trying to dial the pod
    Nov  5 12:18:39.193: INFO: Controller my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c: Got expected result from replica 1 [my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6]: "my-hostname-basic-2694e1cf-f25e-440e-ba21-2080fbe9825c-lcqr6", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov  5 12:18:39.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1274" for this suite. 11/05/22 12:18:39.197
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:18:39.204
Nov  5 12:18:39.204: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:18:39.205
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:39.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:39.231
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/05/22 12:18:39.236
Nov  5 12:18:39.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-5276 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Nov  5 12:18:39.313: INFO: stderr: ""
Nov  5 12:18:39.313: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 11/05/22 12:18:39.313
STEP: verifying the pod e2e-test-httpd-pod was created 11/05/22 12:18:44.365
Nov  5 12:18:44.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-5276 get pod e2e-test-httpd-pod -o json'
Nov  5 12:18:44.426: INFO: stderr: ""
Nov  5 12:18:44.426: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-11-05T12:18:39Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5276\",\n        \"resourceVersion\": \"13663\",\n        \"uid\": \"086cd37d-fe4c-4457-b096-5a813fcf6c04\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-jgbz9\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-0-255\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-jgbz9\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-05T12:18:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-05T12:18:40Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-05T12:18:40Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-05T12:18:39Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://8069d8b9a574e5d35457c9e86f2e6738711694095ce08487dc8aa23884237f92\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-11-05T12:18:40Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.0.255\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.206.132\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.206.132\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-11-05T12:18:39Z\"\n    }\n}\n"
STEP: replace the image in the pod 11/05/22 12:18:44.426
Nov  5 12:18:44.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-5276 replace -f -'
Nov  5 12:18:45.192: INFO: stderr: ""
Nov  5 12:18:45.192: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 11/05/22 12:18:45.192
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Nov  5 12:18:45.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-5276 delete pods e2e-test-httpd-pod'
Nov  5 12:18:47.375: INFO: stderr: ""
Nov  5 12:18:47.375: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:18:47.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5276" for this suite. 11/05/22 12:18:47.379
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":114,"skipped":1997,"failed":0}
------------------------------
• [SLOW TEST] [8.182 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:18:39.204
    Nov  5 12:18:39.204: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:18:39.205
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:39.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:39.231
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/05/22 12:18:39.236
    Nov  5 12:18:39.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-5276 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Nov  5 12:18:39.313: INFO: stderr: ""
    Nov  5 12:18:39.313: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 11/05/22 12:18:39.313
    STEP: verifying the pod e2e-test-httpd-pod was created 11/05/22 12:18:44.365
    Nov  5 12:18:44.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-5276 get pod e2e-test-httpd-pod -o json'
    Nov  5 12:18:44.426: INFO: stderr: ""
    Nov  5 12:18:44.426: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2022-11-05T12:18:39Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5276\",\n        \"resourceVersion\": \"13663\",\n        \"uid\": \"086cd37d-fe4c-4457-b096-5a813fcf6c04\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-jgbz9\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-172-31-0-255\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-jgbz9\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-05T12:18:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-05T12:18:40Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-05T12:18:40Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2022-11-05T12:18:39Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://8069d8b9a574e5d35457c9e86f2e6738711694095ce08487dc8aa23884237f92\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2022-11-05T12:18:40Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.0.255\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.206.132\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.206.132\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2022-11-05T12:18:39Z\"\n    }\n}\n"
    STEP: replace the image in the pod 11/05/22 12:18:44.426
    Nov  5 12:18:44.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-5276 replace -f -'
    Nov  5 12:18:45.192: INFO: stderr: ""
    Nov  5 12:18:45.192: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 11/05/22 12:18:45.192
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Nov  5 12:18:45.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-5276 delete pods e2e-test-httpd-pod'
    Nov  5 12:18:47.375: INFO: stderr: ""
    Nov  5 12:18:47.375: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:18:47.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5276" for this suite. 11/05/22 12:18:47.379
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:18:47.387
Nov  5 12:18:47.387: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 12:18:47.387
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:47.4
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:47.405
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189
STEP: creating service in namespace services-9955 11/05/22 12:18:47.408
STEP: creating service affinity-clusterip-transition in namespace services-9955 11/05/22 12:18:47.409
STEP: creating replication controller affinity-clusterip-transition in namespace services-9955 11/05/22 12:18:47.418
I1105 12:18:47.432789      20 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-9955, replica count: 3
I1105 12:18:50.483076      20 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 12:18:50.491: INFO: Creating new exec pod
Nov  5 12:18:50.497: INFO: Waiting up to 5m0s for pod "execpod-affinitygvcds" in namespace "services-9955" to be "running"
Nov  5 12:18:50.504: INFO: Pod "execpod-affinitygvcds": Phase="Pending", Reason="", readiness=false. Elapsed: 7.346113ms
Nov  5 12:18:52.508: INFO: Pod "execpod-affinitygvcds": Phase="Running", Reason="", readiness=true. Elapsed: 2.01104688s
Nov  5 12:18:52.508: INFO: Pod "execpod-affinitygvcds" satisfied condition "running"
Nov  5 12:18:53.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-9955 exec execpod-affinitygvcds -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Nov  5 12:18:53.691: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Nov  5 12:18:53.691: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 12:18:53.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-9955 exec execpod-affinitygvcds -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.52 80'
Nov  5 12:18:53.899: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.52 80\nConnection to 10.152.183.52 80 port [tcp/http] succeeded!\n"
Nov  5 12:18:53.899: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 12:18:53.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-9955 exec execpod-affinitygvcds -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.52:80/ ; done'
Nov  5 12:18:54.181: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n"
Nov  5 12:18:54.181: INFO: stdout: "\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-r5rpz\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-r5rpz\naffinity-clusterip-transition-r5rpz\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-r5rpz\naffinity-clusterip-transition-r5rpz\naffinity-clusterip-transition-lwj4z"
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-r5rpz
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-r5rpz
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-r5rpz
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-r5rpz
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-r5rpz
Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
Nov  5 12:18:54.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-9955 exec execpod-affinitygvcds -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.52:80/ ; done'
Nov  5 12:18:54.464: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n"
Nov  5 12:18:54.464: INFO: stdout: "\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4"
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
Nov  5 12:18:54.464: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-9955, will wait for the garbage collector to delete the pods 11/05/22 12:18:54.478
Nov  5 12:18:54.538: INFO: Deleting ReplicationController affinity-clusterip-transition took: 6.059046ms
Nov  5 12:18:54.639: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.370473ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 12:18:56.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9955" for this suite. 11/05/22 12:18:56.462
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":115,"skipped":1997,"failed":0}
------------------------------
• [SLOW TEST] [9.082 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:18:47.387
    Nov  5 12:18:47.387: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 12:18:47.387
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:47.4
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:47.405
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2189
    STEP: creating service in namespace services-9955 11/05/22 12:18:47.408
    STEP: creating service affinity-clusterip-transition in namespace services-9955 11/05/22 12:18:47.409
    STEP: creating replication controller affinity-clusterip-transition in namespace services-9955 11/05/22 12:18:47.418
    I1105 12:18:47.432789      20 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-9955, replica count: 3
    I1105 12:18:50.483076      20 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 12:18:50.491: INFO: Creating new exec pod
    Nov  5 12:18:50.497: INFO: Waiting up to 5m0s for pod "execpod-affinitygvcds" in namespace "services-9955" to be "running"
    Nov  5 12:18:50.504: INFO: Pod "execpod-affinitygvcds": Phase="Pending", Reason="", readiness=false. Elapsed: 7.346113ms
    Nov  5 12:18:52.508: INFO: Pod "execpod-affinitygvcds": Phase="Running", Reason="", readiness=true. Elapsed: 2.01104688s
    Nov  5 12:18:52.508: INFO: Pod "execpod-affinitygvcds" satisfied condition "running"
    Nov  5 12:18:53.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-9955 exec execpod-affinitygvcds -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Nov  5 12:18:53.691: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip-transition 80\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Nov  5 12:18:53.691: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 12:18:53.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-9955 exec execpod-affinitygvcds -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.52 80'
    Nov  5 12:18:53.899: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.52 80\nConnection to 10.152.183.52 80 port [tcp/http] succeeded!\n"
    Nov  5 12:18:53.899: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 12:18:53.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-9955 exec execpod-affinitygvcds -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.52:80/ ; done'
    Nov  5 12:18:54.181: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n"
    Nov  5 12:18:54.181: INFO: stdout: "\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-r5rpz\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-r5rpz\naffinity-clusterip-transition-r5rpz\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-lwj4z\naffinity-clusterip-transition-r5rpz\naffinity-clusterip-transition-r5rpz\naffinity-clusterip-transition-lwj4z"
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-r5rpz
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-r5rpz
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-r5rpz
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-r5rpz
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-r5rpz
    Nov  5 12:18:54.181: INFO: Received response from host: affinity-clusterip-transition-lwj4z
    Nov  5 12:18:54.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-9955 exec execpod-affinitygvcds -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.52:80/ ; done'
    Nov  5 12:18:54.464: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.52:80/\n"
    Nov  5 12:18:54.464: INFO: stdout: "\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4\naffinity-clusterip-transition-25xd4"
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Received response from host: affinity-clusterip-transition-25xd4
    Nov  5 12:18:54.464: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-9955, will wait for the garbage collector to delete the pods 11/05/22 12:18:54.478
    Nov  5 12:18:54.538: INFO: Deleting ReplicationController affinity-clusterip-transition took: 6.059046ms
    Nov  5 12:18:54.639: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.370473ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 12:18:56.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9955" for this suite. 11/05/22 12:18:56.462
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:18:56.47
Nov  5 12:18:56.470: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename prestop 11/05/22 12:18:56.47
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:56.486
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:56.49
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-5488 11/05/22 12:18:56.494
STEP: Waiting for pods to come up. 11/05/22 12:18:56.503
Nov  5 12:18:56.503: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-5488" to be "running"
Nov  5 12:18:56.506: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 3.044814ms
Nov  5 12:18:58.511: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.007620515s
Nov  5 12:18:58.511: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-5488 11/05/22 12:18:58.514
Nov  5 12:18:58.521: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-5488" to be "running"
Nov  5 12:18:58.528: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 6.669627ms
Nov  5 12:19:00.533: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.011524085s
Nov  5 12:19:00.533: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 11/05/22 12:19:00.533
Nov  5 12:19:05.551: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 11/05/22 12:19:05.551
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Nov  5 12:19:05.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5488" for this suite. 11/05/22 12:19:05.565
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":116,"skipped":2030,"failed":0}
------------------------------
• [SLOW TEST] [9.102 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:18:56.47
    Nov  5 12:18:56.470: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename prestop 11/05/22 12:18:56.47
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:18:56.486
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:18:56.49
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-5488 11/05/22 12:18:56.494
    STEP: Waiting for pods to come up. 11/05/22 12:18:56.503
    Nov  5 12:18:56.503: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-5488" to be "running"
    Nov  5 12:18:56.506: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 3.044814ms
    Nov  5 12:18:58.511: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.007620515s
    Nov  5 12:18:58.511: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-5488 11/05/22 12:18:58.514
    Nov  5 12:18:58.521: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-5488" to be "running"
    Nov  5 12:18:58.528: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 6.669627ms
    Nov  5 12:19:00.533: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.011524085s
    Nov  5 12:19:00.533: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 11/05/22 12:19:00.533
    Nov  5 12:19:05.551: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 11/05/22 12:19:05.551
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Nov  5 12:19:05.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-5488" for this suite. 11/05/22 12:19:05.565
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:19:05.572
Nov  5 12:19:05.572: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename deployment 11/05/22 12:19:05.573
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:05.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:05.588
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Nov  5 12:19:05.591: INFO: Creating deployment "webserver-deployment"
Nov  5 12:19:05.597: INFO: Waiting for observed generation 1
Nov  5 12:19:07.607: INFO: Waiting for all required pods to come up
Nov  5 12:19:07.611: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 11/05/22 12:19:07.611
Nov  5 12:19:07.611: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-f77dk" in namespace "deployment-7713" to be "running"
Nov  5 12:19:07.611: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-fd6g6" in namespace "deployment-7713" to be "running"
Nov  5 12:19:07.615: INFO: Pod "webserver-deployment-845c8977d9-f77dk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.542406ms
Nov  5 12:19:07.615: INFO: Pod "webserver-deployment-845c8977d9-fd6g6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.814186ms
Nov  5 12:19:09.620: INFO: Pod "webserver-deployment-845c8977d9-f77dk": Phase="Running", Reason="", readiness=true. Elapsed: 2.008173359s
Nov  5 12:19:09.620: INFO: Pod "webserver-deployment-845c8977d9-f77dk" satisfied condition "running"
Nov  5 12:19:09.620: INFO: Pod "webserver-deployment-845c8977d9-fd6g6": Phase="Running", Reason="", readiness=true. Elapsed: 2.008584344s
Nov  5 12:19:09.620: INFO: Pod "webserver-deployment-845c8977d9-fd6g6" satisfied condition "running"
Nov  5 12:19:09.620: INFO: Waiting for deployment "webserver-deployment" to complete
Nov  5 12:19:09.627: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov  5 12:19:09.638: INFO: Updating deployment webserver-deployment
Nov  5 12:19:09.638: INFO: Waiting for observed generation 2
Nov  5 12:19:11.651: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov  5 12:19:11.654: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov  5 12:19:11.657: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  5 12:19:11.667: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov  5 12:19:11.667: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov  5 12:19:11.671: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  5 12:19:11.677: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov  5 12:19:11.677: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov  5 12:19:11.686: INFO: Updating deployment webserver-deployment
Nov  5 12:19:11.686: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov  5 12:19:11.697: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov  5 12:19:11.701: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov  5 12:19:11.723: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-7713  830b2f2f-9123-4ece-8af2-f051a1533a7e 14224 3 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0048f0018 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-11-05 12:19:09 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-05 12:19:11 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov  5 12:19:11.732: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-7713  192c1133-ab49-4fa7-b400-e6555fa3f95f 14220 3 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 830b2f2f-9123-4ece-8af2-f051a1533a7e 0xc0048f0467 0xc0048f0468}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"830b2f2f-9123-4ece-8af2-f051a1533a7e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0048f0508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  5 12:19:11.732: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov  5 12:19:11.732: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-7713  c86d57d0-9d98-4472-803b-25a610a9e163 14219 3 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 830b2f2f-9123-4ece-8af2-f051a1533a7e 0xc0048f0567 0xc0048f0568}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"830b2f2f-9123-4ece-8af2-f051a1533a7e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0048f05f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov  5 12:19:11.746: INFO: Pod "webserver-deployment-69b7448995-82nkp" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-82nkp webserver-deployment-69b7448995- deployment-7713  a9203c16-ff4c-4ba8-88b2-ea178f43b4e3 14207 0 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c8647 0xc0049c8648}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.242.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-blftb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-blftb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-27-199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.27.199,PodIP:192.168.242.7,StartTime:2022-11-05 12:19:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.242.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.746: INFO: Pod "webserver-deployment-69b7448995-cm2mr" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-cm2mr webserver-deployment-69b7448995- deployment-7713  a7b0e8ff-953f-4617-99f9-780ecdb21a94 14209 0 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c8867 0xc0049c8868}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.81\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6ggvv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6ggvv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.81,StartTime:2022-11-05 12:19:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.746: INFO: Pod "webserver-deployment-69b7448995-fg2mp" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fg2mp webserver-deployment-69b7448995- deployment-7713  1e91e710-66c6-4fc7-ac19-7a121b9cee5b 14238 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c8a97 0xc0049c8a98}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7qljt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7qljt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.746: INFO: Pod "webserver-deployment-69b7448995-fvg2r" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fvg2r webserver-deployment-69b7448995- deployment-7713  cc5d129d-1a18-4005-b51c-5ce4075d7fae 14237 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c8c10 0xc0049c8c11}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-87t6m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-87t6m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-27-199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.27.199,PodIP:,StartTime:2022-11-05 12:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.747: INFO: Pod "webserver-deployment-69b7448995-jmww2" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jmww2 webserver-deployment-69b7448995- deployment-7713  764d6cf0-6b1b-442f-93d8-ddf4bed5d3ce 14215 0 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c8df7 0xc0049c8df8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.144\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rhwwx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rhwwx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.144,StartTime:2022-11-05 12:19:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.747: INFO: Pod "webserver-deployment-69b7448995-ljwb5" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-ljwb5 webserver-deployment-69b7448995- deployment-7713  30eeaf8c-3473-47c5-b9b2-481d1d2323b4 14235 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c9017 0xc0049c9018}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mvdd2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mvdd2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.747: INFO: Pod "webserver-deployment-69b7448995-qxvht" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-qxvht webserver-deployment-69b7448995- deployment-7713  734217ce-122b-4aae-9cc3-a5a35f31b4d5 14231 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c9187 0xc0049c9188}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w2hhg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w2hhg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.747: INFO: Pod "webserver-deployment-69b7448995-rwm4x" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-rwm4x webserver-deployment-69b7448995- deployment-7713  55aa79be-b076-43ac-8fb8-8410d55290e2 14212 0 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c92d7 0xc0049c92d8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.141\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dvpbm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dvpbm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.141,StartTime:2022-11-05 12:19:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.141,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.748: INFO: Pod "webserver-deployment-69b7448995-sfvr8" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-sfvr8 webserver-deployment-69b7448995- deployment-7713  ada2e25c-f7e4-4beb-9c02-d47694b99fe4 14203 0 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c94f7 0xc0049c94f8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.80\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7hkm9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7hkm9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.80,StartTime:2022-11-05 12:19:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.80,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.748: INFO: Pod "webserver-deployment-845c8977d9-4d9rz" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4d9rz webserver-deployment-845c8977d9- deployment-7713  ec59acfc-2eb6-4a3f-ba0f-f43c873e0bc5 14083 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc0049c9717 0xc0049c9718}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.137\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qsqt6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qsqt6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.137,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://49376f246930401b8009f4bb75f50ae6ae66e98801863b1106dce2b7f594c111,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.137,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.748: INFO: Pod "webserver-deployment-845c8977d9-4znd6" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-4znd6 webserver-deployment-845c8977d9- deployment-7713  075c117c-fe1a-42ca-b6e6-2faeff91174d 14087 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc0049c9907 0xc0049c9908}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.139\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2skgp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2skgp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.139,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f0b527f78cf73682c150ce91877580bf8bbf166bfda7cd3af69f9674ef1980b8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.139,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.748: INFO: Pod "webserver-deployment-845c8977d9-6h7ql" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-6h7ql webserver-deployment-845c8977d9- deployment-7713  1a7ad01a-bc45-41e4-b04c-e66b4261b6ce 14077 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc0049c9b07 0xc0049c9b08}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.242.63\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w28k2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w28k2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-27-199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.27.199,PodIP:192.168.242.63,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://516c84f1b1703a07824482af0188f256dedb202570f212b2dd235b8cf1b982ca,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.242.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.749: INFO: Pod "webserver-deployment-845c8977d9-7mbbp" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-7mbbp webserver-deployment-845c8977d9- deployment-7713  42a30080-f310-428d-a6db-83ca17b4e380 14072 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc0049c9d07 0xc0049c9d08}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.242.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cx52p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cx52p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-27-199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.27.199,PodIP:192.168.242.62,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://371f5e8d5a88b88d682b7514a2aa2d6c2ea602316fbcff0419fa95efb389deac,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.242.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.749: INFO: Pod "webserver-deployment-845c8977d9-9qf2x" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-9qf2x webserver-deployment-845c8977d9- deployment-7713  15ec893a-0190-4c56-b4cc-f5467deab21a 14234 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc0049c9f07 0xc0049c9f08}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nj466,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nj466,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.749: INFO: Pod "webserver-deployment-845c8977d9-b66kx" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-b66kx webserver-deployment-845c8977d9- deployment-7713  94a1e266-1015-46e3-9308-a4fcc4803bb4 14229 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c02047 0xc000c02048}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vnl7q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vnl7q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.749: INFO: Pod "webserver-deployment-845c8977d9-fd6g6" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-fd6g6 webserver-deployment-845c8977d9- deployment-7713  6c779eef-9159-4ad8-9955-22028cf6aed1 14090 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c02197 0xc000c02198}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.138\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wvm6s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wvm6s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.138,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://47e83cb353f9b82fe91ab7ff133cf4f69683e3b363ec899388be4414574646a5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.138,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.749: INFO: Pod "webserver-deployment-845c8977d9-gwjr4" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gwjr4 webserver-deployment-845c8977d9- deployment-7713  4882d721-70d3-4984-b8dd-ef151a72932e 14066 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c02517 0xc000c02518}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.242.61\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sjs46,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sjs46,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-27-199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.27.199,PodIP:192.168.242.61,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b463f002226011e926b52ff5f4360a1ca1b0e7e0f88b9716d7e1a71f7c8f81f9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.242.61,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.750: INFO: Pod "webserver-deployment-845c8977d9-hgws8" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-hgws8 webserver-deployment-845c8977d9- deployment-7713  6f76908f-57df-4b83-bde7-f98812584152 14227 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c02e87 0xc000c02e88}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wgsqf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wgsqf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.750: INFO: Pod "webserver-deployment-845c8977d9-mxqq2" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-mxqq2 webserver-deployment-845c8977d9- deployment-7713  257c53b4-b0d9-4c0c-9d1d-d02f20b7a018 14068 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c032f7 0xc000c032f8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.79\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6hsll,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6hsll,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.79,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6ea9534d5d1fbb0b662fba30060641ef8e2de2f5bf4c229fa4ed82c517afa70c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.79,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.750: INFO: Pod "webserver-deployment-845c8977d9-tgr5l" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-tgr5l webserver-deployment-845c8977d9- deployment-7713  c4a92179-07d0-4b29-b5b1-441b08c80cc5 14236 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c034e7 0xc000c034e8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dlcfw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dlcfw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:,StartTime:2022-11-05 12:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:19:11.750: INFO: Pod "webserver-deployment-845c8977d9-twd86" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-twd86 webserver-deployment-845c8977d9- deployment-7713  29650fe0-2ada-46d0-99d2-3edb50f808a6 14064 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c036b7 0xc000c036b8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.78\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tgmxv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tgmxv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.78,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9502763ef7ef5efddde2ca455ca44cfe523aa7052a5595d57a5c815214f201ac,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.78,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov  5 12:19:11.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7713" for this suite. 11/05/22 12:19:11.762
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":117,"skipped":2039,"failed":0}
------------------------------
• [SLOW TEST] [6.235 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:19:05.572
    Nov  5 12:19:05.572: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename deployment 11/05/22 12:19:05.573
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:05.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:05.588
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Nov  5 12:19:05.591: INFO: Creating deployment "webserver-deployment"
    Nov  5 12:19:05.597: INFO: Waiting for observed generation 1
    Nov  5 12:19:07.607: INFO: Waiting for all required pods to come up
    Nov  5 12:19:07.611: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 11/05/22 12:19:07.611
    Nov  5 12:19:07.611: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-f77dk" in namespace "deployment-7713" to be "running"
    Nov  5 12:19:07.611: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-fd6g6" in namespace "deployment-7713" to be "running"
    Nov  5 12:19:07.615: INFO: Pod "webserver-deployment-845c8977d9-f77dk": Phase="Pending", Reason="", readiness=false. Elapsed: 3.542406ms
    Nov  5 12:19:07.615: INFO: Pod "webserver-deployment-845c8977d9-fd6g6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.814186ms
    Nov  5 12:19:09.620: INFO: Pod "webserver-deployment-845c8977d9-f77dk": Phase="Running", Reason="", readiness=true. Elapsed: 2.008173359s
    Nov  5 12:19:09.620: INFO: Pod "webserver-deployment-845c8977d9-f77dk" satisfied condition "running"
    Nov  5 12:19:09.620: INFO: Pod "webserver-deployment-845c8977d9-fd6g6": Phase="Running", Reason="", readiness=true. Elapsed: 2.008584344s
    Nov  5 12:19:09.620: INFO: Pod "webserver-deployment-845c8977d9-fd6g6" satisfied condition "running"
    Nov  5 12:19:09.620: INFO: Waiting for deployment "webserver-deployment" to complete
    Nov  5 12:19:09.627: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Nov  5 12:19:09.638: INFO: Updating deployment webserver-deployment
    Nov  5 12:19:09.638: INFO: Waiting for observed generation 2
    Nov  5 12:19:11.651: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Nov  5 12:19:11.654: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Nov  5 12:19:11.657: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Nov  5 12:19:11.667: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Nov  5 12:19:11.667: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Nov  5 12:19:11.671: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Nov  5 12:19:11.677: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Nov  5 12:19:11.677: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Nov  5 12:19:11.686: INFO: Updating deployment webserver-deployment
    Nov  5 12:19:11.686: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Nov  5 12:19:11.697: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Nov  5 12:19:11.701: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov  5 12:19:11.723: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-7713  830b2f2f-9123-4ece-8af2-f051a1533a7e 14224 3 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0048f0018 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2022-11-05 12:19:09 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-05 12:19:11 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

    Nov  5 12:19:11.732: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-7713  192c1133-ab49-4fa7-b400-e6555fa3f95f 14220 3 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 830b2f2f-9123-4ece-8af2-f051a1533a7e 0xc0048f0467 0xc0048f0468}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"830b2f2f-9123-4ece-8af2-f051a1533a7e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0048f0508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 12:19:11.732: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Nov  5 12:19:11.732: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-7713  c86d57d0-9d98-4472-803b-25a610a9e163 14219 3 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 830b2f2f-9123-4ece-8af2-f051a1533a7e 0xc0048f0567 0xc0048f0568}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status} {kube-controller-manager Update apps/v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"830b2f2f-9123-4ece-8af2-f051a1533a7e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} }]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0048f05f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 12:19:11.746: INFO: Pod "webserver-deployment-69b7448995-82nkp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-82nkp webserver-deployment-69b7448995- deployment-7713  a9203c16-ff4c-4ba8-88b2-ea178f43b4e3 14207 0 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c8647 0xc0049c8648}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.242.7\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-blftb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-blftb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-27-199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.27.199,PodIP:192.168.242.7,StartTime:2022-11-05 12:19:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.242.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.746: INFO: Pod "webserver-deployment-69b7448995-cm2mr" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-cm2mr webserver-deployment-69b7448995- deployment-7713  a7b0e8ff-953f-4617-99f9-780ecdb21a94 14209 0 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c8867 0xc0049c8868}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.81\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6ggvv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6ggvv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.81,StartTime:2022-11-05 12:19:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.746: INFO: Pod "webserver-deployment-69b7448995-fg2mp" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fg2mp webserver-deployment-69b7448995- deployment-7713  1e91e710-66c6-4fc7-ac19-7a121b9cee5b 14238 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c8a97 0xc0049c8a98}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7qljt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7qljt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.746: INFO: Pod "webserver-deployment-69b7448995-fvg2r" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fvg2r webserver-deployment-69b7448995- deployment-7713  cc5d129d-1a18-4005-b51c-5ce4075d7fae 14237 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c8c10 0xc0049c8c11}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-87t6m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-87t6m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-27-199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.27.199,PodIP:,StartTime:2022-11-05 12:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.747: INFO: Pod "webserver-deployment-69b7448995-jmww2" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jmww2 webserver-deployment-69b7448995- deployment-7713  764d6cf0-6b1b-442f-93d8-ddf4bed5d3ce 14215 0 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c8df7 0xc0049c8df8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.144\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rhwwx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rhwwx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.144,StartTime:2022-11-05 12:19:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.747: INFO: Pod "webserver-deployment-69b7448995-ljwb5" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-ljwb5 webserver-deployment-69b7448995- deployment-7713  30eeaf8c-3473-47c5-b9b2-481d1d2323b4 14235 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c9017 0xc0049c9018}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-mvdd2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-mvdd2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.747: INFO: Pod "webserver-deployment-69b7448995-qxvht" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-qxvht webserver-deployment-69b7448995- deployment-7713  734217ce-122b-4aae-9cc3-a5a35f31b4d5 14231 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c9187 0xc0049c9188}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w2hhg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w2hhg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.747: INFO: Pod "webserver-deployment-69b7448995-rwm4x" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-rwm4x webserver-deployment-69b7448995- deployment-7713  55aa79be-b076-43ac-8fb8-8410d55290e2 14212 0 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c92d7 0xc0049c92d8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.141\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dvpbm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dvpbm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.141,StartTime:2022-11-05 12:19:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.141,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.748: INFO: Pod "webserver-deployment-69b7448995-sfvr8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-sfvr8 webserver-deployment-69b7448995- deployment-7713  ada2e25c-f7e4-4beb-9c02-d47694b99fe4 14203 0 2022-11-05 12:19:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 192c1133-ab49-4fa7-b400-e6555fa3f95f 0xc0049c94f7 0xc0049c94f8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:09 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"192c1133-ab49-4fa7-b400-e6555fa3f95f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.80\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7hkm9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7hkm9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.80,StartTime:2022-11-05 12:19:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.80,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.748: INFO: Pod "webserver-deployment-845c8977d9-4d9rz" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4d9rz webserver-deployment-845c8977d9- deployment-7713  ec59acfc-2eb6-4a3f-ba0f-f43c873e0bc5 14083 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc0049c9717 0xc0049c9718}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.137\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qsqt6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qsqt6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.137,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://49376f246930401b8009f4bb75f50ae6ae66e98801863b1106dce2b7f594c111,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.137,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.748: INFO: Pod "webserver-deployment-845c8977d9-4znd6" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-4znd6 webserver-deployment-845c8977d9- deployment-7713  075c117c-fe1a-42ca-b6e6-2faeff91174d 14087 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc0049c9907 0xc0049c9908}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.139\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2skgp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2skgp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.139,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f0b527f78cf73682c150ce91877580bf8bbf166bfda7cd3af69f9674ef1980b8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.139,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.748: INFO: Pod "webserver-deployment-845c8977d9-6h7ql" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-6h7ql webserver-deployment-845c8977d9- deployment-7713  1a7ad01a-bc45-41e4-b04c-e66b4261b6ce 14077 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc0049c9b07 0xc0049c9b08}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.242.63\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-w28k2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-w28k2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-27-199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.27.199,PodIP:192.168.242.63,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://516c84f1b1703a07824482af0188f256dedb202570f212b2dd235b8cf1b982ca,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.242.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.749: INFO: Pod "webserver-deployment-845c8977d9-7mbbp" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-7mbbp webserver-deployment-845c8977d9- deployment-7713  42a30080-f310-428d-a6db-83ca17b4e380 14072 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc0049c9d07 0xc0049c9d08}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.242.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cx52p,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cx52p,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-27-199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.27.199,PodIP:192.168.242.62,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://371f5e8d5a88b88d682b7514a2aa2d6c2ea602316fbcff0419fa95efb389deac,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.242.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.749: INFO: Pod "webserver-deployment-845c8977d9-9qf2x" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-9qf2x webserver-deployment-845c8977d9- deployment-7713  15ec893a-0190-4c56-b4cc-f5467deab21a 14234 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc0049c9f07 0xc0049c9f08}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-nj466,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-nj466,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.749: INFO: Pod "webserver-deployment-845c8977d9-b66kx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-b66kx webserver-deployment-845c8977d9- deployment-7713  94a1e266-1015-46e3-9308-a4fcc4803bb4 14229 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c02047 0xc000c02048}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-vnl7q,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-vnl7q,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.749: INFO: Pod "webserver-deployment-845c8977d9-fd6g6" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-fd6g6 webserver-deployment-845c8977d9- deployment-7713  6c779eef-9159-4ad8-9955-22028cf6aed1 14090 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c02197 0xc000c02198}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.138\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wvm6s,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wvm6s,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.138,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://47e83cb353f9b82fe91ab7ff133cf4f69683e3b363ec899388be4414574646a5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.138,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.749: INFO: Pod "webserver-deployment-845c8977d9-gwjr4" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gwjr4 webserver-deployment-845c8977d9- deployment-7713  4882d721-70d3-4984-b8dd-ef151a72932e 14066 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c02517 0xc000c02518}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.242.61\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sjs46,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sjs46,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-27-199,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.27.199,PodIP:192.168.242.61,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b463f002226011e926b52ff5f4360a1ca1b0e7e0f88b9716d7e1a71f7c8f81f9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.242.61,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.750: INFO: Pod "webserver-deployment-845c8977d9-hgws8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-hgws8 webserver-deployment-845c8977d9- deployment-7713  6f76908f-57df-4b83-bde7-f98812584152 14227 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c02e87 0xc000c02e88}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wgsqf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wgsqf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.750: INFO: Pod "webserver-deployment-845c8977d9-mxqq2" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-mxqq2 webserver-deployment-845c8977d9- deployment-7713  257c53b4-b0d9-4c0c-9d1d-d02f20b7a018 14068 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c032f7 0xc000c032f8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.79\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6hsll,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6hsll,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.79,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://6ea9534d5d1fbb0b662fba30060641ef8e2de2f5bf4c229fa4ed82c517afa70c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.79,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.750: INFO: Pod "webserver-deployment-845c8977d9-tgr5l" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-tgr5l webserver-deployment-845c8977d9- deployment-7713  c4a92179-07d0-4b29-b5b1-441b08c80cc5 14236 0 2022-11-05 12:19:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c034e7 0xc000c034e8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:11 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dlcfw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dlcfw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:,StartTime:2022-11-05 12:19:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:19:11.750: INFO: Pod "webserver-deployment-845c8977d9-twd86" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-twd86 webserver-deployment-845c8977d9- deployment-7713  29650fe0-2ada-46d0-99d2-3edb50f808a6 14064 0 2022-11-05 12:19:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 c86d57d0-9d98-4472-803b-25a610a9e163 0xc000c036b7 0xc000c036b8}] [] [{kube-controller-manager Update v1 2022-11-05 12:19:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c86d57d0-9d98-4472-803b-25a610a9e163\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:19:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.78\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-tgmxv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-tgmxv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:19:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.78,StartTime:2022-11-05 12:19:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:19:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://9502763ef7ef5efddde2ca455ca44cfe523aa7052a5595d57a5c815214f201ac,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.78,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov  5 12:19:11.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7713" for this suite. 11/05/22 12:19:11.762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:19:11.809
Nov  5 12:19:11.809: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 12:19:11.811
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:12.015
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:12.019
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 11/05/22 12:19:12.023
Nov  5 12:19:12.034: INFO: Waiting up to 5m0s for pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12" in namespace "pods-631" to be "running and ready"
Nov  5 12:19:12.040: INFO: Pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12": Phase="Pending", Reason="", readiness=false. Elapsed: 5.976606ms
Nov  5 12:19:12.040: INFO: The phase of Pod pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:19:14.044: INFO: Pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010576943s
Nov  5 12:19:14.044: INFO: The phase of Pod pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:19:16.045: INFO: Pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010744126s
Nov  5 12:19:16.045: INFO: The phase of Pod pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:19:18.045: INFO: Pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12": Phase="Running", Reason="", readiness=true. Elapsed: 6.011364562s
Nov  5 12:19:18.045: INFO: The phase of Pod pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12 is Running (Ready = true)
Nov  5 12:19:18.045: INFO: Pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12" satisfied condition "running and ready"
Nov  5 12:19:18.054: INFO: Pod pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12 has hostIP: 172.31.41.19
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov  5 12:19:18.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-631" for this suite. 11/05/22 12:19:18.059
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":118,"skipped":2046,"failed":0}
------------------------------
• [SLOW TEST] [6.256 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:19:11.809
    Nov  5 12:19:11.809: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 12:19:11.811
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:12.015
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:12.019
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 11/05/22 12:19:12.023
    Nov  5 12:19:12.034: INFO: Waiting up to 5m0s for pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12" in namespace "pods-631" to be "running and ready"
    Nov  5 12:19:12.040: INFO: Pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12": Phase="Pending", Reason="", readiness=false. Elapsed: 5.976606ms
    Nov  5 12:19:12.040: INFO: The phase of Pod pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:19:14.044: INFO: Pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010576943s
    Nov  5 12:19:14.044: INFO: The phase of Pod pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:19:16.045: INFO: Pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010744126s
    Nov  5 12:19:16.045: INFO: The phase of Pod pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:19:18.045: INFO: Pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12": Phase="Running", Reason="", readiness=true. Elapsed: 6.011364562s
    Nov  5 12:19:18.045: INFO: The phase of Pod pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12 is Running (Ready = true)
    Nov  5 12:19:18.045: INFO: Pod "pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12" satisfied condition "running and ready"
    Nov  5 12:19:18.054: INFO: Pod pod-hostip-0ac9ac4d-798f-4d23-bbeb-cfc240c42c12 has hostIP: 172.31.41.19
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov  5 12:19:18.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-631" for this suite. 11/05/22 12:19:18.059
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:19:18.066
Nov  5 12:19:18.066: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 12:19:18.067
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:18.081
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:18.086
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 11/05/22 12:19:18.09
Nov  5 12:19:18.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d" in namespace "downward-api-6728" to be "Succeeded or Failed"
Nov  5 12:19:18.108: INFO: Pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.426653ms
Nov  5 12:19:20.112: INFO: Pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011551098s
Nov  5 12:19:22.112: INFO: Pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011182012s
Nov  5 12:19:24.113: INFO: Pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012130846s
STEP: Saw pod success 11/05/22 12:19:24.113
Nov  5 12:19:24.113: INFO: Pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d" satisfied condition "Succeeded or Failed"
Nov  5 12:19:24.116: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d container client-container: <nil>
STEP: delete the pod 11/05/22 12:19:24.129
Nov  5 12:19:24.142: INFO: Waiting for pod downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d to disappear
Nov  5 12:19:24.145: INFO: Pod downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 12:19:24.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6728" for this suite. 11/05/22 12:19:24.149
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":119,"skipped":2052,"failed":0}
------------------------------
• [SLOW TEST] [6.089 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:19:18.066
    Nov  5 12:19:18.066: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 12:19:18.067
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:18.081
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:18.086
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 11/05/22 12:19:18.09
    Nov  5 12:19:18.100: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d" in namespace "downward-api-6728" to be "Succeeded or Failed"
    Nov  5 12:19:18.108: INFO: Pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.426653ms
    Nov  5 12:19:20.112: INFO: Pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011551098s
    Nov  5 12:19:22.112: INFO: Pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011182012s
    Nov  5 12:19:24.113: INFO: Pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012130846s
    STEP: Saw pod success 11/05/22 12:19:24.113
    Nov  5 12:19:24.113: INFO: Pod "downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d" satisfied condition "Succeeded or Failed"
    Nov  5 12:19:24.116: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d container client-container: <nil>
    STEP: delete the pod 11/05/22 12:19:24.129
    Nov  5 12:19:24.142: INFO: Waiting for pod downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d to disappear
    Nov  5 12:19:24.145: INFO: Pod downwardapi-volume-c5c56a26-89bc-4745-8fd2-6d402719a83d no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 12:19:24.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6728" for this suite. 11/05/22 12:19:24.149
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:19:24.155
Nov  5 12:19:24.156: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:19:24.156
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:24.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:24.172
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-103ca35d-85c7-470c-bd6f-af97e18273a6 11/05/22 12:19:24.179
STEP: Creating a pod to test consume configMaps 11/05/22 12:19:24.185
Nov  5 12:19:24.194: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488" in namespace "projected-8154" to be "Succeeded or Failed"
Nov  5 12:19:24.198: INFO: Pod "pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488": Phase="Pending", Reason="", readiness=false. Elapsed: 4.768678ms
Nov  5 12:19:26.203: INFO: Pod "pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009057544s
Nov  5 12:19:28.204: INFO: Pod "pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010283608s
STEP: Saw pod success 11/05/22 12:19:28.204
Nov  5 12:19:28.204: INFO: Pod "pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488" satisfied condition "Succeeded or Failed"
Nov  5 12:19:28.208: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488 container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:19:28.214
Nov  5 12:19:28.225: INFO: Waiting for pod pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488 to disappear
Nov  5 12:19:28.228: INFO: Pod pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov  5 12:19:28.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8154" for this suite. 11/05/22 12:19:28.232
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":120,"skipped":2057,"failed":0}
------------------------------
• [4.082 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:19:24.155
    Nov  5 12:19:24.156: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:19:24.156
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:24.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:24.172
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-103ca35d-85c7-470c-bd6f-af97e18273a6 11/05/22 12:19:24.179
    STEP: Creating a pod to test consume configMaps 11/05/22 12:19:24.185
    Nov  5 12:19:24.194: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488" in namespace "projected-8154" to be "Succeeded or Failed"
    Nov  5 12:19:24.198: INFO: Pod "pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488": Phase="Pending", Reason="", readiness=false. Elapsed: 4.768678ms
    Nov  5 12:19:26.203: INFO: Pod "pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009057544s
    Nov  5 12:19:28.204: INFO: Pod "pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010283608s
    STEP: Saw pod success 11/05/22 12:19:28.204
    Nov  5 12:19:28.204: INFO: Pod "pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488" satisfied condition "Succeeded or Failed"
    Nov  5 12:19:28.208: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488 container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:19:28.214
    Nov  5 12:19:28.225: INFO: Waiting for pod pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488 to disappear
    Nov  5 12:19:28.228: INFO: Pod pod-projected-configmaps-8726e07b-73ce-4289-8957-618f00603488 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov  5 12:19:28.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8154" for this suite. 11/05/22 12:19:28.232
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:19:28.241
Nov  5 12:19:28.241: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename svc-latency 11/05/22 12:19:28.242
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:28.254
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:28.26
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Nov  5 12:19:28.263: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4334 11/05/22 12:19:28.264
I1105 12:19:28.270075      20 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4334, replica count: 1
I1105 12:19:29.321055      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1105 12:19:30.321518      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 12:19:30.432: INFO: Created: latency-svc-mwbcl
Nov  5 12:19:30.445: INFO: Got endpoints: latency-svc-mwbcl [23.179721ms]
Nov  5 12:19:30.465: INFO: Created: latency-svc-g7sgz
Nov  5 12:19:30.475: INFO: Got endpoints: latency-svc-g7sgz [29.735632ms]
Nov  5 12:19:30.478: INFO: Created: latency-svc-2ndm2
Nov  5 12:19:30.483: INFO: Created: latency-svc-5fgb8
Nov  5 12:19:30.490: INFO: Got endpoints: latency-svc-2ndm2 [43.92879ms]
Nov  5 12:19:30.496: INFO: Got endpoints: latency-svc-5fgb8 [50.034395ms]
Nov  5 12:19:30.498: INFO: Created: latency-svc-fddzs
Nov  5 12:19:30.505: INFO: Created: latency-svc-fzq9k
Nov  5 12:19:30.508: INFO: Got endpoints: latency-svc-fddzs [62.152451ms]
Nov  5 12:19:30.515: INFO: Created: latency-svc-7b84f
Nov  5 12:19:30.516: INFO: Got endpoints: latency-svc-fzq9k [70.813873ms]
Nov  5 12:19:30.522: INFO: Got endpoints: latency-svc-7b84f [76.66517ms]
Nov  5 12:19:30.526: INFO: Created: latency-svc-dx497
Nov  5 12:19:30.528: INFO: Got endpoints: latency-svc-dx497 [82.391082ms]
Nov  5 12:19:30.532: INFO: Created: latency-svc-hk9d2
Nov  5 12:19:30.547: INFO: Got endpoints: latency-svc-hk9d2 [100.951408ms]
Nov  5 12:19:30.547: INFO: Created: latency-svc-bgb6t
Nov  5 12:19:30.555: INFO: Got endpoints: latency-svc-bgb6t [108.336992ms]
Nov  5 12:19:30.559: INFO: Created: latency-svc-xvkzq
Nov  5 12:19:30.566: INFO: Got endpoints: latency-svc-xvkzq [119.5915ms]
Nov  5 12:19:30.570: INFO: Created: latency-svc-4vm9x
Nov  5 12:19:30.576: INFO: Got endpoints: latency-svc-4vm9x [129.74485ms]
Nov  5 12:19:30.576: INFO: Created: latency-svc-m4fd2
Nov  5 12:19:30.581: INFO: Created: latency-svc-xbknl
Nov  5 12:19:30.583: INFO: Got endpoints: latency-svc-m4fd2 [136.508742ms]
Nov  5 12:19:30.592: INFO: Got endpoints: latency-svc-xbknl [145.633338ms]
Nov  5 12:19:30.596: INFO: Created: latency-svc-nqw2x
Nov  5 12:19:30.603: INFO: Created: latency-svc-mnrbw
Nov  5 12:19:30.605: INFO: Got endpoints: latency-svc-nqw2x [158.907006ms]
Nov  5 12:19:30.611: INFO: Created: latency-svc-52j25
Nov  5 12:19:30.613: INFO: Got endpoints: latency-svc-mnrbw [166.729463ms]
Nov  5 12:19:30.617: INFO: Got endpoints: latency-svc-52j25 [141.549208ms]
Nov  5 12:19:30.624: INFO: Created: latency-svc-m5xkp
Nov  5 12:19:30.628: INFO: Created: latency-svc-69444
Nov  5 12:19:30.630: INFO: Got endpoints: latency-svc-m5xkp [140.481825ms]
Nov  5 12:19:30.638: INFO: Got endpoints: latency-svc-69444 [141.661271ms]
Nov  5 12:19:30.641: INFO: Created: latency-svc-jlksn
Nov  5 12:19:30.649: INFO: Got endpoints: latency-svc-jlksn [140.845988ms]
Nov  5 12:19:30.649: INFO: Created: latency-svc-kbvlp
Nov  5 12:19:30.655: INFO: Created: latency-svc-cb2qw
Nov  5 12:19:30.657: INFO: Got endpoints: latency-svc-kbvlp [140.814119ms]
Nov  5 12:19:30.661: INFO: Got endpoints: latency-svc-cb2qw [138.327728ms]
Nov  5 12:19:30.666: INFO: Created: latency-svc-qrqmr
Nov  5 12:19:30.671: INFO: Got endpoints: latency-svc-qrqmr [142.337473ms]
Nov  5 12:19:30.676: INFO: Created: latency-svc-wvv6j
Nov  5 12:19:30.681: INFO: Got endpoints: latency-svc-wvv6j [133.905535ms]
Nov  5 12:19:30.684: INFO: Created: latency-svc-wjktj
Nov  5 12:19:30.691: INFO: Got endpoints: latency-svc-wjktj [136.661913ms]
Nov  5 12:19:30.696: INFO: Created: latency-svc-nhk5d
Nov  5 12:19:30.699: INFO: Got endpoints: latency-svc-nhk5d [133.069756ms]
Nov  5 12:19:30.704: INFO: Created: latency-svc-2n5wh
Nov  5 12:19:30.708: INFO: Got endpoints: latency-svc-2n5wh [132.171823ms]
Nov  5 12:19:30.712: INFO: Created: latency-svc-hjz8v
Nov  5 12:19:30.718: INFO: Got endpoints: latency-svc-hjz8v [135.012017ms]
Nov  5 12:19:30.722: INFO: Created: latency-svc-h9qbs
Nov  5 12:19:30.727: INFO: Got endpoints: latency-svc-h9qbs [134.740289ms]
Nov  5 12:19:30.733: INFO: Created: latency-svc-lzvt5
Nov  5 12:19:30.737: INFO: Created: latency-svc-hrgf6
Nov  5 12:19:30.740: INFO: Got endpoints: latency-svc-lzvt5 [135.145349ms]
Nov  5 12:19:30.747: INFO: Got endpoints: latency-svc-hrgf6 [133.881979ms]
Nov  5 12:19:30.751: INFO: Created: latency-svc-lhstl
Nov  5 12:19:30.762: INFO: Got endpoints: latency-svc-lhstl [144.864632ms]
Nov  5 12:19:30.762: INFO: Created: latency-svc-hn9xv
Nov  5 12:19:30.765: INFO: Got endpoints: latency-svc-hn9xv [134.950219ms]
Nov  5 12:19:30.767: INFO: Created: latency-svc-kssrr
Nov  5 12:19:30.774: INFO: Got endpoints: latency-svc-kssrr [136.064675ms]
Nov  5 12:19:30.779: INFO: Created: latency-svc-6pwwv
Nov  5 12:19:30.782: INFO: Got endpoints: latency-svc-6pwwv [133.828802ms]
Nov  5 12:19:30.789: INFO: Created: latency-svc-6pkc6
Nov  5 12:19:30.794: INFO: Created: latency-svc-9gfjc
Nov  5 12:19:30.796: INFO: Got endpoints: latency-svc-6pkc6 [138.5343ms]
Nov  5 12:19:30.806: INFO: Got endpoints: latency-svc-9gfjc [144.576989ms]
Nov  5 12:19:30.806: INFO: Created: latency-svc-cdls2
Nov  5 12:19:30.813: INFO: Created: latency-svc-lktnh
Nov  5 12:19:30.818: INFO: Created: latency-svc-h29sn
Nov  5 12:19:30.825: INFO: Created: latency-svc-fpv52
Nov  5 12:19:30.831: INFO: Created: latency-svc-tjp7b
Nov  5 12:19:30.836: INFO: Created: latency-svc-z6n6x
Nov  5 12:19:30.837: INFO: Got endpoints: latency-svc-cdls2 [165.765143ms]
Nov  5 12:19:30.843: INFO: Created: latency-svc-gvmgv
Nov  5 12:19:30.849: INFO: Created: latency-svc-wfslt
Nov  5 12:19:30.852: INFO: Created: latency-svc-lqcrn
Nov  5 12:19:30.859: INFO: Created: latency-svc-p9gqp
Nov  5 12:19:30.866: INFO: Created: latency-svc-jngv6
Nov  5 12:19:30.871: INFO: Created: latency-svc-m57gh
Nov  5 12:19:30.877: INFO: Created: latency-svc-sgk2b
Nov  5 12:19:30.885: INFO: Created: latency-svc-vs8q5
Nov  5 12:19:30.887: INFO: Created: latency-svc-d8625
Nov  5 12:19:30.888: INFO: Got endpoints: latency-svc-lktnh [206.930911ms]
Nov  5 12:19:30.894: INFO: Created: latency-svc-c2ztq
Nov  5 12:19:30.901: INFO: Created: latency-svc-tfvnf
Nov  5 12:19:30.939: INFO: Got endpoints: latency-svc-h29sn [248.062184ms]
Nov  5 12:19:30.950: INFO: Created: latency-svc-xcf7g
Nov  5 12:19:30.997: INFO: Got endpoints: latency-svc-fpv52 [298.074813ms]
Nov  5 12:19:31.011: INFO: Created: latency-svc-gbr55
Nov  5 12:19:31.039: INFO: Got endpoints: latency-svc-tjp7b [331.12952ms]
Nov  5 12:19:31.051: INFO: Created: latency-svc-w6rft
Nov  5 12:19:31.089: INFO: Got endpoints: latency-svc-z6n6x [371.27313ms]
Nov  5 12:19:31.099: INFO: Created: latency-svc-nmlg7
Nov  5 12:19:31.138: INFO: Got endpoints: latency-svc-gvmgv [411.47303ms]
Nov  5 12:19:31.148: INFO: Created: latency-svc-4z68t
Nov  5 12:19:31.189: INFO: Got endpoints: latency-svc-wfslt [448.921278ms]
Nov  5 12:19:31.199: INFO: Created: latency-svc-fmrnw
Nov  5 12:19:31.241: INFO: Got endpoints: latency-svc-lqcrn [493.857622ms]
Nov  5 12:19:31.252: INFO: Created: latency-svc-zbqxm
Nov  5 12:19:31.288: INFO: Got endpoints: latency-svc-p9gqp [526.04848ms]
Nov  5 12:19:31.298: INFO: Created: latency-svc-lxmgc
Nov  5 12:19:31.339: INFO: Got endpoints: latency-svc-jngv6 [574.01679ms]
Nov  5 12:19:31.350: INFO: Created: latency-svc-gm7r2
Nov  5 12:19:31.391: INFO: Got endpoints: latency-svc-m57gh [617.179462ms]
Nov  5 12:19:31.400: INFO: Created: latency-svc-r2zs6
Nov  5 12:19:31.439: INFO: Got endpoints: latency-svc-sgk2b [656.592465ms]
Nov  5 12:19:31.452: INFO: Created: latency-svc-p2f8n
Nov  5 12:19:31.489: INFO: Got endpoints: latency-svc-vs8q5 [693.40802ms]
Nov  5 12:19:31.500: INFO: Created: latency-svc-5rxqx
Nov  5 12:19:31.541: INFO: Got endpoints: latency-svc-d8625 [735.322429ms]
Nov  5 12:19:31.551: INFO: Created: latency-svc-bqh7d
Nov  5 12:19:31.590: INFO: Got endpoints: latency-svc-c2ztq [753.637918ms]
Nov  5 12:19:31.601: INFO: Created: latency-svc-t9g9b
Nov  5 12:19:31.639: INFO: Got endpoints: latency-svc-tfvnf [750.556445ms]
Nov  5 12:19:31.650: INFO: Created: latency-svc-sf6bk
Nov  5 12:19:31.690: INFO: Got endpoints: latency-svc-xcf7g [750.382667ms]
Nov  5 12:19:31.703: INFO: Created: latency-svc-zrc5t
Nov  5 12:19:31.738: INFO: Got endpoints: latency-svc-gbr55 [741.360804ms]
Nov  5 12:19:31.749: INFO: Created: latency-svc-k689n
Nov  5 12:19:31.789: INFO: Got endpoints: latency-svc-w6rft [749.915398ms]
Nov  5 12:19:31.799: INFO: Created: latency-svc-4ms5c
Nov  5 12:19:31.840: INFO: Got endpoints: latency-svc-nmlg7 [751.006091ms]
Nov  5 12:19:31.851: INFO: Created: latency-svc-75mvj
Nov  5 12:19:31.890: INFO: Got endpoints: latency-svc-4z68t [752.017651ms]
Nov  5 12:19:31.901: INFO: Created: latency-svc-xghmm
Nov  5 12:19:31.937: INFO: Got endpoints: latency-svc-fmrnw [748.237151ms]
Nov  5 12:19:31.949: INFO: Created: latency-svc-ttc5s
Nov  5 12:19:31.989: INFO: Got endpoints: latency-svc-zbqxm [747.615778ms]
Nov  5 12:19:31.999: INFO: Created: latency-svc-869l7
Nov  5 12:19:32.040: INFO: Got endpoints: latency-svc-lxmgc [752.057438ms]
Nov  5 12:19:32.052: INFO: Created: latency-svc-k2stw
Nov  5 12:19:32.088: INFO: Got endpoints: latency-svc-gm7r2 [749.130284ms]
Nov  5 12:19:32.101: INFO: Created: latency-svc-8m59d
Nov  5 12:19:32.137: INFO: Got endpoints: latency-svc-r2zs6 [746.561196ms]
Nov  5 12:19:32.149: INFO: Created: latency-svc-7xb6q
Nov  5 12:19:32.190: INFO: Got endpoints: latency-svc-p2f8n [750.888762ms]
Nov  5 12:19:32.199: INFO: Created: latency-svc-zgqxm
Nov  5 12:19:32.238: INFO: Got endpoints: latency-svc-5rxqx [749.220187ms]
Nov  5 12:19:32.249: INFO: Created: latency-svc-jbnqx
Nov  5 12:19:32.290: INFO: Got endpoints: latency-svc-bqh7d [749.25777ms]
Nov  5 12:19:32.300: INFO: Created: latency-svc-469q5
Nov  5 12:19:32.340: INFO: Got endpoints: latency-svc-t9g9b [749.695487ms]
Nov  5 12:19:32.351: INFO: Created: latency-svc-26mhg
Nov  5 12:19:32.389: INFO: Got endpoints: latency-svc-sf6bk [749.867228ms]
Nov  5 12:19:32.405: INFO: Created: latency-svc-k4fqq
Nov  5 12:19:32.443: INFO: Got endpoints: latency-svc-zrc5t [753.186387ms]
Nov  5 12:19:32.455: INFO: Created: latency-svc-jjp5c
Nov  5 12:19:32.493: INFO: Got endpoints: latency-svc-k689n [754.827004ms]
Nov  5 12:19:32.504: INFO: Created: latency-svc-wldl2
Nov  5 12:19:32.538: INFO: Got endpoints: latency-svc-4ms5c [749.201698ms]
Nov  5 12:19:32.549: INFO: Created: latency-svc-zs45b
Nov  5 12:19:32.590: INFO: Got endpoints: latency-svc-75mvj [749.696118ms]
Nov  5 12:19:32.600: INFO: Created: latency-svc-d94nf
Nov  5 12:19:32.639: INFO: Got endpoints: latency-svc-xghmm [749.050244ms]
Nov  5 12:19:32.651: INFO: Created: latency-svc-mbvj9
Nov  5 12:19:32.689: INFO: Got endpoints: latency-svc-ttc5s [751.909843ms]
Nov  5 12:19:32.702: INFO: Created: latency-svc-qms66
Nov  5 12:19:32.740: INFO: Got endpoints: latency-svc-869l7 [751.181771ms]
Nov  5 12:19:32.753: INFO: Created: latency-svc-rdmjl
Nov  5 12:19:32.790: INFO: Got endpoints: latency-svc-k2stw [749.853791ms]
Nov  5 12:19:32.799: INFO: Created: latency-svc-hscbt
Nov  5 12:19:32.838: INFO: Got endpoints: latency-svc-8m59d [749.773583ms]
Nov  5 12:19:32.849: INFO: Created: latency-svc-n5vv8
Nov  5 12:19:32.888: INFO: Got endpoints: latency-svc-7xb6q [750.58927ms]
Nov  5 12:19:32.899: INFO: Created: latency-svc-k6tql
Nov  5 12:19:32.939: INFO: Got endpoints: latency-svc-zgqxm [749.149754ms]
Nov  5 12:19:32.949: INFO: Created: latency-svc-lvq9v
Nov  5 12:19:32.988: INFO: Got endpoints: latency-svc-jbnqx [749.413749ms]
Nov  5 12:19:33.040: INFO: Got endpoints: latency-svc-469q5 [749.606519ms]
Nov  5 12:19:33.049: INFO: Created: latency-svc-n88jt
Nov  5 12:19:33.054: INFO: Created: latency-svc-vnz7b
Nov  5 12:19:33.089: INFO: Got endpoints: latency-svc-26mhg [749.070625ms]
Nov  5 12:19:33.099: INFO: Created: latency-svc-5hhqc
Nov  5 12:19:33.140: INFO: Got endpoints: latency-svc-k4fqq [751.425167ms]
Nov  5 12:19:33.153: INFO: Created: latency-svc-9gtns
Nov  5 12:19:33.189: INFO: Got endpoints: latency-svc-jjp5c [746.41097ms]
Nov  5 12:19:33.200: INFO: Created: latency-svc-psk7z
Nov  5 12:19:33.241: INFO: Got endpoints: latency-svc-wldl2 [747.240162ms]
Nov  5 12:19:33.257: INFO: Created: latency-svc-gfp2k
Nov  5 12:19:33.289: INFO: Got endpoints: latency-svc-zs45b [751.078318ms]
Nov  5 12:19:33.341: INFO: Got endpoints: latency-svc-d94nf [751.153086ms]
Nov  5 12:19:33.374: INFO: Created: latency-svc-xlkpb
Nov  5 12:19:33.379: INFO: Created: latency-svc-pkllx
Nov  5 12:19:33.389: INFO: Got endpoints: latency-svc-mbvj9 [749.312995ms]
Nov  5 12:19:33.400: INFO: Created: latency-svc-qwfzn
Nov  5 12:19:33.441: INFO: Got endpoints: latency-svc-qms66 [751.690846ms]
Nov  5 12:19:33.458: INFO: Created: latency-svc-96kgg
Nov  5 12:19:33.493: INFO: Got endpoints: latency-svc-rdmjl [753.073144ms]
Nov  5 12:19:33.509: INFO: Created: latency-svc-99jfg
Nov  5 12:19:33.542: INFO: Got endpoints: latency-svc-hscbt [752.083153ms]
Nov  5 12:19:33.553: INFO: Created: latency-svc-rm4tb
Nov  5 12:19:33.591: INFO: Got endpoints: latency-svc-n5vv8 [752.739965ms]
Nov  5 12:19:33.604: INFO: Created: latency-svc-bx7qd
Nov  5 12:19:33.639: INFO: Got endpoints: latency-svc-k6tql [750.926474ms]
Nov  5 12:19:33.650: INFO: Created: latency-svc-n2djt
Nov  5 12:19:33.690: INFO: Got endpoints: latency-svc-lvq9v [750.597167ms]
Nov  5 12:19:33.702: INFO: Created: latency-svc-w9rdh
Nov  5 12:19:33.740: INFO: Got endpoints: latency-svc-n88jt [752.152303ms]
Nov  5 12:19:33.751: INFO: Created: latency-svc-kr8vm
Nov  5 12:19:33.788: INFO: Got endpoints: latency-svc-vnz7b [748.128048ms]
Nov  5 12:19:33.798: INFO: Created: latency-svc-48j88
Nov  5 12:19:33.843: INFO: Got endpoints: latency-svc-5hhqc [753.895455ms]
Nov  5 12:19:33.854: INFO: Created: latency-svc-l29n9
Nov  5 12:19:33.891: INFO: Got endpoints: latency-svc-9gtns [750.698552ms]
Nov  5 12:19:33.901: INFO: Created: latency-svc-ms8fp
Nov  5 12:19:33.939: INFO: Got endpoints: latency-svc-psk7z [749.74767ms]
Nov  5 12:19:33.950: INFO: Created: latency-svc-pc2zx
Nov  5 12:19:33.987: INFO: Got endpoints: latency-svc-gfp2k [746.708387ms]
Nov  5 12:19:33.998: INFO: Created: latency-svc-n94r8
Nov  5 12:19:34.041: INFO: Got endpoints: latency-svc-xlkpb [751.749413ms]
Nov  5 12:19:34.052: INFO: Created: latency-svc-rwlrs
Nov  5 12:19:34.094: INFO: Got endpoints: latency-svc-pkllx [753.334836ms]
Nov  5 12:19:34.106: INFO: Created: latency-svc-fksdc
Nov  5 12:19:34.139: INFO: Got endpoints: latency-svc-qwfzn [750.007927ms]
Nov  5 12:19:34.150: INFO: Created: latency-svc-rr2xk
Nov  5 12:19:34.189: INFO: Got endpoints: latency-svc-96kgg [747.875487ms]
Nov  5 12:19:34.203: INFO: Created: latency-svc-52l5s
Nov  5 12:19:34.238: INFO: Got endpoints: latency-svc-99jfg [745.597385ms]
Nov  5 12:19:34.249: INFO: Created: latency-svc-655h7
Nov  5 12:19:34.288: INFO: Got endpoints: latency-svc-rm4tb [745.642246ms]
Nov  5 12:19:34.299: INFO: Created: latency-svc-dm244
Nov  5 12:19:34.340: INFO: Got endpoints: latency-svc-bx7qd [748.96886ms]
Nov  5 12:19:34.350: INFO: Created: latency-svc-bzp47
Nov  5 12:19:34.391: INFO: Got endpoints: latency-svc-n2djt [752.284547ms]
Nov  5 12:19:34.404: INFO: Created: latency-svc-2wmvm
Nov  5 12:19:34.439: INFO: Got endpoints: latency-svc-w9rdh [749.198791ms]
Nov  5 12:19:34.455: INFO: Created: latency-svc-k6s62
Nov  5 12:19:34.492: INFO: Got endpoints: latency-svc-kr8vm [752.010119ms]
Nov  5 12:19:34.504: INFO: Created: latency-svc-pht94
Nov  5 12:19:34.538: INFO: Got endpoints: latency-svc-48j88 [749.897489ms]
Nov  5 12:19:34.548: INFO: Created: latency-svc-pchdm
Nov  5 12:19:34.589: INFO: Got endpoints: latency-svc-l29n9 [745.926242ms]
Nov  5 12:19:34.608: INFO: Created: latency-svc-gq94h
Nov  5 12:19:34.641: INFO: Got endpoints: latency-svc-ms8fp [749.969822ms]
Nov  5 12:19:34.652: INFO: Created: latency-svc-zfrvj
Nov  5 12:19:34.688: INFO: Got endpoints: latency-svc-pc2zx [748.54335ms]
Nov  5 12:19:34.700: INFO: Created: latency-svc-6nwpr
Nov  5 12:19:34.739: INFO: Got endpoints: latency-svc-n94r8 [751.579474ms]
Nov  5 12:19:34.750: INFO: Created: latency-svc-rnxnl
Nov  5 12:19:34.787: INFO: Got endpoints: latency-svc-rwlrs [746.001367ms]
Nov  5 12:19:34.799: INFO: Created: latency-svc-b6zx8
Nov  5 12:19:34.838: INFO: Got endpoints: latency-svc-fksdc [744.106205ms]
Nov  5 12:19:34.849: INFO: Created: latency-svc-mw48x
Nov  5 12:19:34.890: INFO: Got endpoints: latency-svc-rr2xk [751.187738ms]
Nov  5 12:19:34.900: INFO: Created: latency-svc-cdsv9
Nov  5 12:19:34.941: INFO: Got endpoints: latency-svc-52l5s [752.428691ms]
Nov  5 12:19:34.951: INFO: Created: latency-svc-8xdvr
Nov  5 12:19:34.990: INFO: Got endpoints: latency-svc-655h7 [751.516115ms]
Nov  5 12:19:35.001: INFO: Created: latency-svc-66qvl
Nov  5 12:19:35.039: INFO: Got endpoints: latency-svc-dm244 [751.103008ms]
Nov  5 12:19:35.053: INFO: Created: latency-svc-fz59t
Nov  5 12:19:35.095: INFO: Got endpoints: latency-svc-bzp47 [755.070682ms]
Nov  5 12:19:35.109: INFO: Created: latency-svc-s7jkx
Nov  5 12:19:35.141: INFO: Got endpoints: latency-svc-2wmvm [749.608772ms]
Nov  5 12:19:35.160: INFO: Created: latency-svc-p9tcw
Nov  5 12:19:35.189: INFO: Got endpoints: latency-svc-k6s62 [750.171187ms]
Nov  5 12:19:35.201: INFO: Created: latency-svc-qn2xx
Nov  5 12:19:35.239: INFO: Got endpoints: latency-svc-pht94 [747.082386ms]
Nov  5 12:19:35.250: INFO: Created: latency-svc-59n9w
Nov  5 12:19:35.287: INFO: Got endpoints: latency-svc-pchdm [748.899594ms]
Nov  5 12:19:35.298: INFO: Created: latency-svc-xfm2k
Nov  5 12:19:35.339: INFO: Got endpoints: latency-svc-gq94h [749.490853ms]
Nov  5 12:19:35.350: INFO: Created: latency-svc-4qd5t
Nov  5 12:19:35.387: INFO: Got endpoints: latency-svc-zfrvj [746.066561ms]
Nov  5 12:19:35.398: INFO: Created: latency-svc-6xcd2
Nov  5 12:19:35.440: INFO: Got endpoints: latency-svc-6nwpr [752.368702ms]
Nov  5 12:19:35.452: INFO: Created: latency-svc-fz4t6
Nov  5 12:19:35.490: INFO: Got endpoints: latency-svc-rnxnl [750.580577ms]
Nov  5 12:19:35.502: INFO: Created: latency-svc-pdjlg
Nov  5 12:19:35.537: INFO: Got endpoints: latency-svc-b6zx8 [750.035013ms]
Nov  5 12:19:35.552: INFO: Created: latency-svc-mkd9r
Nov  5 12:19:35.588: INFO: Got endpoints: latency-svc-mw48x [749.317327ms]
Nov  5 12:19:35.599: INFO: Created: latency-svc-9kqjh
Nov  5 12:19:35.640: INFO: Got endpoints: latency-svc-cdsv9 [749.984161ms]
Nov  5 12:19:35.649: INFO: Created: latency-svc-c2677
Nov  5 12:19:35.689: INFO: Got endpoints: latency-svc-8xdvr [747.931072ms]
Nov  5 12:19:35.701: INFO: Created: latency-svc-mkfpz
Nov  5 12:19:35.739: INFO: Got endpoints: latency-svc-66qvl [749.412951ms]
Nov  5 12:19:35.750: INFO: Created: latency-svc-b2695
Nov  5 12:19:35.788: INFO: Got endpoints: latency-svc-fz59t [748.947771ms]
Nov  5 12:19:35.798: INFO: Created: latency-svc-f76t7
Nov  5 12:19:35.839: INFO: Got endpoints: latency-svc-s7jkx [743.478443ms]
Nov  5 12:19:35.852: INFO: Created: latency-svc-g27pb
Nov  5 12:19:35.888: INFO: Got endpoints: latency-svc-p9tcw [746.470711ms]
Nov  5 12:19:35.899: INFO: Created: latency-svc-4mg62
Nov  5 12:19:35.939: INFO: Got endpoints: latency-svc-qn2xx [749.787467ms]
Nov  5 12:19:35.949: INFO: Created: latency-svc-pf5q2
Nov  5 12:19:35.989: INFO: Got endpoints: latency-svc-59n9w [749.267861ms]
Nov  5 12:19:36.000: INFO: Created: latency-svc-v948l
Nov  5 12:19:36.040: INFO: Got endpoints: latency-svc-xfm2k [753.193084ms]
Nov  5 12:19:36.052: INFO: Created: latency-svc-9qkx8
Nov  5 12:19:36.091: INFO: Got endpoints: latency-svc-4qd5t [752.329673ms]
Nov  5 12:19:36.101: INFO: Created: latency-svc-bx9p4
Nov  5 12:19:36.140: INFO: Got endpoints: latency-svc-6xcd2 [752.686312ms]
Nov  5 12:19:36.150: INFO: Created: latency-svc-smph6
Nov  5 12:19:36.191: INFO: Got endpoints: latency-svc-fz4t6 [750.232866ms]
Nov  5 12:19:36.201: INFO: Created: latency-svc-4q2wd
Nov  5 12:19:36.240: INFO: Got endpoints: latency-svc-pdjlg [750.301876ms]
Nov  5 12:19:36.251: INFO: Created: latency-svc-62t6z
Nov  5 12:19:36.287: INFO: Got endpoints: latency-svc-mkd9r [749.32261ms]
Nov  5 12:19:36.298: INFO: Created: latency-svc-2jc65
Nov  5 12:19:36.339: INFO: Got endpoints: latency-svc-9kqjh [751.153427ms]
Nov  5 12:19:36.351: INFO: Created: latency-svc-q65ft
Nov  5 12:19:36.391: INFO: Got endpoints: latency-svc-c2677 [751.281667ms]
Nov  5 12:19:36.401: INFO: Created: latency-svc-s5b7z
Nov  5 12:19:36.441: INFO: Got endpoints: latency-svc-mkfpz [751.895572ms]
Nov  5 12:19:36.452: INFO: Created: latency-svc-7dwcc
Nov  5 12:19:36.489: INFO: Got endpoints: latency-svc-b2695 [749.984969ms]
Nov  5 12:19:36.505: INFO: Created: latency-svc-znwp5
Nov  5 12:19:36.541: INFO: Got endpoints: latency-svc-f76t7 [753.228945ms]
Nov  5 12:19:36.552: INFO: Created: latency-svc-569ls
Nov  5 12:19:36.589: INFO: Got endpoints: latency-svc-g27pb [750.584312ms]
Nov  5 12:19:36.600: INFO: Created: latency-svc-8wlq8
Nov  5 12:19:36.640: INFO: Got endpoints: latency-svc-4mg62 [752.690383ms]
Nov  5 12:19:36.650: INFO: Created: latency-svc-2z8nq
Nov  5 12:19:36.689: INFO: Got endpoints: latency-svc-pf5q2 [749.737915ms]
Nov  5 12:19:36.699: INFO: Created: latency-svc-6ljdb
Nov  5 12:19:36.739: INFO: Got endpoints: latency-svc-v948l [749.905652ms]
Nov  5 12:19:36.749: INFO: Created: latency-svc-kdhxr
Nov  5 12:19:36.787: INFO: Got endpoints: latency-svc-9qkx8 [746.836529ms]
Nov  5 12:19:36.798: INFO: Created: latency-svc-9vzgg
Nov  5 12:19:36.839: INFO: Got endpoints: latency-svc-bx9p4 [747.74158ms]
Nov  5 12:19:36.848: INFO: Created: latency-svc-cqffb
Nov  5 12:19:36.887: INFO: Got endpoints: latency-svc-smph6 [747.695271ms]
Nov  5 12:19:36.898: INFO: Created: latency-svc-gk9qt
Nov  5 12:19:36.941: INFO: Got endpoints: latency-svc-4q2wd [749.909406ms]
Nov  5 12:19:36.951: INFO: Created: latency-svc-khj42
Nov  5 12:19:36.989: INFO: Got endpoints: latency-svc-62t6z [748.581923ms]
Nov  5 12:19:36.998: INFO: Created: latency-svc-rx5zv
Nov  5 12:19:37.039: INFO: Got endpoints: latency-svc-2jc65 [751.519098ms]
Nov  5 12:19:37.052: INFO: Created: latency-svc-54q7k
Nov  5 12:19:37.089: INFO: Got endpoints: latency-svc-q65ft [749.83828ms]
Nov  5 12:19:37.102: INFO: Created: latency-svc-n2l5t
Nov  5 12:19:37.148: INFO: Got endpoints: latency-svc-s5b7z [756.859422ms]
Nov  5 12:19:37.159: INFO: Created: latency-svc-b96qk
Nov  5 12:19:37.193: INFO: Got endpoints: latency-svc-7dwcc [751.299272ms]
Nov  5 12:19:37.204: INFO: Created: latency-svc-fvtj8
Nov  5 12:19:37.239: INFO: Got endpoints: latency-svc-znwp5 [748.994464ms]
Nov  5 12:19:37.248: INFO: Created: latency-svc-9clgm
Nov  5 12:19:37.288: INFO: Got endpoints: latency-svc-569ls [746.739335ms]
Nov  5 12:19:37.299: INFO: Created: latency-svc-drcwv
Nov  5 12:19:37.340: INFO: Got endpoints: latency-svc-8wlq8 [750.406474ms]
Nov  5 12:19:37.350: INFO: Created: latency-svc-l7cl6
Nov  5 12:19:37.392: INFO: Got endpoints: latency-svc-2z8nq [751.396342ms]
Nov  5 12:19:37.403: INFO: Created: latency-svc-xhnpp
Nov  5 12:19:37.442: INFO: Got endpoints: latency-svc-6ljdb [752.531345ms]
Nov  5 12:19:37.457: INFO: Created: latency-svc-cvf4c
Nov  5 12:19:37.492: INFO: Got endpoints: latency-svc-kdhxr [753.318778ms]
Nov  5 12:19:37.508: INFO: Created: latency-svc-zsz4s
Nov  5 12:19:37.539: INFO: Got endpoints: latency-svc-9vzgg [752.170905ms]
Nov  5 12:19:37.553: INFO: Created: latency-svc-rh7vr
Nov  5 12:19:37.591: INFO: Got endpoints: latency-svc-cqffb [751.999391ms]
Nov  5 12:19:37.601: INFO: Created: latency-svc-hd9dw
Nov  5 12:19:37.641: INFO: Got endpoints: latency-svc-gk9qt [753.435323ms]
Nov  5 12:19:37.653: INFO: Created: latency-svc-xnvhj
Nov  5 12:19:37.689: INFO: Got endpoints: latency-svc-khj42 [748.850684ms]
Nov  5 12:19:37.700: INFO: Created: latency-svc-dk2z5
Nov  5 12:19:37.742: INFO: Got endpoints: latency-svc-rx5zv [753.7349ms]
Nov  5 12:19:37.751: INFO: Created: latency-svc-h49bh
Nov  5 12:19:37.789: INFO: Got endpoints: latency-svc-54q7k [750.481853ms]
Nov  5 12:19:37.801: INFO: Created: latency-svc-4nsz6
Nov  5 12:19:37.840: INFO: Got endpoints: latency-svc-n2l5t [750.586271ms]
Nov  5 12:19:37.850: INFO: Created: latency-svc-mmfz4
Nov  5 12:19:37.889: INFO: Got endpoints: latency-svc-b96qk [740.579874ms]
Nov  5 12:19:37.898: INFO: Created: latency-svc-vsnjt
Nov  5 12:19:37.939: INFO: Got endpoints: latency-svc-fvtj8 [746.742881ms]
Nov  5 12:19:37.952: INFO: Created: latency-svc-sf4mh
Nov  5 12:19:37.989: INFO: Got endpoints: latency-svc-9clgm [750.183662ms]
Nov  5 12:19:38.002: INFO: Created: latency-svc-jjsg9
Nov  5 12:19:38.040: INFO: Got endpoints: latency-svc-drcwv [751.948861ms]
Nov  5 12:19:38.049: INFO: Created: latency-svc-5kr6r
Nov  5 12:19:38.089: INFO: Got endpoints: latency-svc-l7cl6 [748.886044ms]
Nov  5 12:19:38.100: INFO: Created: latency-svc-5pdnf
Nov  5 12:19:38.141: INFO: Got endpoints: latency-svc-xhnpp [748.629203ms]
Nov  5 12:19:38.151: INFO: Created: latency-svc-jdn64
Nov  5 12:19:38.190: INFO: Got endpoints: latency-svc-cvf4c [748.436706ms]
Nov  5 12:19:38.201: INFO: Created: latency-svc-9bt97
Nov  5 12:19:38.238: INFO: Got endpoints: latency-svc-zsz4s [745.32275ms]
Nov  5 12:19:38.249: INFO: Created: latency-svc-k2f4x
Nov  5 12:19:38.290: INFO: Got endpoints: latency-svc-rh7vr [750.004881ms]
Nov  5 12:19:38.339: INFO: Got endpoints: latency-svc-hd9dw [748.394376ms]
Nov  5 12:19:38.389: INFO: Got endpoints: latency-svc-xnvhj [748.11418ms]
Nov  5 12:19:38.441: INFO: Got endpoints: latency-svc-dk2z5 [751.338216ms]
Nov  5 12:19:38.490: INFO: Got endpoints: latency-svc-h49bh [747.472125ms]
Nov  5 12:19:38.540: INFO: Got endpoints: latency-svc-4nsz6 [751.143056ms]
Nov  5 12:19:38.589: INFO: Got endpoints: latency-svc-mmfz4 [749.746021ms]
Nov  5 12:19:38.641: INFO: Got endpoints: latency-svc-vsnjt [751.653559ms]
Nov  5 12:19:38.689: INFO: Got endpoints: latency-svc-sf4mh [749.461254ms]
Nov  5 12:19:38.739: INFO: Got endpoints: latency-svc-jjsg9 [750.614399ms]
Nov  5 12:19:38.790: INFO: Got endpoints: latency-svc-5kr6r [750.082852ms]
Nov  5 12:19:38.841: INFO: Got endpoints: latency-svc-5pdnf [751.725121ms]
Nov  5 12:19:38.899: INFO: Got endpoints: latency-svc-jdn64 [757.876683ms]
Nov  5 12:19:38.941: INFO: Got endpoints: latency-svc-9bt97 [750.626486ms]
Nov  5 12:19:38.990: INFO: Got endpoints: latency-svc-k2f4x [752.400132ms]
Nov  5 12:19:38.990: INFO: Latencies: [29.735632ms 43.92879ms 50.034395ms 62.152451ms 70.813873ms 76.66517ms 82.391082ms 100.951408ms 108.336992ms 119.5915ms 129.74485ms 132.171823ms 133.069756ms 133.828802ms 133.881979ms 133.905535ms 134.740289ms 134.950219ms 135.012017ms 135.145349ms 136.064675ms 136.508742ms 136.661913ms 138.327728ms 138.5343ms 140.481825ms 140.814119ms 140.845988ms 141.549208ms 141.661271ms 142.337473ms 144.576989ms 144.864632ms 145.633338ms 158.907006ms 165.765143ms 166.729463ms 206.930911ms 248.062184ms 298.074813ms 331.12952ms 371.27313ms 411.47303ms 448.921278ms 493.857622ms 526.04848ms 574.01679ms 617.179462ms 656.592465ms 693.40802ms 735.322429ms 740.579874ms 741.360804ms 743.478443ms 744.106205ms 745.32275ms 745.597385ms 745.642246ms 745.926242ms 746.001367ms 746.066561ms 746.41097ms 746.470711ms 746.561196ms 746.708387ms 746.739335ms 746.742881ms 746.836529ms 747.082386ms 747.240162ms 747.472125ms 747.615778ms 747.695271ms 747.74158ms 747.875487ms 747.931072ms 748.11418ms 748.128048ms 748.237151ms 748.394376ms 748.436706ms 748.54335ms 748.581923ms 748.629203ms 748.850684ms 748.886044ms 748.899594ms 748.947771ms 748.96886ms 748.994464ms 749.050244ms 749.070625ms 749.130284ms 749.149754ms 749.198791ms 749.201698ms 749.220187ms 749.25777ms 749.267861ms 749.312995ms 749.317327ms 749.32261ms 749.412951ms 749.413749ms 749.461254ms 749.490853ms 749.606519ms 749.608772ms 749.695487ms 749.696118ms 749.737915ms 749.746021ms 749.74767ms 749.773583ms 749.787467ms 749.83828ms 749.853791ms 749.867228ms 749.897489ms 749.905652ms 749.909406ms 749.915398ms 749.969822ms 749.984161ms 749.984969ms 750.004881ms 750.007927ms 750.035013ms 750.082852ms 750.171187ms 750.183662ms 750.232866ms 750.301876ms 750.382667ms 750.406474ms 750.481853ms 750.556445ms 750.580577ms 750.584312ms 750.586271ms 750.58927ms 750.597167ms 750.614399ms 750.626486ms 750.698552ms 750.888762ms 750.926474ms 751.006091ms 751.078318ms 751.103008ms 751.143056ms 751.153086ms 751.153427ms 751.181771ms 751.187738ms 751.281667ms 751.299272ms 751.338216ms 751.396342ms 751.425167ms 751.516115ms 751.519098ms 751.579474ms 751.653559ms 751.690846ms 751.725121ms 751.749413ms 751.895572ms 751.909843ms 751.948861ms 751.999391ms 752.010119ms 752.017651ms 752.057438ms 752.083153ms 752.152303ms 752.170905ms 752.284547ms 752.329673ms 752.368702ms 752.400132ms 752.428691ms 752.531345ms 752.686312ms 752.690383ms 752.739965ms 753.073144ms 753.186387ms 753.193084ms 753.228945ms 753.318778ms 753.334836ms 753.435323ms 753.637918ms 753.7349ms 753.895455ms 754.827004ms 755.070682ms 756.859422ms 757.876683ms]
Nov  5 12:19:38.990: INFO: 50 %ile: 749.317327ms
Nov  5 12:19:38.990: INFO: 90 %ile: 752.400132ms
Nov  5 12:19:38.990: INFO: 99 %ile: 756.859422ms
Nov  5 12:19:38.990: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Nov  5 12:19:38.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4334" for this suite. 11/05/22 12:19:38.996
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":121,"skipped":2148,"failed":0}
------------------------------
• [SLOW TEST] [10.762 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:19:28.241
    Nov  5 12:19:28.241: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename svc-latency 11/05/22 12:19:28.242
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:28.254
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:28.26
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Nov  5 12:19:28.263: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-4334 11/05/22 12:19:28.264
    I1105 12:19:28.270075      20 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4334, replica count: 1
    I1105 12:19:29.321055      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1105 12:19:30.321518      20 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 12:19:30.432: INFO: Created: latency-svc-mwbcl
    Nov  5 12:19:30.445: INFO: Got endpoints: latency-svc-mwbcl [23.179721ms]
    Nov  5 12:19:30.465: INFO: Created: latency-svc-g7sgz
    Nov  5 12:19:30.475: INFO: Got endpoints: latency-svc-g7sgz [29.735632ms]
    Nov  5 12:19:30.478: INFO: Created: latency-svc-2ndm2
    Nov  5 12:19:30.483: INFO: Created: latency-svc-5fgb8
    Nov  5 12:19:30.490: INFO: Got endpoints: latency-svc-2ndm2 [43.92879ms]
    Nov  5 12:19:30.496: INFO: Got endpoints: latency-svc-5fgb8 [50.034395ms]
    Nov  5 12:19:30.498: INFO: Created: latency-svc-fddzs
    Nov  5 12:19:30.505: INFO: Created: latency-svc-fzq9k
    Nov  5 12:19:30.508: INFO: Got endpoints: latency-svc-fddzs [62.152451ms]
    Nov  5 12:19:30.515: INFO: Created: latency-svc-7b84f
    Nov  5 12:19:30.516: INFO: Got endpoints: latency-svc-fzq9k [70.813873ms]
    Nov  5 12:19:30.522: INFO: Got endpoints: latency-svc-7b84f [76.66517ms]
    Nov  5 12:19:30.526: INFO: Created: latency-svc-dx497
    Nov  5 12:19:30.528: INFO: Got endpoints: latency-svc-dx497 [82.391082ms]
    Nov  5 12:19:30.532: INFO: Created: latency-svc-hk9d2
    Nov  5 12:19:30.547: INFO: Got endpoints: latency-svc-hk9d2 [100.951408ms]
    Nov  5 12:19:30.547: INFO: Created: latency-svc-bgb6t
    Nov  5 12:19:30.555: INFO: Got endpoints: latency-svc-bgb6t [108.336992ms]
    Nov  5 12:19:30.559: INFO: Created: latency-svc-xvkzq
    Nov  5 12:19:30.566: INFO: Got endpoints: latency-svc-xvkzq [119.5915ms]
    Nov  5 12:19:30.570: INFO: Created: latency-svc-4vm9x
    Nov  5 12:19:30.576: INFO: Got endpoints: latency-svc-4vm9x [129.74485ms]
    Nov  5 12:19:30.576: INFO: Created: latency-svc-m4fd2
    Nov  5 12:19:30.581: INFO: Created: latency-svc-xbknl
    Nov  5 12:19:30.583: INFO: Got endpoints: latency-svc-m4fd2 [136.508742ms]
    Nov  5 12:19:30.592: INFO: Got endpoints: latency-svc-xbknl [145.633338ms]
    Nov  5 12:19:30.596: INFO: Created: latency-svc-nqw2x
    Nov  5 12:19:30.603: INFO: Created: latency-svc-mnrbw
    Nov  5 12:19:30.605: INFO: Got endpoints: latency-svc-nqw2x [158.907006ms]
    Nov  5 12:19:30.611: INFO: Created: latency-svc-52j25
    Nov  5 12:19:30.613: INFO: Got endpoints: latency-svc-mnrbw [166.729463ms]
    Nov  5 12:19:30.617: INFO: Got endpoints: latency-svc-52j25 [141.549208ms]
    Nov  5 12:19:30.624: INFO: Created: latency-svc-m5xkp
    Nov  5 12:19:30.628: INFO: Created: latency-svc-69444
    Nov  5 12:19:30.630: INFO: Got endpoints: latency-svc-m5xkp [140.481825ms]
    Nov  5 12:19:30.638: INFO: Got endpoints: latency-svc-69444 [141.661271ms]
    Nov  5 12:19:30.641: INFO: Created: latency-svc-jlksn
    Nov  5 12:19:30.649: INFO: Got endpoints: latency-svc-jlksn [140.845988ms]
    Nov  5 12:19:30.649: INFO: Created: latency-svc-kbvlp
    Nov  5 12:19:30.655: INFO: Created: latency-svc-cb2qw
    Nov  5 12:19:30.657: INFO: Got endpoints: latency-svc-kbvlp [140.814119ms]
    Nov  5 12:19:30.661: INFO: Got endpoints: latency-svc-cb2qw [138.327728ms]
    Nov  5 12:19:30.666: INFO: Created: latency-svc-qrqmr
    Nov  5 12:19:30.671: INFO: Got endpoints: latency-svc-qrqmr [142.337473ms]
    Nov  5 12:19:30.676: INFO: Created: latency-svc-wvv6j
    Nov  5 12:19:30.681: INFO: Got endpoints: latency-svc-wvv6j [133.905535ms]
    Nov  5 12:19:30.684: INFO: Created: latency-svc-wjktj
    Nov  5 12:19:30.691: INFO: Got endpoints: latency-svc-wjktj [136.661913ms]
    Nov  5 12:19:30.696: INFO: Created: latency-svc-nhk5d
    Nov  5 12:19:30.699: INFO: Got endpoints: latency-svc-nhk5d [133.069756ms]
    Nov  5 12:19:30.704: INFO: Created: latency-svc-2n5wh
    Nov  5 12:19:30.708: INFO: Got endpoints: latency-svc-2n5wh [132.171823ms]
    Nov  5 12:19:30.712: INFO: Created: latency-svc-hjz8v
    Nov  5 12:19:30.718: INFO: Got endpoints: latency-svc-hjz8v [135.012017ms]
    Nov  5 12:19:30.722: INFO: Created: latency-svc-h9qbs
    Nov  5 12:19:30.727: INFO: Got endpoints: latency-svc-h9qbs [134.740289ms]
    Nov  5 12:19:30.733: INFO: Created: latency-svc-lzvt5
    Nov  5 12:19:30.737: INFO: Created: latency-svc-hrgf6
    Nov  5 12:19:30.740: INFO: Got endpoints: latency-svc-lzvt5 [135.145349ms]
    Nov  5 12:19:30.747: INFO: Got endpoints: latency-svc-hrgf6 [133.881979ms]
    Nov  5 12:19:30.751: INFO: Created: latency-svc-lhstl
    Nov  5 12:19:30.762: INFO: Got endpoints: latency-svc-lhstl [144.864632ms]
    Nov  5 12:19:30.762: INFO: Created: latency-svc-hn9xv
    Nov  5 12:19:30.765: INFO: Got endpoints: latency-svc-hn9xv [134.950219ms]
    Nov  5 12:19:30.767: INFO: Created: latency-svc-kssrr
    Nov  5 12:19:30.774: INFO: Got endpoints: latency-svc-kssrr [136.064675ms]
    Nov  5 12:19:30.779: INFO: Created: latency-svc-6pwwv
    Nov  5 12:19:30.782: INFO: Got endpoints: latency-svc-6pwwv [133.828802ms]
    Nov  5 12:19:30.789: INFO: Created: latency-svc-6pkc6
    Nov  5 12:19:30.794: INFO: Created: latency-svc-9gfjc
    Nov  5 12:19:30.796: INFO: Got endpoints: latency-svc-6pkc6 [138.5343ms]
    Nov  5 12:19:30.806: INFO: Got endpoints: latency-svc-9gfjc [144.576989ms]
    Nov  5 12:19:30.806: INFO: Created: latency-svc-cdls2
    Nov  5 12:19:30.813: INFO: Created: latency-svc-lktnh
    Nov  5 12:19:30.818: INFO: Created: latency-svc-h29sn
    Nov  5 12:19:30.825: INFO: Created: latency-svc-fpv52
    Nov  5 12:19:30.831: INFO: Created: latency-svc-tjp7b
    Nov  5 12:19:30.836: INFO: Created: latency-svc-z6n6x
    Nov  5 12:19:30.837: INFO: Got endpoints: latency-svc-cdls2 [165.765143ms]
    Nov  5 12:19:30.843: INFO: Created: latency-svc-gvmgv
    Nov  5 12:19:30.849: INFO: Created: latency-svc-wfslt
    Nov  5 12:19:30.852: INFO: Created: latency-svc-lqcrn
    Nov  5 12:19:30.859: INFO: Created: latency-svc-p9gqp
    Nov  5 12:19:30.866: INFO: Created: latency-svc-jngv6
    Nov  5 12:19:30.871: INFO: Created: latency-svc-m57gh
    Nov  5 12:19:30.877: INFO: Created: latency-svc-sgk2b
    Nov  5 12:19:30.885: INFO: Created: latency-svc-vs8q5
    Nov  5 12:19:30.887: INFO: Created: latency-svc-d8625
    Nov  5 12:19:30.888: INFO: Got endpoints: latency-svc-lktnh [206.930911ms]
    Nov  5 12:19:30.894: INFO: Created: latency-svc-c2ztq
    Nov  5 12:19:30.901: INFO: Created: latency-svc-tfvnf
    Nov  5 12:19:30.939: INFO: Got endpoints: latency-svc-h29sn [248.062184ms]
    Nov  5 12:19:30.950: INFO: Created: latency-svc-xcf7g
    Nov  5 12:19:30.997: INFO: Got endpoints: latency-svc-fpv52 [298.074813ms]
    Nov  5 12:19:31.011: INFO: Created: latency-svc-gbr55
    Nov  5 12:19:31.039: INFO: Got endpoints: latency-svc-tjp7b [331.12952ms]
    Nov  5 12:19:31.051: INFO: Created: latency-svc-w6rft
    Nov  5 12:19:31.089: INFO: Got endpoints: latency-svc-z6n6x [371.27313ms]
    Nov  5 12:19:31.099: INFO: Created: latency-svc-nmlg7
    Nov  5 12:19:31.138: INFO: Got endpoints: latency-svc-gvmgv [411.47303ms]
    Nov  5 12:19:31.148: INFO: Created: latency-svc-4z68t
    Nov  5 12:19:31.189: INFO: Got endpoints: latency-svc-wfslt [448.921278ms]
    Nov  5 12:19:31.199: INFO: Created: latency-svc-fmrnw
    Nov  5 12:19:31.241: INFO: Got endpoints: latency-svc-lqcrn [493.857622ms]
    Nov  5 12:19:31.252: INFO: Created: latency-svc-zbqxm
    Nov  5 12:19:31.288: INFO: Got endpoints: latency-svc-p9gqp [526.04848ms]
    Nov  5 12:19:31.298: INFO: Created: latency-svc-lxmgc
    Nov  5 12:19:31.339: INFO: Got endpoints: latency-svc-jngv6 [574.01679ms]
    Nov  5 12:19:31.350: INFO: Created: latency-svc-gm7r2
    Nov  5 12:19:31.391: INFO: Got endpoints: latency-svc-m57gh [617.179462ms]
    Nov  5 12:19:31.400: INFO: Created: latency-svc-r2zs6
    Nov  5 12:19:31.439: INFO: Got endpoints: latency-svc-sgk2b [656.592465ms]
    Nov  5 12:19:31.452: INFO: Created: latency-svc-p2f8n
    Nov  5 12:19:31.489: INFO: Got endpoints: latency-svc-vs8q5 [693.40802ms]
    Nov  5 12:19:31.500: INFO: Created: latency-svc-5rxqx
    Nov  5 12:19:31.541: INFO: Got endpoints: latency-svc-d8625 [735.322429ms]
    Nov  5 12:19:31.551: INFO: Created: latency-svc-bqh7d
    Nov  5 12:19:31.590: INFO: Got endpoints: latency-svc-c2ztq [753.637918ms]
    Nov  5 12:19:31.601: INFO: Created: latency-svc-t9g9b
    Nov  5 12:19:31.639: INFO: Got endpoints: latency-svc-tfvnf [750.556445ms]
    Nov  5 12:19:31.650: INFO: Created: latency-svc-sf6bk
    Nov  5 12:19:31.690: INFO: Got endpoints: latency-svc-xcf7g [750.382667ms]
    Nov  5 12:19:31.703: INFO: Created: latency-svc-zrc5t
    Nov  5 12:19:31.738: INFO: Got endpoints: latency-svc-gbr55 [741.360804ms]
    Nov  5 12:19:31.749: INFO: Created: latency-svc-k689n
    Nov  5 12:19:31.789: INFO: Got endpoints: latency-svc-w6rft [749.915398ms]
    Nov  5 12:19:31.799: INFO: Created: latency-svc-4ms5c
    Nov  5 12:19:31.840: INFO: Got endpoints: latency-svc-nmlg7 [751.006091ms]
    Nov  5 12:19:31.851: INFO: Created: latency-svc-75mvj
    Nov  5 12:19:31.890: INFO: Got endpoints: latency-svc-4z68t [752.017651ms]
    Nov  5 12:19:31.901: INFO: Created: latency-svc-xghmm
    Nov  5 12:19:31.937: INFO: Got endpoints: latency-svc-fmrnw [748.237151ms]
    Nov  5 12:19:31.949: INFO: Created: latency-svc-ttc5s
    Nov  5 12:19:31.989: INFO: Got endpoints: latency-svc-zbqxm [747.615778ms]
    Nov  5 12:19:31.999: INFO: Created: latency-svc-869l7
    Nov  5 12:19:32.040: INFO: Got endpoints: latency-svc-lxmgc [752.057438ms]
    Nov  5 12:19:32.052: INFO: Created: latency-svc-k2stw
    Nov  5 12:19:32.088: INFO: Got endpoints: latency-svc-gm7r2 [749.130284ms]
    Nov  5 12:19:32.101: INFO: Created: latency-svc-8m59d
    Nov  5 12:19:32.137: INFO: Got endpoints: latency-svc-r2zs6 [746.561196ms]
    Nov  5 12:19:32.149: INFO: Created: latency-svc-7xb6q
    Nov  5 12:19:32.190: INFO: Got endpoints: latency-svc-p2f8n [750.888762ms]
    Nov  5 12:19:32.199: INFO: Created: latency-svc-zgqxm
    Nov  5 12:19:32.238: INFO: Got endpoints: latency-svc-5rxqx [749.220187ms]
    Nov  5 12:19:32.249: INFO: Created: latency-svc-jbnqx
    Nov  5 12:19:32.290: INFO: Got endpoints: latency-svc-bqh7d [749.25777ms]
    Nov  5 12:19:32.300: INFO: Created: latency-svc-469q5
    Nov  5 12:19:32.340: INFO: Got endpoints: latency-svc-t9g9b [749.695487ms]
    Nov  5 12:19:32.351: INFO: Created: latency-svc-26mhg
    Nov  5 12:19:32.389: INFO: Got endpoints: latency-svc-sf6bk [749.867228ms]
    Nov  5 12:19:32.405: INFO: Created: latency-svc-k4fqq
    Nov  5 12:19:32.443: INFO: Got endpoints: latency-svc-zrc5t [753.186387ms]
    Nov  5 12:19:32.455: INFO: Created: latency-svc-jjp5c
    Nov  5 12:19:32.493: INFO: Got endpoints: latency-svc-k689n [754.827004ms]
    Nov  5 12:19:32.504: INFO: Created: latency-svc-wldl2
    Nov  5 12:19:32.538: INFO: Got endpoints: latency-svc-4ms5c [749.201698ms]
    Nov  5 12:19:32.549: INFO: Created: latency-svc-zs45b
    Nov  5 12:19:32.590: INFO: Got endpoints: latency-svc-75mvj [749.696118ms]
    Nov  5 12:19:32.600: INFO: Created: latency-svc-d94nf
    Nov  5 12:19:32.639: INFO: Got endpoints: latency-svc-xghmm [749.050244ms]
    Nov  5 12:19:32.651: INFO: Created: latency-svc-mbvj9
    Nov  5 12:19:32.689: INFO: Got endpoints: latency-svc-ttc5s [751.909843ms]
    Nov  5 12:19:32.702: INFO: Created: latency-svc-qms66
    Nov  5 12:19:32.740: INFO: Got endpoints: latency-svc-869l7 [751.181771ms]
    Nov  5 12:19:32.753: INFO: Created: latency-svc-rdmjl
    Nov  5 12:19:32.790: INFO: Got endpoints: latency-svc-k2stw [749.853791ms]
    Nov  5 12:19:32.799: INFO: Created: latency-svc-hscbt
    Nov  5 12:19:32.838: INFO: Got endpoints: latency-svc-8m59d [749.773583ms]
    Nov  5 12:19:32.849: INFO: Created: latency-svc-n5vv8
    Nov  5 12:19:32.888: INFO: Got endpoints: latency-svc-7xb6q [750.58927ms]
    Nov  5 12:19:32.899: INFO: Created: latency-svc-k6tql
    Nov  5 12:19:32.939: INFO: Got endpoints: latency-svc-zgqxm [749.149754ms]
    Nov  5 12:19:32.949: INFO: Created: latency-svc-lvq9v
    Nov  5 12:19:32.988: INFO: Got endpoints: latency-svc-jbnqx [749.413749ms]
    Nov  5 12:19:33.040: INFO: Got endpoints: latency-svc-469q5 [749.606519ms]
    Nov  5 12:19:33.049: INFO: Created: latency-svc-n88jt
    Nov  5 12:19:33.054: INFO: Created: latency-svc-vnz7b
    Nov  5 12:19:33.089: INFO: Got endpoints: latency-svc-26mhg [749.070625ms]
    Nov  5 12:19:33.099: INFO: Created: latency-svc-5hhqc
    Nov  5 12:19:33.140: INFO: Got endpoints: latency-svc-k4fqq [751.425167ms]
    Nov  5 12:19:33.153: INFO: Created: latency-svc-9gtns
    Nov  5 12:19:33.189: INFO: Got endpoints: latency-svc-jjp5c [746.41097ms]
    Nov  5 12:19:33.200: INFO: Created: latency-svc-psk7z
    Nov  5 12:19:33.241: INFO: Got endpoints: latency-svc-wldl2 [747.240162ms]
    Nov  5 12:19:33.257: INFO: Created: latency-svc-gfp2k
    Nov  5 12:19:33.289: INFO: Got endpoints: latency-svc-zs45b [751.078318ms]
    Nov  5 12:19:33.341: INFO: Got endpoints: latency-svc-d94nf [751.153086ms]
    Nov  5 12:19:33.374: INFO: Created: latency-svc-xlkpb
    Nov  5 12:19:33.379: INFO: Created: latency-svc-pkllx
    Nov  5 12:19:33.389: INFO: Got endpoints: latency-svc-mbvj9 [749.312995ms]
    Nov  5 12:19:33.400: INFO: Created: latency-svc-qwfzn
    Nov  5 12:19:33.441: INFO: Got endpoints: latency-svc-qms66 [751.690846ms]
    Nov  5 12:19:33.458: INFO: Created: latency-svc-96kgg
    Nov  5 12:19:33.493: INFO: Got endpoints: latency-svc-rdmjl [753.073144ms]
    Nov  5 12:19:33.509: INFO: Created: latency-svc-99jfg
    Nov  5 12:19:33.542: INFO: Got endpoints: latency-svc-hscbt [752.083153ms]
    Nov  5 12:19:33.553: INFO: Created: latency-svc-rm4tb
    Nov  5 12:19:33.591: INFO: Got endpoints: latency-svc-n5vv8 [752.739965ms]
    Nov  5 12:19:33.604: INFO: Created: latency-svc-bx7qd
    Nov  5 12:19:33.639: INFO: Got endpoints: latency-svc-k6tql [750.926474ms]
    Nov  5 12:19:33.650: INFO: Created: latency-svc-n2djt
    Nov  5 12:19:33.690: INFO: Got endpoints: latency-svc-lvq9v [750.597167ms]
    Nov  5 12:19:33.702: INFO: Created: latency-svc-w9rdh
    Nov  5 12:19:33.740: INFO: Got endpoints: latency-svc-n88jt [752.152303ms]
    Nov  5 12:19:33.751: INFO: Created: latency-svc-kr8vm
    Nov  5 12:19:33.788: INFO: Got endpoints: latency-svc-vnz7b [748.128048ms]
    Nov  5 12:19:33.798: INFO: Created: latency-svc-48j88
    Nov  5 12:19:33.843: INFO: Got endpoints: latency-svc-5hhqc [753.895455ms]
    Nov  5 12:19:33.854: INFO: Created: latency-svc-l29n9
    Nov  5 12:19:33.891: INFO: Got endpoints: latency-svc-9gtns [750.698552ms]
    Nov  5 12:19:33.901: INFO: Created: latency-svc-ms8fp
    Nov  5 12:19:33.939: INFO: Got endpoints: latency-svc-psk7z [749.74767ms]
    Nov  5 12:19:33.950: INFO: Created: latency-svc-pc2zx
    Nov  5 12:19:33.987: INFO: Got endpoints: latency-svc-gfp2k [746.708387ms]
    Nov  5 12:19:33.998: INFO: Created: latency-svc-n94r8
    Nov  5 12:19:34.041: INFO: Got endpoints: latency-svc-xlkpb [751.749413ms]
    Nov  5 12:19:34.052: INFO: Created: latency-svc-rwlrs
    Nov  5 12:19:34.094: INFO: Got endpoints: latency-svc-pkllx [753.334836ms]
    Nov  5 12:19:34.106: INFO: Created: latency-svc-fksdc
    Nov  5 12:19:34.139: INFO: Got endpoints: latency-svc-qwfzn [750.007927ms]
    Nov  5 12:19:34.150: INFO: Created: latency-svc-rr2xk
    Nov  5 12:19:34.189: INFO: Got endpoints: latency-svc-96kgg [747.875487ms]
    Nov  5 12:19:34.203: INFO: Created: latency-svc-52l5s
    Nov  5 12:19:34.238: INFO: Got endpoints: latency-svc-99jfg [745.597385ms]
    Nov  5 12:19:34.249: INFO: Created: latency-svc-655h7
    Nov  5 12:19:34.288: INFO: Got endpoints: latency-svc-rm4tb [745.642246ms]
    Nov  5 12:19:34.299: INFO: Created: latency-svc-dm244
    Nov  5 12:19:34.340: INFO: Got endpoints: latency-svc-bx7qd [748.96886ms]
    Nov  5 12:19:34.350: INFO: Created: latency-svc-bzp47
    Nov  5 12:19:34.391: INFO: Got endpoints: latency-svc-n2djt [752.284547ms]
    Nov  5 12:19:34.404: INFO: Created: latency-svc-2wmvm
    Nov  5 12:19:34.439: INFO: Got endpoints: latency-svc-w9rdh [749.198791ms]
    Nov  5 12:19:34.455: INFO: Created: latency-svc-k6s62
    Nov  5 12:19:34.492: INFO: Got endpoints: latency-svc-kr8vm [752.010119ms]
    Nov  5 12:19:34.504: INFO: Created: latency-svc-pht94
    Nov  5 12:19:34.538: INFO: Got endpoints: latency-svc-48j88 [749.897489ms]
    Nov  5 12:19:34.548: INFO: Created: latency-svc-pchdm
    Nov  5 12:19:34.589: INFO: Got endpoints: latency-svc-l29n9 [745.926242ms]
    Nov  5 12:19:34.608: INFO: Created: latency-svc-gq94h
    Nov  5 12:19:34.641: INFO: Got endpoints: latency-svc-ms8fp [749.969822ms]
    Nov  5 12:19:34.652: INFO: Created: latency-svc-zfrvj
    Nov  5 12:19:34.688: INFO: Got endpoints: latency-svc-pc2zx [748.54335ms]
    Nov  5 12:19:34.700: INFO: Created: latency-svc-6nwpr
    Nov  5 12:19:34.739: INFO: Got endpoints: latency-svc-n94r8 [751.579474ms]
    Nov  5 12:19:34.750: INFO: Created: latency-svc-rnxnl
    Nov  5 12:19:34.787: INFO: Got endpoints: latency-svc-rwlrs [746.001367ms]
    Nov  5 12:19:34.799: INFO: Created: latency-svc-b6zx8
    Nov  5 12:19:34.838: INFO: Got endpoints: latency-svc-fksdc [744.106205ms]
    Nov  5 12:19:34.849: INFO: Created: latency-svc-mw48x
    Nov  5 12:19:34.890: INFO: Got endpoints: latency-svc-rr2xk [751.187738ms]
    Nov  5 12:19:34.900: INFO: Created: latency-svc-cdsv9
    Nov  5 12:19:34.941: INFO: Got endpoints: latency-svc-52l5s [752.428691ms]
    Nov  5 12:19:34.951: INFO: Created: latency-svc-8xdvr
    Nov  5 12:19:34.990: INFO: Got endpoints: latency-svc-655h7 [751.516115ms]
    Nov  5 12:19:35.001: INFO: Created: latency-svc-66qvl
    Nov  5 12:19:35.039: INFO: Got endpoints: latency-svc-dm244 [751.103008ms]
    Nov  5 12:19:35.053: INFO: Created: latency-svc-fz59t
    Nov  5 12:19:35.095: INFO: Got endpoints: latency-svc-bzp47 [755.070682ms]
    Nov  5 12:19:35.109: INFO: Created: latency-svc-s7jkx
    Nov  5 12:19:35.141: INFO: Got endpoints: latency-svc-2wmvm [749.608772ms]
    Nov  5 12:19:35.160: INFO: Created: latency-svc-p9tcw
    Nov  5 12:19:35.189: INFO: Got endpoints: latency-svc-k6s62 [750.171187ms]
    Nov  5 12:19:35.201: INFO: Created: latency-svc-qn2xx
    Nov  5 12:19:35.239: INFO: Got endpoints: latency-svc-pht94 [747.082386ms]
    Nov  5 12:19:35.250: INFO: Created: latency-svc-59n9w
    Nov  5 12:19:35.287: INFO: Got endpoints: latency-svc-pchdm [748.899594ms]
    Nov  5 12:19:35.298: INFO: Created: latency-svc-xfm2k
    Nov  5 12:19:35.339: INFO: Got endpoints: latency-svc-gq94h [749.490853ms]
    Nov  5 12:19:35.350: INFO: Created: latency-svc-4qd5t
    Nov  5 12:19:35.387: INFO: Got endpoints: latency-svc-zfrvj [746.066561ms]
    Nov  5 12:19:35.398: INFO: Created: latency-svc-6xcd2
    Nov  5 12:19:35.440: INFO: Got endpoints: latency-svc-6nwpr [752.368702ms]
    Nov  5 12:19:35.452: INFO: Created: latency-svc-fz4t6
    Nov  5 12:19:35.490: INFO: Got endpoints: latency-svc-rnxnl [750.580577ms]
    Nov  5 12:19:35.502: INFO: Created: latency-svc-pdjlg
    Nov  5 12:19:35.537: INFO: Got endpoints: latency-svc-b6zx8 [750.035013ms]
    Nov  5 12:19:35.552: INFO: Created: latency-svc-mkd9r
    Nov  5 12:19:35.588: INFO: Got endpoints: latency-svc-mw48x [749.317327ms]
    Nov  5 12:19:35.599: INFO: Created: latency-svc-9kqjh
    Nov  5 12:19:35.640: INFO: Got endpoints: latency-svc-cdsv9 [749.984161ms]
    Nov  5 12:19:35.649: INFO: Created: latency-svc-c2677
    Nov  5 12:19:35.689: INFO: Got endpoints: latency-svc-8xdvr [747.931072ms]
    Nov  5 12:19:35.701: INFO: Created: latency-svc-mkfpz
    Nov  5 12:19:35.739: INFO: Got endpoints: latency-svc-66qvl [749.412951ms]
    Nov  5 12:19:35.750: INFO: Created: latency-svc-b2695
    Nov  5 12:19:35.788: INFO: Got endpoints: latency-svc-fz59t [748.947771ms]
    Nov  5 12:19:35.798: INFO: Created: latency-svc-f76t7
    Nov  5 12:19:35.839: INFO: Got endpoints: latency-svc-s7jkx [743.478443ms]
    Nov  5 12:19:35.852: INFO: Created: latency-svc-g27pb
    Nov  5 12:19:35.888: INFO: Got endpoints: latency-svc-p9tcw [746.470711ms]
    Nov  5 12:19:35.899: INFO: Created: latency-svc-4mg62
    Nov  5 12:19:35.939: INFO: Got endpoints: latency-svc-qn2xx [749.787467ms]
    Nov  5 12:19:35.949: INFO: Created: latency-svc-pf5q2
    Nov  5 12:19:35.989: INFO: Got endpoints: latency-svc-59n9w [749.267861ms]
    Nov  5 12:19:36.000: INFO: Created: latency-svc-v948l
    Nov  5 12:19:36.040: INFO: Got endpoints: latency-svc-xfm2k [753.193084ms]
    Nov  5 12:19:36.052: INFO: Created: latency-svc-9qkx8
    Nov  5 12:19:36.091: INFO: Got endpoints: latency-svc-4qd5t [752.329673ms]
    Nov  5 12:19:36.101: INFO: Created: latency-svc-bx9p4
    Nov  5 12:19:36.140: INFO: Got endpoints: latency-svc-6xcd2 [752.686312ms]
    Nov  5 12:19:36.150: INFO: Created: latency-svc-smph6
    Nov  5 12:19:36.191: INFO: Got endpoints: latency-svc-fz4t6 [750.232866ms]
    Nov  5 12:19:36.201: INFO: Created: latency-svc-4q2wd
    Nov  5 12:19:36.240: INFO: Got endpoints: latency-svc-pdjlg [750.301876ms]
    Nov  5 12:19:36.251: INFO: Created: latency-svc-62t6z
    Nov  5 12:19:36.287: INFO: Got endpoints: latency-svc-mkd9r [749.32261ms]
    Nov  5 12:19:36.298: INFO: Created: latency-svc-2jc65
    Nov  5 12:19:36.339: INFO: Got endpoints: latency-svc-9kqjh [751.153427ms]
    Nov  5 12:19:36.351: INFO: Created: latency-svc-q65ft
    Nov  5 12:19:36.391: INFO: Got endpoints: latency-svc-c2677 [751.281667ms]
    Nov  5 12:19:36.401: INFO: Created: latency-svc-s5b7z
    Nov  5 12:19:36.441: INFO: Got endpoints: latency-svc-mkfpz [751.895572ms]
    Nov  5 12:19:36.452: INFO: Created: latency-svc-7dwcc
    Nov  5 12:19:36.489: INFO: Got endpoints: latency-svc-b2695 [749.984969ms]
    Nov  5 12:19:36.505: INFO: Created: latency-svc-znwp5
    Nov  5 12:19:36.541: INFO: Got endpoints: latency-svc-f76t7 [753.228945ms]
    Nov  5 12:19:36.552: INFO: Created: latency-svc-569ls
    Nov  5 12:19:36.589: INFO: Got endpoints: latency-svc-g27pb [750.584312ms]
    Nov  5 12:19:36.600: INFO: Created: latency-svc-8wlq8
    Nov  5 12:19:36.640: INFO: Got endpoints: latency-svc-4mg62 [752.690383ms]
    Nov  5 12:19:36.650: INFO: Created: latency-svc-2z8nq
    Nov  5 12:19:36.689: INFO: Got endpoints: latency-svc-pf5q2 [749.737915ms]
    Nov  5 12:19:36.699: INFO: Created: latency-svc-6ljdb
    Nov  5 12:19:36.739: INFO: Got endpoints: latency-svc-v948l [749.905652ms]
    Nov  5 12:19:36.749: INFO: Created: latency-svc-kdhxr
    Nov  5 12:19:36.787: INFO: Got endpoints: latency-svc-9qkx8 [746.836529ms]
    Nov  5 12:19:36.798: INFO: Created: latency-svc-9vzgg
    Nov  5 12:19:36.839: INFO: Got endpoints: latency-svc-bx9p4 [747.74158ms]
    Nov  5 12:19:36.848: INFO: Created: latency-svc-cqffb
    Nov  5 12:19:36.887: INFO: Got endpoints: latency-svc-smph6 [747.695271ms]
    Nov  5 12:19:36.898: INFO: Created: latency-svc-gk9qt
    Nov  5 12:19:36.941: INFO: Got endpoints: latency-svc-4q2wd [749.909406ms]
    Nov  5 12:19:36.951: INFO: Created: latency-svc-khj42
    Nov  5 12:19:36.989: INFO: Got endpoints: latency-svc-62t6z [748.581923ms]
    Nov  5 12:19:36.998: INFO: Created: latency-svc-rx5zv
    Nov  5 12:19:37.039: INFO: Got endpoints: latency-svc-2jc65 [751.519098ms]
    Nov  5 12:19:37.052: INFO: Created: latency-svc-54q7k
    Nov  5 12:19:37.089: INFO: Got endpoints: latency-svc-q65ft [749.83828ms]
    Nov  5 12:19:37.102: INFO: Created: latency-svc-n2l5t
    Nov  5 12:19:37.148: INFO: Got endpoints: latency-svc-s5b7z [756.859422ms]
    Nov  5 12:19:37.159: INFO: Created: latency-svc-b96qk
    Nov  5 12:19:37.193: INFO: Got endpoints: latency-svc-7dwcc [751.299272ms]
    Nov  5 12:19:37.204: INFO: Created: latency-svc-fvtj8
    Nov  5 12:19:37.239: INFO: Got endpoints: latency-svc-znwp5 [748.994464ms]
    Nov  5 12:19:37.248: INFO: Created: latency-svc-9clgm
    Nov  5 12:19:37.288: INFO: Got endpoints: latency-svc-569ls [746.739335ms]
    Nov  5 12:19:37.299: INFO: Created: latency-svc-drcwv
    Nov  5 12:19:37.340: INFO: Got endpoints: latency-svc-8wlq8 [750.406474ms]
    Nov  5 12:19:37.350: INFO: Created: latency-svc-l7cl6
    Nov  5 12:19:37.392: INFO: Got endpoints: latency-svc-2z8nq [751.396342ms]
    Nov  5 12:19:37.403: INFO: Created: latency-svc-xhnpp
    Nov  5 12:19:37.442: INFO: Got endpoints: latency-svc-6ljdb [752.531345ms]
    Nov  5 12:19:37.457: INFO: Created: latency-svc-cvf4c
    Nov  5 12:19:37.492: INFO: Got endpoints: latency-svc-kdhxr [753.318778ms]
    Nov  5 12:19:37.508: INFO: Created: latency-svc-zsz4s
    Nov  5 12:19:37.539: INFO: Got endpoints: latency-svc-9vzgg [752.170905ms]
    Nov  5 12:19:37.553: INFO: Created: latency-svc-rh7vr
    Nov  5 12:19:37.591: INFO: Got endpoints: latency-svc-cqffb [751.999391ms]
    Nov  5 12:19:37.601: INFO: Created: latency-svc-hd9dw
    Nov  5 12:19:37.641: INFO: Got endpoints: latency-svc-gk9qt [753.435323ms]
    Nov  5 12:19:37.653: INFO: Created: latency-svc-xnvhj
    Nov  5 12:19:37.689: INFO: Got endpoints: latency-svc-khj42 [748.850684ms]
    Nov  5 12:19:37.700: INFO: Created: latency-svc-dk2z5
    Nov  5 12:19:37.742: INFO: Got endpoints: latency-svc-rx5zv [753.7349ms]
    Nov  5 12:19:37.751: INFO: Created: latency-svc-h49bh
    Nov  5 12:19:37.789: INFO: Got endpoints: latency-svc-54q7k [750.481853ms]
    Nov  5 12:19:37.801: INFO: Created: latency-svc-4nsz6
    Nov  5 12:19:37.840: INFO: Got endpoints: latency-svc-n2l5t [750.586271ms]
    Nov  5 12:19:37.850: INFO: Created: latency-svc-mmfz4
    Nov  5 12:19:37.889: INFO: Got endpoints: latency-svc-b96qk [740.579874ms]
    Nov  5 12:19:37.898: INFO: Created: latency-svc-vsnjt
    Nov  5 12:19:37.939: INFO: Got endpoints: latency-svc-fvtj8 [746.742881ms]
    Nov  5 12:19:37.952: INFO: Created: latency-svc-sf4mh
    Nov  5 12:19:37.989: INFO: Got endpoints: latency-svc-9clgm [750.183662ms]
    Nov  5 12:19:38.002: INFO: Created: latency-svc-jjsg9
    Nov  5 12:19:38.040: INFO: Got endpoints: latency-svc-drcwv [751.948861ms]
    Nov  5 12:19:38.049: INFO: Created: latency-svc-5kr6r
    Nov  5 12:19:38.089: INFO: Got endpoints: latency-svc-l7cl6 [748.886044ms]
    Nov  5 12:19:38.100: INFO: Created: latency-svc-5pdnf
    Nov  5 12:19:38.141: INFO: Got endpoints: latency-svc-xhnpp [748.629203ms]
    Nov  5 12:19:38.151: INFO: Created: latency-svc-jdn64
    Nov  5 12:19:38.190: INFO: Got endpoints: latency-svc-cvf4c [748.436706ms]
    Nov  5 12:19:38.201: INFO: Created: latency-svc-9bt97
    Nov  5 12:19:38.238: INFO: Got endpoints: latency-svc-zsz4s [745.32275ms]
    Nov  5 12:19:38.249: INFO: Created: latency-svc-k2f4x
    Nov  5 12:19:38.290: INFO: Got endpoints: latency-svc-rh7vr [750.004881ms]
    Nov  5 12:19:38.339: INFO: Got endpoints: latency-svc-hd9dw [748.394376ms]
    Nov  5 12:19:38.389: INFO: Got endpoints: latency-svc-xnvhj [748.11418ms]
    Nov  5 12:19:38.441: INFO: Got endpoints: latency-svc-dk2z5 [751.338216ms]
    Nov  5 12:19:38.490: INFO: Got endpoints: latency-svc-h49bh [747.472125ms]
    Nov  5 12:19:38.540: INFO: Got endpoints: latency-svc-4nsz6 [751.143056ms]
    Nov  5 12:19:38.589: INFO: Got endpoints: latency-svc-mmfz4 [749.746021ms]
    Nov  5 12:19:38.641: INFO: Got endpoints: latency-svc-vsnjt [751.653559ms]
    Nov  5 12:19:38.689: INFO: Got endpoints: latency-svc-sf4mh [749.461254ms]
    Nov  5 12:19:38.739: INFO: Got endpoints: latency-svc-jjsg9 [750.614399ms]
    Nov  5 12:19:38.790: INFO: Got endpoints: latency-svc-5kr6r [750.082852ms]
    Nov  5 12:19:38.841: INFO: Got endpoints: latency-svc-5pdnf [751.725121ms]
    Nov  5 12:19:38.899: INFO: Got endpoints: latency-svc-jdn64 [757.876683ms]
    Nov  5 12:19:38.941: INFO: Got endpoints: latency-svc-9bt97 [750.626486ms]
    Nov  5 12:19:38.990: INFO: Got endpoints: latency-svc-k2f4x [752.400132ms]
    Nov  5 12:19:38.990: INFO: Latencies: [29.735632ms 43.92879ms 50.034395ms 62.152451ms 70.813873ms 76.66517ms 82.391082ms 100.951408ms 108.336992ms 119.5915ms 129.74485ms 132.171823ms 133.069756ms 133.828802ms 133.881979ms 133.905535ms 134.740289ms 134.950219ms 135.012017ms 135.145349ms 136.064675ms 136.508742ms 136.661913ms 138.327728ms 138.5343ms 140.481825ms 140.814119ms 140.845988ms 141.549208ms 141.661271ms 142.337473ms 144.576989ms 144.864632ms 145.633338ms 158.907006ms 165.765143ms 166.729463ms 206.930911ms 248.062184ms 298.074813ms 331.12952ms 371.27313ms 411.47303ms 448.921278ms 493.857622ms 526.04848ms 574.01679ms 617.179462ms 656.592465ms 693.40802ms 735.322429ms 740.579874ms 741.360804ms 743.478443ms 744.106205ms 745.32275ms 745.597385ms 745.642246ms 745.926242ms 746.001367ms 746.066561ms 746.41097ms 746.470711ms 746.561196ms 746.708387ms 746.739335ms 746.742881ms 746.836529ms 747.082386ms 747.240162ms 747.472125ms 747.615778ms 747.695271ms 747.74158ms 747.875487ms 747.931072ms 748.11418ms 748.128048ms 748.237151ms 748.394376ms 748.436706ms 748.54335ms 748.581923ms 748.629203ms 748.850684ms 748.886044ms 748.899594ms 748.947771ms 748.96886ms 748.994464ms 749.050244ms 749.070625ms 749.130284ms 749.149754ms 749.198791ms 749.201698ms 749.220187ms 749.25777ms 749.267861ms 749.312995ms 749.317327ms 749.32261ms 749.412951ms 749.413749ms 749.461254ms 749.490853ms 749.606519ms 749.608772ms 749.695487ms 749.696118ms 749.737915ms 749.746021ms 749.74767ms 749.773583ms 749.787467ms 749.83828ms 749.853791ms 749.867228ms 749.897489ms 749.905652ms 749.909406ms 749.915398ms 749.969822ms 749.984161ms 749.984969ms 750.004881ms 750.007927ms 750.035013ms 750.082852ms 750.171187ms 750.183662ms 750.232866ms 750.301876ms 750.382667ms 750.406474ms 750.481853ms 750.556445ms 750.580577ms 750.584312ms 750.586271ms 750.58927ms 750.597167ms 750.614399ms 750.626486ms 750.698552ms 750.888762ms 750.926474ms 751.006091ms 751.078318ms 751.103008ms 751.143056ms 751.153086ms 751.153427ms 751.181771ms 751.187738ms 751.281667ms 751.299272ms 751.338216ms 751.396342ms 751.425167ms 751.516115ms 751.519098ms 751.579474ms 751.653559ms 751.690846ms 751.725121ms 751.749413ms 751.895572ms 751.909843ms 751.948861ms 751.999391ms 752.010119ms 752.017651ms 752.057438ms 752.083153ms 752.152303ms 752.170905ms 752.284547ms 752.329673ms 752.368702ms 752.400132ms 752.428691ms 752.531345ms 752.686312ms 752.690383ms 752.739965ms 753.073144ms 753.186387ms 753.193084ms 753.228945ms 753.318778ms 753.334836ms 753.435323ms 753.637918ms 753.7349ms 753.895455ms 754.827004ms 755.070682ms 756.859422ms 757.876683ms]
    Nov  5 12:19:38.990: INFO: 50 %ile: 749.317327ms
    Nov  5 12:19:38.990: INFO: 90 %ile: 752.400132ms
    Nov  5 12:19:38.990: INFO: 99 %ile: 756.859422ms
    Nov  5 12:19:38.990: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Nov  5 12:19:38.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-4334" for this suite. 11/05/22 12:19:38.996
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:19:39.003
Nov  5 12:19:39.004: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replication-controller 11/05/22 12:19:39.004
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:39.017
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:39.021
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf 11/05/22 12:19:39.025
Nov  5 12:19:39.035: INFO: Pod name my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf: Found 0 pods out of 1
Nov  5 12:19:44.042: INFO: Pod name my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf: Found 1 pods out of 1
Nov  5 12:19:44.042: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf" are running
Nov  5 12:19:44.042: INFO: Waiting up to 5m0s for pod "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm" in namespace "replication-controller-4800" to be "running"
Nov  5 12:19:44.046: INFO: Pod "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm": Phase="Running", Reason="", readiness=true. Elapsed: 3.497752ms
Nov  5 12:19:44.046: INFO: Pod "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm" satisfied condition "running"
Nov  5 12:19:44.046: INFO: Pod "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:19:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:19:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:19:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:19:39 +0000 UTC Reason: Message:}])
Nov  5 12:19:44.046: INFO: Trying to dial the pod
Nov  5 12:19:49.058: INFO: Controller my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf: Got expected result from replica 1 [my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm]: "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov  5 12:19:49.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4800" for this suite. 11/05/22 12:19:49.062
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":122,"skipped":2149,"failed":0}
------------------------------
• [SLOW TEST] [10.065 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:19:39.003
    Nov  5 12:19:39.004: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replication-controller 11/05/22 12:19:39.004
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:39.017
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:39.021
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf 11/05/22 12:19:39.025
    Nov  5 12:19:39.035: INFO: Pod name my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf: Found 0 pods out of 1
    Nov  5 12:19:44.042: INFO: Pod name my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf: Found 1 pods out of 1
    Nov  5 12:19:44.042: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf" are running
    Nov  5 12:19:44.042: INFO: Waiting up to 5m0s for pod "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm" in namespace "replication-controller-4800" to be "running"
    Nov  5 12:19:44.046: INFO: Pod "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm": Phase="Running", Reason="", readiness=true. Elapsed: 3.497752ms
    Nov  5 12:19:44.046: INFO: Pod "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm" satisfied condition "running"
    Nov  5 12:19:44.046: INFO: Pod "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:19:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:19:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:19:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2022-11-05 12:19:39 +0000 UTC Reason: Message:}])
    Nov  5 12:19:44.046: INFO: Trying to dial the pod
    Nov  5 12:19:49.058: INFO: Controller my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf: Got expected result from replica 1 [my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm]: "my-hostname-basic-9213aaca-27b9-41f2-a12d-71e999c69baf-jrsxm", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov  5 12:19:49.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-4800" for this suite. 11/05/22 12:19:49.062
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:19:49.07
Nov  5 12:19:49.070: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 12:19:49.071
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:49.084
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:49.088
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 12:19:49.107
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:19:49.494
STEP: Deploying the webhook pod 11/05/22 12:19:49.504
STEP: Wait for the deployment to be ready 11/05/22 12:19:49.517
Nov  5 12:19:49.528: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 12:19:51.539
STEP: Verifying the service has paired with the endpoint 11/05/22 12:19:51.555
Nov  5 12:19:52.555: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Nov  5 12:19:53.556: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
Nov  5 12:19:54.555: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 11/05/22 12:19:54.559
STEP: create a namespace for the webhook 11/05/22 12:19:54.575
STEP: create a configmap should be unconditionally rejected by the webhook 11/05/22 12:19:54.583
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:19:54.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7232" for this suite. 11/05/22 12:19:54.648
STEP: Destroying namespace "webhook-7232-markers" for this suite. 11/05/22 12:19:54.655
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":123,"skipped":2153,"failed":0}
------------------------------
• [SLOW TEST] [5.643 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:19:49.07
    Nov  5 12:19:49.070: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 12:19:49.071
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:49.084
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:49.088
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 12:19:49.107
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:19:49.494
    STEP: Deploying the webhook pod 11/05/22 12:19:49.504
    STEP: Wait for the deployment to be ready 11/05/22 12:19:49.517
    Nov  5 12:19:49.528: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 12:19:51.539
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:19:51.555
    Nov  5 12:19:52.555: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Nov  5 12:19:53.556: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    Nov  5 12:19:54.555: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 11/05/22 12:19:54.559
    STEP: create a namespace for the webhook 11/05/22 12:19:54.575
    STEP: create a configmap should be unconditionally rejected by the webhook 11/05/22 12:19:54.583
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:19:54.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7232" for this suite. 11/05/22 12:19:54.648
    STEP: Destroying namespace "webhook-7232-markers" for this suite. 11/05/22 12:19:54.655
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:19:54.713
Nov  5 12:19:54.713: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename watch 11/05/22 12:19:54.714
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:54.734
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:54.749
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 11/05/22 12:19:54.753
STEP: creating a new configmap 11/05/22 12:19:54.755
STEP: modifying the configmap once 11/05/22 12:19:54.76
STEP: changing the label value of the configmap 11/05/22 12:19:54.768
STEP: Expecting to observe a delete notification for the watched object 11/05/22 12:19:54.777
Nov  5 12:19:54.777: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16505 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:19:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 12:19:54.777: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16506 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:19:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 12:19:54.778: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16507 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:19:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 11/05/22 12:19:54.778
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 11/05/22 12:19:54.786
STEP: changing the label value of the configmap back 11/05/22 12:20:04.788
STEP: modifying the configmap a third time 11/05/22 12:20:04.798
STEP: deleting the configmap 11/05/22 12:20:04.805
STEP: Expecting to observe an add notification for the watched object when the label value was restored 11/05/22 12:20:04.812
Nov  5 12:20:04.812: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16566 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:20:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 12:20:04.813: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16567 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:20:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 12:20:04.813: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16568 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:20:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov  5 12:20:04.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9340" for this suite. 11/05/22 12:20:04.817
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":124,"skipped":2156,"failed":0}
------------------------------
• [SLOW TEST] [10.111 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:19:54.713
    Nov  5 12:19:54.713: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename watch 11/05/22 12:19:54.714
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:19:54.734
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:19:54.749
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 11/05/22 12:19:54.753
    STEP: creating a new configmap 11/05/22 12:19:54.755
    STEP: modifying the configmap once 11/05/22 12:19:54.76
    STEP: changing the label value of the configmap 11/05/22 12:19:54.768
    STEP: Expecting to observe a delete notification for the watched object 11/05/22 12:19:54.777
    Nov  5 12:19:54.777: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16505 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:19:54 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 12:19:54.777: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16506 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:19:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 12:19:54.778: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16507 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:19:54 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 11/05/22 12:19:54.778
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 11/05/22 12:19:54.786
    STEP: changing the label value of the configmap back 11/05/22 12:20:04.788
    STEP: modifying the configmap a third time 11/05/22 12:20:04.798
    STEP: deleting the configmap 11/05/22 12:20:04.805
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 11/05/22 12:20:04.812
    Nov  5 12:20:04.812: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16566 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:20:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 12:20:04.813: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16567 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:20:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 12:20:04.813: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9340  0715d5bc-70a3-497e-a68d-de95638893c4 16568 0 2022-11-05 12:19:54 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2022-11-05 12:20:04 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov  5 12:20:04.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-9340" for this suite. 11/05/22 12:20:04.817
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:20:04.826
Nov  5 12:20:04.826: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename runtimeclass 11/05/22 12:20:04.827
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:20:04.841
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:20:04.845
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Nov  5 12:20:04.860: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-9802 to be scheduled
Nov  5 12:20:04.863: INFO: 1 pods are not scheduled: [runtimeclass-9802/test-runtimeclass-runtimeclass-9802-preconfigured-handler-x27j2(e96d24f3-7100-44ba-921e-6b8fb6bf889f)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov  5 12:20:06.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-9802" for this suite. 11/05/22 12:20:06.878
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":125,"skipped":2179,"failed":0}
------------------------------
• [2.059 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:20:04.826
    Nov  5 12:20:04.826: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename runtimeclass 11/05/22 12:20:04.827
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:20:04.841
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:20:04.845
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Nov  5 12:20:04.860: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-9802 to be scheduled
    Nov  5 12:20:04.863: INFO: 1 pods are not scheduled: [runtimeclass-9802/test-runtimeclass-runtimeclass-9802-preconfigured-handler-x27j2(e96d24f3-7100-44ba-921e-6b8fb6bf889f)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov  5 12:20:06.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-9802" for this suite. 11/05/22 12:20:06.878
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:20:06.886
Nov  5 12:20:06.886: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename custom-resource-definition 11/05/22 12:20:06.887
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:20:06.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:20:06.903
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Nov  5 12:20:06.907: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:20:10.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1662" for this suite. 11/05/22 12:20:10.049
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":126,"skipped":2222,"failed":0}
------------------------------
• [3.169 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:20:06.886
    Nov  5 12:20:06.886: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename custom-resource-definition 11/05/22 12:20:06.887
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:20:06.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:20:06.903
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Nov  5 12:20:06.907: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:20:10.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1662" for this suite. 11/05/22 12:20:10.049
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:20:10.056
Nov  5 12:20:10.056: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-probe 11/05/22 12:20:10.056
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:20:10.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:20:10.072
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-401bcd6c-919e-4993-bf83-3c14980d6078 in namespace container-probe-5324 11/05/22 12:20:10.076
Nov  5 12:20:10.084: INFO: Waiting up to 5m0s for pod "liveness-401bcd6c-919e-4993-bf83-3c14980d6078" in namespace "container-probe-5324" to be "not pending"
Nov  5 12:20:10.088: INFO: Pod "liveness-401bcd6c-919e-4993-bf83-3c14980d6078": Phase="Pending", Reason="", readiness=false. Elapsed: 4.120652ms
Nov  5 12:20:12.092: INFO: Pod "liveness-401bcd6c-919e-4993-bf83-3c14980d6078": Phase="Running", Reason="", readiness=true. Elapsed: 2.007999022s
Nov  5 12:20:12.092: INFO: Pod "liveness-401bcd6c-919e-4993-bf83-3c14980d6078" satisfied condition "not pending"
Nov  5 12:20:12.092: INFO: Started pod liveness-401bcd6c-919e-4993-bf83-3c14980d6078 in namespace container-probe-5324
STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 12:20:12.092
Nov  5 12:20:12.096: INFO: Initial restart count of pod liveness-401bcd6c-919e-4993-bf83-3c14980d6078 is 0
STEP: deleting the pod 11/05/22 12:24:12.655
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov  5 12:24:12.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5324" for this suite. 11/05/22 12:24:12.675
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":127,"skipped":2228,"failed":0}
------------------------------
• [SLOW TEST] [242.631 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:20:10.056
    Nov  5 12:20:10.056: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-probe 11/05/22 12:20:10.056
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:20:10.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:20:10.072
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-401bcd6c-919e-4993-bf83-3c14980d6078 in namespace container-probe-5324 11/05/22 12:20:10.076
    Nov  5 12:20:10.084: INFO: Waiting up to 5m0s for pod "liveness-401bcd6c-919e-4993-bf83-3c14980d6078" in namespace "container-probe-5324" to be "not pending"
    Nov  5 12:20:10.088: INFO: Pod "liveness-401bcd6c-919e-4993-bf83-3c14980d6078": Phase="Pending", Reason="", readiness=false. Elapsed: 4.120652ms
    Nov  5 12:20:12.092: INFO: Pod "liveness-401bcd6c-919e-4993-bf83-3c14980d6078": Phase="Running", Reason="", readiness=true. Elapsed: 2.007999022s
    Nov  5 12:20:12.092: INFO: Pod "liveness-401bcd6c-919e-4993-bf83-3c14980d6078" satisfied condition "not pending"
    Nov  5 12:20:12.092: INFO: Started pod liveness-401bcd6c-919e-4993-bf83-3c14980d6078 in namespace container-probe-5324
    STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 12:20:12.092
    Nov  5 12:20:12.096: INFO: Initial restart count of pod liveness-401bcd6c-919e-4993-bf83-3c14980d6078 is 0
    STEP: deleting the pod 11/05/22 12:24:12.655
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov  5 12:24:12.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5324" for this suite. 11/05/22 12:24:12.675
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:24:12.688
Nov  5 12:24:12.688: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename events 11/05/22 12:24:12.689
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:24:12.701
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:24:12.706
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 11/05/22 12:24:12.709
STEP: listing all events in all namespaces 11/05/22 12:24:12.717
STEP: patching the test event 11/05/22 12:24:12.725
STEP: fetching the test event 11/05/22 12:24:12.731
STEP: updating the test event 11/05/22 12:24:12.734
STEP: getting the test event 11/05/22 12:24:12.743
STEP: deleting the test event 11/05/22 12:24:12.748
STEP: listing all events in all namespaces 11/05/22 12:24:12.755
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Nov  5 12:24:12.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6885" for this suite. 11/05/22 12:24:12.766
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":128,"skipped":2244,"failed":0}
------------------------------
• [0.087 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:24:12.688
    Nov  5 12:24:12.688: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename events 11/05/22 12:24:12.689
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:24:12.701
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:24:12.706
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 11/05/22 12:24:12.709
    STEP: listing all events in all namespaces 11/05/22 12:24:12.717
    STEP: patching the test event 11/05/22 12:24:12.725
    STEP: fetching the test event 11/05/22 12:24:12.731
    STEP: updating the test event 11/05/22 12:24:12.734
    STEP: getting the test event 11/05/22 12:24:12.743
    STEP: deleting the test event 11/05/22 12:24:12.748
    STEP: listing all events in all namespaces 11/05/22 12:24:12.755
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Nov  5 12:24:12.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-6885" for this suite. 11/05/22 12:24:12.766
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:24:12.777
Nov  5 12:24:12.777: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 12:24:12.777
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:24:12.788
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:24:12.792
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 11/05/22 12:24:12.796
Nov  5 12:24:12.805: INFO: Waiting up to 5m0s for pod "pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436" in namespace "emptydir-965" to be "Succeeded or Failed"
Nov  5 12:24:12.812: INFO: Pod "pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436": Phase="Pending", Reason="", readiness=false. Elapsed: 6.584146ms
Nov  5 12:24:14.817: INFO: Pod "pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01185115s
Nov  5 12:24:16.816: INFO: Pod "pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010857576s
STEP: Saw pod success 11/05/22 12:24:16.816
Nov  5 12:24:16.816: INFO: Pod "pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436" satisfied condition "Succeeded or Failed"
Nov  5 12:24:16.820: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436 container test-container: <nil>
STEP: delete the pod 11/05/22 12:24:16.836
Nov  5 12:24:16.847: INFO: Waiting for pod pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436 to disappear
Nov  5 12:24:16.850: INFO: Pod pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 12:24:16.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-965" for this suite. 11/05/22 12:24:16.854
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":129,"skipped":2257,"failed":0}
------------------------------
• [4.084 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:24:12.777
    Nov  5 12:24:12.777: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 12:24:12.777
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:24:12.788
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:24:12.792
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 11/05/22 12:24:12.796
    Nov  5 12:24:12.805: INFO: Waiting up to 5m0s for pod "pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436" in namespace "emptydir-965" to be "Succeeded or Failed"
    Nov  5 12:24:12.812: INFO: Pod "pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436": Phase="Pending", Reason="", readiness=false. Elapsed: 6.584146ms
    Nov  5 12:24:14.817: INFO: Pod "pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01185115s
    Nov  5 12:24:16.816: INFO: Pod "pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010857576s
    STEP: Saw pod success 11/05/22 12:24:16.816
    Nov  5 12:24:16.816: INFO: Pod "pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436" satisfied condition "Succeeded or Failed"
    Nov  5 12:24:16.820: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436 container test-container: <nil>
    STEP: delete the pod 11/05/22 12:24:16.836
    Nov  5 12:24:16.847: INFO: Waiting for pod pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436 to disappear
    Nov  5 12:24:16.850: INFO: Pod pod-62188d2e-e6c5-42ed-8cd4-ca078d6a1436 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 12:24:16.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-965" for this suite. 11/05/22 12:24:16.854
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:24:16.861
Nov  5 12:24:16.862: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename job 11/05/22 12:24:16.862
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:24:16.874
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:24:16.878
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 11/05/22 12:24:16.882
STEP: Ensuring job reaches completions 11/05/22 12:24:16.889
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov  5 12:24:26.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5210" for this suite. 11/05/22 12:24:26.897
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":130,"skipped":2260,"failed":0}
------------------------------
• [SLOW TEST] [10.042 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:24:16.861
    Nov  5 12:24:16.862: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename job 11/05/22 12:24:16.862
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:24:16.874
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:24:16.878
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 11/05/22 12:24:16.882
    STEP: Ensuring job reaches completions 11/05/22 12:24:16.889
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov  5 12:24:26.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-5210" for this suite. 11/05/22 12:24:26.897
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:24:26.904
Nov  5 12:24:26.904: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:24:26.905
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:24:26.917
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:24:26.922
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 11/05/22 12:24:26.925
Nov  5 12:24:26.925: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-8258 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 11/05/22 12:24:26.968
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:24:26.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8258" for this suite. 11/05/22 12:24:26.981
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":131,"skipped":2266,"failed":0}
------------------------------
• [0.084 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:24:26.904
    Nov  5 12:24:26.904: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:24:26.905
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:24:26.917
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:24:26.922
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 11/05/22 12:24:26.925
    Nov  5 12:24:26.925: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-8258 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 11/05/22 12:24:26.968
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:24:26.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8258" for this suite. 11/05/22 12:24:26.981
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:24:26.989
Nov  5 12:24:26.989: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename job 11/05/22 12:24:26.99
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:24:27.001
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:24:27.006
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 11/05/22 12:24:27.01
STEP: Ensuring active pods == parallelism 11/05/22 12:24:27.015
STEP: delete a job 11/05/22 12:24:29.02
STEP: deleting Job.batch foo in namespace job-3154, will wait for the garbage collector to delete the pods 11/05/22 12:24:29.02
Nov  5 12:24:29.081: INFO: Deleting Job.batch foo took: 6.541049ms
Nov  5 12:24:29.181: INFO: Terminating Job.batch foo pods took: 100.096225ms
STEP: Ensuring job was deleted 11/05/22 12:25:01.181
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov  5 12:25:01.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3154" for this suite. 11/05/22 12:25:01.19
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":132,"skipped":2272,"failed":0}
------------------------------
• [SLOW TEST] [34.207 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:24:26.989
    Nov  5 12:24:26.989: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename job 11/05/22 12:24:26.99
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:24:27.001
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:24:27.006
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 11/05/22 12:24:27.01
    STEP: Ensuring active pods == parallelism 11/05/22 12:24:27.015
    STEP: delete a job 11/05/22 12:24:29.02
    STEP: deleting Job.batch foo in namespace job-3154, will wait for the garbage collector to delete the pods 11/05/22 12:24:29.02
    Nov  5 12:24:29.081: INFO: Deleting Job.batch foo took: 6.541049ms
    Nov  5 12:24:29.181: INFO: Terminating Job.batch foo pods took: 100.096225ms
    STEP: Ensuring job was deleted 11/05/22 12:25:01.181
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov  5 12:25:01.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3154" for this suite. 11/05/22 12:25:01.19
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:25:01.197
Nov  5 12:25:01.197: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename statefulset 11/05/22 12:25:01.197
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:01.213
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:01.218
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-9983 11/05/22 12:25:01.222
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 11/05/22 12:25:01.228
STEP: Creating pod with conflicting port in namespace statefulset-9983 11/05/22 12:25:01.235
STEP: Waiting until pod test-pod will start running in namespace statefulset-9983 11/05/22 12:25:01.245
Nov  5 12:25:01.245: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-9983" to be "running"
Nov  5 12:25:01.249: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.230914ms
Nov  5 12:25:03.253: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007567486s
Nov  5 12:25:03.253: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-9983 11/05/22 12:25:03.253
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9983 11/05/22 12:25:03.258
Nov  5 12:25:03.270: INFO: Observed stateful pod in namespace: statefulset-9983, name: ss-0, uid: 4285a40a-5cc6-44cb-a115-bdfdc4ee378c, status phase: Pending. Waiting for statefulset controller to delete.
Nov  5 12:25:03.287: INFO: Observed stateful pod in namespace: statefulset-9983, name: ss-0, uid: 4285a40a-5cc6-44cb-a115-bdfdc4ee378c, status phase: Failed. Waiting for statefulset controller to delete.
Nov  5 12:25:03.295: INFO: Observed stateful pod in namespace: statefulset-9983, name: ss-0, uid: 4285a40a-5cc6-44cb-a115-bdfdc4ee378c, status phase: Failed. Waiting for statefulset controller to delete.
Nov  5 12:25:03.301: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9983
STEP: Removing pod with conflicting port in namespace statefulset-9983 11/05/22 12:25:03.301
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9983 and will be in running state 11/05/22 12:25:03.319
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov  5 12:25:05.330: INFO: Deleting all statefulset in ns statefulset-9983
Nov  5 12:25:05.334: INFO: Scaling statefulset ss to 0
Nov  5 12:25:15.353: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 12:25:15.356: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov  5 12:25:15.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9983" for this suite. 11/05/22 12:25:15.39
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":133,"skipped":2294,"failed":0}
------------------------------
• [SLOW TEST] [14.199 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:25:01.197
    Nov  5 12:25:01.197: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename statefulset 11/05/22 12:25:01.197
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:01.213
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:01.218
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-9983 11/05/22 12:25:01.222
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 11/05/22 12:25:01.228
    STEP: Creating pod with conflicting port in namespace statefulset-9983 11/05/22 12:25:01.235
    STEP: Waiting until pod test-pod will start running in namespace statefulset-9983 11/05/22 12:25:01.245
    Nov  5 12:25:01.245: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-9983" to be "running"
    Nov  5 12:25:01.249: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.230914ms
    Nov  5 12:25:03.253: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007567486s
    Nov  5 12:25:03.253: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-9983 11/05/22 12:25:03.253
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9983 11/05/22 12:25:03.258
    Nov  5 12:25:03.270: INFO: Observed stateful pod in namespace: statefulset-9983, name: ss-0, uid: 4285a40a-5cc6-44cb-a115-bdfdc4ee378c, status phase: Pending. Waiting for statefulset controller to delete.
    Nov  5 12:25:03.287: INFO: Observed stateful pod in namespace: statefulset-9983, name: ss-0, uid: 4285a40a-5cc6-44cb-a115-bdfdc4ee378c, status phase: Failed. Waiting for statefulset controller to delete.
    Nov  5 12:25:03.295: INFO: Observed stateful pod in namespace: statefulset-9983, name: ss-0, uid: 4285a40a-5cc6-44cb-a115-bdfdc4ee378c, status phase: Failed. Waiting for statefulset controller to delete.
    Nov  5 12:25:03.301: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9983
    STEP: Removing pod with conflicting port in namespace statefulset-9983 11/05/22 12:25:03.301
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9983 and will be in running state 11/05/22 12:25:03.319
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov  5 12:25:05.330: INFO: Deleting all statefulset in ns statefulset-9983
    Nov  5 12:25:05.334: INFO: Scaling statefulset ss to 0
    Nov  5 12:25:15.353: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 12:25:15.356: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov  5 12:25:15.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-9983" for this suite. 11/05/22 12:25:15.39
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:25:15.397
Nov  5 12:25:15.397: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename lease-test 11/05/22 12:25:15.398
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:15.413
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:15.416
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Nov  5 12:25:15.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-9406" for this suite. 11/05/22 12:25:15.477
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":134,"skipped":2310,"failed":0}
------------------------------
• [0.086 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:25:15.397
    Nov  5 12:25:15.397: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename lease-test 11/05/22 12:25:15.398
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:15.413
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:15.416
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Nov  5 12:25:15.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-9406" for this suite. 11/05/22 12:25:15.477
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:25:15.486
Nov  5 12:25:15.486: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 12:25:15.487
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:15.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:15.502
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 11/05/22 12:25:15.506
STEP: Creating a ResourceQuota 11/05/22 12:25:20.512
STEP: Ensuring resource quota status is calculated 11/05/22 12:25:20.523
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 12:25:22.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6187" for this suite. 11/05/22 12:25:22.532
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":135,"skipped":2346,"failed":0}
------------------------------
• [SLOW TEST] [7.053 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:25:15.486
    Nov  5 12:25:15.486: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 12:25:15.487
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:15.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:15.502
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 11/05/22 12:25:15.506
    STEP: Creating a ResourceQuota 11/05/22 12:25:20.512
    STEP: Ensuring resource quota status is calculated 11/05/22 12:25:20.523
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 12:25:22.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6187" for this suite. 11/05/22 12:25:22.532
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:25:22.542
Nov  5 12:25:22.542: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename var-expansion 11/05/22 12:25:22.543
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:22.554
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:22.558
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Nov  5 12:25:22.569: INFO: Waiting up to 2m0s for pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6" in namespace "var-expansion-6676" to be "container 0 failed with reason CreateContainerConfigError"
Nov  5 12:25:22.577: INFO: Pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.508132ms
Nov  5 12:25:24.581: INFO: Pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012518866s
Nov  5 12:25:24.581: INFO: Pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Nov  5 12:25:24.581: INFO: Deleting pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6" in namespace "var-expansion-6676"
Nov  5 12:25:24.589: INFO: Wait up to 5m0s for pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov  5 12:25:26.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6676" for this suite. 11/05/22 12:25:26.6
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":136,"skipped":2416,"failed":0}
------------------------------
• [4.065 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:25:22.542
    Nov  5 12:25:22.542: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename var-expansion 11/05/22 12:25:22.543
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:22.554
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:22.558
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Nov  5 12:25:22.569: INFO: Waiting up to 2m0s for pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6" in namespace "var-expansion-6676" to be "container 0 failed with reason CreateContainerConfigError"
    Nov  5 12:25:22.577: INFO: Pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.508132ms
    Nov  5 12:25:24.581: INFO: Pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012518866s
    Nov  5 12:25:24.581: INFO: Pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Nov  5 12:25:24.581: INFO: Deleting pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6" in namespace "var-expansion-6676"
    Nov  5 12:25:24.589: INFO: Wait up to 5m0s for pod "var-expansion-db4d6f16-08dc-4060-9dad-f883f706b1e6" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov  5 12:25:26.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-6676" for this suite. 11/05/22 12:25:26.6
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:25:26.608
Nov  5 12:25:26.609: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sysctl 11/05/22 12:25:26.609
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:26.621
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:26.626
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 11/05/22 12:25:26.63
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Nov  5 12:25:26.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-3829" for this suite. 11/05/22 12:25:26.638
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":137,"skipped":2426,"failed":0}
------------------------------
• [0.036 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:25:26.608
    Nov  5 12:25:26.609: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sysctl 11/05/22 12:25:26.609
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:26.621
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:26.626
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 11/05/22 12:25:26.63
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov  5 12:25:26.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-3829" for this suite. 11/05/22 12:25:26.638
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:25:26.647
Nov  5 12:25:26.647: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename security-context-test 11/05/22 12:25:26.647
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:26.659
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:26.664
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Nov  5 12:25:26.675: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461" in namespace "security-context-test-9034" to be "Succeeded or Failed"
Nov  5 12:25:26.679: INFO: Pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461": Phase="Pending", Reason="", readiness=false. Elapsed: 4.236718ms
Nov  5 12:25:28.684: INFO: Pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008908885s
Nov  5 12:25:30.684: INFO: Pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009059954s
Nov  5 12:25:32.685: INFO: Pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009462595s
Nov  5 12:25:32.685: INFO: Pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov  5 12:25:32.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9034" for this suite. 11/05/22 12:25:32.695
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":138,"skipped":2445,"failed":0}
------------------------------
• [SLOW TEST] [6.056 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:25:26.647
    Nov  5 12:25:26.647: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename security-context-test 11/05/22 12:25:26.647
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:26.659
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:26.664
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Nov  5 12:25:26.675: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461" in namespace "security-context-test-9034" to be "Succeeded or Failed"
    Nov  5 12:25:26.679: INFO: Pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461": Phase="Pending", Reason="", readiness=false. Elapsed: 4.236718ms
    Nov  5 12:25:28.684: INFO: Pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008908885s
    Nov  5 12:25:30.684: INFO: Pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009059954s
    Nov  5 12:25:32.685: INFO: Pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009462595s
    Nov  5 12:25:32.685: INFO: Pod "alpine-nnp-false-577556b8-07e6-4d2e-a832-06385d1b8461" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov  5 12:25:32.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-9034" for this suite. 11/05/22 12:25:32.695
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:25:32.704
Nov  5 12:25:32.704: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:25:32.705
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:32.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:32.724
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 11/05/22 12:25:32.728
Nov  5 12:25:32.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-6799 create -f -'
Nov  5 12:25:32.905: INFO: stderr: ""
Nov  5 12:25:32.905: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 11/05/22 12:25:32.905
Nov  5 12:25:32.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-6799 diff -f -'
Nov  5 12:25:33.698: INFO: rc: 1
Nov  5 12:25:33.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-6799 delete -f -'
Nov  5 12:25:33.833: INFO: stderr: ""
Nov  5 12:25:33.833: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:25:33.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6799" for this suite. 11/05/22 12:25:33.837
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":139,"skipped":2482,"failed":0}
------------------------------
• [1.140 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:25:32.704
    Nov  5 12:25:32.704: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:25:32.705
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:32.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:32.724
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 11/05/22 12:25:32.728
    Nov  5 12:25:32.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-6799 create -f -'
    Nov  5 12:25:32.905: INFO: stderr: ""
    Nov  5 12:25:32.905: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 11/05/22 12:25:32.905
    Nov  5 12:25:32.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-6799 diff -f -'
    Nov  5 12:25:33.698: INFO: rc: 1
    Nov  5 12:25:33.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-6799 delete -f -'
    Nov  5 12:25:33.833: INFO: stderr: ""
    Nov  5 12:25:33.833: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:25:33.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6799" for this suite. 11/05/22 12:25:33.837
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:25:33.846
Nov  5 12:25:33.846: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 12:25:33.846
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:33.912
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:33.916
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-293f4188-ad2d-4cda-9562-6253a1413c6b 11/05/22 12:25:34.022
STEP: Creating a pod to test consume secrets 11/05/22 12:25:34.027
Nov  5 12:25:34.100: INFO: Waiting up to 5m0s for pod "pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10" in namespace "secrets-792" to be "Succeeded or Failed"
Nov  5 12:25:34.262: INFO: Pod "pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10": Phase="Pending", Reason="", readiness=false. Elapsed: 161.847652ms
Nov  5 12:25:36.266: INFO: Pod "pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.166112762s
Nov  5 12:25:38.267: INFO: Pod "pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.166277414s
STEP: Saw pod success 11/05/22 12:25:38.267
Nov  5 12:25:38.267: INFO: Pod "pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10" satisfied condition "Succeeded or Failed"
Nov  5 12:25:38.270: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10 container secret-volume-test: <nil>
STEP: delete the pod 11/05/22 12:25:38.287
Nov  5 12:25:38.360: INFO: Waiting for pod pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10 to disappear
Nov  5 12:25:38.363: INFO: Pod pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov  5 12:25:38.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-792" for this suite. 11/05/22 12:25:38.368
STEP: Destroying namespace "secret-namespace-5653" for this suite. 11/05/22 12:25:38.374
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":140,"skipped":2507,"failed":0}
------------------------------
• [4.569 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:25:33.846
    Nov  5 12:25:33.846: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 12:25:33.846
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:33.912
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:33.916
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-293f4188-ad2d-4cda-9562-6253a1413c6b 11/05/22 12:25:34.022
    STEP: Creating a pod to test consume secrets 11/05/22 12:25:34.027
    Nov  5 12:25:34.100: INFO: Waiting up to 5m0s for pod "pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10" in namespace "secrets-792" to be "Succeeded or Failed"
    Nov  5 12:25:34.262: INFO: Pod "pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10": Phase="Pending", Reason="", readiness=false. Elapsed: 161.847652ms
    Nov  5 12:25:36.266: INFO: Pod "pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.166112762s
    Nov  5 12:25:38.267: INFO: Pod "pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.166277414s
    STEP: Saw pod success 11/05/22 12:25:38.267
    Nov  5 12:25:38.267: INFO: Pod "pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10" satisfied condition "Succeeded or Failed"
    Nov  5 12:25:38.270: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10 container secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 12:25:38.287
    Nov  5 12:25:38.360: INFO: Waiting for pod pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10 to disappear
    Nov  5 12:25:38.363: INFO: Pod pod-secrets-3cd74053-c0d0-4ec6-a55a-61bc63b2dc10 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 12:25:38.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-792" for this suite. 11/05/22 12:25:38.368
    STEP: Destroying namespace "secret-namespace-5653" for this suite. 11/05/22 12:25:38.374
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:25:38.417
Nov  5 12:25:38.417: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename watch 11/05/22 12:25:38.417
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:38.44
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:38.443
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 11/05/22 12:25:38.446
STEP: modifying the configmap once 11/05/22 12:25:38.462
STEP: modifying the configmap a second time 11/05/22 12:25:38.474
STEP: deleting the configmap 11/05/22 12:25:38.491
STEP: creating a watch on configmaps from the resource version returned by the first update 11/05/22 12:25:38.501
STEP: Expecting to observe notifications for all changes to the configmap after the first update 11/05/22 12:25:38.503
Nov  5 12:25:38.503: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2783  702ba61c-0f09-4642-96ad-49edbc75abaa 17836 0 2022-11-05 12:25:38 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-05 12:25:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 12:25:38.507: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2783  702ba61c-0f09-4642-96ad-49edbc75abaa 17837 0 2022-11-05 12:25:38 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-05 12:25:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov  5 12:25:38.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2783" for this suite. 11/05/22 12:25:38.511
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":141,"skipped":2525,"failed":0}
------------------------------
• [0.123 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:25:38.417
    Nov  5 12:25:38.417: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename watch 11/05/22 12:25:38.417
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:38.44
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:38.443
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 11/05/22 12:25:38.446
    STEP: modifying the configmap once 11/05/22 12:25:38.462
    STEP: modifying the configmap a second time 11/05/22 12:25:38.474
    STEP: deleting the configmap 11/05/22 12:25:38.491
    STEP: creating a watch on configmaps from the resource version returned by the first update 11/05/22 12:25:38.501
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 11/05/22 12:25:38.503
    Nov  5 12:25:38.503: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2783  702ba61c-0f09-4642-96ad-49edbc75abaa 17836 0 2022-11-05 12:25:38 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-05 12:25:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 12:25:38.507: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2783  702ba61c-0f09-4642-96ad-49edbc75abaa 17837 0 2022-11-05 12:25:38 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2022-11-05 12:25:38 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov  5 12:25:38.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2783" for this suite. 11/05/22 12:25:38.511
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:25:38.542
Nov  5 12:25:38.542: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pod-network-test 11/05/22 12:25:38.543
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:38.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:38.56
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-1617 11/05/22 12:25:38.574
STEP: creating a selector 11/05/22 12:25:38.574
STEP: Creating the service pods in kubernetes 11/05/22 12:25:38.575
Nov  5 12:25:38.575: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov  5 12:25:38.664: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1617" to be "running and ready"
Nov  5 12:25:38.952: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 288.266874ms
Nov  5 12:25:38.952: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:25:40.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.29273681s
Nov  5 12:25:40.956: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 12:25:42.958: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.294034948s
Nov  5 12:25:42.958: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 12:25:44.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.292225991s
Nov  5 12:25:44.956: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 12:25:46.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.29245867s
Nov  5 12:25:46.956: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 12:25:48.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.292649121s
Nov  5 12:25:48.956: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 12:25:50.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.292623456s
Nov  5 12:25:50.956: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov  5 12:25:50.956: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov  5 12:25:50.960: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1617" to be "running and ready"
Nov  5 12:25:50.963: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 3.535262ms
Nov  5 12:25:50.963: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov  5 12:25:52.968: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.008359045s
Nov  5 12:25:52.968: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov  5 12:25:54.969: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.008932742s
Nov  5 12:25:54.969: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov  5 12:25:56.968: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.00827988s
Nov  5 12:25:56.968: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov  5 12:25:58.968: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.008602503s
Nov  5 12:25:58.968: INFO: The phase of Pod netserver-1 is Running (Ready = false)
Nov  5 12:26:00.967: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.007498364s
Nov  5 12:26:00.967: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov  5 12:26:00.967: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov  5 12:26:00.971: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-1617" to be "running and ready"
Nov  5 12:26:00.974: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.512806ms
Nov  5 12:26:00.974: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov  5 12:26:00.974: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/05/22 12:26:00.977
Nov  5 12:26:00.992: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1617" to be "running"
Nov  5 12:26:00.998: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.182173ms
Nov  5 12:26:03.002: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.01028379s
Nov  5 12:26:03.002: INFO: Pod "test-container-pod" satisfied condition "running"
Nov  5 12:26:03.006: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1617" to be "running"
Nov  5 12:26:03.009: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.593468ms
Nov  5 12:26:03.009: INFO: Pod "host-test-container-pod" satisfied condition "running"
Nov  5 12:26:03.013: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov  5 12:26:03.013: INFO: Going to poll 192.168.206.158 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov  5 12:26:03.016: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.206.158:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1617 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 12:26:03.016: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 12:26:03.017: INFO: ExecWithOptions: Clientset creation
Nov  5 12:26:03.017: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1617/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.206.158%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov  5 12:26:03.115: INFO: Found all 1 expected endpoints: [netserver-0]
Nov  5 12:26:03.115: INFO: Going to poll 192.168.242.8 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov  5 12:26:03.119: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.242.8:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1617 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 12:26:03.119: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 12:26:03.120: INFO: ExecWithOptions: Clientset creation
Nov  5 12:26:03.120: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1617/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.242.8%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov  5 12:26:03.211: INFO: Found all 1 expected endpoints: [netserver-1]
Nov  5 12:26:03.211: INFO: Going to poll 192.168.90.85 on port 8083 at least 0 times, with a maximum of 39 tries before failing
Nov  5 12:26:03.215: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.90.85:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1617 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 12:26:03.215: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 12:26:03.215: INFO: ExecWithOptions: Clientset creation
Nov  5 12:26:03.215: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1617/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.90.85%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov  5 12:26:03.287: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov  5 12:26:03.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1617" for this suite. 11/05/22 12:26:03.291
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":142,"skipped":2553,"failed":0}
------------------------------
• [SLOW TEST] [24.757 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:25:38.542
    Nov  5 12:25:38.542: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pod-network-test 11/05/22 12:25:38.543
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:25:38.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:25:38.56
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-1617 11/05/22 12:25:38.574
    STEP: creating a selector 11/05/22 12:25:38.574
    STEP: Creating the service pods in kubernetes 11/05/22 12:25:38.575
    Nov  5 12:25:38.575: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov  5 12:25:38.664: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-1617" to be "running and ready"
    Nov  5 12:25:38.952: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 288.266874ms
    Nov  5 12:25:38.952: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:25:40.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.29273681s
    Nov  5 12:25:40.956: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 12:25:42.958: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.294034948s
    Nov  5 12:25:42.958: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 12:25:44.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.292225991s
    Nov  5 12:25:44.956: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 12:25:46.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.29245867s
    Nov  5 12:25:46.956: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 12:25:48.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.292649121s
    Nov  5 12:25:48.956: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 12:25:50.956: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.292623456s
    Nov  5 12:25:50.956: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov  5 12:25:50.956: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov  5 12:25:50.960: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-1617" to be "running and ready"
    Nov  5 12:25:50.963: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 3.535262ms
    Nov  5 12:25:50.963: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov  5 12:25:52.968: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 2.008359045s
    Nov  5 12:25:52.968: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov  5 12:25:54.969: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 4.008932742s
    Nov  5 12:25:54.969: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov  5 12:25:56.968: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 6.00827988s
    Nov  5 12:25:56.968: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov  5 12:25:58.968: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=false. Elapsed: 8.008602503s
    Nov  5 12:25:58.968: INFO: The phase of Pod netserver-1 is Running (Ready = false)
    Nov  5 12:26:00.967: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 10.007498364s
    Nov  5 12:26:00.967: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov  5 12:26:00.967: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov  5 12:26:00.971: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-1617" to be "running and ready"
    Nov  5 12:26:00.974: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.512806ms
    Nov  5 12:26:00.974: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov  5 12:26:00.974: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/05/22 12:26:00.977
    Nov  5 12:26:00.992: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-1617" to be "running"
    Nov  5 12:26:00.998: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.182173ms
    Nov  5 12:26:03.002: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.01028379s
    Nov  5 12:26:03.002: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov  5 12:26:03.006: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-1617" to be "running"
    Nov  5 12:26:03.009: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.593468ms
    Nov  5 12:26:03.009: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Nov  5 12:26:03.013: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov  5 12:26:03.013: INFO: Going to poll 192.168.206.158 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov  5 12:26:03.016: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.206.158:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1617 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 12:26:03.016: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 12:26:03.017: INFO: ExecWithOptions: Clientset creation
    Nov  5 12:26:03.017: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1617/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.206.158%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov  5 12:26:03.115: INFO: Found all 1 expected endpoints: [netserver-0]
    Nov  5 12:26:03.115: INFO: Going to poll 192.168.242.8 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov  5 12:26:03.119: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.242.8:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1617 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 12:26:03.119: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 12:26:03.120: INFO: ExecWithOptions: Clientset creation
    Nov  5 12:26:03.120: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1617/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.242.8%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov  5 12:26:03.211: INFO: Found all 1 expected endpoints: [netserver-1]
    Nov  5 12:26:03.211: INFO: Going to poll 192.168.90.85 on port 8083 at least 0 times, with a maximum of 39 tries before failing
    Nov  5 12:26:03.215: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.90.85:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1617 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 12:26:03.215: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 12:26:03.215: INFO: ExecWithOptions: Clientset creation
    Nov  5 12:26:03.215: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-1617/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F192.168.90.85%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov  5 12:26:03.287: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov  5 12:26:03.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-1617" for this suite. 11/05/22 12:26:03.291
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:26:03.301
Nov  5 12:26:03.301: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename daemonsets 11/05/22 12:26:03.301
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:03.314
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:03.318
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Nov  5 12:26:03.342: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 11/05/22 12:26:03.348
Nov  5 12:26:03.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:26:03.353: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 11/05/22 12:26:03.353
Nov  5 12:26:03.375: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:26:03.375: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
Nov  5 12:26:04.379: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:26:04.379: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
Nov  5 12:26:05.379: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov  5 12:26:05.379: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 11/05/22 12:26:05.383
Nov  5 12:26:05.402: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov  5 12:26:05.402: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Nov  5 12:26:06.407: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:26:06.407: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 11/05/22 12:26:06.407
Nov  5 12:26:06.419: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:26:06.419: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
Nov  5 12:26:07.424: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:26:07.424: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
Nov  5 12:26:08.425: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:26:08.425: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
Nov  5 12:26:09.424: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Nov  5 12:26:09.424: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/05/22 12:26:09.431
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4764, will wait for the garbage collector to delete the pods 11/05/22 12:26:09.431
Nov  5 12:26:09.491: INFO: Deleting DaemonSet.extensions daemon-set took: 6.357722ms
Nov  5 12:26:09.591: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.360445ms
Nov  5 12:26:12.097: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:26:12.097: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov  5 12:26:12.100: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18118"},"items":null}

Nov  5 12:26:12.103: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18118"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:26:12.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4764" for this suite. 11/05/22 12:26:12.128
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":143,"skipped":2572,"failed":0}
------------------------------
• [SLOW TEST] [8.847 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:26:03.301
    Nov  5 12:26:03.301: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename daemonsets 11/05/22 12:26:03.301
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:03.314
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:03.318
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Nov  5 12:26:03.342: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 11/05/22 12:26:03.348
    Nov  5 12:26:03.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:26:03.353: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 11/05/22 12:26:03.353
    Nov  5 12:26:03.375: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:26:03.375: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
    Nov  5 12:26:04.379: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:26:04.379: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
    Nov  5 12:26:05.379: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov  5 12:26:05.379: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 11/05/22 12:26:05.383
    Nov  5 12:26:05.402: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov  5 12:26:05.402: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Nov  5 12:26:06.407: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:26:06.407: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 11/05/22 12:26:06.407
    Nov  5 12:26:06.419: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:26:06.419: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
    Nov  5 12:26:07.424: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:26:07.424: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
    Nov  5 12:26:08.425: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:26:08.425: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
    Nov  5 12:26:09.424: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Nov  5 12:26:09.424: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/05/22 12:26:09.431
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4764, will wait for the garbage collector to delete the pods 11/05/22 12:26:09.431
    Nov  5 12:26:09.491: INFO: Deleting DaemonSet.extensions daemon-set took: 6.357722ms
    Nov  5 12:26:09.591: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.360445ms
    Nov  5 12:26:12.097: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:26:12.097: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov  5 12:26:12.100: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"18118"},"items":null}

    Nov  5 12:26:12.103: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"18118"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:26:12.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4764" for this suite. 11/05/22 12:26:12.128
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:26:12.148
Nov  5 12:26:12.148: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:26:12.149
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:12.216
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:12.22
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-4ea6fbb1-722f-4a41-96c9-e294c76595e7 11/05/22 12:26:12.224
STEP: Creating a pod to test consume secrets 11/05/22 12:26:12.266
Nov  5 12:26:12.339: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a" in namespace "projected-2630" to be "Succeeded or Failed"
Nov  5 12:26:12.397: INFO: Pod "pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a": Phase="Pending", Reason="", readiness=false. Elapsed: 58.086426ms
Nov  5 12:26:14.402: INFO: Pod "pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062462282s
Nov  5 12:26:16.402: INFO: Pod "pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062955545s
STEP: Saw pod success 11/05/22 12:26:16.402
Nov  5 12:26:16.402: INFO: Pod "pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a" satisfied condition "Succeeded or Failed"
Nov  5 12:26:16.410: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a container projected-secret-volume-test: <nil>
STEP: delete the pod 11/05/22 12:26:16.417
Nov  5 12:26:16.486: INFO: Waiting for pod pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a to disappear
Nov  5 12:26:16.489: INFO: Pod pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov  5 12:26:16.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2630" for this suite. 11/05/22 12:26:16.493
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":144,"skipped":2573,"failed":0}
------------------------------
• [4.351 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:26:12.148
    Nov  5 12:26:12.148: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:26:12.149
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:12.216
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:12.22
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-4ea6fbb1-722f-4a41-96c9-e294c76595e7 11/05/22 12:26:12.224
    STEP: Creating a pod to test consume secrets 11/05/22 12:26:12.266
    Nov  5 12:26:12.339: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a" in namespace "projected-2630" to be "Succeeded or Failed"
    Nov  5 12:26:12.397: INFO: Pod "pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a": Phase="Pending", Reason="", readiness=false. Elapsed: 58.086426ms
    Nov  5 12:26:14.402: INFO: Pod "pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062462282s
    Nov  5 12:26:16.402: INFO: Pod "pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062955545s
    STEP: Saw pod success 11/05/22 12:26:16.402
    Nov  5 12:26:16.402: INFO: Pod "pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a" satisfied condition "Succeeded or Failed"
    Nov  5 12:26:16.410: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 12:26:16.417
    Nov  5 12:26:16.486: INFO: Waiting for pod pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a to disappear
    Nov  5 12:26:16.489: INFO: Pod pod-projected-secrets-6ebf32ba-4aab-4358-a431-1f3a1784bb9a no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov  5 12:26:16.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2630" for this suite. 11/05/22 12:26:16.493
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:26:16.502
Nov  5 12:26:16.502: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 12:26:16.503
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:16.573
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:16.577
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-b6a2de34-99fe-4931-9eeb-1f3255a811dd 11/05/22 12:26:16.686
STEP: Creating a pod to test consume configMaps 11/05/22 12:26:16.692
Nov  5 12:26:16.769: INFO: Waiting up to 5m0s for pod "pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e" in namespace "configmap-788" to be "Succeeded or Failed"
Nov  5 12:26:16.773: INFO: Pod "pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.983239ms
Nov  5 12:26:18.777: INFO: Pod "pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008621785s
Nov  5 12:26:20.778: INFO: Pod "pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008871673s
STEP: Saw pod success 11/05/22 12:26:20.778
Nov  5 12:26:20.778: INFO: Pod "pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e" satisfied condition "Succeeded or Failed"
Nov  5 12:26:20.781: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e container configmap-volume-test: <nil>
STEP: delete the pod 11/05/22 12:26:20.788
Nov  5 12:26:20.799: INFO: Waiting for pod pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e to disappear
Nov  5 12:26:20.803: INFO: Pod pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 12:26:20.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-788" for this suite. 11/05/22 12:26:20.807
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":145,"skipped":2610,"failed":0}
------------------------------
• [4.310 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:26:16.502
    Nov  5 12:26:16.502: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 12:26:16.503
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:16.573
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:16.577
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-b6a2de34-99fe-4931-9eeb-1f3255a811dd 11/05/22 12:26:16.686
    STEP: Creating a pod to test consume configMaps 11/05/22 12:26:16.692
    Nov  5 12:26:16.769: INFO: Waiting up to 5m0s for pod "pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e" in namespace "configmap-788" to be "Succeeded or Failed"
    Nov  5 12:26:16.773: INFO: Pod "pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.983239ms
    Nov  5 12:26:18.777: INFO: Pod "pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008621785s
    Nov  5 12:26:20.778: INFO: Pod "pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008871673s
    STEP: Saw pod success 11/05/22 12:26:20.778
    Nov  5 12:26:20.778: INFO: Pod "pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e" satisfied condition "Succeeded or Failed"
    Nov  5 12:26:20.781: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e container configmap-volume-test: <nil>
    STEP: delete the pod 11/05/22 12:26:20.788
    Nov  5 12:26:20.799: INFO: Waiting for pod pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e to disappear
    Nov  5 12:26:20.803: INFO: Pod pod-configmaps-84a49fbb-1a8a-45c0-95b4-fe54a6ba884e no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 12:26:20.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-788" for this suite. 11/05/22 12:26:20.807
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:26:20.814
Nov  5 12:26:20.814: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:26:20.815
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:20.827
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:20.832
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-8d903ea4-64b5-45d9-8798-4b33b10ef5c3 11/05/22 12:26:20.836
STEP: Creating a pod to test consume secrets 11/05/22 12:26:20.841
Nov  5 12:26:20.851: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04" in namespace "projected-4214" to be "Succeeded or Failed"
Nov  5 12:26:20.856: INFO: Pod "pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04": Phase="Pending", Reason="", readiness=false. Elapsed: 5.018315ms
Nov  5 12:26:22.860: INFO: Pod "pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009243409s
Nov  5 12:26:24.861: INFO: Pod "pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010073093s
STEP: Saw pod success 11/05/22 12:26:24.861
Nov  5 12:26:24.861: INFO: Pod "pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04" satisfied condition "Succeeded or Failed"
Nov  5 12:26:24.865: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/05/22 12:26:24.872
Nov  5 12:26:24.884: INFO: Waiting for pod pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04 to disappear
Nov  5 12:26:24.889: INFO: Pod pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov  5 12:26:24.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4214" for this suite. 11/05/22 12:26:24.893
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":146,"skipped":2613,"failed":0}
------------------------------
• [4.088 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:26:20.814
    Nov  5 12:26:20.814: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:26:20.815
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:20.827
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:20.832
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-8d903ea4-64b5-45d9-8798-4b33b10ef5c3 11/05/22 12:26:20.836
    STEP: Creating a pod to test consume secrets 11/05/22 12:26:20.841
    Nov  5 12:26:20.851: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04" in namespace "projected-4214" to be "Succeeded or Failed"
    Nov  5 12:26:20.856: INFO: Pod "pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04": Phase="Pending", Reason="", readiness=false. Elapsed: 5.018315ms
    Nov  5 12:26:22.860: INFO: Pod "pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009243409s
    Nov  5 12:26:24.861: INFO: Pod "pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010073093s
    STEP: Saw pod success 11/05/22 12:26:24.861
    Nov  5 12:26:24.861: INFO: Pod "pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04" satisfied condition "Succeeded or Failed"
    Nov  5 12:26:24.865: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 12:26:24.872
    Nov  5 12:26:24.884: INFO: Waiting for pod pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04 to disappear
    Nov  5 12:26:24.889: INFO: Pod pod-projected-secrets-a73eb0d3-5ca3-432b-b57c-420b1dd53e04 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov  5 12:26:24.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4214" for this suite. 11/05/22 12:26:24.893
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:26:24.904
Nov  5 12:26:24.904: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 12:26:24.905
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:24.926
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:24.931
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 11/05/22 12:26:24.936
Nov  5 12:26:24.949: INFO: Waiting up to 5m0s for pod "labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2" in namespace "downward-api-2864" to be "running and ready"
Nov  5 12:26:24.954: INFO: Pod "labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.310279ms
Nov  5 12:26:24.954: INFO: The phase of Pod labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:26:26.959: INFO: Pod "labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2": Phase="Running", Reason="", readiness=true. Elapsed: 2.00985933s
Nov  5 12:26:26.959: INFO: The phase of Pod labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2 is Running (Ready = true)
Nov  5 12:26:26.959: INFO: Pod "labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2" satisfied condition "running and ready"
Nov  5 12:26:27.485: INFO: Successfully updated pod "labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 12:26:31.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2864" for this suite. 11/05/22 12:26:31.521
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":147,"skipped":2636,"failed":0}
------------------------------
• [SLOW TEST] [6.624 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:26:24.904
    Nov  5 12:26:24.904: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 12:26:24.905
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:24.926
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:24.931
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 11/05/22 12:26:24.936
    Nov  5 12:26:24.949: INFO: Waiting up to 5m0s for pod "labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2" in namespace "downward-api-2864" to be "running and ready"
    Nov  5 12:26:24.954: INFO: Pod "labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.310279ms
    Nov  5 12:26:24.954: INFO: The phase of Pod labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:26:26.959: INFO: Pod "labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2": Phase="Running", Reason="", readiness=true. Elapsed: 2.00985933s
    Nov  5 12:26:26.959: INFO: The phase of Pod labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2 is Running (Ready = true)
    Nov  5 12:26:26.959: INFO: Pod "labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2" satisfied condition "running and ready"
    Nov  5 12:26:27.485: INFO: Successfully updated pod "labelsupdate1aecb99d-5dbc-4db2-89a0-b2512ecd50a2"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 12:26:31.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2864" for this suite. 11/05/22 12:26:31.521
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:26:31.531
Nov  5 12:26:31.531: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 12:26:31.532
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:31.547
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:31.551
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173
STEP: creating service in namespace services-2237 11/05/22 12:26:31.555
Nov  5 12:26:31.562: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-2237" to be "running and ready"
Nov  5 12:26:31.570: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 7.394738ms
Nov  5 12:26:31.570: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:26:33.575: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.012242507s
Nov  5 12:26:33.575: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Nov  5 12:26:33.575: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Nov  5 12:26:33.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Nov  5 12:26:33.750: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Nov  5 12:26:33.750: INFO: stdout: "iptables"
Nov  5 12:26:33.750: INFO: proxyMode: iptables
Nov  5 12:26:33.767: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Nov  5 12:26:33.770: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-clusterip-timeout in namespace services-2237 11/05/22 12:26:33.77
STEP: creating replication controller affinity-clusterip-timeout in namespace services-2237 11/05/22 12:26:33.789
I1105 12:26:33.800103      20 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-2237, replica count: 3
I1105 12:26:36.850844      20 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 12:26:36.859: INFO: Creating new exec pod
Nov  5 12:26:36.865: INFO: Waiting up to 5m0s for pod "execpod-affinityvfc6h" in namespace "services-2237" to be "running"
Nov  5 12:26:36.872: INFO: Pod "execpod-affinityvfc6h": Phase="Pending", Reason="", readiness=false. Elapsed: 6.633583ms
Nov  5 12:26:38.877: INFO: Pod "execpod-affinityvfc6h": Phase="Running", Reason="", readiness=true. Elapsed: 2.011333397s
Nov  5 12:26:38.877: INFO: Pod "execpod-affinityvfc6h" satisfied condition "running"
Nov  5 12:26:39.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec execpod-affinityvfc6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
Nov  5 12:26:40.022: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
Nov  5 12:26:40.022: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 12:26:40.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec execpod-affinityvfc6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.37 80'
Nov  5 12:26:40.160: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.37 80\nConnection to 10.152.183.37 80 port [tcp/http] succeeded!\n"
Nov  5 12:26:40.160: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 12:26:40.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec execpod-affinityvfc6h -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.37:80/ ; done'
Nov  5 12:26:40.378: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n"
Nov  5 12:26:40.378: INFO: stdout: "\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv"
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
Nov  5 12:26:40.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec execpod-affinityvfc6h -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.37:80/'
Nov  5 12:26:40.529: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n"
Nov  5 12:26:40.529: INFO: stdout: "affinity-clusterip-timeout-6trrv"
Nov  5 12:27:00.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec execpod-affinityvfc6h -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.37:80/'
Nov  5 12:27:00.677: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n"
Nov  5 12:27:00.677: INFO: stdout: "affinity-clusterip-timeout-p8wdh"
Nov  5 12:27:00.677: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-2237, will wait for the garbage collector to delete the pods 11/05/22 12:27:00.69
Nov  5 12:27:00.750: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 6.274802ms
Nov  5 12:27:00.851: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 101.142075ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 12:27:03.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2237" for this suite. 11/05/22 12:27:03.173
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]","completed":148,"skipped":2685,"failed":0}
------------------------------
• [SLOW TEST] [31.649 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:26:31.531
    Nov  5 12:26:31.531: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 12:26:31.532
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:26:31.547
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:26:31.551
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2173
    STEP: creating service in namespace services-2237 11/05/22 12:26:31.555
    Nov  5 12:26:31.562: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-2237" to be "running and ready"
    Nov  5 12:26:31.570: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 7.394738ms
    Nov  5 12:26:31.570: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:26:33.575: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.012242507s
    Nov  5 12:26:33.575: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Nov  5 12:26:33.575: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Nov  5 12:26:33.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Nov  5 12:26:33.750: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Nov  5 12:26:33.750: INFO: stdout: "iptables"
    Nov  5 12:26:33.750: INFO: proxyMode: iptables
    Nov  5 12:26:33.767: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Nov  5 12:26:33.770: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-clusterip-timeout in namespace services-2237 11/05/22 12:26:33.77
    STEP: creating replication controller affinity-clusterip-timeout in namespace services-2237 11/05/22 12:26:33.789
    I1105 12:26:33.800103      20 runners.go:193] Created replication controller with name: affinity-clusterip-timeout, namespace: services-2237, replica count: 3
    I1105 12:26:36.850844      20 runners.go:193] affinity-clusterip-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 12:26:36.859: INFO: Creating new exec pod
    Nov  5 12:26:36.865: INFO: Waiting up to 5m0s for pod "execpod-affinityvfc6h" in namespace "services-2237" to be "running"
    Nov  5 12:26:36.872: INFO: Pod "execpod-affinityvfc6h": Phase="Pending", Reason="", readiness=false. Elapsed: 6.633583ms
    Nov  5 12:26:38.877: INFO: Pod "execpod-affinityvfc6h": Phase="Running", Reason="", readiness=true. Elapsed: 2.011333397s
    Nov  5 12:26:38.877: INFO: Pod "execpod-affinityvfc6h" satisfied condition "running"
    Nov  5 12:26:39.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec execpod-affinityvfc6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-timeout 80'
    Nov  5 12:26:40.022: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 affinity-clusterip-timeout 80\nConnection to affinity-clusterip-timeout 80 port [tcp/http] succeeded!\n"
    Nov  5 12:26:40.022: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 12:26:40.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec execpod-affinityvfc6h -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.37 80'
    Nov  5 12:26:40.160: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.37 80\nConnection to 10.152.183.37 80 port [tcp/http] succeeded!\n"
    Nov  5 12:26:40.160: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 12:26:40.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec execpod-affinityvfc6h -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.37:80/ ; done'
    Nov  5 12:26:40.378: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n"
    Nov  5 12:26:40.378: INFO: stdout: "\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv\naffinity-clusterip-timeout-6trrv"
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Received response from host: affinity-clusterip-timeout-6trrv
    Nov  5 12:26:40.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec execpod-affinityvfc6h -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.37:80/'
    Nov  5 12:26:40.529: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n"
    Nov  5 12:26:40.529: INFO: stdout: "affinity-clusterip-timeout-6trrv"
    Nov  5 12:27:00.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2237 exec execpod-affinityvfc6h -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://10.152.183.37:80/'
    Nov  5 12:27:00.677: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://10.152.183.37:80/\n"
    Nov  5 12:27:00.677: INFO: stdout: "affinity-clusterip-timeout-p8wdh"
    Nov  5 12:27:00.677: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-timeout in namespace services-2237, will wait for the garbage collector to delete the pods 11/05/22 12:27:00.69
    Nov  5 12:27:00.750: INFO: Deleting ReplicationController affinity-clusterip-timeout took: 6.274802ms
    Nov  5 12:27:00.851: INFO: Terminating ReplicationController affinity-clusterip-timeout pods took: 101.142075ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 12:27:03.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2237" for this suite. 11/05/22 12:27:03.173
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:27:03.182
Nov  5 12:27:03.182: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-runtime 11/05/22 12:27:03.182
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:27:03.195
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:27:03.201
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 11/05/22 12:27:03.205
STEP: wait for the container to reach Succeeded 11/05/22 12:27:03.214
STEP: get the container status 11/05/22 12:27:07.235
STEP: the container should be terminated 11/05/22 12:27:07.239
STEP: the termination message should be set 11/05/22 12:27:07.239
Nov  5 12:27:07.239: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 11/05/22 12:27:07.239
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov  5 12:27:07.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1799" for this suite. 11/05/22 12:27:07.259
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":149,"skipped":2724,"failed":0}
------------------------------
• [4.085 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:27:03.182
    Nov  5 12:27:03.182: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-runtime 11/05/22 12:27:03.182
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:27:03.195
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:27:03.201
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 11/05/22 12:27:03.205
    STEP: wait for the container to reach Succeeded 11/05/22 12:27:03.214
    STEP: get the container status 11/05/22 12:27:07.235
    STEP: the container should be terminated 11/05/22 12:27:07.239
    STEP: the termination message should be set 11/05/22 12:27:07.239
    Nov  5 12:27:07.239: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 11/05/22 12:27:07.239
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov  5 12:27:07.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1799" for this suite. 11/05/22 12:27:07.259
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:27:07.269
Nov  5 12:27:07.269: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename cronjob 11/05/22 12:27:07.27
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:27:07.285
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:27:07.289
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 11/05/22 12:27:07.292
STEP: Ensuring no jobs are scheduled 11/05/22 12:27:07.298
STEP: Ensuring no job exists by listing jobs explicitly 11/05/22 12:32:07.305
STEP: Removing cronjob 11/05/22 12:32:07.308
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov  5 12:32:07.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-8484" for this suite. 11/05/22 12:32:07.32
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":150,"skipped":2764,"failed":0}
------------------------------
• [SLOW TEST] [300.057 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:27:07.269
    Nov  5 12:27:07.269: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename cronjob 11/05/22 12:27:07.27
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:27:07.285
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:27:07.289
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 11/05/22 12:27:07.292
    STEP: Ensuring no jobs are scheduled 11/05/22 12:27:07.298
    STEP: Ensuring no job exists by listing jobs explicitly 11/05/22 12:32:07.305
    STEP: Removing cronjob 11/05/22 12:32:07.308
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov  5 12:32:07.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-8484" for this suite. 11/05/22 12:32:07.32
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:32:07.327
Nov  5 12:32:07.327: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 12:32:07.328
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:32:07.34
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:32:07.345
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 12:32:07.365
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:32:07.808
STEP: Deploying the webhook pod 11/05/22 12:32:07.817
STEP: Wait for the deployment to be ready 11/05/22 12:32:07.828
Nov  5 12:32:07.836: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/05/22 12:32:09.848
STEP: Verifying the service has paired with the endpoint 11/05/22 12:32:09.859
Nov  5 12:32:10.860: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 11/05/22 12:32:10.864
STEP: create a pod that should be updated by the webhook 11/05/22 12:32:10.88
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:32:10.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5268" for this suite. 11/05/22 12:32:10.906
STEP: Destroying namespace "webhook-5268-markers" for this suite. 11/05/22 12:32:10.911
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":151,"skipped":2766,"failed":0}
------------------------------
• [3.659 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:32:07.327
    Nov  5 12:32:07.327: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 12:32:07.328
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:32:07.34
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:32:07.345
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 12:32:07.365
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:32:07.808
    STEP: Deploying the webhook pod 11/05/22 12:32:07.817
    STEP: Wait for the deployment to be ready 11/05/22 12:32:07.828
    Nov  5 12:32:07.836: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/05/22 12:32:09.848
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:32:09.859
    Nov  5 12:32:10.860: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 11/05/22 12:32:10.864
    STEP: create a pod that should be updated by the webhook 11/05/22 12:32:10.88
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:32:10.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5268" for this suite. 11/05/22 12:32:10.906
    STEP: Destroying namespace "webhook-5268-markers" for this suite. 11/05/22 12:32:10.911
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:32:10.986
Nov  5 12:32:10.986: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 12:32:10.986
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:32:11.007
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:32:11.015
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-40013ab1-da92-4492-a875-8f1e48f234af 11/05/22 12:32:11.023
STEP: Creating the pod 11/05/22 12:32:11.027
Nov  5 12:32:11.036: INFO: Waiting up to 5m0s for pod "pod-configmaps-120ab67d-43ac-48f2-80a3-8f4b7a01d41b" in namespace "configmap-6561" to be "running"
Nov  5 12:32:11.042: INFO: Pod "pod-configmaps-120ab67d-43ac-48f2-80a3-8f4b7a01d41b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.998526ms
Nov  5 12:32:13.046: INFO: Pod "pod-configmaps-120ab67d-43ac-48f2-80a3-8f4b7a01d41b": Phase="Running", Reason="", readiness=false. Elapsed: 2.010918628s
Nov  5 12:32:13.046: INFO: Pod "pod-configmaps-120ab67d-43ac-48f2-80a3-8f4b7a01d41b" satisfied condition "running"
STEP: Waiting for pod with text data 11/05/22 12:32:13.046
STEP: Waiting for pod with binary data 11/05/22 12:32:13.063
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 12:32:13.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6561" for this suite. 11/05/22 12:32:13.073
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":152,"skipped":2766,"failed":0}
------------------------------
• [2.094 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:32:10.986
    Nov  5 12:32:10.986: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 12:32:10.986
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:32:11.007
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:32:11.015
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-40013ab1-da92-4492-a875-8f1e48f234af 11/05/22 12:32:11.023
    STEP: Creating the pod 11/05/22 12:32:11.027
    Nov  5 12:32:11.036: INFO: Waiting up to 5m0s for pod "pod-configmaps-120ab67d-43ac-48f2-80a3-8f4b7a01d41b" in namespace "configmap-6561" to be "running"
    Nov  5 12:32:11.042: INFO: Pod "pod-configmaps-120ab67d-43ac-48f2-80a3-8f4b7a01d41b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.998526ms
    Nov  5 12:32:13.046: INFO: Pod "pod-configmaps-120ab67d-43ac-48f2-80a3-8f4b7a01d41b": Phase="Running", Reason="", readiness=false. Elapsed: 2.010918628s
    Nov  5 12:32:13.046: INFO: Pod "pod-configmaps-120ab67d-43ac-48f2-80a3-8f4b7a01d41b" satisfied condition "running"
    STEP: Waiting for pod with text data 11/05/22 12:32:13.046
    STEP: Waiting for pod with binary data 11/05/22 12:32:13.063
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 12:32:13.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6561" for this suite. 11/05/22 12:32:13.073
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:32:13.08
Nov  5 12:32:13.080: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename deployment 11/05/22 12:32:13.081
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:32:13.094
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:32:13.099
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Nov  5 12:32:13.111: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov  5 12:32:18.116: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/05/22 12:32:18.116
Nov  5 12:32:18.116: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 11/05/22 12:32:18.127
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov  5 12:32:20.150: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-775  acac0056-9ecd-4a1a-8754-c8df2b16d1de 19343 1 2022-11-05 12:32:18 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-05 12:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:32:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004658b58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-05 12:32:18 +0000 UTC,LastTransitionTime:2022-11-05 12:32:18 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-11-05 12:32:19 +0000 UTC,LastTransitionTime:2022-11-05 12:32:18 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  5 12:32:20.154: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-775  9c956e58-a1d6-44c3-90d4-11de5f4934d2 19333 1 2022-11-05 12:32:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment acac0056-9ecd-4a1a-8754-c8df2b16d1de 0xc0034cc2b7 0xc0034cc2b8}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"acac0056-9ecd-4a1a-8754-c8df2b16d1de\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:32:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034cc368 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  5 12:32:20.158: INFO: Pod "test-cleanup-deployment-69cb9c5497-r9ws6" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-r9ws6 test-cleanup-deployment-69cb9c5497- deployment-775  7468e26f-de88-44b7-8bdf-afd4c9a0e44e 19332 0 2022-11-05 12:32:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 9c956e58-a1d6-44c3-90d4-11de5f4934d2 0xc0034cc727 0xc0034cc728}] [] [{kube-controller-manager Update v1 2022-11-05 12:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9c956e58-a1d6-44c3-90d4-11de5f4934d2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:32:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.185\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ptrk2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ptrk2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:32:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:32:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:32:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.185,StartTime:2022-11-05 12:32:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:32:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://6171ea094a0ebc7ebd518b470a4043eef63ec12c2f5510996e2702ee3ff4eb2e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.185,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov  5 12:32:20.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-775" for this suite. 11/05/22 12:32:20.162
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":153,"skipped":2773,"failed":0}
------------------------------
• [SLOW TEST] [7.089 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:32:13.08
    Nov  5 12:32:13.080: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename deployment 11/05/22 12:32:13.081
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:32:13.094
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:32:13.099
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Nov  5 12:32:13.111: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Nov  5 12:32:18.116: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/05/22 12:32:18.116
    Nov  5 12:32:18.116: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 11/05/22 12:32:18.127
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov  5 12:32:20.150: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-775  acac0056-9ecd-4a1a-8754-c8df2b16d1de 19343 1 2022-11-05 12:32:18 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-05 12:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:32:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004658b58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-05 12:32:18 +0000 UTC,LastTransitionTime:2022-11-05 12:32:18 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2022-11-05 12:32:19 +0000 UTC,LastTransitionTime:2022-11-05 12:32:18 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov  5 12:32:20.154: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-775  9c956e58-a1d6-44c3-90d4-11de5f4934d2 19333 1 2022-11-05 12:32:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment acac0056-9ecd-4a1a-8754-c8df2b16d1de 0xc0034cc2b7 0xc0034cc2b8}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"acac0056-9ecd-4a1a-8754-c8df2b16d1de\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:32:19 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0034cc368 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 12:32:20.158: INFO: Pod "test-cleanup-deployment-69cb9c5497-r9ws6" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-r9ws6 test-cleanup-deployment-69cb9c5497- deployment-775  7468e26f-de88-44b7-8bdf-afd4c9a0e44e 19332 0 2022-11-05 12:32:18 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 9c956e58-a1d6-44c3-90d4-11de5f4934d2 0xc0034cc727 0xc0034cc728}] [] [{kube-controller-manager Update v1 2022-11-05 12:32:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"9c956e58-a1d6-44c3-90d4-11de5f4934d2\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:32:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.185\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ptrk2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ptrk2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:32:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:32:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:32:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:32:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.185,StartTime:2022-11-05 12:32:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:32:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://6171ea094a0ebc7ebd518b470a4043eef63ec12c2f5510996e2702ee3ff4eb2e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.185,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov  5 12:32:20.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-775" for this suite. 11/05/22 12:32:20.162
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:32:20.17
Nov  5 12:32:20.170: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename var-expansion 11/05/22 12:32:20.171
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:32:20.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:32:20.187
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 11/05/22 12:32:20.192
STEP: waiting for pod running 11/05/22 12:32:20.202
Nov  5 12:32:20.202: INFO: Waiting up to 2m0s for pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" in namespace "var-expansion-3396" to be "running"
Nov  5 12:32:20.206: INFO: Pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222": Phase="Pending", Reason="", readiness=false. Elapsed: 3.450702ms
Nov  5 12:32:22.210: INFO: Pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222": Phase="Running", Reason="", readiness=true. Elapsed: 2.00763448s
Nov  5 12:32:22.210: INFO: Pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" satisfied condition "running"
STEP: creating a file in subpath 11/05/22 12:32:22.21
Nov  5 12:32:22.214: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3396 PodName:var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 12:32:22.214: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 12:32:22.215: INFO: ExecWithOptions: Clientset creation
Nov  5 12:32:22.215: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-3396/pods/var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 11/05/22 12:32:22.3
Nov  5 12:32:22.304: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3396 PodName:var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 12:32:22.304: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 12:32:22.305: INFO: ExecWithOptions: Clientset creation
Nov  5 12:32:22.305: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-3396/pods/var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 11/05/22 12:32:22.364
Nov  5 12:32:22.877: INFO: Successfully updated pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222"
STEP: waiting for annotated pod running 11/05/22 12:32:22.877
Nov  5 12:32:22.877: INFO: Waiting up to 2m0s for pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" in namespace "var-expansion-3396" to be "running"
Nov  5 12:32:22.881: INFO: Pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222": Phase="Running", Reason="", readiness=true. Elapsed: 3.467102ms
Nov  5 12:32:22.881: INFO: Pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" satisfied condition "running"
STEP: deleting the pod gracefully 11/05/22 12:32:22.881
Nov  5 12:32:22.881: INFO: Deleting pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" in namespace "var-expansion-3396"
Nov  5 12:32:22.889: INFO: Wait up to 5m0s for pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov  5 12:32:56.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3396" for this suite. 11/05/22 12:32:56.9
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":154,"skipped":2782,"failed":0}
------------------------------
• [SLOW TEST] [36.737 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:32:20.17
    Nov  5 12:32:20.170: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename var-expansion 11/05/22 12:32:20.171
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:32:20.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:32:20.187
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 11/05/22 12:32:20.192
    STEP: waiting for pod running 11/05/22 12:32:20.202
    Nov  5 12:32:20.202: INFO: Waiting up to 2m0s for pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" in namespace "var-expansion-3396" to be "running"
    Nov  5 12:32:20.206: INFO: Pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222": Phase="Pending", Reason="", readiness=false. Elapsed: 3.450702ms
    Nov  5 12:32:22.210: INFO: Pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222": Phase="Running", Reason="", readiness=true. Elapsed: 2.00763448s
    Nov  5 12:32:22.210: INFO: Pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" satisfied condition "running"
    STEP: creating a file in subpath 11/05/22 12:32:22.21
    Nov  5 12:32:22.214: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-3396 PodName:var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 12:32:22.214: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 12:32:22.215: INFO: ExecWithOptions: Clientset creation
    Nov  5 12:32:22.215: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-3396/pods/var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 11/05/22 12:32:22.3
    Nov  5 12:32:22.304: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-3396 PodName:var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222 ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 12:32:22.304: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 12:32:22.305: INFO: ExecWithOptions: Clientset creation
    Nov  5 12:32:22.305: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/var-expansion-3396/pods/var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 11/05/22 12:32:22.364
    Nov  5 12:32:22.877: INFO: Successfully updated pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222"
    STEP: waiting for annotated pod running 11/05/22 12:32:22.877
    Nov  5 12:32:22.877: INFO: Waiting up to 2m0s for pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" in namespace "var-expansion-3396" to be "running"
    Nov  5 12:32:22.881: INFO: Pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222": Phase="Running", Reason="", readiness=true. Elapsed: 3.467102ms
    Nov  5 12:32:22.881: INFO: Pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" satisfied condition "running"
    STEP: deleting the pod gracefully 11/05/22 12:32:22.881
    Nov  5 12:32:22.881: INFO: Deleting pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" in namespace "var-expansion-3396"
    Nov  5 12:32:22.889: INFO: Wait up to 5m0s for pod "var-expansion-c6560aaf-829b-4863-ba82-c8c07908f222" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov  5 12:32:56.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3396" for this suite. 11/05/22 12:32:56.9
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:32:56.908
Nov  5 12:32:56.908: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 12:32:56.909
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:32:56.923
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:32:56.927
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 11/05/22 12:32:56.93
STEP: Ensuring ResourceQuota status is calculated 11/05/22 12:32:56.935
STEP: Creating a ResourceQuota with not best effort scope 11/05/22 12:32:58.939
STEP: Ensuring ResourceQuota status is calculated 11/05/22 12:32:58.944
STEP: Creating a best-effort pod 11/05/22 12:33:00.948
STEP: Ensuring resource quota with best effort scope captures the pod usage 11/05/22 12:33:00.96
STEP: Ensuring resource quota with not best effort ignored the pod usage 11/05/22 12:33:02.964
STEP: Deleting the pod 11/05/22 12:33:04.969
STEP: Ensuring resource quota status released the pod usage 11/05/22 12:33:04.979
STEP: Creating a not best-effort pod 11/05/22 12:33:06.983
STEP: Ensuring resource quota with not best effort scope captures the pod usage 11/05/22 12:33:06.997
STEP: Ensuring resource quota with best effort scope ignored the pod usage 11/05/22 12:33:09.002
STEP: Deleting the pod 11/05/22 12:33:11.007
STEP: Ensuring resource quota status released the pod usage 11/05/22 12:33:11.021
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 12:33:13.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7748" for this suite. 11/05/22 12:33:13.029
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":155,"skipped":2786,"failed":0}
------------------------------
• [SLOW TEST] [16.128 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:32:56.908
    Nov  5 12:32:56.908: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 12:32:56.909
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:32:56.923
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:32:56.927
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 11/05/22 12:32:56.93
    STEP: Ensuring ResourceQuota status is calculated 11/05/22 12:32:56.935
    STEP: Creating a ResourceQuota with not best effort scope 11/05/22 12:32:58.939
    STEP: Ensuring ResourceQuota status is calculated 11/05/22 12:32:58.944
    STEP: Creating a best-effort pod 11/05/22 12:33:00.948
    STEP: Ensuring resource quota with best effort scope captures the pod usage 11/05/22 12:33:00.96
    STEP: Ensuring resource quota with not best effort ignored the pod usage 11/05/22 12:33:02.964
    STEP: Deleting the pod 11/05/22 12:33:04.969
    STEP: Ensuring resource quota status released the pod usage 11/05/22 12:33:04.979
    STEP: Creating a not best-effort pod 11/05/22 12:33:06.983
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 11/05/22 12:33:06.997
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 11/05/22 12:33:09.002
    STEP: Deleting the pod 11/05/22 12:33:11.007
    STEP: Ensuring resource quota status released the pod usage 11/05/22 12:33:11.021
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 12:33:13.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7748" for this suite. 11/05/22 12:33:13.029
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:33:13.038
Nov  5 12:33:13.038: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-probe 11/05/22 12:33:13.039
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:33:13.053
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:33:13.058
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9 in namespace container-probe-5764 11/05/22 12:33:13.061
Nov  5 12:33:13.069: INFO: Waiting up to 5m0s for pod "test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9" in namespace "container-probe-5764" to be "not pending"
Nov  5 12:33:13.090: INFO: Pod "test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.509809ms
Nov  5 12:33:15.095: INFO: Pod "test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9": Phase="Running", Reason="", readiness=true. Elapsed: 2.025295857s
Nov  5 12:33:15.095: INFO: Pod "test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9" satisfied condition "not pending"
Nov  5 12:33:15.095: INFO: Started pod test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9 in namespace container-probe-5764
STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 12:33:15.095
Nov  5 12:33:15.098: INFO: Initial restart count of pod test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9 is 0
STEP: deleting the pod 11/05/22 12:37:15.632
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov  5 12:37:15.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5764" for this suite. 11/05/22 12:37:15.65
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":156,"skipped":2816,"failed":0}
------------------------------
• [SLOW TEST] [242.619 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:33:13.038
    Nov  5 12:33:13.038: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-probe 11/05/22 12:33:13.039
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:33:13.053
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:33:13.058
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9 in namespace container-probe-5764 11/05/22 12:33:13.061
    Nov  5 12:33:13.069: INFO: Waiting up to 5m0s for pod "test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9" in namespace "container-probe-5764" to be "not pending"
    Nov  5 12:33:13.090: INFO: Pod "test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.509809ms
    Nov  5 12:33:15.095: INFO: Pod "test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9": Phase="Running", Reason="", readiness=true. Elapsed: 2.025295857s
    Nov  5 12:33:15.095: INFO: Pod "test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9" satisfied condition "not pending"
    Nov  5 12:33:15.095: INFO: Started pod test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9 in namespace container-probe-5764
    STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 12:33:15.095
    Nov  5 12:33:15.098: INFO: Initial restart count of pod test-webserver-831a6485-3edf-462f-80d8-10e90d6c73f9 is 0
    STEP: deleting the pod 11/05/22 12:37:15.632
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov  5 12:37:15.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-5764" for this suite. 11/05/22 12:37:15.65
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:37:15.658
Nov  5 12:37:15.658: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename events 11/05/22 12:37:15.658
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:15.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:15.684
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 11/05/22 12:37:15.688
STEP: get a list of Events with a label in the current namespace 11/05/22 12:37:15.705
STEP: delete a list of events 11/05/22 12:37:15.708
Nov  5 12:37:15.708: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 11/05/22 12:37:15.727
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Nov  5 12:37:15.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5239" for this suite. 11/05/22 12:37:15.734
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":157,"skipped":2822,"failed":0}
------------------------------
• [0.084 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:37:15.658
    Nov  5 12:37:15.658: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename events 11/05/22 12:37:15.658
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:15.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:15.684
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 11/05/22 12:37:15.688
    STEP: get a list of Events with a label in the current namespace 11/05/22 12:37:15.705
    STEP: delete a list of events 11/05/22 12:37:15.708
    Nov  5 12:37:15.708: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 11/05/22 12:37:15.727
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Nov  5 12:37:15.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-5239" for this suite. 11/05/22 12:37:15.734
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:37:15.742
Nov  5 12:37:15.743: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replication-controller 11/05/22 12:37:15.743
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:15.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:15.76
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 11/05/22 12:37:15.764
Nov  5 12:37:15.776: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-1891" to be "running and ready"
Nov  5 12:37:15.782: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 6.392879ms
Nov  5 12:37:15.782: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:37:17.787: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.011353029s
Nov  5 12:37:17.787: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Nov  5 12:37:17.787: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 11/05/22 12:37:17.791
STEP: Then the orphan pod is adopted 11/05/22 12:37:17.795
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov  5 12:37:18.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1891" for this suite. 11/05/22 12:37:18.808
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":158,"skipped":2831,"failed":0}
------------------------------
• [3.073 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:37:15.742
    Nov  5 12:37:15.743: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replication-controller 11/05/22 12:37:15.743
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:15.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:15.76
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 11/05/22 12:37:15.764
    Nov  5 12:37:15.776: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-1891" to be "running and ready"
    Nov  5 12:37:15.782: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 6.392879ms
    Nov  5 12:37:15.782: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:37:17.787: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.011353029s
    Nov  5 12:37:17.787: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Nov  5 12:37:17.787: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 11/05/22 12:37:17.791
    STEP: Then the orphan pod is adopted 11/05/22 12:37:17.795
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov  5 12:37:18.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-1891" for this suite. 11/05/22 12:37:18.808
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:37:18.816
Nov  5 12:37:18.816: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:37:18.817
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:18.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:18.844
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 11/05/22 12:37:18.847
Nov  5 12:37:18.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 create -f -'
Nov  5 12:37:19.038: INFO: stderr: ""
Nov  5 12:37:19.038: INFO: stdout: "pod/pause created\n"
Nov  5 12:37:19.038: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov  5 12:37:19.038: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9112" to be "running and ready"
Nov  5 12:37:19.043: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.803687ms
Nov  5 12:37:19.043: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'ip-172-31-41-19' to be 'Running' but was 'Pending'
Nov  5 12:37:21.047: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009046316s
Nov  5 12:37:21.047: INFO: Pod "pause" satisfied condition "running and ready"
Nov  5 12:37:21.047: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 11/05/22 12:37:21.048
Nov  5 12:37:21.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 label pods pause testing-label=testing-label-value'
Nov  5 12:37:21.114: INFO: stderr: ""
Nov  5 12:37:21.114: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 11/05/22 12:37:21.114
Nov  5 12:37:21.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 get pod pause -L testing-label'
Nov  5 12:37:21.186: INFO: stderr: ""
Nov  5 12:37:21.186: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 11/05/22 12:37:21.186
Nov  5 12:37:21.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 label pods pause testing-label-'
Nov  5 12:37:21.253: INFO: stderr: ""
Nov  5 12:37:21.253: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 11/05/22 12:37:21.253
Nov  5 12:37:21.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 get pod pause -L testing-label'
Nov  5 12:37:21.317: INFO: stderr: ""
Nov  5 12:37:21.317: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 11/05/22 12:37:21.317
Nov  5 12:37:21.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 delete --grace-period=0 --force -f -'
Nov  5 12:37:21.383: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 12:37:21.383: INFO: stdout: "pod \"pause\" force deleted\n"
Nov  5 12:37:21.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 get rc,svc -l name=pause --no-headers'
Nov  5 12:37:21.448: INFO: stderr: "No resources found in kubectl-9112 namespace.\n"
Nov  5 12:37:21.448: INFO: stdout: ""
Nov  5 12:37:21.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  5 12:37:21.507: INFO: stderr: ""
Nov  5 12:37:21.507: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:37:21.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9112" for this suite. 11/05/22 12:37:21.511
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":159,"skipped":2840,"failed":0}
------------------------------
• [2.702 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:37:18.816
    Nov  5 12:37:18.816: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:37:18.817
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:18.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:18.844
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 11/05/22 12:37:18.847
    Nov  5 12:37:18.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 create -f -'
    Nov  5 12:37:19.038: INFO: stderr: ""
    Nov  5 12:37:19.038: INFO: stdout: "pod/pause created\n"
    Nov  5 12:37:19.038: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Nov  5 12:37:19.038: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9112" to be "running and ready"
    Nov  5 12:37:19.043: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.803687ms
    Nov  5 12:37:19.043: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'ip-172-31-41-19' to be 'Running' but was 'Pending'
    Nov  5 12:37:21.047: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009046316s
    Nov  5 12:37:21.047: INFO: Pod "pause" satisfied condition "running and ready"
    Nov  5 12:37:21.047: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 11/05/22 12:37:21.048
    Nov  5 12:37:21.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 label pods pause testing-label=testing-label-value'
    Nov  5 12:37:21.114: INFO: stderr: ""
    Nov  5 12:37:21.114: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 11/05/22 12:37:21.114
    Nov  5 12:37:21.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 get pod pause -L testing-label'
    Nov  5 12:37:21.186: INFO: stderr: ""
    Nov  5 12:37:21.186: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 11/05/22 12:37:21.186
    Nov  5 12:37:21.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 label pods pause testing-label-'
    Nov  5 12:37:21.253: INFO: stderr: ""
    Nov  5 12:37:21.253: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 11/05/22 12:37:21.253
    Nov  5 12:37:21.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 get pod pause -L testing-label'
    Nov  5 12:37:21.317: INFO: stderr: ""
    Nov  5 12:37:21.317: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 11/05/22 12:37:21.317
    Nov  5 12:37:21.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 delete --grace-period=0 --force -f -'
    Nov  5 12:37:21.383: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov  5 12:37:21.383: INFO: stdout: "pod \"pause\" force deleted\n"
    Nov  5 12:37:21.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 get rc,svc -l name=pause --no-headers'
    Nov  5 12:37:21.448: INFO: stderr: "No resources found in kubectl-9112 namespace.\n"
    Nov  5 12:37:21.448: INFO: stdout: ""
    Nov  5 12:37:21.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9112 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov  5 12:37:21.507: INFO: stderr: ""
    Nov  5 12:37:21.507: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:37:21.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9112" for this suite. 11/05/22 12:37:21.511
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:37:21.518
Nov  5 12:37:21.519: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-webhook 11/05/22 12:37:21.519
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:21.583
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:21.587
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 11/05/22 12:37:21.591
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/05/22 12:37:21.928
STEP: Deploying the custom resource conversion webhook pod 11/05/22 12:37:22.034
STEP: Wait for the deployment to be ready 11/05/22 12:37:22.047
Nov  5 12:37:22.054: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/05/22 12:37:24.065
STEP: Verifying the service has paired with the endpoint 11/05/22 12:37:24.079
Nov  5 12:37:25.079: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Nov  5 12:37:25.084: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Creating a v1 custom resource 11/05/22 12:37:27.665
STEP: Create a v2 custom resource 11/05/22 12:37:27.683
STEP: List CRs in v1 11/05/22 12:37:27.732
STEP: List CRs in v2 11/05/22 12:37:27.739
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:37:28.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4408" for this suite. 11/05/22 12:37:28.262
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":160,"skipped":2842,"failed":0}
------------------------------
• [SLOW TEST] [6.964 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:37:21.518
    Nov  5 12:37:21.519: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-webhook 11/05/22 12:37:21.519
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:21.583
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:21.587
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 11/05/22 12:37:21.591
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 11/05/22 12:37:21.928
    STEP: Deploying the custom resource conversion webhook pod 11/05/22 12:37:22.034
    STEP: Wait for the deployment to be ready 11/05/22 12:37:22.047
    Nov  5 12:37:22.054: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/05/22 12:37:24.065
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:37:24.079
    Nov  5 12:37:25.079: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Nov  5 12:37:25.084: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Creating a v1 custom resource 11/05/22 12:37:27.665
    STEP: Create a v2 custom resource 11/05/22 12:37:27.683
    STEP: List CRs in v1 11/05/22 12:37:27.732
    STEP: List CRs in v2 11/05/22 12:37:27.739
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:37:28.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-4408" for this suite. 11/05/22 12:37:28.262
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:37:28.483
Nov  5 12:37:28.483: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename svcaccounts 11/05/22 12:37:28.483
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:28.504
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:28.508
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Nov  5 12:37:28.525: INFO: Waiting up to 5m0s for pod "pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a" in namespace "svcaccounts-8254" to be "running"
Nov  5 12:37:28.530: INFO: Pod "pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.755389ms
Nov  5 12:37:30.535: INFO: Pod "pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a": Phase="Running", Reason="", readiness=true. Elapsed: 2.009297937s
Nov  5 12:37:30.535: INFO: Pod "pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a" satisfied condition "running"
STEP: reading a file in the container 11/05/22 12:37:30.535
Nov  5 12:37:30.535: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8254 pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 11/05/22 12:37:30.684
Nov  5 12:37:30.684: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8254 pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 11/05/22 12:37:30.812
Nov  5 12:37:30.812: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8254 pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Nov  5 12:37:30.935: INFO: Got root ca configmap in namespace "svcaccounts-8254"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov  5 12:37:30.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8254" for this suite. 11/05/22 12:37:30.942
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":161,"skipped":2845,"failed":0}
------------------------------
• [2.465 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:37:28.483
    Nov  5 12:37:28.483: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename svcaccounts 11/05/22 12:37:28.483
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:28.504
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:28.508
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Nov  5 12:37:28.525: INFO: Waiting up to 5m0s for pod "pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a" in namespace "svcaccounts-8254" to be "running"
    Nov  5 12:37:28.530: INFO: Pod "pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.755389ms
    Nov  5 12:37:30.535: INFO: Pod "pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a": Phase="Running", Reason="", readiness=true. Elapsed: 2.009297937s
    Nov  5 12:37:30.535: INFO: Pod "pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a" satisfied condition "running"
    STEP: reading a file in the container 11/05/22 12:37:30.535
    Nov  5 12:37:30.535: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8254 pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 11/05/22 12:37:30.684
    Nov  5 12:37:30.684: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8254 pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 11/05/22 12:37:30.812
    Nov  5 12:37:30.812: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8254 pod-service-account-b0ff58c5-02e6-4937-b0b1-2c86f4a73b5a -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Nov  5 12:37:30.935: INFO: Got root ca configmap in namespace "svcaccounts-8254"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov  5 12:37:30.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-8254" for this suite. 11/05/22 12:37:30.942
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:37:30.951
Nov  5 12:37:30.952: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename subpath 11/05/22 12:37:30.952
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:30.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:30.97
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/05/22 12:37:30.974
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-fk5h 11/05/22 12:37:30.985
STEP: Creating a pod to test atomic-volume-subpath 11/05/22 12:37:30.985
Nov  5 12:37:30.995: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fk5h" in namespace "subpath-5873" to be "Succeeded or Failed"
Nov  5 12:37:31.000: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Pending", Reason="", readiness=false. Elapsed: 5.13764ms
Nov  5 12:37:33.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 2.009676146s
Nov  5 12:37:35.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 4.009692789s
Nov  5 12:37:37.005: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 6.010041676s
Nov  5 12:37:39.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 8.009576504s
Nov  5 12:37:41.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 10.009674139s
Nov  5 12:37:43.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 12.009620145s
Nov  5 12:37:45.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 14.009249621s
Nov  5 12:37:47.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 16.009607142s
Nov  5 12:37:49.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 18.009536448s
Nov  5 12:37:51.005: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 20.010418623s
Nov  5 12:37:53.005: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=false. Elapsed: 22.010296117s
Nov  5 12:37:55.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.009658598s
STEP: Saw pod success 11/05/22 12:37:55.004
Nov  5 12:37:55.005: INFO: Pod "pod-subpath-test-configmap-fk5h" satisfied condition "Succeeded or Failed"
Nov  5 12:37:55.008: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-subpath-test-configmap-fk5h container test-container-subpath-configmap-fk5h: <nil>
STEP: delete the pod 11/05/22 12:37:55.026
Nov  5 12:37:55.039: INFO: Waiting for pod pod-subpath-test-configmap-fk5h to disappear
Nov  5 12:37:55.042: INFO: Pod pod-subpath-test-configmap-fk5h no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fk5h 11/05/22 12:37:55.042
Nov  5 12:37:55.042: INFO: Deleting pod "pod-subpath-test-configmap-fk5h" in namespace "subpath-5873"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov  5 12:37:55.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5873" for this suite. 11/05/22 12:37:55.049
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":162,"skipped":2916,"failed":0}
------------------------------
• [SLOW TEST] [24.104 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:37:30.951
    Nov  5 12:37:30.952: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename subpath 11/05/22 12:37:30.952
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:30.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:30.97
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/05/22 12:37:30.974
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-fk5h 11/05/22 12:37:30.985
    STEP: Creating a pod to test atomic-volume-subpath 11/05/22 12:37:30.985
    Nov  5 12:37:30.995: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fk5h" in namespace "subpath-5873" to be "Succeeded or Failed"
    Nov  5 12:37:31.000: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Pending", Reason="", readiness=false. Elapsed: 5.13764ms
    Nov  5 12:37:33.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 2.009676146s
    Nov  5 12:37:35.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 4.009692789s
    Nov  5 12:37:37.005: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 6.010041676s
    Nov  5 12:37:39.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 8.009576504s
    Nov  5 12:37:41.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 10.009674139s
    Nov  5 12:37:43.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 12.009620145s
    Nov  5 12:37:45.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 14.009249621s
    Nov  5 12:37:47.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 16.009607142s
    Nov  5 12:37:49.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 18.009536448s
    Nov  5 12:37:51.005: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=true. Elapsed: 20.010418623s
    Nov  5 12:37:53.005: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Running", Reason="", readiness=false. Elapsed: 22.010296117s
    Nov  5 12:37:55.004: INFO: Pod "pod-subpath-test-configmap-fk5h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.009658598s
    STEP: Saw pod success 11/05/22 12:37:55.004
    Nov  5 12:37:55.005: INFO: Pod "pod-subpath-test-configmap-fk5h" satisfied condition "Succeeded or Failed"
    Nov  5 12:37:55.008: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-subpath-test-configmap-fk5h container test-container-subpath-configmap-fk5h: <nil>
    STEP: delete the pod 11/05/22 12:37:55.026
    Nov  5 12:37:55.039: INFO: Waiting for pod pod-subpath-test-configmap-fk5h to disappear
    Nov  5 12:37:55.042: INFO: Pod pod-subpath-test-configmap-fk5h no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-fk5h 11/05/22 12:37:55.042
    Nov  5 12:37:55.042: INFO: Deleting pod "pod-subpath-test-configmap-fk5h" in namespace "subpath-5873"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov  5 12:37:55.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-5873" for this suite. 11/05/22 12:37:55.049
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:37:55.056
Nov  5 12:37:55.056: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 12:37:55.056
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:55.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:55.076
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 11/05/22 12:37:55.08
Nov  5 12:37:55.088: INFO: Waiting up to 5m0s for pod "pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de" in namespace "emptydir-4100" to be "Succeeded or Failed"
Nov  5 12:37:55.092: INFO: Pod "pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de": Phase="Pending", Reason="", readiness=false. Elapsed: 3.298503ms
Nov  5 12:37:57.095: INFO: Pod "pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007176322s
Nov  5 12:37:59.096: INFO: Pod "pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00791918s
STEP: Saw pod success 11/05/22 12:37:59.096
Nov  5 12:37:59.096: INFO: Pod "pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de" satisfied condition "Succeeded or Failed"
Nov  5 12:37:59.100: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de container test-container: <nil>
STEP: delete the pod 11/05/22 12:37:59.106
Nov  5 12:37:59.121: INFO: Waiting for pod pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de to disappear
Nov  5 12:37:59.124: INFO: Pod pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 12:37:59.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4100" for this suite. 11/05/22 12:37:59.128
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":163,"skipped":2918,"failed":0}
------------------------------
• [4.079 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:37:55.056
    Nov  5 12:37:55.056: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 12:37:55.056
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:55.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:55.076
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 11/05/22 12:37:55.08
    Nov  5 12:37:55.088: INFO: Waiting up to 5m0s for pod "pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de" in namespace "emptydir-4100" to be "Succeeded or Failed"
    Nov  5 12:37:55.092: INFO: Pod "pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de": Phase="Pending", Reason="", readiness=false. Elapsed: 3.298503ms
    Nov  5 12:37:57.095: INFO: Pod "pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007176322s
    Nov  5 12:37:59.096: INFO: Pod "pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00791918s
    STEP: Saw pod success 11/05/22 12:37:59.096
    Nov  5 12:37:59.096: INFO: Pod "pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de" satisfied condition "Succeeded or Failed"
    Nov  5 12:37:59.100: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de container test-container: <nil>
    STEP: delete the pod 11/05/22 12:37:59.106
    Nov  5 12:37:59.121: INFO: Waiting for pod pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de to disappear
    Nov  5 12:37:59.124: INFO: Pod pod-f4c6dc89-4309-4f12-a35b-9caa82a5e9de no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 12:37:59.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4100" for this suite. 11/05/22 12:37:59.128
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:37:59.138
Nov  5 12:37:59.138: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 12:37:59.139
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:59.164
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:59.168
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Nov  5 12:37:59.171: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: creating the pod 11/05/22 12:37:59.172
STEP: submitting the pod to kubernetes 11/05/22 12:37:59.172
Nov  5 12:37:59.181: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306" in namespace "pods-6973" to be "running and ready"
Nov  5 12:37:59.185: INFO: Pod "pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306": Phase="Pending", Reason="", readiness=false. Elapsed: 3.748649ms
Nov  5 12:37:59.185: INFO: The phase of Pod pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:38:01.189: INFO: Pod "pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306": Phase="Running", Reason="", readiness=true. Elapsed: 2.007860109s
Nov  5 12:38:01.189: INFO: The phase of Pod pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306 is Running (Ready = true)
Nov  5 12:38:01.189: INFO: Pod "pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov  5 12:38:01.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6973" for this suite. 11/05/22 12:38:01.208
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":164,"skipped":2953,"failed":0}
------------------------------
• [2.078 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:37:59.138
    Nov  5 12:37:59.138: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 12:37:59.139
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:37:59.164
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:37:59.168
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Nov  5 12:37:59.171: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: creating the pod 11/05/22 12:37:59.172
    STEP: submitting the pod to kubernetes 11/05/22 12:37:59.172
    Nov  5 12:37:59.181: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306" in namespace "pods-6973" to be "running and ready"
    Nov  5 12:37:59.185: INFO: Pod "pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306": Phase="Pending", Reason="", readiness=false. Elapsed: 3.748649ms
    Nov  5 12:37:59.185: INFO: The phase of Pod pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:38:01.189: INFO: Pod "pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306": Phase="Running", Reason="", readiness=true. Elapsed: 2.007860109s
    Nov  5 12:38:01.189: INFO: The phase of Pod pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306 is Running (Ready = true)
    Nov  5 12:38:01.189: INFO: Pod "pod-logs-websocket-572b1245-8479-40b7-b7fc-2f5e0ee0b306" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov  5 12:38:01.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6973" for this suite. 11/05/22 12:38:01.208
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:01.218
Nov  5 12:38:01.218: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename dns 11/05/22 12:38:01.218
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:01.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:01.237
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 11/05/22 12:38:01.241
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7535.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7535.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 215.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.215_udp@PTR;check="$$(dig +tcp +noall +answer +search 215.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.215_tcp@PTR;sleep 1; done
 11/05/22 12:38:01.259
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7535.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7535.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 215.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.215_udp@PTR;check="$$(dig +tcp +noall +answer +search 215.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.215_tcp@PTR;sleep 1; done
 11/05/22 12:38:01.259
STEP: creating a pod to probe DNS 11/05/22 12:38:01.26
STEP: submitting the pod to kubernetes 11/05/22 12:38:01.26
Nov  5 12:38:01.277: INFO: Waiting up to 15m0s for pod "dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f" in namespace "dns-7535" to be "running"
Nov  5 12:38:01.289: INFO: Pod "dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.413004ms
Nov  5 12:38:03.293: INFO: Pod "dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01576615s
Nov  5 12:38:03.293: INFO: Pod "dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f" satisfied condition "running"
STEP: retrieving the pod 11/05/22 12:38:03.293
STEP: looking for the results for each expected name from probers 11/05/22 12:38:03.297
Nov  5 12:38:03.302: INFO: Unable to read wheezy_udp@dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
Nov  5 12:38:03.307: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
Nov  5 12:38:03.311: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
Nov  5 12:38:03.315: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
Nov  5 12:38:03.341: INFO: Unable to read jessie_udp@dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
Nov  5 12:38:03.344: INFO: Unable to read jessie_tcp@dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
Nov  5 12:38:03.348: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
Nov  5 12:38:03.355: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
Nov  5 12:38:03.371: INFO: Lookups using dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f failed for: [wheezy_udp@dns-test-service.dns-7535.svc.cluster.local wheezy_tcp@dns-test-service.dns-7535.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local jessie_udp@dns-test-service.dns-7535.svc.cluster.local jessie_tcp@dns-test-service.dns-7535.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local]

Nov  5 12:38:08.439: INFO: DNS probes using dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f succeeded

STEP: deleting the pod 11/05/22 12:38:08.439
STEP: deleting the test service 11/05/22 12:38:08.552
STEP: deleting the test headless service 11/05/22 12:38:08.585
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov  5 12:38:08.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7535" for this suite. 11/05/22 12:38:08.623
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":165,"skipped":3006,"failed":0}
------------------------------
• [SLOW TEST] [7.413 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:01.218
    Nov  5 12:38:01.218: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename dns 11/05/22 12:38:01.218
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:01.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:01.237
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 11/05/22 12:38:01.241
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7535.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7535.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 215.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.215_udp@PTR;check="$$(dig +tcp +noall +answer +search 215.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.215_tcp@PTR;sleep 1; done
     11/05/22 12:38:01.259
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7535.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7535.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7535.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7535.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7535.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 215.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.215_udp@PTR;check="$$(dig +tcp +noall +answer +search 215.183.152.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.152.183.215_tcp@PTR;sleep 1; done
     11/05/22 12:38:01.259
    STEP: creating a pod to probe DNS 11/05/22 12:38:01.26
    STEP: submitting the pod to kubernetes 11/05/22 12:38:01.26
    Nov  5 12:38:01.277: INFO: Waiting up to 15m0s for pod "dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f" in namespace "dns-7535" to be "running"
    Nov  5 12:38:01.289: INFO: Pod "dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.413004ms
    Nov  5 12:38:03.293: INFO: Pod "dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f": Phase="Running", Reason="", readiness=true. Elapsed: 2.01576615s
    Nov  5 12:38:03.293: INFO: Pod "dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f" satisfied condition "running"
    STEP: retrieving the pod 11/05/22 12:38:03.293
    STEP: looking for the results for each expected name from probers 11/05/22 12:38:03.297
    Nov  5 12:38:03.302: INFO: Unable to read wheezy_udp@dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
    Nov  5 12:38:03.307: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
    Nov  5 12:38:03.311: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
    Nov  5 12:38:03.315: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
    Nov  5 12:38:03.341: INFO: Unable to read jessie_udp@dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
    Nov  5 12:38:03.344: INFO: Unable to read jessie_tcp@dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
    Nov  5 12:38:03.348: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
    Nov  5 12:38:03.355: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local from pod dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f: the server could not find the requested resource (get pods dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f)
    Nov  5 12:38:03.371: INFO: Lookups using dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f failed for: [wheezy_udp@dns-test-service.dns-7535.svc.cluster.local wheezy_tcp@dns-test-service.dns-7535.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local jessie_udp@dns-test-service.dns-7535.svc.cluster.local jessie_tcp@dns-test-service.dns-7535.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7535.svc.cluster.local]

    Nov  5 12:38:08.439: INFO: DNS probes using dns-7535/dns-test-c1ba6bb1-59f3-421d-8753-4f4aefed459f succeeded

    STEP: deleting the pod 11/05/22 12:38:08.439
    STEP: deleting the test service 11/05/22 12:38:08.552
    STEP: deleting the test headless service 11/05/22 12:38:08.585
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov  5 12:38:08.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7535" for this suite. 11/05/22 12:38:08.623
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:08.632
Nov  5 12:38:08.632: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename var-expansion 11/05/22 12:38:08.633
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:08.647
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:08.652
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 11/05/22 12:38:08.656
Nov  5 12:38:08.665: INFO: Waiting up to 5m0s for pod "var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e" in namespace "var-expansion-1091" to be "Succeeded or Failed"
Nov  5 12:38:08.670: INFO: Pod "var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.262485ms
Nov  5 12:38:10.674: INFO: Pod "var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009787108s
Nov  5 12:38:12.675: INFO: Pod "var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010465947s
STEP: Saw pod success 11/05/22 12:38:12.675
Nov  5 12:38:12.675: INFO: Pod "var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e" satisfied condition "Succeeded or Failed"
Nov  5 12:38:12.679: INFO: Trying to get logs from node ip-172-31-0-255 pod var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e container dapi-container: <nil>
STEP: delete the pod 11/05/22 12:38:12.685
Nov  5 12:38:12.697: INFO: Waiting for pod var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e to disappear
Nov  5 12:38:12.700: INFO: Pod var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov  5 12:38:12.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1091" for this suite. 11/05/22 12:38:12.704
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":166,"skipped":3033,"failed":0}
------------------------------
• [4.078 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:08.632
    Nov  5 12:38:08.632: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename var-expansion 11/05/22 12:38:08.633
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:08.647
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:08.652
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 11/05/22 12:38:08.656
    Nov  5 12:38:08.665: INFO: Waiting up to 5m0s for pod "var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e" in namespace "var-expansion-1091" to be "Succeeded or Failed"
    Nov  5 12:38:08.670: INFO: Pod "var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.262485ms
    Nov  5 12:38:10.674: INFO: Pod "var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009787108s
    Nov  5 12:38:12.675: INFO: Pod "var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010465947s
    STEP: Saw pod success 11/05/22 12:38:12.675
    Nov  5 12:38:12.675: INFO: Pod "var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e" satisfied condition "Succeeded or Failed"
    Nov  5 12:38:12.679: INFO: Trying to get logs from node ip-172-31-0-255 pod var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e container dapi-container: <nil>
    STEP: delete the pod 11/05/22 12:38:12.685
    Nov  5 12:38:12.697: INFO: Waiting for pod var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e to disappear
    Nov  5 12:38:12.700: INFO: Pod var-expansion-85c3202f-6c52-4953-9fd1-e6db5dc6185e no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov  5 12:38:12.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1091" for this suite. 11/05/22 12:38:12.704
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:12.711
Nov  5 12:38:12.711: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 12:38:12.711
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:12.723
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:12.729
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 12:38:12.747
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:38:13.112
STEP: Deploying the webhook pod 11/05/22 12:38:13.12
STEP: Wait for the deployment to be ready 11/05/22 12:38:13.134
Nov  5 12:38:13.144: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 12:38:15.158
STEP: Verifying the service has paired with the endpoint 11/05/22 12:38:15.174
Nov  5 12:38:16.176: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Nov  5 12:38:16.180: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Registering the custom resource webhook via the AdmissionRegistration API 11/05/22 12:38:16.689
STEP: Creating a custom resource that should be denied by the webhook 11/05/22 12:38:16.704
STEP: Creating a custom resource whose deletion would be denied by the webhook 11/05/22 12:38:18.735
STEP: Updating the custom resource with disallowed data should be denied 11/05/22 12:38:18.744
STEP: Deleting the custom resource should be denied 11/05/22 12:38:18.753
STEP: Remove the offending key and value from the custom resource data 11/05/22 12:38:18.759
STEP: Deleting the updated custom resource should be successful 11/05/22 12:38:18.769
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:38:19.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6167" for this suite. 11/05/22 12:38:19.302
STEP: Destroying namespace "webhook-6167-markers" for this suite. 11/05/22 12:38:19.31
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":167,"skipped":3046,"failed":0}
------------------------------
• [SLOW TEST] [6.685 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:12.711
    Nov  5 12:38:12.711: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 12:38:12.711
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:12.723
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:12.729
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 12:38:12.747
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:38:13.112
    STEP: Deploying the webhook pod 11/05/22 12:38:13.12
    STEP: Wait for the deployment to be ready 11/05/22 12:38:13.134
    Nov  5 12:38:13.144: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 12:38:15.158
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:38:15.174
    Nov  5 12:38:16.176: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Nov  5 12:38:16.180: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 11/05/22 12:38:16.689
    STEP: Creating a custom resource that should be denied by the webhook 11/05/22 12:38:16.704
    STEP: Creating a custom resource whose deletion would be denied by the webhook 11/05/22 12:38:18.735
    STEP: Updating the custom resource with disallowed data should be denied 11/05/22 12:38:18.744
    STEP: Deleting the custom resource should be denied 11/05/22 12:38:18.753
    STEP: Remove the offending key and value from the custom resource data 11/05/22 12:38:18.759
    STEP: Deleting the updated custom resource should be successful 11/05/22 12:38:18.769
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:38:19.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6167" for this suite. 11/05/22 12:38:19.302
    STEP: Destroying namespace "webhook-6167-markers" for this suite. 11/05/22 12:38:19.31
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:19.396
Nov  5 12:38:19.396: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:38:19.397
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:19.424
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:19.432
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/05/22 12:38:19.438
Nov  5 12:38:19.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9655 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Nov  5 12:38:19.517: INFO: stderr: ""
Nov  5 12:38:19.517: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 11/05/22 12:38:19.517
Nov  5 12:38:19.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9655 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Nov  5 12:38:20.473: INFO: stderr: ""
Nov  5 12:38:20.473: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/05/22 12:38:20.473
Nov  5 12:38:20.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9655 delete pods e2e-test-httpd-pod'
Nov  5 12:38:23.451: INFO: stderr: ""
Nov  5 12:38:23.451: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:38:23.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9655" for this suite. 11/05/22 12:38:23.456
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":168,"skipped":3059,"failed":0}
------------------------------
• [4.066 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:19.396
    Nov  5 12:38:19.396: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:38:19.397
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:19.424
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:19.432
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/05/22 12:38:19.438
    Nov  5 12:38:19.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9655 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Nov  5 12:38:19.517: INFO: stderr: ""
    Nov  5 12:38:19.517: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 11/05/22 12:38:19.517
    Nov  5 12:38:19.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9655 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Nov  5 12:38:20.473: INFO: stderr: ""
    Nov  5 12:38:20.473: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 11/05/22 12:38:20.473
    Nov  5 12:38:20.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-9655 delete pods e2e-test-httpd-pod'
    Nov  5 12:38:23.451: INFO: stderr: ""
    Nov  5 12:38:23.451: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:38:23.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9655" for this suite. 11/05/22 12:38:23.456
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:23.463
Nov  5 12:38:23.463: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 12:38:23.464
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:23.476
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:23.48
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 11/05/22 12:38:23.485
Nov  5 12:38:23.494: INFO: Waiting up to 5m0s for pod "downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93" in namespace "downward-api-9484" to be "Succeeded or Failed"
Nov  5 12:38:23.498: INFO: Pod "downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93": Phase="Pending", Reason="", readiness=false. Elapsed: 3.856127ms
Nov  5 12:38:25.502: INFO: Pod "downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008019037s
Nov  5 12:38:27.502: INFO: Pod "downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008084315s
STEP: Saw pod success 11/05/22 12:38:27.502
Nov  5 12:38:27.502: INFO: Pod "downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93" satisfied condition "Succeeded or Failed"
Nov  5 12:38:27.506: INFO: Trying to get logs from node ip-172-31-41-19 pod downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93 container client-container: <nil>
STEP: delete the pod 11/05/22 12:38:27.526
Nov  5 12:38:27.540: INFO: Waiting for pod downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93 to disappear
Nov  5 12:38:27.543: INFO: Pod downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 12:38:27.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9484" for this suite. 11/05/22 12:38:27.548
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":169,"skipped":3069,"failed":0}
------------------------------
• [4.093 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:23.463
    Nov  5 12:38:23.463: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 12:38:23.464
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:23.476
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:23.48
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 11/05/22 12:38:23.485
    Nov  5 12:38:23.494: INFO: Waiting up to 5m0s for pod "downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93" in namespace "downward-api-9484" to be "Succeeded or Failed"
    Nov  5 12:38:23.498: INFO: Pod "downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93": Phase="Pending", Reason="", readiness=false. Elapsed: 3.856127ms
    Nov  5 12:38:25.502: INFO: Pod "downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008019037s
    Nov  5 12:38:27.502: INFO: Pod "downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008084315s
    STEP: Saw pod success 11/05/22 12:38:27.502
    Nov  5 12:38:27.502: INFO: Pod "downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93" satisfied condition "Succeeded or Failed"
    Nov  5 12:38:27.506: INFO: Trying to get logs from node ip-172-31-41-19 pod downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93 container client-container: <nil>
    STEP: delete the pod 11/05/22 12:38:27.526
    Nov  5 12:38:27.540: INFO: Waiting for pod downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93 to disappear
    Nov  5 12:38:27.543: INFO: Pod downwardapi-volume-633c6c97-9a19-4ae5-a4d7-4f670ddaeb93 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 12:38:27.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9484" for this suite. 11/05/22 12:38:27.548
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:27.556
Nov  5 12:38:27.556: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 12:38:27.557
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:27.569
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:27.572
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-c9a24d6c-852d-46b6-ad15-debf633c692d 11/05/22 12:38:27.577
STEP: Creating a pod to test consume secrets 11/05/22 12:38:27.581
Nov  5 12:38:27.591: INFO: Waiting up to 5m0s for pod "pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8" in namespace "secrets-2666" to be "Succeeded or Failed"
Nov  5 12:38:27.597: INFO: Pod "pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.163178ms
Nov  5 12:38:29.602: INFO: Pod "pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011389073s
Nov  5 12:38:31.601: INFO: Pod "pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010479142s
STEP: Saw pod success 11/05/22 12:38:31.601
Nov  5 12:38:31.601: INFO: Pod "pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8" satisfied condition "Succeeded or Failed"
Nov  5 12:38:31.605: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8 container secret-volume-test: <nil>
STEP: delete the pod 11/05/22 12:38:31.612
Nov  5 12:38:31.626: INFO: Waiting for pod pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8 to disappear
Nov  5 12:38:31.629: INFO: Pod pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov  5 12:38:31.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2666" for this suite. 11/05/22 12:38:31.633
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":170,"skipped":3072,"failed":0}
------------------------------
• [4.084 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:27.556
    Nov  5 12:38:27.556: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 12:38:27.557
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:27.569
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:27.572
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-c9a24d6c-852d-46b6-ad15-debf633c692d 11/05/22 12:38:27.577
    STEP: Creating a pod to test consume secrets 11/05/22 12:38:27.581
    Nov  5 12:38:27.591: INFO: Waiting up to 5m0s for pod "pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8" in namespace "secrets-2666" to be "Succeeded or Failed"
    Nov  5 12:38:27.597: INFO: Pod "pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.163178ms
    Nov  5 12:38:29.602: INFO: Pod "pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011389073s
    Nov  5 12:38:31.601: INFO: Pod "pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010479142s
    STEP: Saw pod success 11/05/22 12:38:31.601
    Nov  5 12:38:31.601: INFO: Pod "pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8" satisfied condition "Succeeded or Failed"
    Nov  5 12:38:31.605: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8 container secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 12:38:31.612
    Nov  5 12:38:31.626: INFO: Waiting for pod pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8 to disappear
    Nov  5 12:38:31.629: INFO: Pod pod-secrets-e26d5796-98e7-4d03-9b74-c3240ed0c9a8 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 12:38:31.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2666" for this suite. 11/05/22 12:38:31.633
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:31.642
Nov  5 12:38:31.643: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename deployment 11/05/22 12:38:31.644
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:31.657
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:31.662
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 11/05/22 12:38:31.67
STEP: waiting for Deployment to be created 11/05/22 12:38:31.676
STEP: waiting for all Replicas to be Ready 11/05/22 12:38:31.678
Nov  5 12:38:31.680: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov  5 12:38:31.680: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov  5 12:38:31.688: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov  5 12:38:31.688: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov  5 12:38:31.704: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov  5 12:38:31.704: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov  5 12:38:31.734: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov  5 12:38:31.734: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Nov  5 12:38:33.100: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Nov  5 12:38:33.101: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Nov  5 12:38:33.463: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 11/05/22 12:38:33.463
W1105 12:38:33.471659      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov  5 12:38:33.473: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 11/05/22 12:38:33.473
Nov  5 12:38:33.477: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
Nov  5 12:38:33.477: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:33.485: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:33.485: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:33.515: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:33.515: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:33.526: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
Nov  5 12:38:33.526: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
Nov  5 12:38:35.117: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:35.117: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:35.141: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
STEP: listing Deployments 11/05/22 12:38:35.141
Nov  5 12:38:35.146: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 11/05/22 12:38:35.146
Nov  5 12:38:35.161: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 11/05/22 12:38:35.161
Nov  5 12:38:35.172: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov  5 12:38:35.172: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov  5 12:38:35.187: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov  5 12:38:35.202: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov  5 12:38:35.210: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov  5 12:38:35.224: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Nov  5 12:38:36.473: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov  5 12:38:36.549: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Nov  5 12:38:36.579: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov  5 12:38:36.601: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Nov  5 12:38:38.210: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 11/05/22 12:38:38.224
STEP: fetching the DeploymentStatus 11/05/22 12:38:38.231
Nov  5 12:38:38.236: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 3
Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
Nov  5 12:38:38.238: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 3
STEP: deleting the Deployment 11/05/22 12:38:38.238
Nov  5 12:38:38.249: INFO: observed event type MODIFIED
Nov  5 12:38:38.249: INFO: observed event type MODIFIED
Nov  5 12:38:38.249: INFO: observed event type MODIFIED
Nov  5 12:38:38.249: INFO: observed event type MODIFIED
Nov  5 12:38:38.249: INFO: observed event type MODIFIED
Nov  5 12:38:38.250: INFO: observed event type MODIFIED
Nov  5 12:38:38.250: INFO: observed event type MODIFIED
Nov  5 12:38:38.250: INFO: observed event type MODIFIED
Nov  5 12:38:38.250: INFO: observed event type MODIFIED
Nov  5 12:38:38.250: INFO: observed event type MODIFIED
Nov  5 12:38:38.250: INFO: observed event type MODIFIED
Nov  5 12:38:38.250: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov  5 12:38:38.254: INFO: Log out all the ReplicaSets if there is no deployment created
Nov  5 12:38:38.258: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
&ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-2904  d219c2d5-0c77-4e12-ad54-57374a43635f 20953 2 2022-11-05 12:38:35 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 18b19386-e12c-475b-8755-786e0dd9e1fe 0xc004aa1577 0xc004aa1578}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:38:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"18b19386-e12c-475b-8755-786e0dd9e1fe\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:38:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004aa1600 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

Nov  5 12:38:38.264: INFO: pod: "test-deployment-7c7d8d58c8-5tb7r":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-5tb7r test-deployment-7c7d8d58c8- deployment-2904  73ebeac9-f85c-4124-b38a-d22f6ee27c9c 20952 0 2022-11-05 12:38:36 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 d219c2d5-0c77-4e12-ad54-57374a43635f 0xc004aa1997 0xc004aa1998}] [] [{kube-controller-manager Update v1 2022-11-05 12:38:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d219c2d5-0c77-4e12-ad54-57374a43635f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:38:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.95\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t4vc8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t4vc8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.95,StartTime:2022-11-05 12:38:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:38:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5dc891f3272993caaed7bf32849f9ca46264453d8b8e930cb94bb062cba58093,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Nov  5 12:38:38.264: INFO: pod: "test-deployment-7c7d8d58c8-tjxb6":
&Pod{ObjectMeta:{test-deployment-7c7d8d58c8-tjxb6 test-deployment-7c7d8d58c8- deployment-2904  fe32c530-80d1-48d0-b74c-446129c08d9e 20904 0 2022-11-05 12:38:35 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 d219c2d5-0c77-4e12-ad54-57374a43635f 0xc004aa1ba7 0xc004aa1ba8}] [] [{kube-controller-manager Update v1 2022-11-05 12:38:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d219c2d5-0c77-4e12-ad54-57374a43635f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:38:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.171\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-75q8z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-75q8z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.171,StartTime:2022-11-05 12:38:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:38:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://855288df90fa3d56fa1919ea2bb17aea8c5f64f8cabf5f51a31031d9bd23038d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.171,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

Nov  5 12:38:38.265: INFO: ReplicaSet "test-deployment-8594bb6fdd":
&ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-2904  20ceaf5a-22b3-4d4c-9785-a148c32a51aa 20847 3 2022-11-05 12:38:31 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 18b19386-e12c-475b-8755-786e0dd9e1fe 0xc004aa1667 0xc004aa1668}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:38:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"18b19386-e12c-475b-8755-786e0dd9e1fe\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:38:35 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004aa16f0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov  5 12:38:38.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2904" for this suite. 11/05/22 12:38:38.274
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":171,"skipped":3089,"failed":0}
------------------------------
• [SLOW TEST] [6.638 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:31.642
    Nov  5 12:38:31.643: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename deployment 11/05/22 12:38:31.644
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:31.657
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:31.662
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 11/05/22 12:38:31.67
    STEP: waiting for Deployment to be created 11/05/22 12:38:31.676
    STEP: waiting for all Replicas to be Ready 11/05/22 12:38:31.678
    Nov  5 12:38:31.680: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov  5 12:38:31.680: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov  5 12:38:31.688: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov  5 12:38:31.688: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov  5 12:38:31.704: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov  5 12:38:31.704: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov  5 12:38:31.734: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov  5 12:38:31.734: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Nov  5 12:38:33.100: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Nov  5 12:38:33.101: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Nov  5 12:38:33.463: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 11/05/22 12:38:33.463
    W1105 12:38:33.471659      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov  5 12:38:33.473: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 11/05/22 12:38:33.473
    Nov  5 12:38:33.477: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
    Nov  5 12:38:33.477: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 0
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:33.478: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:33.485: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:33.485: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:33.515: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:33.515: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:33.526: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    Nov  5 12:38:33.526: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    Nov  5 12:38:35.117: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:35.117: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:35.141: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    STEP: listing Deployments 11/05/22 12:38:35.141
    Nov  5 12:38:35.146: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 11/05/22 12:38:35.146
    Nov  5 12:38:35.161: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 11/05/22 12:38:35.161
    Nov  5 12:38:35.172: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov  5 12:38:35.172: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov  5 12:38:35.187: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov  5 12:38:35.202: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov  5 12:38:35.210: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov  5 12:38:35.224: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Nov  5 12:38:36.473: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov  5 12:38:36.549: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Nov  5 12:38:36.579: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov  5 12:38:36.601: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Nov  5 12:38:38.210: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 11/05/22 12:38:38.224
    STEP: fetching the DeploymentStatus 11/05/22 12:38:38.231
    Nov  5 12:38:38.236: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 1
    Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 3
    Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:38.237: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 2
    Nov  5 12:38:38.238: INFO: observed Deployment test-deployment in namespace deployment-2904 with ReadyReplicas 3
    STEP: deleting the Deployment 11/05/22 12:38:38.238
    Nov  5 12:38:38.249: INFO: observed event type MODIFIED
    Nov  5 12:38:38.249: INFO: observed event type MODIFIED
    Nov  5 12:38:38.249: INFO: observed event type MODIFIED
    Nov  5 12:38:38.249: INFO: observed event type MODIFIED
    Nov  5 12:38:38.249: INFO: observed event type MODIFIED
    Nov  5 12:38:38.250: INFO: observed event type MODIFIED
    Nov  5 12:38:38.250: INFO: observed event type MODIFIED
    Nov  5 12:38:38.250: INFO: observed event type MODIFIED
    Nov  5 12:38:38.250: INFO: observed event type MODIFIED
    Nov  5 12:38:38.250: INFO: observed event type MODIFIED
    Nov  5 12:38:38.250: INFO: observed event type MODIFIED
    Nov  5 12:38:38.250: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov  5 12:38:38.254: INFO: Log out all the ReplicaSets if there is no deployment created
    Nov  5 12:38:38.258: INFO: ReplicaSet "test-deployment-7c7d8d58c8":
    &ReplicaSet{ObjectMeta:{test-deployment-7c7d8d58c8  deployment-2904  d219c2d5-0c77-4e12-ad54-57374a43635f 20953 2 2022-11-05 12:38:35 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:3] [{apps/v1 Deployment test-deployment 18b19386-e12c-475b-8755-786e0dd9e1fe 0xc004aa1577 0xc004aa1578}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:38:36 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"18b19386-e12c-475b-8755-786e0dd9e1fe\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:38:38 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 7c7d8d58c8,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004aa1600 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:2,AvailableReplicas:2,Conditions:[]ReplicaSetCondition{},},}

    Nov  5 12:38:38.264: INFO: pod: "test-deployment-7c7d8d58c8-5tb7r":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-5tb7r test-deployment-7c7d8d58c8- deployment-2904  73ebeac9-f85c-4124-b38a-d22f6ee27c9c 20952 0 2022-11-05 12:38:36 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 d219c2d5-0c77-4e12-ad54-57374a43635f 0xc004aa1997 0xc004aa1998}] [] [{kube-controller-manager Update v1 2022-11-05 12:38:36 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d219c2d5-0c77-4e12-ad54-57374a43635f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:38:38 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.95\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-t4vc8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-t4vc8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.95,StartTime:2022-11-05 12:38:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:38:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5dc891f3272993caaed7bf32849f9ca46264453d8b8e930cb94bb062cba58093,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Nov  5 12:38:38.264: INFO: pod: "test-deployment-7c7d8d58c8-tjxb6":
    &Pod{ObjectMeta:{test-deployment-7c7d8d58c8-tjxb6 test-deployment-7c7d8d58c8- deployment-2904  fe32c530-80d1-48d0-b74c-446129c08d9e 20904 0 2022-11-05 12:38:35 +0000 UTC <nil> <nil> map[pod-template-hash:7c7d8d58c8 test-deployment-static:true] map[] [{apps/v1 ReplicaSet test-deployment-7c7d8d58c8 d219c2d5-0c77-4e12-ad54-57374a43635f 0xc004aa1ba7 0xc004aa1ba8}] [] [{kube-controller-manager Update v1 2022-11-05 12:38:35 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"d219c2d5-0c77-4e12-ad54-57374a43635f\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:38:36 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.171\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-75q8z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:test-deployment,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-75q8z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*1,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.171,StartTime:2022-11-05 12:38:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:test-deployment,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:38:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://855288df90fa3d56fa1919ea2bb17aea8c5f64f8cabf5f51a31031d9bd23038d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.171,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

    Nov  5 12:38:38.265: INFO: ReplicaSet "test-deployment-8594bb6fdd":
    &ReplicaSet{ObjectMeta:{test-deployment-8594bb6fdd  deployment-2904  20ceaf5a-22b3-4d4c-9785-a148c32a51aa 20847 3 2022-11-05 12:38:31 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment 18b19386-e12c-475b-8755-786e0dd9e1fe 0xc004aa1667 0xc004aa1668}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:38:35 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"18b19386-e12c-475b-8755-786e0dd9e1fe\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:pod-template-hash":{},"f:test-deployment-static":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"test-deployment\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:38:35 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{pod-template-hash: 8594bb6fdd,test-deployment-static: true,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[pod-template-hash:8594bb6fdd test-deployment-static:true] map[] [] [] []} {[] [] [{test-deployment registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc004aa16f0 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}

    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov  5 12:38:38.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-2904" for this suite. 11/05/22 12:38:38.274
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:38.284
Nov  5 12:38:38.284: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename deployment 11/05/22 12:38:38.285
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:38.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:38.305
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Nov  5 12:38:38.309: INFO: Creating deployment "test-recreate-deployment"
Nov  5 12:38:38.315: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov  5 12:38:38.323: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov  5 12:38:40.332: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov  5 12:38:40.335: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 38, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 38, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 38, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 38, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:38:42.340: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov  5 12:38:42.351: INFO: Updating deployment test-recreate-deployment
Nov  5 12:38:42.351: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov  5 12:38:42.450: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-4340  0cf28b3e-88da-4d89-b753-b2407686cf03 21049 2 2022-11-05 12:38:38 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0022f0438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-05 12:38:42 +0000 UTC,LastTransitionTime:2022-11-05 12:38:42 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-11-05 12:38:42 +0000 UTC,LastTransitionTime:2022-11-05 12:38:38 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov  5 12:38:42.454: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-4340  7c91f94d-85ad-4264-b9e4-b934647d193e 21047 1 2022-11-05 12:38:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 0cf28b3e-88da-4d89-b753-b2407686cf03 0xc0022f0930 0xc0022f0931}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0cf28b3e-88da-4d89-b753-b2407686cf03\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0022f09c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  5 12:38:42.454: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov  5 12:38:42.454: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-4340  a519fa47-f7d4-4dbe-b620-5cb24f209039 21037 2 2022-11-05 12:38:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 0cf28b3e-88da-4d89-b753-b2407686cf03 0xc0022f0807 0xc0022f0808}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0cf28b3e-88da-4d89-b753-b2407686cf03\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0022f08b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  5 12:38:42.458: INFO: Pod "test-recreate-deployment-9d58999df-4659r" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-4659r test-recreate-deployment-9d58999df- deployment-4340  4388a37c-f7ad-48ba-9e2b-b3f015f1adee 21048 0 2022-11-05 12:38:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 7c91f94d-85ad-4264-b9e4-b934647d193e 0xc002b4d500 0xc002b4d501}] [] [{kube-controller-manager Update v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c91f94d-85ad-4264-b9e4-b934647d193e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hglpm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hglpm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:,StartTime:2022-11-05 12:38:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov  5 12:38:42.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4340" for this suite. 11/05/22 12:38:42.461
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":172,"skipped":3114,"failed":0}
------------------------------
• [4.183 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:38.284
    Nov  5 12:38:38.284: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename deployment 11/05/22 12:38:38.285
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:38.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:38.305
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Nov  5 12:38:38.309: INFO: Creating deployment "test-recreate-deployment"
    Nov  5 12:38:38.315: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Nov  5 12:38:38.323: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Nov  5 12:38:40.332: INFO: Waiting deployment "test-recreate-deployment" to complete
    Nov  5 12:38:40.335: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 38, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 38, 38, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 38, 38, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 38, 38, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-7d8b6f647f\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:38:42.340: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Nov  5 12:38:42.351: INFO: Updating deployment test-recreate-deployment
    Nov  5 12:38:42.351: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov  5 12:38:42.450: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-4340  0cf28b3e-88da-4d89-b753-b2407686cf03 21049 2 2022-11-05 12:38:38 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0022f0438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2022-11-05 12:38:42 +0000 UTC,LastTransitionTime:2022-11-05 12:38:42 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2022-11-05 12:38:42 +0000 UTC,LastTransitionTime:2022-11-05 12:38:38 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Nov  5 12:38:42.454: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-4340  7c91f94d-85ad-4264-b9e4-b934647d193e 21047 1 2022-11-05 12:38:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 0cf28b3e-88da-4d89-b753-b2407686cf03 0xc0022f0930 0xc0022f0931}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0cf28b3e-88da-4d89-b753-b2407686cf03\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0022f09c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 12:38:42.454: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Nov  5 12:38:42.454: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-4340  a519fa47-f7d4-4dbe-b620-5cb24f209039 21037 2 2022-11-05 12:38:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 0cf28b3e-88da-4d89-b753-b2407686cf03 0xc0022f0807 0xc0022f0808}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"0cf28b3e-88da-4d89-b753-b2407686cf03\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0022f08b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 12:38:42.458: INFO: Pod "test-recreate-deployment-9d58999df-4659r" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-4659r test-recreate-deployment-9d58999df- deployment-4340  4388a37c-f7ad-48ba-9e2b-b3f015f1adee 21048 0 2022-11-05 12:38:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df 7c91f94d-85ad-4264-b9e4-b934647d193e 0xc002b4d500 0xc002b4d501}] [] [{kube-controller-manager Update v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"7c91f94d-85ad-4264-b9e4-b934647d193e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:38:42 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hglpm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hglpm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:38:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:,StartTime:2022-11-05 12:38:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov  5 12:38:42.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-4340" for this suite. 11/05/22 12:38:42.461
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:42.47
Nov  5 12:38:42.470: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 12:38:42.471
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:42.491
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:42.495
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-f414f811-5d33-4aa2-9743-88691ed1ecde 11/05/22 12:38:42.498
STEP: Creating a pod to test consume secrets 11/05/22 12:38:42.503
Nov  5 12:38:42.511: INFO: Waiting up to 5m0s for pod "pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca" in namespace "secrets-3986" to be "Succeeded or Failed"
Nov  5 12:38:42.517: INFO: Pod "pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca": Phase="Pending", Reason="", readiness=false. Elapsed: 5.581222ms
Nov  5 12:38:44.521: INFO: Pod "pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010139775s
Nov  5 12:38:46.521: INFO: Pod "pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00984135s
STEP: Saw pod success 11/05/22 12:38:46.521
Nov  5 12:38:46.521: INFO: Pod "pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca" satisfied condition "Succeeded or Failed"
Nov  5 12:38:46.525: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca container secret-volume-test: <nil>
STEP: delete the pod 11/05/22 12:38:46.531
Nov  5 12:38:46.543: INFO: Waiting for pod pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca to disappear
Nov  5 12:38:46.547: INFO: Pod pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov  5 12:38:46.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3986" for this suite. 11/05/22 12:38:46.551
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":173,"skipped":3126,"failed":0}
------------------------------
• [4.087 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:42.47
    Nov  5 12:38:42.470: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 12:38:42.471
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:42.491
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:42.495
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-f414f811-5d33-4aa2-9743-88691ed1ecde 11/05/22 12:38:42.498
    STEP: Creating a pod to test consume secrets 11/05/22 12:38:42.503
    Nov  5 12:38:42.511: INFO: Waiting up to 5m0s for pod "pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca" in namespace "secrets-3986" to be "Succeeded or Failed"
    Nov  5 12:38:42.517: INFO: Pod "pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca": Phase="Pending", Reason="", readiness=false. Elapsed: 5.581222ms
    Nov  5 12:38:44.521: INFO: Pod "pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010139775s
    Nov  5 12:38:46.521: INFO: Pod "pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00984135s
    STEP: Saw pod success 11/05/22 12:38:46.521
    Nov  5 12:38:46.521: INFO: Pod "pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca" satisfied condition "Succeeded or Failed"
    Nov  5 12:38:46.525: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca container secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 12:38:46.531
    Nov  5 12:38:46.543: INFO: Waiting for pod pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca to disappear
    Nov  5 12:38:46.547: INFO: Pod pod-secrets-e8880837-72ae-4729-b371-beb9e6d798ca no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 12:38:46.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3986" for this suite. 11/05/22 12:38:46.551
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:46.559
Nov  5 12:38:46.560: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sched-pred 11/05/22 12:38:46.56
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:46.573
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:46.578
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov  5 12:38:46.582: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  5 12:38:46.591: INFO: Waiting for terminating namespaces to be deleted...
Nov  5 12:38:46.594: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-0-255 before test
Nov  5 12:38:46.599: INFO: test-recreate-deployment-9d58999df-4659r from deployment-4340 started at 2022-11-05 12:38:42 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.599: INFO: 	Container httpd ready: false, restart count 0
Nov  5 12:38:46.599: INFO: nginx-ingress-controller-kubernetes-worker-v9666 from ingress-nginx-kubernetes-worker started at 2022-11-05 12:07:51 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.599: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 12:38:46.599: INFO: sonobuoy from sonobuoy started at 2022-11-05 11:55:13 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.599: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  5 12:38:46.599: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 12:38:46.599: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:38:46.599: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 12:38:46.599: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-27-199 before test
Nov  5 12:38:46.604: INFO: default-http-backend-kubernetes-worker-6546b9855c-tdc5h from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.604: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov  5 12:38:46.604: INFO: nginx-ingress-controller-kubernetes-worker-l6972 from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.604: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 12:38:46.604: INFO: calico-kube-controllers-b5bd6849d-zg9jq from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.604: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  5 12:38:46.604: INFO: coredns-6bcf44f4cc-ddkx4 from kube-system started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.604: INFO: 	Container coredns ready: true, restart count 0
Nov  5 12:38:46.604: INFO: kube-state-metrics-74f5d549cc-cc4bl from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.604: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov  5 12:38:46.604: INFO: metrics-server-v0.5.2-6b48dc6f97-cp95w from kube-system started at 2022-11-05 11:49:10 +0000 UTC (2 container statuses recorded)
Nov  5 12:38:46.604: INFO: 	Container metrics-server ready: true, restart count 1
Nov  5 12:38:46.604: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov  5 12:38:46.604: INFO: dashboard-metrics-scraper-85d45476c6-4v4zk from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.604: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  5 12:38:46.604: INFO: kubernetes-dashboard-7fb574cb-6lhg6 from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.604: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Nov  5 12:38:46.604: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-w6fxs from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 12:38:46.604: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:38:46.604: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 12:38:46.604: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-41-19 before test
Nov  5 12:38:46.609: INFO: nginx-ingress-controller-kubernetes-worker-879hx from ingress-nginx-kubernetes-worker started at 2022-11-05 11:50:52 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:46.609: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 12:38:46.609: INFO: sonobuoy-e2e-job-b878a59025e244cf from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 12:38:46.609: INFO: 	Container e2e ready: true, restart count 0
Nov  5 12:38:46.609: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:38:46.609: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-zjsjg from sonobuoy started at 2022-11-05 11:55:17 +0000 UTC (2 container statuses recorded)
Nov  5 12:38:46.609: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:38:46.609: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node ip-172-31-0-255 11/05/22 12:38:46.623
STEP: verifying the node has the label node ip-172-31-27-199 11/05/22 12:38:46.636
STEP: verifying the node has the label node ip-172-31-41-19 11/05/22 12:38:46.651
Nov  5 12:38:46.661: INFO: Pod test-recreate-deployment-9d58999df-4659r requesting resource cpu=0m on Node ip-172-31-0-255
Nov  5 12:38:46.661: INFO: Pod default-http-backend-kubernetes-worker-6546b9855c-tdc5h requesting resource cpu=10m on Node ip-172-31-27-199
Nov  5 12:38:46.661: INFO: Pod nginx-ingress-controller-kubernetes-worker-879hx requesting resource cpu=0m on Node ip-172-31-41-19
Nov  5 12:38:46.661: INFO: Pod nginx-ingress-controller-kubernetes-worker-l6972 requesting resource cpu=0m on Node ip-172-31-27-199
Nov  5 12:38:46.661: INFO: Pod nginx-ingress-controller-kubernetes-worker-v9666 requesting resource cpu=0m on Node ip-172-31-0-255
Nov  5 12:38:46.661: INFO: Pod calico-kube-controllers-b5bd6849d-zg9jq requesting resource cpu=0m on Node ip-172-31-27-199
Nov  5 12:38:46.661: INFO: Pod coredns-6bcf44f4cc-ddkx4 requesting resource cpu=100m on Node ip-172-31-27-199
Nov  5 12:38:46.661: INFO: Pod kube-state-metrics-74f5d549cc-cc4bl requesting resource cpu=0m on Node ip-172-31-27-199
Nov  5 12:38:46.661: INFO: Pod metrics-server-v0.5.2-6b48dc6f97-cp95w requesting resource cpu=5m on Node ip-172-31-27-199
Nov  5 12:38:46.661: INFO: Pod dashboard-metrics-scraper-85d45476c6-4v4zk requesting resource cpu=0m on Node ip-172-31-27-199
Nov  5 12:38:46.661: INFO: Pod kubernetes-dashboard-7fb574cb-6lhg6 requesting resource cpu=0m on Node ip-172-31-27-199
Nov  5 12:38:46.661: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-0-255
Nov  5 12:38:46.661: INFO: Pod sonobuoy-e2e-job-b878a59025e244cf requesting resource cpu=0m on Node ip-172-31-41-19
Nov  5 12:38:46.661: INFO: Pod sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl requesting resource cpu=0m on Node ip-172-31-0-255
Nov  5 12:38:46.661: INFO: Pod sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-w6fxs requesting resource cpu=0m on Node ip-172-31-27-199
Nov  5 12:38:46.661: INFO: Pod sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-zjsjg requesting resource cpu=0m on Node ip-172-31-41-19
STEP: Starting Pods to consume most of the cluster CPU. 11/05/22 12:38:46.661
Nov  5 12:38:46.661: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-0-255
Nov  5 12:38:46.669: INFO: Creating a pod which consumes cpu=1319m on Node ip-172-31-27-199
Nov  5 12:38:46.677: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-41-19
Nov  5 12:38:46.686: INFO: Waiting up to 5m0s for pod "filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b" in namespace "sched-pred-5810" to be "running"
Nov  5 12:38:46.693: INFO: Pod "filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.624464ms
Nov  5 12:38:48.698: INFO: Pod "filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b": Phase="Running", Reason="", readiness=true. Elapsed: 2.011911857s
Nov  5 12:38:48.698: INFO: Pod "filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b" satisfied condition "running"
Nov  5 12:38:48.698: INFO: Waiting up to 5m0s for pod "filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea" in namespace "sched-pred-5810" to be "running"
Nov  5 12:38:48.701: INFO: Pod "filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea": Phase="Running", Reason="", readiness=true. Elapsed: 3.660508ms
Nov  5 12:38:48.701: INFO: Pod "filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea" satisfied condition "running"
Nov  5 12:38:48.701: INFO: Waiting up to 5m0s for pod "filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea" in namespace "sched-pred-5810" to be "running"
Nov  5 12:38:48.705: INFO: Pod "filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea": Phase="Running", Reason="", readiness=true. Elapsed: 3.21277ms
Nov  5 12:38:48.705: INFO: Pod "filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 11/05/22 12:38:48.705
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea.1724b0977ba27422], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5810/filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea to ip-172-31-27-199] 11/05/22 12:38:48.709
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea.1724b097a6cc6934], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/05/22 12:38:48.709
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea.1724b097a9e68032], Reason = [Created], Message = [Created container filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea] 11/05/22 12:38:48.709
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea.1724b097ae98707e], Reason = [Started], Message = [Started container filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea] 11/05/22 12:38:48.709
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea.1724b0977c0c278b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5810/filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea to ip-172-31-41-19] 11/05/22 12:38:48.709
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea.1724b097a7214e2c], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/05/22 12:38:48.709
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea.1724b097a9ee535b], Reason = [Created], Message = [Created container filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea] 11/05/22 12:38:48.709
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea.1724b097ae5ae0c3], Reason = [Started], Message = [Started container filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea] 11/05/22 12:38:48.71
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b.1724b0977b23c03a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5810/filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b to ip-172-31-0-255] 11/05/22 12:38:48.71
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b.1724b097a4c88b5e], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/05/22 12:38:48.71
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b.1724b097a76831a4], Reason = [Created], Message = [Created container filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b] 11/05/22 12:38:48.71
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b.1724b097abf763ae], Reason = [Started], Message = [Started container filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b] 11/05/22 12:38:48.711
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1724b097f4c1f90a], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] 11/05/22 12:38:48.727
STEP: removing the label node off the node ip-172-31-41-19 11/05/22 12:38:49.722
STEP: verifying the node doesn't have the label node 11/05/22 12:38:49.734
STEP: removing the label node off the node ip-172-31-0-255 11/05/22 12:38:49.74
STEP: verifying the node doesn't have the label node 11/05/22 12:38:49.754
STEP: removing the label node off the node ip-172-31-27-199 11/05/22 12:38:49.765
STEP: verifying the node doesn't have the label node 11/05/22 12:38:49.777
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:38:49.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5810" for this suite. 11/05/22 12:38:49.787
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":174,"skipped":3155,"failed":0}
------------------------------
• [3.234 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:46.559
    Nov  5 12:38:46.560: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sched-pred 11/05/22 12:38:46.56
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:46.573
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:46.578
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov  5 12:38:46.582: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov  5 12:38:46.591: INFO: Waiting for terminating namespaces to be deleted...
    Nov  5 12:38:46.594: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-0-255 before test
    Nov  5 12:38:46.599: INFO: test-recreate-deployment-9d58999df-4659r from deployment-4340 started at 2022-11-05 12:38:42 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.599: INFO: 	Container httpd ready: false, restart count 0
    Nov  5 12:38:46.599: INFO: nginx-ingress-controller-kubernetes-worker-v9666 from ingress-nginx-kubernetes-worker started at 2022-11-05 12:07:51 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.599: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 12:38:46.599: INFO: sonobuoy from sonobuoy started at 2022-11-05 11:55:13 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.599: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov  5 12:38:46.599: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 12:38:46.599: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:38:46.599: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov  5 12:38:46.599: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-27-199 before test
    Nov  5 12:38:46.604: INFO: default-http-backend-kubernetes-worker-6546b9855c-tdc5h from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.604: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov  5 12:38:46.604: INFO: nginx-ingress-controller-kubernetes-worker-l6972 from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.604: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 12:38:46.604: INFO: calico-kube-controllers-b5bd6849d-zg9jq from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.604: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov  5 12:38:46.604: INFO: coredns-6bcf44f4cc-ddkx4 from kube-system started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.604: INFO: 	Container coredns ready: true, restart count 0
    Nov  5 12:38:46.604: INFO: kube-state-metrics-74f5d549cc-cc4bl from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.604: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov  5 12:38:46.604: INFO: metrics-server-v0.5.2-6b48dc6f97-cp95w from kube-system started at 2022-11-05 11:49:10 +0000 UTC (2 container statuses recorded)
    Nov  5 12:38:46.604: INFO: 	Container metrics-server ready: true, restart count 1
    Nov  5 12:38:46.604: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov  5 12:38:46.604: INFO: dashboard-metrics-scraper-85d45476c6-4v4zk from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.604: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov  5 12:38:46.604: INFO: kubernetes-dashboard-7fb574cb-6lhg6 from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.604: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
    Nov  5 12:38:46.604: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-w6fxs from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 12:38:46.604: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:38:46.604: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov  5 12:38:46.604: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-41-19 before test
    Nov  5 12:38:46.609: INFO: nginx-ingress-controller-kubernetes-worker-879hx from ingress-nginx-kubernetes-worker started at 2022-11-05 11:50:52 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:46.609: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 12:38:46.609: INFO: sonobuoy-e2e-job-b878a59025e244cf from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 12:38:46.609: INFO: 	Container e2e ready: true, restart count 0
    Nov  5 12:38:46.609: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:38:46.609: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-zjsjg from sonobuoy started at 2022-11-05 11:55:17 +0000 UTC (2 container statuses recorded)
    Nov  5 12:38:46.609: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:38:46.609: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node ip-172-31-0-255 11/05/22 12:38:46.623
    STEP: verifying the node has the label node ip-172-31-27-199 11/05/22 12:38:46.636
    STEP: verifying the node has the label node ip-172-31-41-19 11/05/22 12:38:46.651
    Nov  5 12:38:46.661: INFO: Pod test-recreate-deployment-9d58999df-4659r requesting resource cpu=0m on Node ip-172-31-0-255
    Nov  5 12:38:46.661: INFO: Pod default-http-backend-kubernetes-worker-6546b9855c-tdc5h requesting resource cpu=10m on Node ip-172-31-27-199
    Nov  5 12:38:46.661: INFO: Pod nginx-ingress-controller-kubernetes-worker-879hx requesting resource cpu=0m on Node ip-172-31-41-19
    Nov  5 12:38:46.661: INFO: Pod nginx-ingress-controller-kubernetes-worker-l6972 requesting resource cpu=0m on Node ip-172-31-27-199
    Nov  5 12:38:46.661: INFO: Pod nginx-ingress-controller-kubernetes-worker-v9666 requesting resource cpu=0m on Node ip-172-31-0-255
    Nov  5 12:38:46.661: INFO: Pod calico-kube-controllers-b5bd6849d-zg9jq requesting resource cpu=0m on Node ip-172-31-27-199
    Nov  5 12:38:46.661: INFO: Pod coredns-6bcf44f4cc-ddkx4 requesting resource cpu=100m on Node ip-172-31-27-199
    Nov  5 12:38:46.661: INFO: Pod kube-state-metrics-74f5d549cc-cc4bl requesting resource cpu=0m on Node ip-172-31-27-199
    Nov  5 12:38:46.661: INFO: Pod metrics-server-v0.5.2-6b48dc6f97-cp95w requesting resource cpu=5m on Node ip-172-31-27-199
    Nov  5 12:38:46.661: INFO: Pod dashboard-metrics-scraper-85d45476c6-4v4zk requesting resource cpu=0m on Node ip-172-31-27-199
    Nov  5 12:38:46.661: INFO: Pod kubernetes-dashboard-7fb574cb-6lhg6 requesting resource cpu=0m on Node ip-172-31-27-199
    Nov  5 12:38:46.661: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-172-31-0-255
    Nov  5 12:38:46.661: INFO: Pod sonobuoy-e2e-job-b878a59025e244cf requesting resource cpu=0m on Node ip-172-31-41-19
    Nov  5 12:38:46.661: INFO: Pod sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl requesting resource cpu=0m on Node ip-172-31-0-255
    Nov  5 12:38:46.661: INFO: Pod sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-w6fxs requesting resource cpu=0m on Node ip-172-31-27-199
    Nov  5 12:38:46.661: INFO: Pod sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-zjsjg requesting resource cpu=0m on Node ip-172-31-41-19
    STEP: Starting Pods to consume most of the cluster CPU. 11/05/22 12:38:46.661
    Nov  5 12:38:46.661: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-0-255
    Nov  5 12:38:46.669: INFO: Creating a pod which consumes cpu=1319m on Node ip-172-31-27-199
    Nov  5 12:38:46.677: INFO: Creating a pod which consumes cpu=1400m on Node ip-172-31-41-19
    Nov  5 12:38:46.686: INFO: Waiting up to 5m0s for pod "filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b" in namespace "sched-pred-5810" to be "running"
    Nov  5 12:38:46.693: INFO: Pod "filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.624464ms
    Nov  5 12:38:48.698: INFO: Pod "filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b": Phase="Running", Reason="", readiness=true. Elapsed: 2.011911857s
    Nov  5 12:38:48.698: INFO: Pod "filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b" satisfied condition "running"
    Nov  5 12:38:48.698: INFO: Waiting up to 5m0s for pod "filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea" in namespace "sched-pred-5810" to be "running"
    Nov  5 12:38:48.701: INFO: Pod "filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea": Phase="Running", Reason="", readiness=true. Elapsed: 3.660508ms
    Nov  5 12:38:48.701: INFO: Pod "filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea" satisfied condition "running"
    Nov  5 12:38:48.701: INFO: Waiting up to 5m0s for pod "filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea" in namespace "sched-pred-5810" to be "running"
    Nov  5 12:38:48.705: INFO: Pod "filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea": Phase="Running", Reason="", readiness=true. Elapsed: 3.21277ms
    Nov  5 12:38:48.705: INFO: Pod "filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 11/05/22 12:38:48.705
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea.1724b0977ba27422], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5810/filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea to ip-172-31-27-199] 11/05/22 12:38:48.709
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea.1724b097a6cc6934], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/05/22 12:38:48.709
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea.1724b097a9e68032], Reason = [Created], Message = [Created container filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea] 11/05/22 12:38:48.709
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea.1724b097ae98707e], Reason = [Started], Message = [Started container filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea] 11/05/22 12:38:48.709
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea.1724b0977c0c278b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5810/filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea to ip-172-31-41-19] 11/05/22 12:38:48.709
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea.1724b097a7214e2c], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/05/22 12:38:48.709
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea.1724b097a9ee535b], Reason = [Created], Message = [Created container filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea] 11/05/22 12:38:48.709
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea.1724b097ae5ae0c3], Reason = [Started], Message = [Started container filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea] 11/05/22 12:38:48.71
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b.1724b0977b23c03a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-5810/filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b to ip-172-31-0-255] 11/05/22 12:38:48.71
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b.1724b097a4c88b5e], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 11/05/22 12:38:48.71
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b.1724b097a76831a4], Reason = [Created], Message = [Created container filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b] 11/05/22 12:38:48.71
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b.1724b097abf763ae], Reason = [Started], Message = [Started container filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b] 11/05/22 12:38:48.711
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.1724b097f4c1f90a], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }, 3 Insufficient cpu. preemption: 0/5 nodes are available: 2 Preemption is not helpful for scheduling, 3 No preemption victims found for incoming pod.] 11/05/22 12:38:48.727
    STEP: removing the label node off the node ip-172-31-41-19 11/05/22 12:38:49.722
    STEP: verifying the node doesn't have the label node 11/05/22 12:38:49.734
    STEP: removing the label node off the node ip-172-31-0-255 11/05/22 12:38:49.74
    STEP: verifying the node doesn't have the label node 11/05/22 12:38:49.754
    STEP: removing the label node off the node ip-172-31-27-199 11/05/22 12:38:49.765
    STEP: verifying the node doesn't have the label node 11/05/22 12:38:49.777
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:38:49.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-5810" for this suite. 11/05/22 12:38:49.787
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:38:49.794
Nov  5 12:38:49.794: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sched-pred 11/05/22 12:38:49.795
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:49.807
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:49.811
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov  5 12:38:49.815: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  5 12:38:49.822: INFO: Waiting for terminating namespaces to be deleted...
Nov  5 12:38:49.826: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-0-255 before test
Nov  5 12:38:49.830: INFO: nginx-ingress-controller-kubernetes-worker-v9666 from ingress-nginx-kubernetes-worker started at 2022-11-05 12:07:51 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.830: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 12:38:49.830: INFO: filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b from sched-pred-5810 started at 2022-11-05 12:38:46 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.830: INFO: 	Container filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b ready: true, restart count 0
Nov  5 12:38:49.830: INFO: sonobuoy from sonobuoy started at 2022-11-05 11:55:13 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.830: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  5 12:38:49.830: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 12:38:49.830: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:38:49.830: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 12:38:49.830: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-27-199 before test
Nov  5 12:38:49.836: INFO: default-http-backend-kubernetes-worker-6546b9855c-tdc5h from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.836: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov  5 12:38:49.836: INFO: nginx-ingress-controller-kubernetes-worker-l6972 from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.836: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 12:38:49.836: INFO: calico-kube-controllers-b5bd6849d-zg9jq from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.836: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  5 12:38:49.836: INFO: coredns-6bcf44f4cc-ddkx4 from kube-system started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.836: INFO: 	Container coredns ready: true, restart count 0
Nov  5 12:38:49.836: INFO: kube-state-metrics-74f5d549cc-cc4bl from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.836: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov  5 12:38:49.836: INFO: metrics-server-v0.5.2-6b48dc6f97-cp95w from kube-system started at 2022-11-05 11:49:10 +0000 UTC (2 container statuses recorded)
Nov  5 12:38:49.836: INFO: 	Container metrics-server ready: true, restart count 1
Nov  5 12:38:49.836: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov  5 12:38:49.836: INFO: dashboard-metrics-scraper-85d45476c6-4v4zk from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.836: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  5 12:38:49.836: INFO: kubernetes-dashboard-7fb574cb-6lhg6 from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.836: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Nov  5 12:38:49.836: INFO: filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea from sched-pred-5810 started at 2022-11-05 12:38:46 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.836: INFO: 	Container filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea ready: true, restart count 0
Nov  5 12:38:49.836: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-w6fxs from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 12:38:49.836: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:38:49.836: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 12:38:49.836: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-41-19 before test
Nov  5 12:38:49.841: INFO: nginx-ingress-controller-kubernetes-worker-879hx from ingress-nginx-kubernetes-worker started at 2022-11-05 11:50:52 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.841: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 12:38:49.841: INFO: filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea from sched-pred-5810 started at 2022-11-05 12:38:46 +0000 UTC (1 container statuses recorded)
Nov  5 12:38:49.841: INFO: 	Container filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea ready: true, restart count 0
Nov  5 12:38:49.841: INFO: sonobuoy-e2e-job-b878a59025e244cf from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 12:38:49.841: INFO: 	Container e2e ready: true, restart count 0
Nov  5 12:38:49.841: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:38:49.841: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-zjsjg from sonobuoy started at 2022-11-05 11:55:17 +0000 UTC (2 container statuses recorded)
Nov  5 12:38:49.841: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 12:38:49.841: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/05/22 12:38:49.841
Nov  5 12:38:49.849: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-3918" to be "running"
Nov  5 12:38:49.855: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 6.731242ms
Nov  5 12:38:51.860: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.011252289s
Nov  5 12:38:51.860: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/05/22 12:38:51.864
STEP: Trying to apply a random label on the found node. 11/05/22 12:38:51.884
STEP: verifying the node has the label kubernetes.io/e2e-429d5dc2-4148-412d-a7eb-2607c18924e4 95 11/05/22 12:38:51.891
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 11/05/22 12:38:51.895
Nov  5 12:38:51.900: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-3918" to be "not pending"
Nov  5 12:38:51.903: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.281948ms
Nov  5 12:38:53.908: INFO: Pod "pod4": Phase="Running", Reason="", readiness=false. Elapsed: 2.008054198s
Nov  5 12:38:53.908: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.0.255 on the node which pod4 resides and expect not scheduled 11/05/22 12:38:53.908
Nov  5 12:38:53.914: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-3918" to be "not pending"
Nov  5 12:38:53.924: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.436386ms
Nov  5 12:38:55.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013439604s
Nov  5 12:38:57.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013574763s
Nov  5 12:38:59.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013253408s
Nov  5 12:39:01.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013865047s
Nov  5 12:39:03.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.013232359s
Nov  5 12:39:05.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014387456s
Nov  5 12:39:07.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.013903543s
Nov  5 12:39:09.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.013696346s
Nov  5 12:39:11.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.013764725s
Nov  5 12:39:13.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.013176375s
Nov  5 12:39:15.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.014314342s
Nov  5 12:39:17.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.013776626s
Nov  5 12:39:19.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.014396518s
Nov  5 12:39:21.930: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.015553868s
Nov  5 12:39:23.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.014434867s
Nov  5 12:39:25.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.013930626s
Nov  5 12:39:27.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.014327225s
Nov  5 12:39:29.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.01425956s
Nov  5 12:39:31.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.01367338s
Nov  5 12:39:33.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.013644394s
Nov  5 12:39:35.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.014444211s
Nov  5 12:39:37.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.014169973s
Nov  5 12:39:39.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.01376614s
Nov  5 12:39:41.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.014279734s
Nov  5 12:39:43.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.013794784s
Nov  5 12:39:45.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.01398013s
Nov  5 12:39:47.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.013934696s
Nov  5 12:39:49.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.014195059s
Nov  5 12:39:51.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.013798857s
Nov  5 12:39:53.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.01413534s
Nov  5 12:39:55.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.013653228s
Nov  5 12:39:57.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.01483843s
Nov  5 12:39:59.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.013500498s
Nov  5 12:40:01.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.013608758s
Nov  5 12:40:03.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.013919145s
Nov  5 12:40:05.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.014135494s
Nov  5 12:40:07.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.013408494s
Nov  5 12:40:09.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.013582453s
Nov  5 12:40:11.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.013426311s
Nov  5 12:40:13.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.013593258s
Nov  5 12:40:15.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.013857187s
Nov  5 12:40:17.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.013924773s
Nov  5 12:40:19.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.014271373s
Nov  5 12:40:21.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.013515617s
Nov  5 12:40:23.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013948678s
Nov  5 12:40:25.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.014326114s
Nov  5 12:40:27.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.013652085s
Nov  5 12:40:29.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.013946001s
Nov  5 12:40:31.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.013991778s
Nov  5 12:40:33.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.013782125s
Nov  5 12:40:35.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.014330276s
Nov  5 12:40:37.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.014920953s
Nov  5 12:40:39.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.014374824s
Nov  5 12:40:41.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.013689158s
Nov  5 12:40:43.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.013648384s
Nov  5 12:40:45.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.013527202s
Nov  5 12:40:47.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.013419952s
Nov  5 12:40:49.930: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.015464364s
Nov  5 12:40:51.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.013306525s
Nov  5 12:40:53.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.013506517s
Nov  5 12:40:55.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.01376741s
Nov  5 12:40:57.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.013884481s
Nov  5 12:40:59.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.014094562s
Nov  5 12:41:01.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.013825133s
Nov  5 12:41:03.932: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.017985039s
Nov  5 12:41:05.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.013976474s
Nov  5 12:41:07.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.01506006s
Nov  5 12:41:09.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.014641421s
Nov  5 12:41:11.930: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.01526676s
Nov  5 12:41:13.937: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.022275536s
Nov  5 12:41:15.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.013854476s
Nov  5 12:41:17.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.013937338s
Nov  5 12:41:19.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.013767592s
Nov  5 12:41:21.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.014462973s
Nov  5 12:41:23.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.013599413s
Nov  5 12:41:25.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.014355506s
Nov  5 12:41:27.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.0137445s
Nov  5 12:41:29.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.013898126s
Nov  5 12:41:31.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.013879378s
Nov  5 12:41:33.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.013336053s
Nov  5 12:41:35.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.014776041s
Nov  5 12:41:37.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.013808039s
Nov  5 12:41:39.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.014103656s
Nov  5 12:41:41.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.013335614s
Nov  5 12:41:43.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.013567462s
Nov  5 12:41:45.937: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.022138851s
Nov  5 12:41:47.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.014129799s
Nov  5 12:41:49.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.014901922s
Nov  5 12:41:51.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.013869321s
Nov  5 12:41:53.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.014410278s
Nov  5 12:41:55.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.014125581s
Nov  5 12:41:57.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.013300032s
Nov  5 12:41:59.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.014804314s
Nov  5 12:42:01.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.014077816s
Nov  5 12:42:03.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.01487324s
Nov  5 12:42:05.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.014003825s
Nov  5 12:42:07.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.014337481s
Nov  5 12:42:09.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.014450077s
Nov  5 12:42:11.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.01328753s
Nov  5 12:42:13.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.013760038s
Nov  5 12:42:15.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.013899786s
Nov  5 12:42:17.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.014382766s
Nov  5 12:42:19.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.013753732s
Nov  5 12:42:21.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.013332897s
Nov  5 12:42:23.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.014590966s
Nov  5 12:42:25.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.013715121s
Nov  5 12:42:27.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.014368264s
Nov  5 12:42:29.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.014646629s
Nov  5 12:42:31.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.013449117s
Nov  5 12:42:33.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.01436676s
Nov  5 12:42:35.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.013900209s
Nov  5 12:42:37.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.014302281s
Nov  5 12:42:39.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.013592422s
Nov  5 12:42:41.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.014231701s
Nov  5 12:42:43.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.013348835s
Nov  5 12:42:45.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.013838861s
Nov  5 12:42:47.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.013740302s
Nov  5 12:42:49.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.013746823s
Nov  5 12:42:51.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.013997649s
Nov  5 12:42:53.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.014310069s
Nov  5 12:42:55.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.01369599s
Nov  5 12:42:57.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.013389542s
Nov  5 12:42:59.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.014221726s
Nov  5 12:43:01.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.014683888s
Nov  5 12:43:03.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.013380622s
Nov  5 12:43:05.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.013620349s
Nov  5 12:43:07.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.013407626s
Nov  5 12:43:09.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.013564771s
Nov  5 12:43:11.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.014278793s
Nov  5 12:43:13.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.013929133s
Nov  5 12:43:15.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.013437504s
Nov  5 12:43:17.930: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.015380127s
Nov  5 12:43:19.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.013993339s
Nov  5 12:43:21.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.013317614s
Nov  5 12:43:23.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.013553358s
Nov  5 12:43:25.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.014432724s
Nov  5 12:43:27.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.014226841s
Nov  5 12:43:29.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.013965302s
Nov  5 12:43:31.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.014445559s
Nov  5 12:43:33.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.014076229s
Nov  5 12:43:35.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.014280166s
Nov  5 12:43:37.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.014080736s
Nov  5 12:43:39.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.013226353s
Nov  5 12:43:41.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.014052773s
Nov  5 12:43:43.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.013691134s
Nov  5 12:43:45.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.014142277s
Nov  5 12:43:47.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.013813956s
Nov  5 12:43:49.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.013694525s
Nov  5 12:43:51.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.013321271s
Nov  5 12:43:53.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.014613077s
Nov  5 12:43:53.933: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.018169152s
STEP: removing the label kubernetes.io/e2e-429d5dc2-4148-412d-a7eb-2607c18924e4 off the node ip-172-31-0-255 11/05/22 12:43:53.933
STEP: verifying the node doesn't have the label kubernetes.io/e2e-429d5dc2-4148-412d-a7eb-2607c18924e4 11/05/22 12:43:53.944
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:43:53.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3918" for this suite. 11/05/22 12:43:53.953
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":175,"skipped":3159,"failed":0}
------------------------------
• [SLOW TEST] [304.167 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:38:49.794
    Nov  5 12:38:49.794: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sched-pred 11/05/22 12:38:49.795
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:38:49.807
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:38:49.811
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov  5 12:38:49.815: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov  5 12:38:49.822: INFO: Waiting for terminating namespaces to be deleted...
    Nov  5 12:38:49.826: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-0-255 before test
    Nov  5 12:38:49.830: INFO: nginx-ingress-controller-kubernetes-worker-v9666 from ingress-nginx-kubernetes-worker started at 2022-11-05 12:07:51 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.830: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 12:38:49.830: INFO: filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b from sched-pred-5810 started at 2022-11-05 12:38:46 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.830: INFO: 	Container filler-pod-cc9e5b24-e2f1-4ee2-823e-ed1be311704b ready: true, restart count 0
    Nov  5 12:38:49.830: INFO: sonobuoy from sonobuoy started at 2022-11-05 11:55:13 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.830: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov  5 12:38:49.830: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 12:38:49.830: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:38:49.830: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov  5 12:38:49.830: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-27-199 before test
    Nov  5 12:38:49.836: INFO: default-http-backend-kubernetes-worker-6546b9855c-tdc5h from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.836: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov  5 12:38:49.836: INFO: nginx-ingress-controller-kubernetes-worker-l6972 from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.836: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 12:38:49.836: INFO: calico-kube-controllers-b5bd6849d-zg9jq from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.836: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov  5 12:38:49.836: INFO: coredns-6bcf44f4cc-ddkx4 from kube-system started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.836: INFO: 	Container coredns ready: true, restart count 0
    Nov  5 12:38:49.836: INFO: kube-state-metrics-74f5d549cc-cc4bl from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.836: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov  5 12:38:49.836: INFO: metrics-server-v0.5.2-6b48dc6f97-cp95w from kube-system started at 2022-11-05 11:49:10 +0000 UTC (2 container statuses recorded)
    Nov  5 12:38:49.836: INFO: 	Container metrics-server ready: true, restart count 1
    Nov  5 12:38:49.836: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov  5 12:38:49.836: INFO: dashboard-metrics-scraper-85d45476c6-4v4zk from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.836: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov  5 12:38:49.836: INFO: kubernetes-dashboard-7fb574cb-6lhg6 from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.836: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
    Nov  5 12:38:49.836: INFO: filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea from sched-pred-5810 started at 2022-11-05 12:38:46 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.836: INFO: 	Container filler-pod-0b1623b9-1914-49d0-92ff-70d0612afaea ready: true, restart count 0
    Nov  5 12:38:49.836: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-w6fxs from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 12:38:49.836: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:38:49.836: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov  5 12:38:49.836: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-41-19 before test
    Nov  5 12:38:49.841: INFO: nginx-ingress-controller-kubernetes-worker-879hx from ingress-nginx-kubernetes-worker started at 2022-11-05 11:50:52 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.841: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 12:38:49.841: INFO: filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea from sched-pred-5810 started at 2022-11-05 12:38:46 +0000 UTC (1 container statuses recorded)
    Nov  5 12:38:49.841: INFO: 	Container filler-pod-43d4b20d-9793-4532-a90d-d300392d80ea ready: true, restart count 0
    Nov  5 12:38:49.841: INFO: sonobuoy-e2e-job-b878a59025e244cf from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 12:38:49.841: INFO: 	Container e2e ready: true, restart count 0
    Nov  5 12:38:49.841: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:38:49.841: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-zjsjg from sonobuoy started at 2022-11-05 11:55:17 +0000 UTC (2 container statuses recorded)
    Nov  5 12:38:49.841: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 12:38:49.841: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/05/22 12:38:49.841
    Nov  5 12:38:49.849: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-3918" to be "running"
    Nov  5 12:38:49.855: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 6.731242ms
    Nov  5 12:38:51.860: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.011252289s
    Nov  5 12:38:51.860: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/05/22 12:38:51.864
    STEP: Trying to apply a random label on the found node. 11/05/22 12:38:51.884
    STEP: verifying the node has the label kubernetes.io/e2e-429d5dc2-4148-412d-a7eb-2607c18924e4 95 11/05/22 12:38:51.891
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 11/05/22 12:38:51.895
    Nov  5 12:38:51.900: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-3918" to be "not pending"
    Nov  5 12:38:51.903: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.281948ms
    Nov  5 12:38:53.908: INFO: Pod "pod4": Phase="Running", Reason="", readiness=false. Elapsed: 2.008054198s
    Nov  5 12:38:53.908: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 172.31.0.255 on the node which pod4 resides and expect not scheduled 11/05/22 12:38:53.908
    Nov  5 12:38:53.914: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-3918" to be "not pending"
    Nov  5 12:38:53.924: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.436386ms
    Nov  5 12:38:55.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013439604s
    Nov  5 12:38:57.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013574763s
    Nov  5 12:38:59.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013253408s
    Nov  5 12:39:01.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013865047s
    Nov  5 12:39:03.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.013232359s
    Nov  5 12:39:05.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014387456s
    Nov  5 12:39:07.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.013903543s
    Nov  5 12:39:09.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.013696346s
    Nov  5 12:39:11.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.013764725s
    Nov  5 12:39:13.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.013176375s
    Nov  5 12:39:15.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.014314342s
    Nov  5 12:39:17.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.013776626s
    Nov  5 12:39:19.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.014396518s
    Nov  5 12:39:21.930: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.015553868s
    Nov  5 12:39:23.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.014434867s
    Nov  5 12:39:25.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.013930626s
    Nov  5 12:39:27.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.014327225s
    Nov  5 12:39:29.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.01425956s
    Nov  5 12:39:31.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.01367338s
    Nov  5 12:39:33.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.013644394s
    Nov  5 12:39:35.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.014444211s
    Nov  5 12:39:37.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.014169973s
    Nov  5 12:39:39.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.01376614s
    Nov  5 12:39:41.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.014279734s
    Nov  5 12:39:43.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.013794784s
    Nov  5 12:39:45.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.01398013s
    Nov  5 12:39:47.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.013934696s
    Nov  5 12:39:49.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.014195059s
    Nov  5 12:39:51.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.013798857s
    Nov  5 12:39:53.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.01413534s
    Nov  5 12:39:55.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.013653228s
    Nov  5 12:39:57.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.01483843s
    Nov  5 12:39:59.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.013500498s
    Nov  5 12:40:01.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.013608758s
    Nov  5 12:40:03.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.013919145s
    Nov  5 12:40:05.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.014135494s
    Nov  5 12:40:07.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.013408494s
    Nov  5 12:40:09.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.013582453s
    Nov  5 12:40:11.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.013426311s
    Nov  5 12:40:13.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.013593258s
    Nov  5 12:40:15.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.013857187s
    Nov  5 12:40:17.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.013924773s
    Nov  5 12:40:19.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.014271373s
    Nov  5 12:40:21.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.013515617s
    Nov  5 12:40:23.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.013948678s
    Nov  5 12:40:25.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.014326114s
    Nov  5 12:40:27.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.013652085s
    Nov  5 12:40:29.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.013946001s
    Nov  5 12:40:31.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.013991778s
    Nov  5 12:40:33.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.013782125s
    Nov  5 12:40:35.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.014330276s
    Nov  5 12:40:37.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.014920953s
    Nov  5 12:40:39.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.014374824s
    Nov  5 12:40:41.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.013689158s
    Nov  5 12:40:43.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.013648384s
    Nov  5 12:40:45.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.013527202s
    Nov  5 12:40:47.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.013419952s
    Nov  5 12:40:49.930: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.015464364s
    Nov  5 12:40:51.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.013306525s
    Nov  5 12:40:53.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.013506517s
    Nov  5 12:40:55.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.01376741s
    Nov  5 12:40:57.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.013884481s
    Nov  5 12:40:59.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.014094562s
    Nov  5 12:41:01.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.013825133s
    Nov  5 12:41:03.932: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.017985039s
    Nov  5 12:41:05.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.013976474s
    Nov  5 12:41:07.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.01506006s
    Nov  5 12:41:09.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.014641421s
    Nov  5 12:41:11.930: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.01526676s
    Nov  5 12:41:13.937: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.022275536s
    Nov  5 12:41:15.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.013854476s
    Nov  5 12:41:17.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.013937338s
    Nov  5 12:41:19.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.013767592s
    Nov  5 12:41:21.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.014462973s
    Nov  5 12:41:23.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.013599413s
    Nov  5 12:41:25.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.014355506s
    Nov  5 12:41:27.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.0137445s
    Nov  5 12:41:29.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.013898126s
    Nov  5 12:41:31.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.013879378s
    Nov  5 12:41:33.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.013336053s
    Nov  5 12:41:35.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.014776041s
    Nov  5 12:41:37.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.013808039s
    Nov  5 12:41:39.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.014103656s
    Nov  5 12:41:41.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.013335614s
    Nov  5 12:41:43.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.013567462s
    Nov  5 12:41:45.937: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.022138851s
    Nov  5 12:41:47.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.014129799s
    Nov  5 12:41:49.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.014901922s
    Nov  5 12:41:51.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.013869321s
    Nov  5 12:41:53.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.014410278s
    Nov  5 12:41:55.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.014125581s
    Nov  5 12:41:57.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.013300032s
    Nov  5 12:41:59.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.014804314s
    Nov  5 12:42:01.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.014077816s
    Nov  5 12:42:03.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.01487324s
    Nov  5 12:42:05.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.014003825s
    Nov  5 12:42:07.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.014337481s
    Nov  5 12:42:09.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.014450077s
    Nov  5 12:42:11.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.01328753s
    Nov  5 12:42:13.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.013760038s
    Nov  5 12:42:15.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.013899786s
    Nov  5 12:42:17.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.014382766s
    Nov  5 12:42:19.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.013753732s
    Nov  5 12:42:21.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.013332897s
    Nov  5 12:42:23.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.014590966s
    Nov  5 12:42:25.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.013715121s
    Nov  5 12:42:27.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.014368264s
    Nov  5 12:42:29.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.014646629s
    Nov  5 12:42:31.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.013449117s
    Nov  5 12:42:33.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.01436676s
    Nov  5 12:42:35.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.013900209s
    Nov  5 12:42:37.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.014302281s
    Nov  5 12:42:39.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.013592422s
    Nov  5 12:42:41.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.014231701s
    Nov  5 12:42:43.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.013348835s
    Nov  5 12:42:45.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.013838861s
    Nov  5 12:42:47.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.013740302s
    Nov  5 12:42:49.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.013746823s
    Nov  5 12:42:51.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.013997649s
    Nov  5 12:42:53.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.014310069s
    Nov  5 12:42:55.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.01369599s
    Nov  5 12:42:57.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.013389542s
    Nov  5 12:42:59.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.014221726s
    Nov  5 12:43:01.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.014683888s
    Nov  5 12:43:03.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.013380622s
    Nov  5 12:43:05.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.013620349s
    Nov  5 12:43:07.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.013407626s
    Nov  5 12:43:09.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.013564771s
    Nov  5 12:43:11.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.014278793s
    Nov  5 12:43:13.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.013929133s
    Nov  5 12:43:15.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.013437504s
    Nov  5 12:43:17.930: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.015380127s
    Nov  5 12:43:19.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.013993339s
    Nov  5 12:43:21.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.013317614s
    Nov  5 12:43:23.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.013553358s
    Nov  5 12:43:25.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.014432724s
    Nov  5 12:43:27.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.014226841s
    Nov  5 12:43:29.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.013965302s
    Nov  5 12:43:31.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.014445559s
    Nov  5 12:43:33.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.014076229s
    Nov  5 12:43:35.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.014280166s
    Nov  5 12:43:37.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.014080736s
    Nov  5 12:43:39.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.013226353s
    Nov  5 12:43:41.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.014052773s
    Nov  5 12:43:43.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.013691134s
    Nov  5 12:43:45.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.014142277s
    Nov  5 12:43:47.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.013813956s
    Nov  5 12:43:49.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.013694525s
    Nov  5 12:43:51.928: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.013321271s
    Nov  5 12:43:53.929: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.014613077s
    Nov  5 12:43:53.933: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.018169152s
    STEP: removing the label kubernetes.io/e2e-429d5dc2-4148-412d-a7eb-2607c18924e4 off the node ip-172-31-0-255 11/05/22 12:43:53.933
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-429d5dc2-4148-412d-a7eb-2607c18924e4 11/05/22 12:43:53.944
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:43:53.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-3918" for this suite. 11/05/22 12:43:53.953
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:43:53.963
Nov  5 12:43:53.963: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-probe 11/05/22 12:43:53.963
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:43:53.977
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:43:53.981
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-05854f07-e277-48db-be90-1569fe5791ca in namespace container-probe-8330 11/05/22 12:43:53.984
Nov  5 12:43:53.993: INFO: Waiting up to 5m0s for pod "busybox-05854f07-e277-48db-be90-1569fe5791ca" in namespace "container-probe-8330" to be "not pending"
Nov  5 12:43:54.000: INFO: Pod "busybox-05854f07-e277-48db-be90-1569fe5791ca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.823391ms
Nov  5 12:43:56.005: INFO: Pod "busybox-05854f07-e277-48db-be90-1569fe5791ca": Phase="Running", Reason="", readiness=true. Elapsed: 2.011599812s
Nov  5 12:43:56.005: INFO: Pod "busybox-05854f07-e277-48db-be90-1569fe5791ca" satisfied condition "not pending"
Nov  5 12:43:56.005: INFO: Started pod busybox-05854f07-e277-48db-be90-1569fe5791ca in namespace container-probe-8330
STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 12:43:56.005
Nov  5 12:43:56.008: INFO: Initial restart count of pod busybox-05854f07-e277-48db-be90-1569fe5791ca is 0
Nov  5 12:44:46.122: INFO: Restart count of pod container-probe-8330/busybox-05854f07-e277-48db-be90-1569fe5791ca is now 1 (50.113351946s elapsed)
STEP: deleting the pod 11/05/22 12:44:46.122
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov  5 12:44:46.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8330" for this suite. 11/05/22 12:44:46.136
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":176,"skipped":3185,"failed":0}
------------------------------
• [SLOW TEST] [52.180 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:43:53.963
    Nov  5 12:43:53.963: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-probe 11/05/22 12:43:53.963
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:43:53.977
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:43:53.981
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-05854f07-e277-48db-be90-1569fe5791ca in namespace container-probe-8330 11/05/22 12:43:53.984
    Nov  5 12:43:53.993: INFO: Waiting up to 5m0s for pod "busybox-05854f07-e277-48db-be90-1569fe5791ca" in namespace "container-probe-8330" to be "not pending"
    Nov  5 12:43:54.000: INFO: Pod "busybox-05854f07-e277-48db-be90-1569fe5791ca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.823391ms
    Nov  5 12:43:56.005: INFO: Pod "busybox-05854f07-e277-48db-be90-1569fe5791ca": Phase="Running", Reason="", readiness=true. Elapsed: 2.011599812s
    Nov  5 12:43:56.005: INFO: Pod "busybox-05854f07-e277-48db-be90-1569fe5791ca" satisfied condition "not pending"
    Nov  5 12:43:56.005: INFO: Started pod busybox-05854f07-e277-48db-be90-1569fe5791ca in namespace container-probe-8330
    STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 12:43:56.005
    Nov  5 12:43:56.008: INFO: Initial restart count of pod busybox-05854f07-e277-48db-be90-1569fe5791ca is 0
    Nov  5 12:44:46.122: INFO: Restart count of pod container-probe-8330/busybox-05854f07-e277-48db-be90-1569fe5791ca is now 1 (50.113351946s elapsed)
    STEP: deleting the pod 11/05/22 12:44:46.122
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov  5 12:44:46.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8330" for this suite. 11/05/22 12:44:46.136
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:44:46.145
Nov  5 12:44:46.145: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename disruption 11/05/22 12:44:46.146
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:44:46.159
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:44:46.164
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:44:46.169
Nov  5 12:44:46.169: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename disruption-2 11/05/22 12:44:46.17
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:44:46.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:44:46.187
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 11/05/22 12:44:46.195
STEP: Waiting for the pdb to be processed 11/05/22 12:44:48.214
STEP: Waiting for the pdb to be processed 11/05/22 12:44:48.226
STEP: listing a collection of PDBs across all namespaces 11/05/22 12:44:48.232
STEP: listing a collection of PDBs in namespace disruption-258 11/05/22 12:44:48.235
STEP: deleting a collection of PDBs 11/05/22 12:44:48.239
STEP: Waiting for the PDB collection to be deleted 11/05/22 12:44:48.25
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Nov  5 12:44:48.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-6138" for this suite. 11/05/22 12:44:48.257
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov  5 12:44:48.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-258" for this suite. 11/05/22 12:44:48.267
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":177,"skipped":3227,"failed":0}
------------------------------
• [2.129 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:44:46.145
    Nov  5 12:44:46.145: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename disruption 11/05/22 12:44:46.146
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:44:46.159
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:44:46.164
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:44:46.169
    Nov  5 12:44:46.169: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename disruption-2 11/05/22 12:44:46.17
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:44:46.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:44:46.187
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 11/05/22 12:44:46.195
    STEP: Waiting for the pdb to be processed 11/05/22 12:44:48.214
    STEP: Waiting for the pdb to be processed 11/05/22 12:44:48.226
    STEP: listing a collection of PDBs across all namespaces 11/05/22 12:44:48.232
    STEP: listing a collection of PDBs in namespace disruption-258 11/05/22 12:44:48.235
    STEP: deleting a collection of PDBs 11/05/22 12:44:48.239
    STEP: Waiting for the PDB collection to be deleted 11/05/22 12:44:48.25
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Nov  5 12:44:48.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-6138" for this suite. 11/05/22 12:44:48.257
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov  5 12:44:48.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-258" for this suite. 11/05/22 12:44:48.267
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:44:48.275
Nov  5 12:44:48.275: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 12:44:48.276
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:44:48.289
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:44:48.292
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-130f687b-083b-4e30-b9df-6c6afc84c60a 11/05/22 12:44:48.296
STEP: Creating a pod to test consume configMaps 11/05/22 12:44:48.301
Nov  5 12:44:48.309: INFO: Waiting up to 5m0s for pod "pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b" in namespace "configmap-8679" to be "Succeeded or Failed"
Nov  5 12:44:48.315: INFO: Pod "pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.983721ms
Nov  5 12:44:50.320: INFO: Pod "pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01032264s
Nov  5 12:44:52.320: INFO: Pod "pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010031266s
STEP: Saw pod success 11/05/22 12:44:52.32
Nov  5 12:44:52.320: INFO: Pod "pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b" satisfied condition "Succeeded or Failed"
Nov  5 12:44:52.323: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:44:52.339
Nov  5 12:44:52.355: INFO: Waiting for pod pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b to disappear
Nov  5 12:44:52.358: INFO: Pod pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 12:44:52.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8679" for this suite. 11/05/22 12:44:52.361
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":178,"skipped":3276,"failed":0}
------------------------------
• [4.094 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:44:48.275
    Nov  5 12:44:48.275: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 12:44:48.276
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:44:48.289
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:44:48.292
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-130f687b-083b-4e30-b9df-6c6afc84c60a 11/05/22 12:44:48.296
    STEP: Creating a pod to test consume configMaps 11/05/22 12:44:48.301
    Nov  5 12:44:48.309: INFO: Waiting up to 5m0s for pod "pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b" in namespace "configmap-8679" to be "Succeeded or Failed"
    Nov  5 12:44:48.315: INFO: Pod "pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.983721ms
    Nov  5 12:44:50.320: INFO: Pod "pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01032264s
    Nov  5 12:44:52.320: INFO: Pod "pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010031266s
    STEP: Saw pod success 11/05/22 12:44:52.32
    Nov  5 12:44:52.320: INFO: Pod "pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b" satisfied condition "Succeeded or Failed"
    Nov  5 12:44:52.323: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:44:52.339
    Nov  5 12:44:52.355: INFO: Waiting for pod pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b to disappear
    Nov  5 12:44:52.358: INFO: Pod pod-configmaps-65dfa42e-21ea-4996-8805-c1bea412681b no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 12:44:52.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8679" for this suite. 11/05/22 12:44:52.361
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:44:52.369
Nov  5 12:44:52.369: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sched-preemption 11/05/22 12:44:52.37
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:44:52.381
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:44:52.387
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Nov  5 12:44:52.407: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  5 12:45:52.427: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 11/05/22 12:45:52.43
Nov  5 12:45:52.454: INFO: Created pod: pod0-0-sched-preemption-low-priority
Nov  5 12:45:52.462: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Nov  5 12:45:52.479: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Nov  5 12:45:52.486: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Nov  5 12:45:52.503: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Nov  5 12:45:52.511: INFO: Created pod: pod2-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 11/05/22 12:45:52.511
Nov  5 12:45:52.511: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-3754" to be "running"
Nov  5 12:45:52.515: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.153612ms
Nov  5 12:45:54.521: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009509791s
Nov  5 12:45:56.520: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009281009s
Nov  5 12:45:58.520: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009269739s
Nov  5 12:46:00.520: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009384103s
Nov  5 12:46:02.520: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.009112503s
Nov  5 12:46:02.520: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Nov  5 12:46:02.520: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-3754" to be "running"
Nov  5 12:46:02.524: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.358141ms
Nov  5 12:46:02.524: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Nov  5 12:46:02.524: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-3754" to be "running"
Nov  5 12:46:02.527: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.435252ms
Nov  5 12:46:02.527: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Nov  5 12:46:02.527: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-3754" to be "running"
Nov  5 12:46:02.531: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.514561ms
Nov  5 12:46:02.531: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Nov  5 12:46:02.531: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-3754" to be "running"
Nov  5 12:46:02.534: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.156529ms
Nov  5 12:46:02.534: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Nov  5 12:46:02.534: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-3754" to be "running"
Nov  5 12:46:02.537: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.209866ms
Nov  5 12:46:02.537: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 11/05/22 12:46:02.537
Nov  5 12:46:02.548: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Nov  5 12:46:02.551: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.415885ms
Nov  5 12:46:04.556: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008216086s
Nov  5 12:46:06.556: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00795376s
Nov  5 12:46:08.556: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.008141062s
Nov  5 12:46:08.556: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:46:08.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3754" for this suite. 11/05/22 12:46:08.599
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":179,"skipped":3276,"failed":0}
------------------------------
• [SLOW TEST] [76.275 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:44:52.369
    Nov  5 12:44:52.369: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sched-preemption 11/05/22 12:44:52.37
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:44:52.381
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:44:52.387
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Nov  5 12:44:52.407: INFO: Waiting up to 1m0s for all nodes to be ready
    Nov  5 12:45:52.427: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 11/05/22 12:45:52.43
    Nov  5 12:45:52.454: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Nov  5 12:45:52.462: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Nov  5 12:45:52.479: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Nov  5 12:45:52.486: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Nov  5 12:45:52.503: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Nov  5 12:45:52.511: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 11/05/22 12:45:52.511
    Nov  5 12:45:52.511: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-3754" to be "running"
    Nov  5 12:45:52.515: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.153612ms
    Nov  5 12:45:54.521: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009509791s
    Nov  5 12:45:56.520: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009281009s
    Nov  5 12:45:58.520: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009269739s
    Nov  5 12:46:00.520: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.009384103s
    Nov  5 12:46:02.520: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 10.009112503s
    Nov  5 12:46:02.520: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Nov  5 12:46:02.520: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-3754" to be "running"
    Nov  5 12:46:02.524: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.358141ms
    Nov  5 12:46:02.524: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov  5 12:46:02.524: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-3754" to be "running"
    Nov  5 12:46:02.527: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.435252ms
    Nov  5 12:46:02.527: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov  5 12:46:02.527: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-3754" to be "running"
    Nov  5 12:46:02.531: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.514561ms
    Nov  5 12:46:02.531: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Nov  5 12:46:02.531: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-3754" to be "running"
    Nov  5 12:46:02.534: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.156529ms
    Nov  5 12:46:02.534: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Nov  5 12:46:02.534: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-3754" to be "running"
    Nov  5 12:46:02.537: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.209866ms
    Nov  5 12:46:02.537: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 11/05/22 12:46:02.537
    Nov  5 12:46:02.548: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Nov  5 12:46:02.551: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.415885ms
    Nov  5 12:46:04.556: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008216086s
    Nov  5 12:46:06.556: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00795376s
    Nov  5 12:46:08.556: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.008141062s
    Nov  5 12:46:08.556: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:46:08.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-3754" for this suite. 11/05/22 12:46:08.599
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:46:08.645
Nov  5 12:46:08.645: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubelet-test 11/05/22 12:46:08.646
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:08.659
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:08.67
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Nov  5 12:46:08.684: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1" in namespace "kubelet-test-6235" to be "running and ready"
Nov  5 12:46:08.688: INFO: Pod "busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.471825ms
Nov  5 12:46:08.688: INFO: The phase of Pod busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:46:10.693: INFO: Pod "busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008367313s
Nov  5 12:46:10.693: INFO: The phase of Pod busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1 is Running (Ready = true)
Nov  5 12:46:10.693: INFO: Pod "busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov  5 12:46:10.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6235" for this suite. 11/05/22 12:46:10.706
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":180,"skipped":3276,"failed":0}
------------------------------
• [2.067 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:46:08.645
    Nov  5 12:46:08.645: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubelet-test 11/05/22 12:46:08.646
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:08.659
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:08.67
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Nov  5 12:46:08.684: INFO: Waiting up to 5m0s for pod "busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1" in namespace "kubelet-test-6235" to be "running and ready"
    Nov  5 12:46:08.688: INFO: Pod "busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.471825ms
    Nov  5 12:46:08.688: INFO: The phase of Pod busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:46:10.693: INFO: Pod "busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1": Phase="Running", Reason="", readiness=true. Elapsed: 2.008367313s
    Nov  5 12:46:10.693: INFO: The phase of Pod busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1 is Running (Ready = true)
    Nov  5 12:46:10.693: INFO: Pod "busybox-readonly-fs3cae4833-03ed-49d1-ae39-8d2b1e61ddf1" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov  5 12:46:10.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6235" for this suite. 11/05/22 12:46:10.706
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:46:10.713
Nov  5 12:46:10.713: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 12:46:10.713
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:10.726
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:10.73
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 11/05/22 12:46:10.734
Nov  5 12:46:10.741: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2" in namespace "downward-api-3201" to be "Succeeded or Failed"
Nov  5 12:46:10.748: INFO: Pod "downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.748391ms
Nov  5 12:46:12.752: INFO: Pod "downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011019073s
Nov  5 12:46:14.752: INFO: Pod "downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010579065s
STEP: Saw pod success 11/05/22 12:46:14.752
Nov  5 12:46:14.752: INFO: Pod "downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2" satisfied condition "Succeeded or Failed"
Nov  5 12:46:14.756: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2 container client-container: <nil>
STEP: delete the pod 11/05/22 12:46:14.763
Nov  5 12:46:14.775: INFO: Waiting for pod downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2 to disappear
Nov  5 12:46:14.778: INFO: Pod downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 12:46:14.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3201" for this suite. 11/05/22 12:46:14.785
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":181,"skipped":3282,"failed":0}
------------------------------
• [4.091 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:46:10.713
    Nov  5 12:46:10.713: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 12:46:10.713
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:10.726
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:10.73
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 11/05/22 12:46:10.734
    Nov  5 12:46:10.741: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2" in namespace "downward-api-3201" to be "Succeeded or Failed"
    Nov  5 12:46:10.748: INFO: Pod "downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.748391ms
    Nov  5 12:46:12.752: INFO: Pod "downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011019073s
    Nov  5 12:46:14.752: INFO: Pod "downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010579065s
    STEP: Saw pod success 11/05/22 12:46:14.752
    Nov  5 12:46:14.752: INFO: Pod "downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2" satisfied condition "Succeeded or Failed"
    Nov  5 12:46:14.756: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2 container client-container: <nil>
    STEP: delete the pod 11/05/22 12:46:14.763
    Nov  5 12:46:14.775: INFO: Waiting for pod downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2 to disappear
    Nov  5 12:46:14.778: INFO: Pod downwardapi-volume-ec0a8b2d-cd22-454b-907f-bf95ee98f8f2 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 12:46:14.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3201" for this suite. 11/05/22 12:46:14.785
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:46:14.806
Nov  5 12:46:14.806: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-runtime 11/05/22 12:46:14.807
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:14.82
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:14.824
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 11/05/22 12:46:14.842
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 11/05/22 12:46:30.92
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 11/05/22 12:46:30.924
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 11/05/22 12:46:30.931
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 11/05/22 12:46:30.931
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 11/05/22 12:46:30.955
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 11/05/22 12:46:33.971
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 11/05/22 12:46:34.98
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 11/05/22 12:46:34.987
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 11/05/22 12:46:34.987
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 11/05/22 12:46:35.013
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 11/05/22 12:46:36.023
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 11/05/22 12:46:39.04
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 11/05/22 12:46:39.047
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 11/05/22 12:46:39.047
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov  5 12:46:39.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6866" for this suite. 11/05/22 12:46:39.076
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":182,"skipped":3354,"failed":0}
------------------------------
• [SLOW TEST] [24.277 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:46:14.806
    Nov  5 12:46:14.806: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-runtime 11/05/22 12:46:14.807
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:14.82
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:14.824
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 11/05/22 12:46:14.842
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 11/05/22 12:46:30.92
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 11/05/22 12:46:30.924
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 11/05/22 12:46:30.931
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 11/05/22 12:46:30.931
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 11/05/22 12:46:30.955
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 11/05/22 12:46:33.971
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 11/05/22 12:46:34.98
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 11/05/22 12:46:34.987
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 11/05/22 12:46:34.987
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 11/05/22 12:46:35.013
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 11/05/22 12:46:36.023
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 11/05/22 12:46:39.04
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 11/05/22 12:46:39.047
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 11/05/22 12:46:39.047
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov  5 12:46:39.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-6866" for this suite. 11/05/22 12:46:39.076
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:46:39.084
Nov  5 12:46:39.084: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sysctl 11/05/22 12:46:39.084
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:39.098
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:39.101
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 11/05/22 12:46:39.105
STEP: Watching for error events or started pod 11/05/22 12:46:39.112
STEP: Waiting for pod completion 11/05/22 12:46:41.116
Nov  5 12:46:41.116: INFO: Waiting up to 3m0s for pod "sysctl-545132f8-32d7-495a-ab84-b00313c7e3a9" in namespace "sysctl-8554" to be "completed"
Nov  5 12:46:41.120: INFO: Pod "sysctl-545132f8-32d7-495a-ab84-b00313c7e3a9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.862757ms
Nov  5 12:46:43.124: INFO: Pod "sysctl-545132f8-32d7-495a-ab84-b00313c7e3a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007864863s
Nov  5 12:46:43.124: INFO: Pod "sysctl-545132f8-32d7-495a-ab84-b00313c7e3a9" satisfied condition "completed"
STEP: Checking that the pod succeeded 11/05/22 12:46:43.128
STEP: Getting logs from the pod 11/05/22 12:46:43.128
STEP: Checking that the sysctl is actually updated 11/05/22 12:46:43.145
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Nov  5 12:46:43.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-8554" for this suite. 11/05/22 12:46:43.149
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":183,"skipped":3360,"failed":0}
------------------------------
• [4.074 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:46:39.084
    Nov  5 12:46:39.084: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sysctl 11/05/22 12:46:39.084
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:39.098
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:39.101
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 11/05/22 12:46:39.105
    STEP: Watching for error events or started pod 11/05/22 12:46:39.112
    STEP: Waiting for pod completion 11/05/22 12:46:41.116
    Nov  5 12:46:41.116: INFO: Waiting up to 3m0s for pod "sysctl-545132f8-32d7-495a-ab84-b00313c7e3a9" in namespace "sysctl-8554" to be "completed"
    Nov  5 12:46:41.120: INFO: Pod "sysctl-545132f8-32d7-495a-ab84-b00313c7e3a9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.862757ms
    Nov  5 12:46:43.124: INFO: Pod "sysctl-545132f8-32d7-495a-ab84-b00313c7e3a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007864863s
    Nov  5 12:46:43.124: INFO: Pod "sysctl-545132f8-32d7-495a-ab84-b00313c7e3a9" satisfied condition "completed"
    STEP: Checking that the pod succeeded 11/05/22 12:46:43.128
    STEP: Getting logs from the pod 11/05/22 12:46:43.128
    STEP: Checking that the sysctl is actually updated 11/05/22 12:46:43.145
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov  5 12:46:43.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-8554" for this suite. 11/05/22 12:46:43.149
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:46:43.159
Nov  5 12:46:43.159: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 12:46:43.159
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:43.17
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:43.175
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 11/05/22 12:46:43.178
STEP: setting up watch 11/05/22 12:46:43.178
STEP: submitting the pod to kubernetes 11/05/22 12:46:43.282
STEP: verifying the pod is in kubernetes 11/05/22 12:46:43.293
STEP: verifying pod creation was observed 11/05/22 12:46:43.297
Nov  5 12:46:43.297: INFO: Waiting up to 5m0s for pod "pod-submit-remove-34b3341a-316f-44cc-9d5c-aa5e598e0f60" in namespace "pods-9033" to be "running"
Nov  5 12:46:43.301: INFO: Pod "pod-submit-remove-34b3341a-316f-44cc-9d5c-aa5e598e0f60": Phase="Pending", Reason="", readiness=false. Elapsed: 4.269401ms
Nov  5 12:46:45.306: INFO: Pod "pod-submit-remove-34b3341a-316f-44cc-9d5c-aa5e598e0f60": Phase="Running", Reason="", readiness=true. Elapsed: 2.009043122s
Nov  5 12:46:45.306: INFO: Pod "pod-submit-remove-34b3341a-316f-44cc-9d5c-aa5e598e0f60" satisfied condition "running"
STEP: deleting the pod gracefully 11/05/22 12:46:45.31
STEP: verifying pod deletion was observed 11/05/22 12:46:45.322
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov  5 12:46:47.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9033" for this suite. 11/05/22 12:46:47.887
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":184,"skipped":3387,"failed":0}
------------------------------
• [4.737 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:46:43.159
    Nov  5 12:46:43.159: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 12:46:43.159
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:43.17
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:43.175
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 11/05/22 12:46:43.178
    STEP: setting up watch 11/05/22 12:46:43.178
    STEP: submitting the pod to kubernetes 11/05/22 12:46:43.282
    STEP: verifying the pod is in kubernetes 11/05/22 12:46:43.293
    STEP: verifying pod creation was observed 11/05/22 12:46:43.297
    Nov  5 12:46:43.297: INFO: Waiting up to 5m0s for pod "pod-submit-remove-34b3341a-316f-44cc-9d5c-aa5e598e0f60" in namespace "pods-9033" to be "running"
    Nov  5 12:46:43.301: INFO: Pod "pod-submit-remove-34b3341a-316f-44cc-9d5c-aa5e598e0f60": Phase="Pending", Reason="", readiness=false. Elapsed: 4.269401ms
    Nov  5 12:46:45.306: INFO: Pod "pod-submit-remove-34b3341a-316f-44cc-9d5c-aa5e598e0f60": Phase="Running", Reason="", readiness=true. Elapsed: 2.009043122s
    Nov  5 12:46:45.306: INFO: Pod "pod-submit-remove-34b3341a-316f-44cc-9d5c-aa5e598e0f60" satisfied condition "running"
    STEP: deleting the pod gracefully 11/05/22 12:46:45.31
    STEP: verifying pod deletion was observed 11/05/22 12:46:45.322
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov  5 12:46:47.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9033" for this suite. 11/05/22 12:46:47.887
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:46:47.896
Nov  5 12:46:47.896: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replicaset 11/05/22 12:46:47.897
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:47.916
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:47.921
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 11/05/22 12:46:47.925
STEP: Verify that the required pods have come up 11/05/22 12:46:47.932
Nov  5 12:46:47.937: INFO: Pod name sample-pod: Found 0 pods out of 3
Nov  5 12:46:52.942: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 11/05/22 12:46:52.942
Nov  5 12:46:52.945: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 11/05/22 12:46:52.946
STEP: DeleteCollection of the ReplicaSets 11/05/22 12:46:52.952
STEP: After DeleteCollection verify that ReplicaSets have been deleted 11/05/22 12:46:52.96
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov  5 12:46:52.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6565" for this suite. 11/05/22 12:46:52.991
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":185,"skipped":3392,"failed":0}
------------------------------
• [SLOW TEST] [5.104 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:46:47.896
    Nov  5 12:46:47.896: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replicaset 11/05/22 12:46:47.897
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:47.916
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:47.921
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 11/05/22 12:46:47.925
    STEP: Verify that the required pods have come up 11/05/22 12:46:47.932
    Nov  5 12:46:47.937: INFO: Pod name sample-pod: Found 0 pods out of 3
    Nov  5 12:46:52.942: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 11/05/22 12:46:52.942
    Nov  5 12:46:52.945: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 11/05/22 12:46:52.946
    STEP: DeleteCollection of the ReplicaSets 11/05/22 12:46:52.952
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 11/05/22 12:46:52.96
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov  5 12:46:52.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-6565" for this suite. 11/05/22 12:46:52.991
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:46:53
Nov  5 12:46:53.000: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 12:46:53.001
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:53.028
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:53.036
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 11/05/22 12:46:53.044
Nov  5 12:46:53.055: INFO: Waiting up to 5m0s for pod "pod-bztzl" in namespace "pods-7326" to be "running"
Nov  5 12:46:53.065: INFO: Pod "pod-bztzl": Phase="Pending", Reason="", readiness=false. Elapsed: 10.36751ms
Nov  5 12:46:55.070: INFO: Pod "pod-bztzl": Phase="Running", Reason="", readiness=true. Elapsed: 2.015436206s
Nov  5 12:46:55.070: INFO: Pod "pod-bztzl" satisfied condition "running"
STEP: patching /status 11/05/22 12:46:55.07
Nov  5 12:46:55.080: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov  5 12:46:55.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7326" for this suite. 11/05/22 12:46:55.084
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":186,"skipped":3392,"failed":0}
------------------------------
• [2.096 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:46:53
    Nov  5 12:46:53.000: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 12:46:53.001
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:53.028
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:53.036
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 11/05/22 12:46:53.044
    Nov  5 12:46:53.055: INFO: Waiting up to 5m0s for pod "pod-bztzl" in namespace "pods-7326" to be "running"
    Nov  5 12:46:53.065: INFO: Pod "pod-bztzl": Phase="Pending", Reason="", readiness=false. Elapsed: 10.36751ms
    Nov  5 12:46:55.070: INFO: Pod "pod-bztzl": Phase="Running", Reason="", readiness=true. Elapsed: 2.015436206s
    Nov  5 12:46:55.070: INFO: Pod "pod-bztzl" satisfied condition "running"
    STEP: patching /status 11/05/22 12:46:55.07
    Nov  5 12:46:55.080: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov  5 12:46:55.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7326" for this suite. 11/05/22 12:46:55.084
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:46:55.098
Nov  5 12:46:55.098: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename daemonsets 11/05/22 12:46:55.098
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:55.112
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:55.116
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Nov  5 12:46:55.150: INFO: Create a RollingUpdate DaemonSet
Nov  5 12:46:55.155: INFO: Check that daemon pods launch on every node of the cluster
Nov  5 12:46:55.160: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:46:55.160: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:46:55.163: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:46:55.163: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:46:56.169: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:46:56.169: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:46:56.174: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:46:56.174: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:46:57.168: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:46:57.168: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:46:57.172: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov  5 12:46:57.172: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
Nov  5 12:46:57.172: INFO: Update the DaemonSet to trigger a rollout
Nov  5 12:46:57.183: INFO: Updating DaemonSet daemon-set
Nov  5 12:47:00.201: INFO: Roll back the DaemonSet before rollout is complete
Nov  5 12:47:00.212: INFO: Updating DaemonSet daemon-set
Nov  5 12:47:00.212: INFO: Make sure DaemonSet rollback is complete
Nov  5 12:47:00.216: INFO: Wrong image for pod: daemon-set-6fkrm. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Nov  5 12:47:00.216: INFO: Pod daemon-set-6fkrm is not available
Nov  5 12:47:00.220: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:00.220: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:01.229: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:01.229: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:02.225: INFO: Pod daemon-set-z5m6b is not available
Nov  5 12:47:02.229: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:02.229: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/05/22 12:47:02.237
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7477, will wait for the garbage collector to delete the pods 11/05/22 12:47:02.237
Nov  5 12:47:02.301: INFO: Deleting DaemonSet.extensions daemon-set took: 8.959918ms
Nov  5 12:47:02.401: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.295021ms
Nov  5 12:47:04.206: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:47:04.206: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov  5 12:47:04.209: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23056"},"items":null}

Nov  5 12:47:04.212: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23056"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:47:04.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7477" for this suite. 11/05/22 12:47:04.229
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":187,"skipped":3411,"failed":0}
------------------------------
• [SLOW TEST] [9.138 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:46:55.098
    Nov  5 12:46:55.098: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename daemonsets 11/05/22 12:46:55.098
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:46:55.112
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:46:55.116
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Nov  5 12:46:55.150: INFO: Create a RollingUpdate DaemonSet
    Nov  5 12:46:55.155: INFO: Check that daemon pods launch on every node of the cluster
    Nov  5 12:46:55.160: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:46:55.160: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:46:55.163: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:46:55.163: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:46:56.169: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:46:56.169: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:46:56.174: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:46:56.174: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:46:57.168: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:46:57.168: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:46:57.172: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov  5 12:46:57.172: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    Nov  5 12:46:57.172: INFO: Update the DaemonSet to trigger a rollout
    Nov  5 12:46:57.183: INFO: Updating DaemonSet daemon-set
    Nov  5 12:47:00.201: INFO: Roll back the DaemonSet before rollout is complete
    Nov  5 12:47:00.212: INFO: Updating DaemonSet daemon-set
    Nov  5 12:47:00.212: INFO: Make sure DaemonSet rollback is complete
    Nov  5 12:47:00.216: INFO: Wrong image for pod: daemon-set-6fkrm. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Nov  5 12:47:00.216: INFO: Pod daemon-set-6fkrm is not available
    Nov  5 12:47:00.220: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:00.220: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:01.229: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:01.229: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:02.225: INFO: Pod daemon-set-z5m6b is not available
    Nov  5 12:47:02.229: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:02.229: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/05/22 12:47:02.237
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7477, will wait for the garbage collector to delete the pods 11/05/22 12:47:02.237
    Nov  5 12:47:02.301: INFO: Deleting DaemonSet.extensions daemon-set took: 8.959918ms
    Nov  5 12:47:02.401: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.295021ms
    Nov  5 12:47:04.206: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:47:04.206: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov  5 12:47:04.209: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23056"},"items":null}

    Nov  5 12:47:04.212: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23056"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:47:04.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7477" for this suite. 11/05/22 12:47:04.229
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:47:04.236
Nov  5 12:47:04.236: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename daemonsets 11/05/22 12:47:04.237
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:04.252
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:04.255
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Nov  5 12:47:04.289: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 12:47:04.294
Nov  5 12:47:04.300: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:04.300: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:04.304: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:47:04.304: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:47:05.309: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:05.309: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:05.313: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:47:05.313: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 12:47:06.309: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:06.309: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:06.313: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov  5 12:47:06.313: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Update daemon pods image. 11/05/22 12:47:06.327
STEP: Check that daemon pods images are updated. 11/05/22 12:47:06.337
Nov  5 12:47:06.342: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:06.342: INFO: Wrong image for pod: daemon-set-7vzbx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:06.342: INFO: Wrong image for pod: daemon-set-cwdnk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:06.348: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:06.348: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:07.353: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:07.353: INFO: Wrong image for pod: daemon-set-cwdnk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:07.357: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:07.357: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:08.354: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:08.354: INFO: Wrong image for pod: daemon-set-cwdnk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:08.358: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:08.358: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:09.354: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:09.354: INFO: Wrong image for pod: daemon-set-cwdnk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:09.354: INFO: Pod daemon-set-vbvbn is not available
Nov  5 12:47:09.358: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:09.358: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:10.354: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:10.358: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:10.358: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:11.354: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Nov  5 12:47:11.362: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:11.362: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:12.364: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:12.364: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:13.353: INFO: Pod daemon-set-4wn55 is not available
Nov  5 12:47:13.357: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:13.358: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster. 11/05/22 12:47:13.358
Nov  5 12:47:13.362: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:13.362: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:13.365: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov  5 12:47:13.365: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
Nov  5 12:47:14.370: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:14.370: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 12:47:14.374: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov  5 12:47:14.374: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/05/22 12:47:14.39
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1180, will wait for the garbage collector to delete the pods 11/05/22 12:47:14.391
Nov  5 12:47:14.451: INFO: Deleting DaemonSet.extensions daemon-set took: 6.76436ms
Nov  5 12:47:14.551: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.512655ms
Nov  5 12:47:16.955: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 12:47:16.955: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov  5 12:47:16.958: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23269"},"items":null}

Nov  5 12:47:16.962: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23269"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov  5 12:47:16.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1180" for this suite. 11/05/22 12:47:16.979
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":188,"skipped":3414,"failed":0}
------------------------------
• [SLOW TEST] [12.750 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:47:04.236
    Nov  5 12:47:04.236: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename daemonsets 11/05/22 12:47:04.237
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:04.252
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:04.255
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Nov  5 12:47:04.289: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 12:47:04.294
    Nov  5 12:47:04.300: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:04.300: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:04.304: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:47:04.304: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:47:05.309: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:05.309: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:05.313: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:47:05.313: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 12:47:06.309: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:06.309: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:06.313: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov  5 12:47:06.313: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Update daemon pods image. 11/05/22 12:47:06.327
    STEP: Check that daemon pods images are updated. 11/05/22 12:47:06.337
    Nov  5 12:47:06.342: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:06.342: INFO: Wrong image for pod: daemon-set-7vzbx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:06.342: INFO: Wrong image for pod: daemon-set-cwdnk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:06.348: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:06.348: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:07.353: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:07.353: INFO: Wrong image for pod: daemon-set-cwdnk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:07.357: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:07.357: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:08.354: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:08.354: INFO: Wrong image for pod: daemon-set-cwdnk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:08.358: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:08.358: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:09.354: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:09.354: INFO: Wrong image for pod: daemon-set-cwdnk. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:09.354: INFO: Pod daemon-set-vbvbn is not available
    Nov  5 12:47:09.358: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:09.358: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:10.354: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:10.358: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:10.358: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:11.354: INFO: Wrong image for pod: daemon-set-22xkx. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Nov  5 12:47:11.362: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:11.362: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:12.364: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:12.364: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:13.353: INFO: Pod daemon-set-4wn55 is not available
    Nov  5 12:47:13.357: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:13.358: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    STEP: Check that daemon pods are still running on every node of the cluster. 11/05/22 12:47:13.358
    Nov  5 12:47:13.362: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:13.362: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:13.365: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov  5 12:47:13.365: INFO: Node ip-172-31-41-19 is running 0 daemon pod, expected 1
    Nov  5 12:47:14.370: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:14.370: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 12:47:14.374: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov  5 12:47:14.374: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/05/22 12:47:14.39
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1180, will wait for the garbage collector to delete the pods 11/05/22 12:47:14.391
    Nov  5 12:47:14.451: INFO: Deleting DaemonSet.extensions daemon-set took: 6.76436ms
    Nov  5 12:47:14.551: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.512655ms
    Nov  5 12:47:16.955: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 12:47:16.955: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov  5 12:47:16.958: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"23269"},"items":null}

    Nov  5 12:47:16.962: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"23269"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 12:47:16.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-1180" for this suite. 11/05/22 12:47:16.979
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:47:16.986
Nov  5 12:47:16.986: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename svcaccounts 11/05/22 12:47:16.987
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:17.001
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:17.005
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Nov  5 12:47:17.021: INFO: created pod
Nov  5 12:47:17.021: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4783" to be "Succeeded or Failed"
Nov  5 12:47:17.025: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.401017ms
Nov  5 12:47:19.030: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008327433s
Nov  5 12:47:21.029: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007743598s
STEP: Saw pod success 11/05/22 12:47:21.029
Nov  5 12:47:21.029: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Nov  5 12:47:51.029: INFO: polling logs
Nov  5 12:47:51.042: INFO: Pod logs: 
I1105 12:47:17.826918       1 log.go:195] OK: Got token
I1105 12:47:17.826960       1 log.go:195] validating with in-cluster discovery
I1105 12:47:17.827193       1 log.go:195] OK: got issuer https://kubernetes.default.svc
I1105 12:47:17.827211       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-4783:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1667653037, NotBefore:1667652437, IssuedAt:1667652437, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4783", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e4e07b8d-1d91-4be5-9c8a-2ac6c2105ada"}}}
I1105 12:47:17.836041       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
I1105 12:47:17.841331       1 log.go:195] OK: Validated signature on JWT
I1105 12:47:17.841423       1 log.go:195] OK: Got valid claims from token!
I1105 12:47:17.841447       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-4783:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1667653037, NotBefore:1667652437, IssuedAt:1667652437, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4783", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e4e07b8d-1d91-4be5-9c8a-2ac6c2105ada"}}}

Nov  5 12:47:51.042: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov  5 12:47:51.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4783" for this suite. 11/05/22 12:47:51.053
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":189,"skipped":3427,"failed":0}
------------------------------
• [SLOW TEST] [34.075 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:47:16.986
    Nov  5 12:47:16.986: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename svcaccounts 11/05/22 12:47:16.987
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:17.001
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:17.005
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Nov  5 12:47:17.021: INFO: created pod
    Nov  5 12:47:17.021: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4783" to be "Succeeded or Failed"
    Nov  5 12:47:17.025: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.401017ms
    Nov  5 12:47:19.030: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008327433s
    Nov  5 12:47:21.029: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007743598s
    STEP: Saw pod success 11/05/22 12:47:21.029
    Nov  5 12:47:21.029: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Nov  5 12:47:51.029: INFO: polling logs
    Nov  5 12:47:51.042: INFO: Pod logs: 
    I1105 12:47:17.826918       1 log.go:195] OK: Got token
    I1105 12:47:17.826960       1 log.go:195] validating with in-cluster discovery
    I1105 12:47:17.827193       1 log.go:195] OK: got issuer https://kubernetes.default.svc
    I1105 12:47:17.827211       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-4783:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1667653037, NotBefore:1667652437, IssuedAt:1667652437, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4783", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e4e07b8d-1d91-4be5-9c8a-2ac6c2105ada"}}}
    I1105 12:47:17.836041       1 log.go:195] OK: Constructed OIDC provider for issuer https://kubernetes.default.svc
    I1105 12:47:17.841331       1 log.go:195] OK: Validated signature on JWT
    I1105 12:47:17.841423       1 log.go:195] OK: Got valid claims from token!
    I1105 12:47:17.841447       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://kubernetes.default.svc", Subject:"system:serviceaccount:svcaccounts-4783:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1667653037, NotBefore:1667652437, IssuedAt:1667652437, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4783", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"e4e07b8d-1d91-4be5-9c8a-2ac6c2105ada"}}}

    Nov  5 12:47:51.042: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov  5 12:47:51.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4783" for this suite. 11/05/22 12:47:51.053
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:47:51.062
Nov  5 12:47:51.062: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename disruption 11/05/22 12:47:51.063
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:51.075
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:51.079
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 11/05/22 12:47:51.089
STEP: Waiting for all pods to be running 11/05/22 12:47:51.126
Nov  5 12:47:51.131: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov  5 12:47:53.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-6979" for this suite. 11/05/22 12:47:53.144
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":190,"skipped":3436,"failed":0}
------------------------------
• [2.088 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:47:51.062
    Nov  5 12:47:51.062: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename disruption 11/05/22 12:47:51.063
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:51.075
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:51.079
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 11/05/22 12:47:51.089
    STEP: Waiting for all pods to be running 11/05/22 12:47:51.126
    Nov  5 12:47:51.131: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov  5 12:47:53.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-6979" for this suite. 11/05/22 12:47:53.144
  << End Captured GinkgoWriter Output
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:47:53.15
Nov  5 12:47:53.150: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename events 11/05/22 12:47:53.151
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:53.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:53.167
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 11/05/22 12:47:53.17
Nov  5 12:47:53.177: INFO: created test-event-1
Nov  5 12:47:53.182: INFO: created test-event-2
Nov  5 12:47:53.188: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 11/05/22 12:47:53.188
STEP: delete collection of events 11/05/22 12:47:53.192
Nov  5 12:47:53.192: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 11/05/22 12:47:53.213
Nov  5 12:47:53.213: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Nov  5 12:47:53.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5717" for this suite. 11/05/22 12:47:53.221
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":191,"skipped":3436,"failed":0}
------------------------------
• [0.077 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:47:53.15
    Nov  5 12:47:53.150: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename events 11/05/22 12:47:53.151
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:53.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:53.167
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 11/05/22 12:47:53.17
    Nov  5 12:47:53.177: INFO: created test-event-1
    Nov  5 12:47:53.182: INFO: created test-event-2
    Nov  5 12:47:53.188: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 11/05/22 12:47:53.188
    STEP: delete collection of events 11/05/22 12:47:53.192
    Nov  5 12:47:53.192: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 11/05/22 12:47:53.213
    Nov  5 12:47:53.213: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Nov  5 12:47:53.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-5717" for this suite. 11/05/22 12:47:53.221
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:47:53.231
Nov  5 12:47:53.231: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename var-expansion 11/05/22 12:47:53.232
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:53.244
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:53.248
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 11/05/22 12:47:53.251
Nov  5 12:47:53.259: INFO: Waiting up to 5m0s for pod "var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab" in namespace "var-expansion-7038" to be "Succeeded or Failed"
Nov  5 12:47:53.268: INFO: Pod "var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab": Phase="Pending", Reason="", readiness=false. Elapsed: 9.484921ms
Nov  5 12:47:55.273: INFO: Pod "var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013913252s
Nov  5 12:47:57.273: INFO: Pod "var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013963004s
STEP: Saw pod success 11/05/22 12:47:57.273
Nov  5 12:47:57.273: INFO: Pod "var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab" satisfied condition "Succeeded or Failed"
Nov  5 12:47:57.276: INFO: Trying to get logs from node ip-172-31-41-19 pod var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab container dapi-container: <nil>
STEP: delete the pod 11/05/22 12:47:57.283
Nov  5 12:47:57.295: INFO: Waiting for pod var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab to disappear
Nov  5 12:47:57.297: INFO: Pod var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov  5 12:47:57.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7038" for this suite. 11/05/22 12:47:57.301
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":192,"skipped":3479,"failed":0}
------------------------------
• [4.076 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:47:53.231
    Nov  5 12:47:53.231: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename var-expansion 11/05/22 12:47:53.232
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:53.244
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:53.248
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 11/05/22 12:47:53.251
    Nov  5 12:47:53.259: INFO: Waiting up to 5m0s for pod "var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab" in namespace "var-expansion-7038" to be "Succeeded or Failed"
    Nov  5 12:47:53.268: INFO: Pod "var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab": Phase="Pending", Reason="", readiness=false. Elapsed: 9.484921ms
    Nov  5 12:47:55.273: INFO: Pod "var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013913252s
    Nov  5 12:47:57.273: INFO: Pod "var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013963004s
    STEP: Saw pod success 11/05/22 12:47:57.273
    Nov  5 12:47:57.273: INFO: Pod "var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab" satisfied condition "Succeeded or Failed"
    Nov  5 12:47:57.276: INFO: Trying to get logs from node ip-172-31-41-19 pod var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab container dapi-container: <nil>
    STEP: delete the pod 11/05/22 12:47:57.283
    Nov  5 12:47:57.295: INFO: Waiting for pod var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab to disappear
    Nov  5 12:47:57.297: INFO: Pod var-expansion-df58de72-e5a7-46a1-8816-12dd3193a4ab no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov  5 12:47:57.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-7038" for this suite. 11/05/22 12:47:57.301
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:47:57.309
Nov  5 12:47:57.309: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename csistoragecapacity 11/05/22 12:47:57.309
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:57.321
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:57.325
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 11/05/22 12:47:57.329
STEP: getting /apis/storage.k8s.io 11/05/22 12:47:57.332
STEP: getting /apis/storage.k8s.io/v1 11/05/22 12:47:57.333
STEP: creating 11/05/22 12:47:57.337
STEP: watching 11/05/22 12:47:57.353
Nov  5 12:47:57.353: INFO: starting watch
STEP: getting 11/05/22 12:47:57.361
STEP: listing in namespace 11/05/22 12:47:57.364
STEP: listing across namespaces 11/05/22 12:47:57.368
STEP: patching 11/05/22 12:47:57.371
STEP: updating 11/05/22 12:47:57.376
Nov  5 12:47:57.382: INFO: waiting for watch events with expected annotations in namespace
Nov  5 12:47:57.382: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 11/05/22 12:47:57.382
STEP: deleting a collection 11/05/22 12:47:57.394
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Nov  5 12:47:57.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-3023" for this suite. 11/05/22 12:47:57.413
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":193,"skipped":3531,"failed":0}
------------------------------
• [0.110 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:47:57.309
    Nov  5 12:47:57.309: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename csistoragecapacity 11/05/22 12:47:57.309
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:57.321
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:57.325
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 11/05/22 12:47:57.329
    STEP: getting /apis/storage.k8s.io 11/05/22 12:47:57.332
    STEP: getting /apis/storage.k8s.io/v1 11/05/22 12:47:57.333
    STEP: creating 11/05/22 12:47:57.337
    STEP: watching 11/05/22 12:47:57.353
    Nov  5 12:47:57.353: INFO: starting watch
    STEP: getting 11/05/22 12:47:57.361
    STEP: listing in namespace 11/05/22 12:47:57.364
    STEP: listing across namespaces 11/05/22 12:47:57.368
    STEP: patching 11/05/22 12:47:57.371
    STEP: updating 11/05/22 12:47:57.376
    Nov  5 12:47:57.382: INFO: waiting for watch events with expected annotations in namespace
    Nov  5 12:47:57.382: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 11/05/22 12:47:57.382
    STEP: deleting a collection 11/05/22 12:47:57.394
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Nov  5 12:47:57.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-3023" for this suite. 11/05/22 12:47:57.413
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:47:57.42
Nov  5 12:47:57.420: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename dns 11/05/22 12:47:57.421
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:57.434
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:57.438
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 11/05/22 12:47:57.441
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6910.svc.cluster.local;sleep 1; done
 11/05/22 12:47:57.447
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6910.svc.cluster.local;sleep 1; done
 11/05/22 12:47:57.447
STEP: creating a pod to probe DNS 11/05/22 12:47:57.447
STEP: submitting the pod to kubernetes 11/05/22 12:47:57.447
Nov  5 12:47:57.460: INFO: Waiting up to 15m0s for pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7" in namespace "dns-6910" to be "running"
Nov  5 12:47:57.466: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.433149ms
Nov  5 12:47:59.470: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010149729s
Nov  5 12:48:01.470: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010283527s
Nov  5 12:48:03.472: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012659967s
Nov  5 12:48:05.470: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7": Phase="Running", Reason="", readiness=true. Elapsed: 8.010494464s
Nov  5 12:48:05.470: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7" satisfied condition "running"
STEP: retrieving the pod 11/05/22 12:48:05.47
STEP: looking for the results for each expected name from probers 11/05/22 12:48:05.474
Nov  5 12:48:05.480: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
Nov  5 12:48:05.485: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
Nov  5 12:48:05.489: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
Nov  5 12:48:05.493: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
Nov  5 12:48:05.497: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
Nov  5 12:48:05.502: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
Nov  5 12:48:05.506: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
Nov  5 12:48:05.510: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
Nov  5 12:48:05.510: INFO: Lookups using dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6910.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6910.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local jessie_udp@dns-test-service-2.dns-6910.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6910.svc.cluster.local]

Nov  5 12:48:10.549: INFO: DNS probes using dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7 succeeded

STEP: deleting the pod 11/05/22 12:48:10.549
STEP: deleting the test headless service 11/05/22 12:48:10.568
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov  5 12:48:10.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6910" for this suite. 11/05/22 12:48:10.598
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":194,"skipped":3547,"failed":0}
------------------------------
• [SLOW TEST] [13.185 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:47:57.42
    Nov  5 12:47:57.420: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename dns 11/05/22 12:47:57.421
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:47:57.434
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:47:57.438
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 11/05/22 12:47:57.441
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6910.svc.cluster.local;sleep 1; done
     11/05/22 12:47:57.447
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6910.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6910.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6910.svc.cluster.local;sleep 1; done
     11/05/22 12:47:57.447
    STEP: creating a pod to probe DNS 11/05/22 12:47:57.447
    STEP: submitting the pod to kubernetes 11/05/22 12:47:57.447
    Nov  5 12:47:57.460: INFO: Waiting up to 15m0s for pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7" in namespace "dns-6910" to be "running"
    Nov  5 12:47:57.466: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.433149ms
    Nov  5 12:47:59.470: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010149729s
    Nov  5 12:48:01.470: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010283527s
    Nov  5 12:48:03.472: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012659967s
    Nov  5 12:48:05.470: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7": Phase="Running", Reason="", readiness=true. Elapsed: 8.010494464s
    Nov  5 12:48:05.470: INFO: Pod "dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7" satisfied condition "running"
    STEP: retrieving the pod 11/05/22 12:48:05.47
    STEP: looking for the results for each expected name from probers 11/05/22 12:48:05.474
    Nov  5 12:48:05.480: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
    Nov  5 12:48:05.485: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
    Nov  5 12:48:05.489: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
    Nov  5 12:48:05.493: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
    Nov  5 12:48:05.497: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
    Nov  5 12:48:05.502: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
    Nov  5 12:48:05.506: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
    Nov  5 12:48:05.510: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6910.svc.cluster.local from pod dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7: the server could not find the requested resource (get pods dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7)
    Nov  5 12:48:05.510: INFO: Lookups using dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6910.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6910.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6910.svc.cluster.local jessie_udp@dns-test-service-2.dns-6910.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6910.svc.cluster.local]

    Nov  5 12:48:10.549: INFO: DNS probes using dns-6910/dns-test-815b4d3b-40a1-49ca-89ff-da8efee9e5a7 succeeded

    STEP: deleting the pod 11/05/22 12:48:10.549
    STEP: deleting the test headless service 11/05/22 12:48:10.568
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov  5 12:48:10.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6910" for this suite. 11/05/22 12:48:10.598
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:10.606
Nov  5 12:48:10.606: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename security-context-test 11/05/22 12:48:10.606
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:10.62
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:10.625
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Nov  5 12:48:10.636: INFO: Waiting up to 5m0s for pod "busybox-user-65534-08625eb5-9632-48e7-bb2b-f3502fbad3c2" in namespace "security-context-test-960" to be "Succeeded or Failed"
Nov  5 12:48:10.640: INFO: Pod "busybox-user-65534-08625eb5-9632-48e7-bb2b-f3502fbad3c2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.538771ms
Nov  5 12:48:12.645: INFO: Pod "busybox-user-65534-08625eb5-9632-48e7-bb2b-f3502fbad3c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008779703s
Nov  5 12:48:14.646: INFO: Pod "busybox-user-65534-08625eb5-9632-48e7-bb2b-f3502fbad3c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009699222s
Nov  5 12:48:14.646: INFO: Pod "busybox-user-65534-08625eb5-9632-48e7-bb2b-f3502fbad3c2" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov  5 12:48:14.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-960" for this suite. 11/05/22 12:48:14.65
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":195,"skipped":3555,"failed":0}
------------------------------
• [4.051 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:10.606
    Nov  5 12:48:10.606: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename security-context-test 11/05/22 12:48:10.606
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:10.62
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:10.625
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Nov  5 12:48:10.636: INFO: Waiting up to 5m0s for pod "busybox-user-65534-08625eb5-9632-48e7-bb2b-f3502fbad3c2" in namespace "security-context-test-960" to be "Succeeded or Failed"
    Nov  5 12:48:10.640: INFO: Pod "busybox-user-65534-08625eb5-9632-48e7-bb2b-f3502fbad3c2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.538771ms
    Nov  5 12:48:12.645: INFO: Pod "busybox-user-65534-08625eb5-9632-48e7-bb2b-f3502fbad3c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008779703s
    Nov  5 12:48:14.646: INFO: Pod "busybox-user-65534-08625eb5-9632-48e7-bb2b-f3502fbad3c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009699222s
    Nov  5 12:48:14.646: INFO: Pod "busybox-user-65534-08625eb5-9632-48e7-bb2b-f3502fbad3c2" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov  5 12:48:14.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-960" for this suite. 11/05/22 12:48:14.65
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:14.657
Nov  5 12:48:14.657: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 12:48:14.657
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:14.669
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:14.674
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-9015/configmap-test-536dcfae-95c1-42f9-b600-ae62da1deae4 11/05/22 12:48:14.678
STEP: Creating a pod to test consume configMaps 11/05/22 12:48:14.682
Nov  5 12:48:14.694: INFO: Waiting up to 5m0s for pod "pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982" in namespace "configmap-9015" to be "Succeeded or Failed"
Nov  5 12:48:14.697: INFO: Pod "pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.334191ms
Nov  5 12:48:16.701: INFO: Pod "pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007429986s
Nov  5 12:48:18.701: INFO: Pod "pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007794425s
STEP: Saw pod success 11/05/22 12:48:18.702
Nov  5 12:48:18.702: INFO: Pod "pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982" satisfied condition "Succeeded or Failed"
Nov  5 12:48:18.705: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982 container env-test: <nil>
STEP: delete the pod 11/05/22 12:48:18.711
Nov  5 12:48:18.721: INFO: Waiting for pod pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982 to disappear
Nov  5 12:48:18.724: INFO: Pod pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 12:48:18.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9015" for this suite. 11/05/22 12:48:18.728
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":196,"skipped":3557,"failed":0}
------------------------------
• [4.078 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:14.657
    Nov  5 12:48:14.657: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 12:48:14.657
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:14.669
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:14.674
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-9015/configmap-test-536dcfae-95c1-42f9-b600-ae62da1deae4 11/05/22 12:48:14.678
    STEP: Creating a pod to test consume configMaps 11/05/22 12:48:14.682
    Nov  5 12:48:14.694: INFO: Waiting up to 5m0s for pod "pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982" in namespace "configmap-9015" to be "Succeeded or Failed"
    Nov  5 12:48:14.697: INFO: Pod "pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982": Phase="Pending", Reason="", readiness=false. Elapsed: 3.334191ms
    Nov  5 12:48:16.701: INFO: Pod "pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007429986s
    Nov  5 12:48:18.701: INFO: Pod "pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007794425s
    STEP: Saw pod success 11/05/22 12:48:18.702
    Nov  5 12:48:18.702: INFO: Pod "pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982" satisfied condition "Succeeded or Failed"
    Nov  5 12:48:18.705: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982 container env-test: <nil>
    STEP: delete the pod 11/05/22 12:48:18.711
    Nov  5 12:48:18.721: INFO: Waiting for pod pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982 to disappear
    Nov  5 12:48:18.724: INFO: Pod pod-configmaps-9c4f9c6c-d157-47a5-8813-ca7f7dc29982 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 12:48:18.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9015" for this suite. 11/05/22 12:48:18.728
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:18.736
Nov  5 12:48:18.736: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:48:18.736
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:18.749
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:18.754
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-f99130e2-96d4-46ce-b2e2-c3481dafc4e6 11/05/22 12:48:18.757
STEP: Creating a pod to test consume configMaps 11/05/22 12:48:18.761
Nov  5 12:48:18.771: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed" in namespace "projected-5156" to be "Succeeded or Failed"
Nov  5 12:48:18.776: INFO: Pod "pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed": Phase="Pending", Reason="", readiness=false. Elapsed: 5.193147ms
Nov  5 12:48:20.780: INFO: Pod "pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009112008s
Nov  5 12:48:22.780: INFO: Pod "pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00944775s
STEP: Saw pod success 11/05/22 12:48:22.78
Nov  5 12:48:22.780: INFO: Pod "pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed" satisfied condition "Succeeded or Failed"
Nov  5 12:48:22.784: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:48:22.79
Nov  5 12:48:22.803: INFO: Waiting for pod pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed to disappear
Nov  5 12:48:22.806: INFO: Pod pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov  5 12:48:22.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5156" for this suite. 11/05/22 12:48:22.81
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":197,"skipped":3561,"failed":0}
------------------------------
• [4.081 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:18.736
    Nov  5 12:48:18.736: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:48:18.736
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:18.749
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:18.754
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-f99130e2-96d4-46ce-b2e2-c3481dafc4e6 11/05/22 12:48:18.757
    STEP: Creating a pod to test consume configMaps 11/05/22 12:48:18.761
    Nov  5 12:48:18.771: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed" in namespace "projected-5156" to be "Succeeded or Failed"
    Nov  5 12:48:18.776: INFO: Pod "pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed": Phase="Pending", Reason="", readiness=false. Elapsed: 5.193147ms
    Nov  5 12:48:20.780: INFO: Pod "pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009112008s
    Nov  5 12:48:22.780: INFO: Pod "pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00944775s
    STEP: Saw pod success 11/05/22 12:48:22.78
    Nov  5 12:48:22.780: INFO: Pod "pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed" satisfied condition "Succeeded or Failed"
    Nov  5 12:48:22.784: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:48:22.79
    Nov  5 12:48:22.803: INFO: Waiting for pod pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed to disappear
    Nov  5 12:48:22.806: INFO: Pod pod-projected-configmaps-4ba568e6-e5dc-4700-9942-7acd5e0e34ed no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov  5 12:48:22.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5156" for this suite. 11/05/22 12:48:22.81
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:22.818
Nov  5 12:48:22.818: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 12:48:22.818
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:22.831
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:22.836
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 12:48:22.852
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:48:23.115
STEP: Deploying the webhook pod 11/05/22 12:48:23.122
STEP: Wait for the deployment to be ready 11/05/22 12:48:23.134
Nov  5 12:48:23.148: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 12:48:25.16
STEP: Verifying the service has paired with the endpoint 11/05/22 12:48:25.169
Nov  5 12:48:26.170: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 11/05/22 12:48:26.174
STEP: create a pod that should be denied by the webhook 11/05/22 12:48:26.189
STEP: create a pod that causes the webhook to hang 11/05/22 12:48:26.198
STEP: create a configmap that should be denied by the webhook 11/05/22 12:48:36.211
STEP: create a configmap that should be admitted by the webhook 11/05/22 12:48:36.219
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 11/05/22 12:48:36.229
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 11/05/22 12:48:36.237
STEP: create a namespace that bypass the webhook 11/05/22 12:48:36.243
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 11/05/22 12:48:36.25
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:48:36.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7634" for this suite. 11/05/22 12:48:36.279
STEP: Destroying namespace "webhook-7634-markers" for this suite. 11/05/22 12:48:36.285
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":198,"skipped":3565,"failed":0}
------------------------------
• [SLOW TEST] [13.516 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:22.818
    Nov  5 12:48:22.818: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 12:48:22.818
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:22.831
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:22.836
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 12:48:22.852
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 12:48:23.115
    STEP: Deploying the webhook pod 11/05/22 12:48:23.122
    STEP: Wait for the deployment to be ready 11/05/22 12:48:23.134
    Nov  5 12:48:23.148: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 12:48:25.16
    STEP: Verifying the service has paired with the endpoint 11/05/22 12:48:25.169
    Nov  5 12:48:26.170: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 11/05/22 12:48:26.174
    STEP: create a pod that should be denied by the webhook 11/05/22 12:48:26.189
    STEP: create a pod that causes the webhook to hang 11/05/22 12:48:26.198
    STEP: create a configmap that should be denied by the webhook 11/05/22 12:48:36.211
    STEP: create a configmap that should be admitted by the webhook 11/05/22 12:48:36.219
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 11/05/22 12:48:36.229
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 11/05/22 12:48:36.237
    STEP: create a namespace that bypass the webhook 11/05/22 12:48:36.243
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 11/05/22 12:48:36.25
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:48:36.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7634" for this suite. 11/05/22 12:48:36.279
    STEP: Destroying namespace "webhook-7634-markers" for this suite. 11/05/22 12:48:36.285
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:36.335
Nov  5 12:48:36.335: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename watch 11/05/22 12:48:36.335
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:36.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:36.36
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 11/05/22 12:48:36.364
STEP: creating a new configmap 11/05/22 12:48:36.365
STEP: modifying the configmap once 11/05/22 12:48:36.375
STEP: closing the watch once it receives two notifications 11/05/22 12:48:36.384
Nov  5 12:48:36.384: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7869  78524e4c-7197-454f-a539-d2f0fd421948 23896 0 2022-11-05 12:48:36 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-05 12:48:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 12:48:36.384: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7869  78524e4c-7197-454f-a539-d2f0fd421948 23897 0 2022-11-05 12:48:36 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-05 12:48:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 11/05/22 12:48:36.384
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 11/05/22 12:48:36.392
STEP: deleting the configmap 11/05/22 12:48:36.394
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 11/05/22 12:48:36.402
Nov  5 12:48:36.402: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7869  78524e4c-7197-454f-a539-d2f0fd421948 23898 0 2022-11-05 12:48:36 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-05 12:48:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 12:48:36.403: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7869  78524e4c-7197-454f-a539-d2f0fd421948 23899 0 2022-11-05 12:48:36 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-05 12:48:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov  5 12:48:36.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7869" for this suite. 11/05/22 12:48:36.409
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":199,"skipped":3567,"failed":0}
------------------------------
• [0.081 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:36.335
    Nov  5 12:48:36.335: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename watch 11/05/22 12:48:36.335
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:36.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:36.36
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 11/05/22 12:48:36.364
    STEP: creating a new configmap 11/05/22 12:48:36.365
    STEP: modifying the configmap once 11/05/22 12:48:36.375
    STEP: closing the watch once it receives two notifications 11/05/22 12:48:36.384
    Nov  5 12:48:36.384: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7869  78524e4c-7197-454f-a539-d2f0fd421948 23896 0 2022-11-05 12:48:36 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-05 12:48:36 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 12:48:36.384: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7869  78524e4c-7197-454f-a539-d2f0fd421948 23897 0 2022-11-05 12:48:36 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-05 12:48:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 11/05/22 12:48:36.384
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 11/05/22 12:48:36.392
    STEP: deleting the configmap 11/05/22 12:48:36.394
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 11/05/22 12:48:36.402
    Nov  5 12:48:36.402: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7869  78524e4c-7197-454f-a539-d2f0fd421948 23898 0 2022-11-05 12:48:36 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-05 12:48:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 12:48:36.403: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7869  78524e4c-7197-454f-a539-d2f0fd421948 23899 0 2022-11-05 12:48:36 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2022-11-05 12:48:36 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov  5 12:48:36.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-7869" for this suite. 11/05/22 12:48:36.409
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:36.417
Nov  5 12:48:36.417: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 12:48:36.418
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:36.433
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:36.436
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-423281e9-56a9-44a2-92dc-2d869e0cf0bd 11/05/22 12:48:36.44
STEP: Creating a pod to test consume secrets 11/05/22 12:48:36.446
Nov  5 12:48:36.454: INFO: Waiting up to 5m0s for pod "pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7" in namespace "secrets-6303" to be "Succeeded or Failed"
Nov  5 12:48:36.458: INFO: Pod "pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.402446ms
Nov  5 12:48:38.463: INFO: Pod "pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00872771s
Nov  5 12:48:40.463: INFO: Pod "pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00878941s
STEP: Saw pod success 11/05/22 12:48:40.463
Nov  5 12:48:40.463: INFO: Pod "pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7" satisfied condition "Succeeded or Failed"
Nov  5 12:48:40.466: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7 container secret-env-test: <nil>
STEP: delete the pod 11/05/22 12:48:40.473
Nov  5 12:48:40.486: INFO: Waiting for pod pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7 to disappear
Nov  5 12:48:40.489: INFO: Pod pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov  5 12:48:40.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6303" for this suite. 11/05/22 12:48:40.493
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":200,"skipped":3575,"failed":0}
------------------------------
• [4.083 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:36.417
    Nov  5 12:48:36.417: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 12:48:36.418
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:36.433
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:36.436
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-423281e9-56a9-44a2-92dc-2d869e0cf0bd 11/05/22 12:48:36.44
    STEP: Creating a pod to test consume secrets 11/05/22 12:48:36.446
    Nov  5 12:48:36.454: INFO: Waiting up to 5m0s for pod "pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7" in namespace "secrets-6303" to be "Succeeded or Failed"
    Nov  5 12:48:36.458: INFO: Pod "pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.402446ms
    Nov  5 12:48:38.463: INFO: Pod "pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00872771s
    Nov  5 12:48:40.463: INFO: Pod "pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00878941s
    STEP: Saw pod success 11/05/22 12:48:40.463
    Nov  5 12:48:40.463: INFO: Pod "pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7" satisfied condition "Succeeded or Failed"
    Nov  5 12:48:40.466: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7 container secret-env-test: <nil>
    STEP: delete the pod 11/05/22 12:48:40.473
    Nov  5 12:48:40.486: INFO: Waiting for pod pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7 to disappear
    Nov  5 12:48:40.489: INFO: Pod pod-secrets-16b748b5-7a30-453d-bfb0-37222344e7c7 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 12:48:40.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6303" for this suite. 11/05/22 12:48:40.493
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:40.505
Nov  5 12:48:40.505: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 12:48:40.506
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:40.519
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:40.525
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2766 11/05/22 12:48:40.528
STEP: changing the ExternalName service to type=ClusterIP 11/05/22 12:48:40.536
STEP: creating replication controller externalname-service in namespace services-2766 11/05/22 12:48:40.618
I1105 12:48:40.627936      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-2766, replica count: 2
I1105 12:48:43.679024      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 12:48:43.679: INFO: Creating new exec pod
Nov  5 12:48:43.685: INFO: Waiting up to 5m0s for pod "execpodv245k" in namespace "services-2766" to be "running"
Nov  5 12:48:43.691: INFO: Pod "execpodv245k": Phase="Pending", Reason="", readiness=false. Elapsed: 5.581837ms
Nov  5 12:48:45.699: INFO: Pod "execpodv245k": Phase="Running", Reason="", readiness=true. Elapsed: 2.013942992s
Nov  5 12:48:45.699: INFO: Pod "execpodv245k" satisfied condition "running"
Nov  5 12:48:46.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2766 exec execpodv245k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Nov  5 12:48:46.852: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  5 12:48:46.852: INFO: stdout: "externalname-service-t9vwc"
Nov  5 12:48:46.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2766 exec execpodv245k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
Nov  5 12:48:46.993: INFO: stderr: "+ nc -v -t -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Nov  5 12:48:46.993: INFO: stdout: ""
Nov  5 12:48:47.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2766 exec execpodv245k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
Nov  5 12:48:48.125: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n"
Nov  5 12:48:48.125: INFO: stdout: ""
Nov  5 12:48:48.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2766 exec execpodv245k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
Nov  5 12:48:49.108: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n"
Nov  5 12:48:49.108: INFO: stdout: ""
Nov  5 12:48:49.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2766 exec execpodv245k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
Nov  5 12:48:50.131: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n"
Nov  5 12:48:50.131: INFO: stdout: "externalname-service-t9vwc"
Nov  5 12:48:50.131: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 12:48:50.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2766" for this suite. 11/05/22 12:48:50.168
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":201,"skipped":3622,"failed":0}
------------------------------
• [SLOW TEST] [9.671 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:40.505
    Nov  5 12:48:40.505: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 12:48:40.506
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:40.519
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:40.525
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-2766 11/05/22 12:48:40.528
    STEP: changing the ExternalName service to type=ClusterIP 11/05/22 12:48:40.536
    STEP: creating replication controller externalname-service in namespace services-2766 11/05/22 12:48:40.618
    I1105 12:48:40.627936      20 runners.go:193] Created replication controller with name: externalname-service, namespace: services-2766, replica count: 2
    I1105 12:48:43.679024      20 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 12:48:43.679: INFO: Creating new exec pod
    Nov  5 12:48:43.685: INFO: Waiting up to 5m0s for pod "execpodv245k" in namespace "services-2766" to be "running"
    Nov  5 12:48:43.691: INFO: Pod "execpodv245k": Phase="Pending", Reason="", readiness=false. Elapsed: 5.581837ms
    Nov  5 12:48:45.699: INFO: Pod "execpodv245k": Phase="Running", Reason="", readiness=true. Elapsed: 2.013942992s
    Nov  5 12:48:45.699: INFO: Pod "execpodv245k" satisfied condition "running"
    Nov  5 12:48:46.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2766 exec execpodv245k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Nov  5 12:48:46.852: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Nov  5 12:48:46.852: INFO: stdout: "externalname-service-t9vwc"
    Nov  5 12:48:46.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2766 exec execpodv245k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
    Nov  5 12:48:46.993: INFO: stderr: "+ nc -v -t -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Nov  5 12:48:46.993: INFO: stdout: ""
    Nov  5 12:48:47.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2766 exec execpodv245k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
    Nov  5 12:48:48.125: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n"
    Nov  5 12:48:48.125: INFO: stdout: ""
    Nov  5 12:48:48.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2766 exec execpodv245k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
    Nov  5 12:48:49.108: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n"
    Nov  5 12:48:49.108: INFO: stdout: ""
    Nov  5 12:48:49.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2766 exec execpodv245k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.28 80'
    Nov  5 12:48:50.131: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.28 80\nConnection to 10.152.183.28 80 port [tcp/http] succeeded!\n"
    Nov  5 12:48:50.131: INFO: stdout: "externalname-service-t9vwc"
    Nov  5 12:48:50.131: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 12:48:50.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2766" for this suite. 11/05/22 12:48:50.168
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:50.177
Nov  5 12:48:50.177: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 12:48:50.178
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:50.194
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:50.199
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 11/05/22 12:48:50.203
STEP: submitting the pod to kubernetes 11/05/22 12:48:50.204
Nov  5 12:48:50.212: INFO: Waiting up to 5m0s for pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1" in namespace "pods-4601" to be "running and ready"
Nov  5 12:48:50.218: INFO: Pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.262872ms
Nov  5 12:48:50.218: INFO: The phase of Pod pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:48:52.223: INFO: Pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1": Phase="Running", Reason="", readiness=true. Elapsed: 2.010684946s
Nov  5 12:48:52.223: INFO: The phase of Pod pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1 is Running (Ready = true)
Nov  5 12:48:52.223: INFO: Pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 11/05/22 12:48:52.226
STEP: updating the pod 11/05/22 12:48:52.229
Nov  5 12:48:52.741: INFO: Successfully updated pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1"
Nov  5 12:48:52.741: INFO: Waiting up to 5m0s for pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1" in namespace "pods-4601" to be "running"
Nov  5 12:48:52.745: INFO: Pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1": Phase="Running", Reason="", readiness=true. Elapsed: 3.704594ms
Nov  5 12:48:52.745: INFO: Pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 11/05/22 12:48:52.745
Nov  5 12:48:52.748: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov  5 12:48:52.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4601" for this suite. 11/05/22 12:48:52.752
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":202,"skipped":3663,"failed":0}
------------------------------
• [2.581 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:50.177
    Nov  5 12:48:50.177: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 12:48:50.178
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:50.194
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:50.199
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 11/05/22 12:48:50.203
    STEP: submitting the pod to kubernetes 11/05/22 12:48:50.204
    Nov  5 12:48:50.212: INFO: Waiting up to 5m0s for pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1" in namespace "pods-4601" to be "running and ready"
    Nov  5 12:48:50.218: INFO: Pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.262872ms
    Nov  5 12:48:50.218: INFO: The phase of Pod pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:48:52.223: INFO: Pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1": Phase="Running", Reason="", readiness=true. Elapsed: 2.010684946s
    Nov  5 12:48:52.223: INFO: The phase of Pod pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1 is Running (Ready = true)
    Nov  5 12:48:52.223: INFO: Pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 11/05/22 12:48:52.226
    STEP: updating the pod 11/05/22 12:48:52.229
    Nov  5 12:48:52.741: INFO: Successfully updated pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1"
    Nov  5 12:48:52.741: INFO: Waiting up to 5m0s for pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1" in namespace "pods-4601" to be "running"
    Nov  5 12:48:52.745: INFO: Pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1": Phase="Running", Reason="", readiness=true. Elapsed: 3.704594ms
    Nov  5 12:48:52.745: INFO: Pod "pod-update-4b70cb08-f41a-4ecd-a435-05ae8fe810c1" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 11/05/22 12:48:52.745
    Nov  5 12:48:52.748: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov  5 12:48:52.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4601" for this suite. 11/05/22 12:48:52.752
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:52.759
Nov  5 12:48:52.759: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 12:48:52.759
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:52.771
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:52.775
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-dbf01014-b233-47f7-b20b-1b1dec51fc7c 11/05/22 12:48:52.779
STEP: Creating a pod to test consume configMaps 11/05/22 12:48:52.785
Nov  5 12:48:52.792: INFO: Waiting up to 5m0s for pod "pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3" in namespace "configmap-4740" to be "Succeeded or Failed"
Nov  5 12:48:52.796: INFO: Pod "pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.466224ms
Nov  5 12:48:54.801: INFO: Pod "pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008953379s
Nov  5 12:48:56.801: INFO: Pod "pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00919494s
STEP: Saw pod success 11/05/22 12:48:56.801
Nov  5 12:48:56.801: INFO: Pod "pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3" satisfied condition "Succeeded or Failed"
Nov  5 12:48:56.805: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3 container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:48:56.811
Nov  5 12:48:56.825: INFO: Waiting for pod pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3 to disappear
Nov  5 12:48:56.830: INFO: Pod pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 12:48:56.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4740" for this suite. 11/05/22 12:48:56.834
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":203,"skipped":3665,"failed":0}
------------------------------
• [4.082 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:52.759
    Nov  5 12:48:52.759: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 12:48:52.759
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:52.771
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:52.775
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-dbf01014-b233-47f7-b20b-1b1dec51fc7c 11/05/22 12:48:52.779
    STEP: Creating a pod to test consume configMaps 11/05/22 12:48:52.785
    Nov  5 12:48:52.792: INFO: Waiting up to 5m0s for pod "pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3" in namespace "configmap-4740" to be "Succeeded or Failed"
    Nov  5 12:48:52.796: INFO: Pod "pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.466224ms
    Nov  5 12:48:54.801: INFO: Pod "pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008953379s
    Nov  5 12:48:56.801: INFO: Pod "pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00919494s
    STEP: Saw pod success 11/05/22 12:48:56.801
    Nov  5 12:48:56.801: INFO: Pod "pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3" satisfied condition "Succeeded or Failed"
    Nov  5 12:48:56.805: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3 container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:48:56.811
    Nov  5 12:48:56.825: INFO: Waiting for pod pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3 to disappear
    Nov  5 12:48:56.830: INFO: Pod pod-configmaps-c0842b92-2b14-469e-b1f2-cb1925df3cc3 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 12:48:56.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-4740" for this suite. 11/05/22 12:48:56.834
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:56.842
Nov  5 12:48:56.842: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename deployment 11/05/22 12:48:56.843
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:56.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:56.859
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Nov  5 12:48:56.863: INFO: Creating simple deployment test-new-deployment
Nov  5 12:48:56.874: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource 11/05/22 12:48:58.889
STEP: updating a scale subresource 11/05/22 12:48:58.892
STEP: verifying the deployment Spec.Replicas was modified 11/05/22 12:48:58.9
STEP: Patch a scale subresource 11/05/22 12:48:58.905
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov  5 12:48:58.926: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-6121  781d0921-ce90-45bc-b931-772ca190d680 24203 3 2022-11-05 12:48:56 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-11-05 12:48:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002749ed8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-05 12:48:58 +0000 UTC,LastTransitionTime:2022-11-05 12:48:58 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-11-05 12:48:58 +0000 UTC,LastTransitionTime:2022-11-05 12:48:56 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  5 12:48:58.930: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-6121  592111db-d9e0-42e7-b9bf-7234565c187b 24208 2 2022-11-05 12:48:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 781d0921-ce90-45bc-b931-772ca190d680 0xc0038b6337 0xc0038b6338}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"781d0921-ce90-45bc-b931-772ca190d680\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:48:58 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038b63c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  5 12:48:58.937: INFO: Pod "test-new-deployment-845c8977d9-llk5t" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-llk5t test-new-deployment-845c8977d9- deployment-6121  cd373ea7-a68c-4e93-adf0-71681012b046 24207 0 2022-11-05 12:48:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 592111db-d9e0-42e7-b9bf-7234565c187b 0xc00365d017 0xc00365d018}] [] [{kube-controller-manager Update v1 2022-11-05 12:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"592111db-d9e0-42e7-b9bf-7234565c187b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c4nhg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c4nhg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:48:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 12:48:58.937: INFO: Pod "test-new-deployment-845c8977d9-rkfsk" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-rkfsk test-new-deployment-845c8977d9- deployment-6121  ff972641-ab35-4431-80f4-6e6641af9e19 24192 0 2022-11-05 12:48:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 592111db-d9e0-42e7-b9bf-7234565c187b 0xc00365d180 0xc00365d181}] [] [{kube-controller-manager Update v1 2022-11-05 12:48:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"592111db-d9e0-42e7-b9bf-7234565c187b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:48:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.106\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4zmv6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4zmv6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:48:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:48:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:48:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:48:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.106,StartTime:2022-11-05 12:48:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:48:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bed74f167cee9c04b5fd57609ea06f1b0725b809ba9a2572050e78be8c5be190,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.106,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov  5 12:48:58.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6121" for this suite. 11/05/22 12:48:58.947
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":204,"skipped":3677,"failed":0}
------------------------------
• [2.120 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:56.842
    Nov  5 12:48:56.842: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename deployment 11/05/22 12:48:56.843
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:56.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:56.859
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Nov  5 12:48:56.863: INFO: Creating simple deployment test-new-deployment
    Nov  5 12:48:56.874: INFO: deployment "test-new-deployment" doesn't have the required revision set
    STEP: getting scale subresource 11/05/22 12:48:58.889
    STEP: updating a scale subresource 11/05/22 12:48:58.892
    STEP: verifying the deployment Spec.Replicas was modified 11/05/22 12:48:58.9
    STEP: Patch a scale subresource 11/05/22 12:48:58.905
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov  5 12:48:58.926: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-6121  781d0921-ce90-45bc-b931-772ca190d680 24203 3 2022-11-05 12:48:56 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2022-11-05 12:48:56 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002749ed8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-05 12:48:58 +0000 UTC,LastTransitionTime:2022-11-05 12:48:58 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2022-11-05 12:48:58 +0000 UTC,LastTransitionTime:2022-11-05 12:48:56 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov  5 12:48:58.930: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-6121  592111db-d9e0-42e7-b9bf-7234565c187b 24208 2 2022-11-05 12:48:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:2 deployment.kubernetes.io/max-replicas:3 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment 781d0921-ce90-45bc-b931-772ca190d680 0xc0038b6337 0xc0038b6338}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"781d0921-ce90-45bc-b931-772ca190d680\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:48:58 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*2,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0038b63c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 12:48:58.937: INFO: Pod "test-new-deployment-845c8977d9-llk5t" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-llk5t test-new-deployment-845c8977d9- deployment-6121  cd373ea7-a68c-4e93-adf0-71681012b046 24207 0 2022-11-05 12:48:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 592111db-d9e0-42e7-b9bf-7234565c187b 0xc00365d017 0xc00365d018}] [] [{kube-controller-manager Update v1 2022-11-05 12:48:58 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"592111db-d9e0-42e7-b9bf-7234565c187b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c4nhg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c4nhg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:48:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 12:48:58.937: INFO: Pod "test-new-deployment-845c8977d9-rkfsk" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-rkfsk test-new-deployment-845c8977d9- deployment-6121  ff972641-ab35-4431-80f4-6e6641af9e19 24192 0 2022-11-05 12:48:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 592111db-d9e0-42e7-b9bf-7234565c187b 0xc00365d180 0xc00365d181}] [] [{kube-controller-manager Update v1 2022-11-05 12:48:56 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"592111db-d9e0-42e7-b9bf-7234565c187b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:48:58 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.90.106\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-4zmv6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-4zmv6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-41-19,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:48:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:48:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:48:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:48:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.41.19,PodIP:192.168.90.106,StartTime:2022-11-05 12:48:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:48:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bed74f167cee9c04b5fd57609ea06f1b0725b809ba9a2572050e78be8c5be190,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.90.106,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov  5 12:48:58.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-6121" for this suite. 11/05/22 12:48:58.947
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:58.962
Nov  5 12:48:58.963: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename podtemplate 11/05/22 12:48:58.963
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:58.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:58.991
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 11/05/22 12:48:58.998
STEP: Replace a pod template 11/05/22 12:48:59.003
Nov  5 12:48:59.012: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Nov  5 12:48:59.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-8150" for this suite. 11/05/22 12:48:59.016
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":205,"skipped":3679,"failed":0}
------------------------------
• [0.060 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:58.962
    Nov  5 12:48:58.963: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename podtemplate 11/05/22 12:48:58.963
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:58.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:58.991
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 11/05/22 12:48:58.998
    STEP: Replace a pod template 11/05/22 12:48:59.003
    Nov  5 12:48:59.012: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Nov  5 12:48:59.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-8150" for this suite. 11/05/22 12:48:59.016
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:59.027
Nov  5 12:48:59.027: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename runtimeclass 11/05/22 12:48:59.028
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:59.041
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:59.045
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 11/05/22 12:48:59.048
STEP: getting /apis/node.k8s.io 11/05/22 12:48:59.051
STEP: getting /apis/node.k8s.io/v1 11/05/22 12:48:59.053
STEP: creating 11/05/22 12:48:59.054
STEP: watching 11/05/22 12:48:59.069
Nov  5 12:48:59.069: INFO: starting watch
STEP: getting 11/05/22 12:48:59.077
STEP: listing 11/05/22 12:48:59.08
STEP: patching 11/05/22 12:48:59.083
STEP: updating 11/05/22 12:48:59.09
Nov  5 12:48:59.095: INFO: waiting for watch events with expected annotations
STEP: deleting 11/05/22 12:48:59.095
STEP: deleting a collection 11/05/22 12:48:59.107
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov  5 12:48:59.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-267" for this suite. 11/05/22 12:48:59.125
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":206,"skipped":3715,"failed":0}
------------------------------
• [0.105 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:59.027
    Nov  5 12:48:59.027: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename runtimeclass 11/05/22 12:48:59.028
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:59.041
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:59.045
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 11/05/22 12:48:59.048
    STEP: getting /apis/node.k8s.io 11/05/22 12:48:59.051
    STEP: getting /apis/node.k8s.io/v1 11/05/22 12:48:59.053
    STEP: creating 11/05/22 12:48:59.054
    STEP: watching 11/05/22 12:48:59.069
    Nov  5 12:48:59.069: INFO: starting watch
    STEP: getting 11/05/22 12:48:59.077
    STEP: listing 11/05/22 12:48:59.08
    STEP: patching 11/05/22 12:48:59.083
    STEP: updating 11/05/22 12:48:59.09
    Nov  5 12:48:59.095: INFO: waiting for watch events with expected annotations
    STEP: deleting 11/05/22 12:48:59.095
    STEP: deleting a collection 11/05/22 12:48:59.107
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov  5 12:48:59.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-267" for this suite. 11/05/22 12:48:59.125
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:59.133
Nov  5 12:48:59.133: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:48:59.133
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:59.145
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:59.15
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Nov  5 12:48:59.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-3000 version'
Nov  5 12:48:59.205: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Nov  5 12:48:59.205: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.3\", GitCommit:\"434bfd82814af038ad94d62ebe59b133fcb50506\", GitTreeState:\"clean\", BuildDate:\"2022-10-12T10:57:26Z\", GoVersion:\"go1.19.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.3\", GitCommit:\"434bfd82814af038ad94d62ebe59b133fcb50506\", GitTreeState:\"clean\", BuildDate:\"2022-10-14T02:12:18Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:48:59.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3000" for this suite. 11/05/22 12:48:59.209
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":207,"skipped":3728,"failed":0}
------------------------------
• [0.083 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:59.133
    Nov  5 12:48:59.133: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:48:59.133
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:59.145
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:59.15
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Nov  5 12:48:59.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-3000 version'
    Nov  5 12:48:59.205: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Nov  5 12:48:59.205: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.3\", GitCommit:\"434bfd82814af038ad94d62ebe59b133fcb50506\", GitTreeState:\"clean\", BuildDate:\"2022-10-12T10:57:26Z\", GoVersion:\"go1.19.2\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.3\", GitCommit:\"434bfd82814af038ad94d62ebe59b133fcb50506\", GitTreeState:\"clean\", BuildDate:\"2022-10-14T02:12:18Z\", GoVersion:\"go1.19\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:48:59.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3000" for this suite. 11/05/22 12:48:59.209
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:48:59.218
Nov  5 12:48:59.218: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubelet-test 11/05/22 12:48:59.219
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:59.232
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:59.236
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov  5 12:49:03.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6508" for this suite. 11/05/22 12:49:03.265
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":208,"skipped":3751,"failed":0}
------------------------------
• [4.057 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:48:59.218
    Nov  5 12:48:59.218: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubelet-test 11/05/22 12:48:59.219
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:48:59.232
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:48:59.236
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov  5 12:49:03.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6508" for this suite. 11/05/22 12:49:03.265
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:49:03.276
Nov  5 12:49:03.276: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename ingress 11/05/22 12:49:03.276
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:49:03.29
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:49:03.295
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 11/05/22 12:49:03.302
STEP: getting /apis/networking.k8s.io 11/05/22 12:49:03.305
STEP: getting /apis/networking.k8s.iov1 11/05/22 12:49:03.307
STEP: creating 11/05/22 12:49:03.308
STEP: getting 11/05/22 12:49:03.331
STEP: listing 11/05/22 12:49:03.337
STEP: watching 11/05/22 12:49:03.341
Nov  5 12:49:03.341: INFO: starting watch
STEP: cluster-wide listing 11/05/22 12:49:03.343
STEP: cluster-wide watching 11/05/22 12:49:03.346
Nov  5 12:49:03.347: INFO: starting watch
STEP: patching 11/05/22 12:49:03.348
STEP: updating 11/05/22 12:49:03.354
Nov  5 12:49:03.366: INFO: waiting for watch events with expected annotations
Nov  5 12:49:03.366: INFO: saw patched and updated annotations
STEP: patching /status 11/05/22 12:49:03.366
STEP: updating /status 11/05/22 12:49:03.376
STEP: get /status 11/05/22 12:49:03.392
STEP: deleting 11/05/22 12:49:03.395
STEP: deleting a collection 11/05/22 12:49:03.412
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Nov  5 12:49:03.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-3783" for this suite. 11/05/22 12:49:03.433
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":209,"skipped":3783,"failed":0}
------------------------------
• [0.166 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:49:03.276
    Nov  5 12:49:03.276: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename ingress 11/05/22 12:49:03.276
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:49:03.29
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:49:03.295
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 11/05/22 12:49:03.302
    STEP: getting /apis/networking.k8s.io 11/05/22 12:49:03.305
    STEP: getting /apis/networking.k8s.iov1 11/05/22 12:49:03.307
    STEP: creating 11/05/22 12:49:03.308
    STEP: getting 11/05/22 12:49:03.331
    STEP: listing 11/05/22 12:49:03.337
    STEP: watching 11/05/22 12:49:03.341
    Nov  5 12:49:03.341: INFO: starting watch
    STEP: cluster-wide listing 11/05/22 12:49:03.343
    STEP: cluster-wide watching 11/05/22 12:49:03.346
    Nov  5 12:49:03.347: INFO: starting watch
    STEP: patching 11/05/22 12:49:03.348
    STEP: updating 11/05/22 12:49:03.354
    Nov  5 12:49:03.366: INFO: waiting for watch events with expected annotations
    Nov  5 12:49:03.366: INFO: saw patched and updated annotations
    STEP: patching /status 11/05/22 12:49:03.366
    STEP: updating /status 11/05/22 12:49:03.376
    STEP: get /status 11/05/22 12:49:03.392
    STEP: deleting 11/05/22 12:49:03.395
    STEP: deleting a collection 11/05/22 12:49:03.412
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Nov  5 12:49:03.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-3783" for this suite. 11/05/22 12:49:03.433
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:49:03.444
Nov  5 12:49:03.445: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename deployment 11/05/22 12:49:03.446
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:49:03.464
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:49:03.471
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Nov  5 12:49:03.490: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov  5 12:49:08.496: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/05/22 12:49:08.496
Nov  5 12:49:08.496: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov  5 12:49:10.500: INFO: Creating deployment "test-rollover-deployment"
Nov  5 12:49:10.510: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov  5 12:49:12.519: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov  5 12:49:12.526: INFO: Ensure that both replica sets have 1 created replica
Nov  5 12:49:12.533: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov  5 12:49:12.543: INFO: Updating deployment test-rollover-deployment
Nov  5 12:49:12.543: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov  5 12:49:14.553: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov  5 12:49:14.560: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov  5 12:49:14.567: INFO: all replica sets need to contain the pod-template-hash label
Nov  5 12:49:14.567: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:49:16.575: INFO: all replica sets need to contain the pod-template-hash label
Nov  5 12:49:16.575: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:49:18.575: INFO: all replica sets need to contain the pod-template-hash label
Nov  5 12:49:18.575: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:49:20.576: INFO: all replica sets need to contain the pod-template-hash label
Nov  5 12:49:20.576: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:49:22.575: INFO: all replica sets need to contain the pod-template-hash label
Nov  5 12:49:22.576: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:49:24.576: INFO: 
Nov  5 12:49:24.576: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov  5 12:49:24.586: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9005  f14682b9-4cac-465d-beab-addce78549ce 24543 2 2022-11-05 12:49:10 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-05 12:49:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:49:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00470f3a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-05 12:49:10 +0000 UTC,LastTransitionTime:2022-11-05 12:49:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-11-05 12:49:23 +0000 UTC,LastTransitionTime:2022-11-05 12:49:10 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  5 12:49:24.589: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-9005  fb4bb8b9-9f4c-4e33-bad7-92c5d7d558e4 24533 2 2022-11-05 12:49:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment f14682b9-4cac-465d-beab-addce78549ce 0xc00470f9b7 0xc00470f9b8}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:49:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f14682b9-4cac-465d-beab-addce78549ce\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:49:23 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00470fa68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  5 12:49:24.589: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov  5 12:49:24.590: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9005  44badc9f-f147-4d97-9769-8513790d7f9e 24542 2 2022-11-05 12:49:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment f14682b9-4cac-465d-beab-addce78549ce 0xc00470f757 0xc00470f758}] [] [{e2e.test Update apps/v1 2022-11-05 12:49:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:49:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f14682b9-4cac-465d-beab-addce78549ce\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:49:23 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00470f828 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  5 12:49:24.590: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-9005  5ca93ca8-b4f9-4038-a2e4-c1902ee87b37 24493 2 2022-11-05 12:49:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment f14682b9-4cac-465d-beab-addce78549ce 0xc00470f897 0xc00470f898}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:49:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f14682b9-4cac-465d-beab-addce78549ce\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:49:12 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00470f948 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  5 12:49:24.593: INFO: Pod "test-rollover-deployment-6d45fd857b-g5brp" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-g5brp test-rollover-deployment-6d45fd857b- deployment-9005  dc92c043-fbc5-4b3a-a1a2-e617da52e75e 24511 0 2022-11-05 12:49:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b fb4bb8b9-9f4c-4e33-bad7-92c5d7d558e4 0xc00470ffb7 0xc00470ffb8}] [] [{kube-controller-manager Update v1 2022-11-05 12:49:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb4bb8b9-9f4c-4e33-bad7-92c5d7d558e4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:49:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.154\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-449bf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-449bf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:49:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:49:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:49:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:49:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.154,StartTime:2022-11-05 12:49:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:49:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://097f0a6c3542e9f469f194038098ee32331c94ff1eb771baec5aff12d39e6e4b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.154,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov  5 12:49:24.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9005" for this suite. 11/05/22 12:49:24.597
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":210,"skipped":3798,"failed":0}
------------------------------
• [SLOW TEST] [21.159 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:49:03.444
    Nov  5 12:49:03.445: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename deployment 11/05/22 12:49:03.446
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:49:03.464
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:49:03.471
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Nov  5 12:49:03.490: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Nov  5 12:49:08.496: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/05/22 12:49:08.496
    Nov  5 12:49:08.496: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Nov  5 12:49:10.500: INFO: Creating deployment "test-rollover-deployment"
    Nov  5 12:49:10.510: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Nov  5 12:49:12.519: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Nov  5 12:49:12.526: INFO: Ensure that both replica sets have 1 created replica
    Nov  5 12:49:12.533: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Nov  5 12:49:12.543: INFO: Updating deployment test-rollover-deployment
    Nov  5 12:49:12.543: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Nov  5 12:49:14.553: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Nov  5 12:49:14.560: INFO: Make sure deployment "test-rollover-deployment" is complete
    Nov  5 12:49:14.567: INFO: all replica sets need to contain the pod-template-hash label
    Nov  5 12:49:14.567: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:49:16.575: INFO: all replica sets need to contain the pod-template-hash label
    Nov  5 12:49:16.575: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:49:18.575: INFO: all replica sets need to contain the pod-template-hash label
    Nov  5 12:49:18.575: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:49:20.576: INFO: all replica sets need to contain the pod-template-hash label
    Nov  5 12:49:20.576: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:49:22.575: INFO: all replica sets need to contain the pod-template-hash label
    Nov  5 12:49:22.576: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 49, 13, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 10, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:49:24.576: INFO: 
    Nov  5 12:49:24.576: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov  5 12:49:24.586: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-9005  f14682b9-4cac-465d-beab-addce78549ce 24543 2 2022-11-05 12:49:10 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2022-11-05 12:49:12 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:49:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00470f3a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2022-11-05 12:49:10 +0000 UTC,LastTransitionTime:2022-11-05 12:49:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2022-11-05 12:49:23 +0000 UTC,LastTransitionTime:2022-11-05 12:49:10 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov  5 12:49:24.589: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-9005  fb4bb8b9-9f4c-4e33-bad7-92c5d7d558e4 24533 2 2022-11-05 12:49:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment f14682b9-4cac-465d-beab-addce78549ce 0xc00470f9b7 0xc00470f9b8}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:49:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f14682b9-4cac-465d-beab-addce78549ce\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:49:23 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00470fa68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 12:49:24.589: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Nov  5 12:49:24.590: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9005  44badc9f-f147-4d97-9769-8513790d7f9e 24542 2 2022-11-05 12:49:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment f14682b9-4cac-465d-beab-addce78549ce 0xc00470f757 0xc00470f758}] [] [{e2e.test Update apps/v1 2022-11-05 12:49:03 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:49:23 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f14682b9-4cac-465d-beab-addce78549ce\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:49:23 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00470f828 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 12:49:24.590: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-9005  5ca93ca8-b4f9-4038-a2e4-c1902ee87b37 24493 2 2022-11-05 12:49:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment f14682b9-4cac-465d-beab-addce78549ce 0xc00470f897 0xc00470f898}] [] [{kube-controller-manager Update apps/v1 2022-11-05 12:49:12 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f14682b9-4cac-465d-beab-addce78549ce\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 12:49:12 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00470f948 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 12:49:24.593: INFO: Pod "test-rollover-deployment-6d45fd857b-g5brp" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-g5brp test-rollover-deployment-6d45fd857b- deployment-9005  dc92c043-fbc5-4b3a-a1a2-e617da52e75e 24511 0 2022-11-05 12:49:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b fb4bb8b9-9f4c-4e33-bad7-92c5d7d558e4 0xc00470ffb7 0xc00470ffb8}] [] [{kube-controller-manager Update v1 2022-11-05 12:49:12 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"fb4bb8b9-9f4c-4e33-bad7-92c5d7d558e4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 12:49:13 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.154\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-449bf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-449bf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:49:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:49:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:49:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 12:49:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.154,StartTime:2022-11-05 12:49:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 12:49:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://097f0a6c3542e9f469f194038098ee32331c94ff1eb771baec5aff12d39e6e4b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.154,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov  5 12:49:24.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9005" for this suite. 11/05/22 12:49:24.597
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:49:24.605
Nov  5 12:49:24.605: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename containers 11/05/22 12:49:24.606
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:49:24.62
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:49:24.625
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 11/05/22 12:49:24.628
Nov  5 12:49:24.637: INFO: Waiting up to 5m0s for pod "client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55" in namespace "containers-3867" to be "Succeeded or Failed"
Nov  5 12:49:24.641: INFO: Pod "client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.339883ms
Nov  5 12:49:26.645: INFO: Pod "client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007817567s
Nov  5 12:49:28.646: INFO: Pod "client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008134403s
STEP: Saw pod success 11/05/22 12:49:28.646
Nov  5 12:49:28.646: INFO: Pod "client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55" satisfied condition "Succeeded or Failed"
Nov  5 12:49:28.650: INFO: Trying to get logs from node ip-172-31-41-19 pod client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55 container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:49:28.657
Nov  5 12:49:28.670: INFO: Waiting for pod client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55 to disappear
Nov  5 12:49:28.674: INFO: Pod client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov  5 12:49:28.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3867" for this suite. 11/05/22 12:49:28.678
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":211,"skipped":3811,"failed":0}
------------------------------
• [4.079 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:49:24.605
    Nov  5 12:49:24.605: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename containers 11/05/22 12:49:24.606
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:49:24.62
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:49:24.625
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 11/05/22 12:49:24.628
    Nov  5 12:49:24.637: INFO: Waiting up to 5m0s for pod "client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55" in namespace "containers-3867" to be "Succeeded or Failed"
    Nov  5 12:49:24.641: INFO: Pod "client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.339883ms
    Nov  5 12:49:26.645: INFO: Pod "client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007817567s
    Nov  5 12:49:28.646: INFO: Pod "client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008134403s
    STEP: Saw pod success 11/05/22 12:49:28.646
    Nov  5 12:49:28.646: INFO: Pod "client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55" satisfied condition "Succeeded or Failed"
    Nov  5 12:49:28.650: INFO: Trying to get logs from node ip-172-31-41-19 pod client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55 container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:49:28.657
    Nov  5 12:49:28.670: INFO: Waiting for pod client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55 to disappear
    Nov  5 12:49:28.674: INFO: Pod client-containers-6d1d6a0b-5669-40e3-a058-8aacb540be55 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov  5 12:49:28.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-3867" for this suite. 11/05/22 12:49:28.678
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:49:28.686
Nov  5 12:49:28.686: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename init-container 11/05/22 12:49:28.687
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:49:28.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:49:28.701
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 11/05/22 12:49:28.705
Nov  5 12:49:28.705: INFO: PodSpec: initContainers in spec.initContainers
Nov  5 12:50:09.703: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-db8ffbbb-8092-4f40-99b9-1fa666538f36", GenerateName:"", Namespace:"init-container-9887", SelfLink:"", UID:"40c3827b-1550-4340-ab5a-f42acede431f", ResourceVersion:"24740", Generation:0, CreationTimestamp:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"705933137"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00356bf50), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 5, 12, 50, 9, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00356bf80), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-xb8nv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc002a8f7c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xb8nv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xb8nv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xb8nv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002531b98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-0-255", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0003fea80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002531c20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002531c40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002531c48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002531c4c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc00098a490), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.0.255", PodIP:"192.168.206.155", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.206.155"}}, StartTime:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0003febd0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0003fecb0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://94ca608c1b821af3ffd5753b631ff77e84dcfdaa31303f0f48cb1c18f8caf736", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002a8f840), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002a8f820), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc002531ccf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov  5 12:50:09.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9887" for this suite. 11/05/22 12:50:09.707
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":212,"skipped":3857,"failed":0}
------------------------------
• [SLOW TEST] [41.027 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:49:28.686
    Nov  5 12:49:28.686: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename init-container 11/05/22 12:49:28.687
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:49:28.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:49:28.701
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 11/05/22 12:49:28.705
    Nov  5 12:49:28.705: INFO: PodSpec: initContainers in spec.initContainers
    Nov  5 12:50:09.703: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-db8ffbbb-8092-4f40-99b9-1fa666538f36", GenerateName:"", Namespace:"init-container-9887", SelfLink:"", UID:"40c3827b-1550-4340-ab5a-f42acede431f", ResourceVersion:"24740", Generation:0, CreationTimestamp:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"705933137"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00356bf50), Subresource:""}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2022, time.November, 5, 12, 50, 9, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc00356bf80), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-xb8nv", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc002a8f7c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xb8nv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xb8nv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-xb8nv", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002531b98), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-172-31-0-255", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0003fea80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002531c20)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002531c40)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002531c48), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002531c4c), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc00098a490), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.0.255", PodIP:"192.168.206.155", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.206.155"}}, StartTime:time.Date(2022, time.November, 5, 12, 49, 28, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0003febd0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0003fecb0)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://94ca608c1b821af3ffd5753b631ff77e84dcfdaa31303f0f48cb1c18f8caf736", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002a8f840), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002a8f820), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc002531ccf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov  5 12:50:09.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-9887" for this suite. 11/05/22 12:50:09.707
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:50:09.716
Nov  5 12:50:09.716: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 12:50:09.717
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:09.73
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:09.734
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-5abce45b-f736-46dc-bec1-eef51b2ccd85 11/05/22 12:50:09.738
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 12:50:09.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8522" for this suite. 11/05/22 12:50:09.744
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":213,"skipped":3905,"failed":0}
------------------------------
• [0.035 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:50:09.716
    Nov  5 12:50:09.716: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 12:50:09.717
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:09.73
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:09.734
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-5abce45b-f736-46dc-bec1-eef51b2ccd85 11/05/22 12:50:09.738
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 12:50:09.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8522" for this suite. 11/05/22 12:50:09.744
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:50:09.751
Nov  5 12:50:09.752: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:50:09.752
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:09.765
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:09.768
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-28d22b58-fda4-45b4-894b-b89ae3f4a00d 11/05/22 12:50:09.774
STEP: Creating a pod to test consume secrets 11/05/22 12:50:09.779
Nov  5 12:50:09.786: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb" in namespace "projected-9362" to be "Succeeded or Failed"
Nov  5 12:50:09.794: INFO: Pod "pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.181912ms
Nov  5 12:50:11.798: INFO: Pod "pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011455056s
Nov  5 12:50:13.798: INFO: Pod "pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011551441s
STEP: Saw pod success 11/05/22 12:50:13.798
Nov  5 12:50:13.798: INFO: Pod "pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb" satisfied condition "Succeeded or Failed"
Nov  5 12:50:13.802: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb container projected-secret-volume-test: <nil>
STEP: delete the pod 11/05/22 12:50:13.808
Nov  5 12:50:13.821: INFO: Waiting for pod pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb to disappear
Nov  5 12:50:13.825: INFO: Pod pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov  5 12:50:13.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9362" for this suite. 11/05/22 12:50:13.829
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":214,"skipped":3919,"failed":0}
------------------------------
• [4.084 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:50:09.751
    Nov  5 12:50:09.752: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:50:09.752
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:09.765
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:09.768
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-28d22b58-fda4-45b4-894b-b89ae3f4a00d 11/05/22 12:50:09.774
    STEP: Creating a pod to test consume secrets 11/05/22 12:50:09.779
    Nov  5 12:50:09.786: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb" in namespace "projected-9362" to be "Succeeded or Failed"
    Nov  5 12:50:09.794: INFO: Pod "pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.181912ms
    Nov  5 12:50:11.798: INFO: Pod "pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011455056s
    Nov  5 12:50:13.798: INFO: Pod "pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011551441s
    STEP: Saw pod success 11/05/22 12:50:13.798
    Nov  5 12:50:13.798: INFO: Pod "pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb" satisfied condition "Succeeded or Failed"
    Nov  5 12:50:13.802: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 12:50:13.808
    Nov  5 12:50:13.821: INFO: Waiting for pod pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb to disappear
    Nov  5 12:50:13.825: INFO: Pod pod-projected-secrets-7945f942-77bd-4fae-ab42-b994215dbaeb no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov  5 12:50:13.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9362" for this suite. 11/05/22 12:50:13.829
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:50:13.838
Nov  5 12:50:13.838: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 12:50:13.839
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:13.853
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:13.859
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 11/05/22 12:50:13.862
Nov  5 12:50:13.872: INFO: Waiting up to 5m0s for pod "pod-a3899702-299f-4efb-8c0e-8ff328750727" in namespace "emptydir-866" to be "Succeeded or Failed"
Nov  5 12:50:13.878: INFO: Pod "pod-a3899702-299f-4efb-8c0e-8ff328750727": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055639ms
Nov  5 12:50:15.883: INFO: Pod "pod-a3899702-299f-4efb-8c0e-8ff328750727": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010818486s
Nov  5 12:50:17.883: INFO: Pod "pod-a3899702-299f-4efb-8c0e-8ff328750727": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01095315s
STEP: Saw pod success 11/05/22 12:50:17.883
Nov  5 12:50:17.883: INFO: Pod "pod-a3899702-299f-4efb-8c0e-8ff328750727" satisfied condition "Succeeded or Failed"
Nov  5 12:50:17.887: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-a3899702-299f-4efb-8c0e-8ff328750727 container test-container: <nil>
STEP: delete the pod 11/05/22 12:50:17.893
Nov  5 12:50:17.906: INFO: Waiting for pod pod-a3899702-299f-4efb-8c0e-8ff328750727 to disappear
Nov  5 12:50:17.909: INFO: Pod pod-a3899702-299f-4efb-8c0e-8ff328750727 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 12:50:17.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-866" for this suite. 11/05/22 12:50:17.913
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":215,"skipped":3943,"failed":0}
------------------------------
• [4.081 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:50:13.838
    Nov  5 12:50:13.838: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 12:50:13.839
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:13.853
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:13.859
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 11/05/22 12:50:13.862
    Nov  5 12:50:13.872: INFO: Waiting up to 5m0s for pod "pod-a3899702-299f-4efb-8c0e-8ff328750727" in namespace "emptydir-866" to be "Succeeded or Failed"
    Nov  5 12:50:13.878: INFO: Pod "pod-a3899702-299f-4efb-8c0e-8ff328750727": Phase="Pending", Reason="", readiness=false. Elapsed: 6.055639ms
    Nov  5 12:50:15.883: INFO: Pod "pod-a3899702-299f-4efb-8c0e-8ff328750727": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010818486s
    Nov  5 12:50:17.883: INFO: Pod "pod-a3899702-299f-4efb-8c0e-8ff328750727": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01095315s
    STEP: Saw pod success 11/05/22 12:50:17.883
    Nov  5 12:50:17.883: INFO: Pod "pod-a3899702-299f-4efb-8c0e-8ff328750727" satisfied condition "Succeeded or Failed"
    Nov  5 12:50:17.887: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-a3899702-299f-4efb-8c0e-8ff328750727 container test-container: <nil>
    STEP: delete the pod 11/05/22 12:50:17.893
    Nov  5 12:50:17.906: INFO: Waiting for pod pod-a3899702-299f-4efb-8c0e-8ff328750727 to disappear
    Nov  5 12:50:17.909: INFO: Pod pod-a3899702-299f-4efb-8c0e-8ff328750727 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 12:50:17.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-866" for this suite. 11/05/22 12:50:17.913
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:50:17.921
Nov  5 12:50:17.921: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubelet-test 11/05/22 12:50:17.921
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:17.933
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:17.937
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov  5 12:50:17.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2808" for this suite. 11/05/22 12:50:17.985
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":216,"skipped":3960,"failed":0}
------------------------------
• [0.072 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:50:17.921
    Nov  5 12:50:17.921: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubelet-test 11/05/22 12:50:17.921
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:17.933
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:17.937
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov  5 12:50:17.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-2808" for this suite. 11/05/22 12:50:17.985
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:50:17.994
Nov  5 12:50:17.994: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename containers 11/05/22 12:50:17.994
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:18.013
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:18.016
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 11/05/22 12:50:18.019
Nov  5 12:50:18.027: INFO: Waiting up to 5m0s for pod "client-containers-4ce31f76-940f-403c-82d4-482086756f38" in namespace "containers-7980" to be "Succeeded or Failed"
Nov  5 12:50:18.033: INFO: Pod "client-containers-4ce31f76-940f-403c-82d4-482086756f38": Phase="Pending", Reason="", readiness=false. Elapsed: 5.788256ms
Nov  5 12:50:20.037: INFO: Pod "client-containers-4ce31f76-940f-403c-82d4-482086756f38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009939605s
Nov  5 12:50:22.037: INFO: Pod "client-containers-4ce31f76-940f-403c-82d4-482086756f38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010196815s
STEP: Saw pod success 11/05/22 12:50:22.037
Nov  5 12:50:22.037: INFO: Pod "client-containers-4ce31f76-940f-403c-82d4-482086756f38" satisfied condition "Succeeded or Failed"
Nov  5 12:50:22.041: INFO: Trying to get logs from node ip-172-31-0-255 pod client-containers-4ce31f76-940f-403c-82d4-482086756f38 container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:50:22.058
Nov  5 12:50:22.068: INFO: Waiting for pod client-containers-4ce31f76-940f-403c-82d4-482086756f38 to disappear
Nov  5 12:50:22.071: INFO: Pod client-containers-4ce31f76-940f-403c-82d4-482086756f38 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov  5 12:50:22.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7980" for this suite. 11/05/22 12:50:22.075
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":217,"skipped":3972,"failed":0}
------------------------------
• [4.088 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:50:17.994
    Nov  5 12:50:17.994: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename containers 11/05/22 12:50:17.994
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:18.013
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:18.016
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 11/05/22 12:50:18.019
    Nov  5 12:50:18.027: INFO: Waiting up to 5m0s for pod "client-containers-4ce31f76-940f-403c-82d4-482086756f38" in namespace "containers-7980" to be "Succeeded or Failed"
    Nov  5 12:50:18.033: INFO: Pod "client-containers-4ce31f76-940f-403c-82d4-482086756f38": Phase="Pending", Reason="", readiness=false. Elapsed: 5.788256ms
    Nov  5 12:50:20.037: INFO: Pod "client-containers-4ce31f76-940f-403c-82d4-482086756f38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009939605s
    Nov  5 12:50:22.037: INFO: Pod "client-containers-4ce31f76-940f-403c-82d4-482086756f38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010196815s
    STEP: Saw pod success 11/05/22 12:50:22.037
    Nov  5 12:50:22.037: INFO: Pod "client-containers-4ce31f76-940f-403c-82d4-482086756f38" satisfied condition "Succeeded or Failed"
    Nov  5 12:50:22.041: INFO: Trying to get logs from node ip-172-31-0-255 pod client-containers-4ce31f76-940f-403c-82d4-482086756f38 container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:50:22.058
    Nov  5 12:50:22.068: INFO: Waiting for pod client-containers-4ce31f76-940f-403c-82d4-482086756f38 to disappear
    Nov  5 12:50:22.071: INFO: Pod client-containers-4ce31f76-940f-403c-82d4-482086756f38 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov  5 12:50:22.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-7980" for this suite. 11/05/22 12:50:22.075
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:50:22.083
Nov  5 12:50:22.083: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename gc 11/05/22 12:50:22.083
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:22.097
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:22.102
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 11/05/22 12:50:22.105
STEP: Wait for the Deployment to create new ReplicaSet 11/05/22 12:50:22.11
STEP: delete the deployment 11/05/22 12:50:22.228
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 11/05/22 12:50:22.236
STEP: Gathering metrics 11/05/22 12:50:22.771
W1105 12:50:22.774931      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov  5 12:50:22.775: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov  5 12:50:22.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1776" for this suite. 11/05/22 12:50:22.778
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":218,"skipped":3976,"failed":0}
------------------------------
• [0.702 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:50:22.083
    Nov  5 12:50:22.083: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename gc 11/05/22 12:50:22.083
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:22.097
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:22.102
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 11/05/22 12:50:22.105
    STEP: Wait for the Deployment to create new ReplicaSet 11/05/22 12:50:22.11
    STEP: delete the deployment 11/05/22 12:50:22.228
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 11/05/22 12:50:22.236
    STEP: Gathering metrics 11/05/22 12:50:22.771
    W1105 12:50:22.774931      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov  5 12:50:22.775: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov  5 12:50:22.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1776" for this suite. 11/05/22 12:50:22.778
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:50:22.786
Nov  5 12:50:22.786: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename custom-resource-definition 11/05/22 12:50:22.787
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:22.799
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:22.803
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Nov  5 12:50:22.911: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:50:29.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7171" for this suite. 11/05/22 12:50:29.14
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":219,"skipped":3981,"failed":0}
------------------------------
• [SLOW TEST] [6.362 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:50:22.786
    Nov  5 12:50:22.786: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename custom-resource-definition 11/05/22 12:50:22.787
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:22.799
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:22.803
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Nov  5 12:50:22.911: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:50:29.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7171" for this suite. 11/05/22 12:50:29.14
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:50:29.148
Nov  5 12:50:29.148: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename aggregator 11/05/22 12:50:29.149
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:29.164
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:29.168
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Nov  5 12:50:29.171: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 11/05/22 12:50:29.172
Nov  5 12:50:29.615: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov  5 12:50:31.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:33.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:35.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:37.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:39.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:41.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:43.674: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:45.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:47.674: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:49.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:51.674: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:53.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  5 12:50:55.800: INFO: Waited 119.404904ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 11/05/22 12:50:55.85
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 11/05/22 12:50:55.854
STEP: List APIServices 11/05/22 12:50:55.862
Nov  5 12:50:55.867: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Nov  5 12:50:56.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5122" for this suite. 11/05/22 12:50:56.039
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":220,"skipped":3995,"failed":0}
------------------------------
• [SLOW TEST] [26.947 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:50:29.148
    Nov  5 12:50:29.148: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename aggregator 11/05/22 12:50:29.149
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:29.164
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:29.168
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Nov  5 12:50:29.171: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 11/05/22 12:50:29.172
    Nov  5 12:50:29.615: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Nov  5 12:50:31.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:33.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:35.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:37.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:39.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:41.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:43.674: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:45.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:47.674: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:49.675: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:51.674: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:53.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 12, 50, 29, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-78794cb777\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Nov  5 12:50:55.800: INFO: Waited 119.404904ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 11/05/22 12:50:55.85
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 11/05/22 12:50:55.854
    STEP: List APIServices 11/05/22 12:50:55.862
    Nov  5 12:50:55.867: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Nov  5 12:50:56.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-5122" for this suite. 11/05/22 12:50:56.039
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:50:56.095
Nov  5 12:50:56.095: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 12:50:56.096
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:56.11
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:56.113
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 11/05/22 12:50:56.117
STEP: submitting the pod to kubernetes 11/05/22 12:50:56.117
Nov  5 12:50:56.123: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6" in namespace "pods-2367" to be "running and ready"
Nov  5 12:50:56.127: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.669224ms
Nov  5 12:50:56.127: INFO: The phase of Pod pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:50:58.132: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Running", Reason="", readiness=true. Elapsed: 2.008453072s
Nov  5 12:50:58.132: INFO: The phase of Pod pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6 is Running (Ready = true)
Nov  5 12:50:58.132: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 11/05/22 12:50:58.136
STEP: updating the pod 11/05/22 12:50:58.139
Nov  5 12:50:58.650: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6"
Nov  5 12:50:58.650: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6" in namespace "pods-2367" to be "terminated with reason DeadlineExceeded"
Nov  5 12:50:58.654: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Running", Reason="", readiness=true. Elapsed: 3.209926ms
Nov  5 12:51:00.659: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Running", Reason="", readiness=true. Elapsed: 2.00819077s
Nov  5 12:51:02.658: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Running", Reason="", readiness=false. Elapsed: 4.007463248s
Nov  5 12:51:04.659: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.00823816s
Nov  5 12:51:04.659: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov  5 12:51:04.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2367" for this suite. 11/05/22 12:51:04.663
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":221,"skipped":4000,"failed":0}
------------------------------
• [SLOW TEST] [8.574 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:50:56.095
    Nov  5 12:50:56.095: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 12:50:56.096
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:50:56.11
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:50:56.113
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 11/05/22 12:50:56.117
    STEP: submitting the pod to kubernetes 11/05/22 12:50:56.117
    Nov  5 12:50:56.123: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6" in namespace "pods-2367" to be "running and ready"
    Nov  5 12:50:56.127: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.669224ms
    Nov  5 12:50:56.127: INFO: The phase of Pod pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:50:58.132: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Running", Reason="", readiness=true. Elapsed: 2.008453072s
    Nov  5 12:50:58.132: INFO: The phase of Pod pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6 is Running (Ready = true)
    Nov  5 12:50:58.132: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 11/05/22 12:50:58.136
    STEP: updating the pod 11/05/22 12:50:58.139
    Nov  5 12:50:58.650: INFO: Successfully updated pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6"
    Nov  5 12:50:58.650: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6" in namespace "pods-2367" to be "terminated with reason DeadlineExceeded"
    Nov  5 12:50:58.654: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Running", Reason="", readiness=true. Elapsed: 3.209926ms
    Nov  5 12:51:00.659: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Running", Reason="", readiness=true. Elapsed: 2.00819077s
    Nov  5 12:51:02.658: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Running", Reason="", readiness=false. Elapsed: 4.007463248s
    Nov  5 12:51:04.659: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 6.00823816s
    Nov  5 12:51:04.659: INFO: Pod "pod-update-activedeadlineseconds-4d8727d8-e532-4598-90eb-a12c5f046aa6" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov  5 12:51:04.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2367" for this suite. 11/05/22 12:51:04.663
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:04.67
Nov  5 12:51:04.670: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:51:04.671
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:04.689
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:04.693
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-926578ac-05a1-4d22-8157-dd6d0d107286 11/05/22 12:51:04.703
STEP: Creating the pod 11/05/22 12:51:04.708
Nov  5 12:51:04.717: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326" in namespace "projected-5727" to be "running and ready"
Nov  5 12:51:04.721: INFO: Pod "pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326": Phase="Pending", Reason="", readiness=false. Elapsed: 3.361324ms
Nov  5 12:51:04.721: INFO: The phase of Pod pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:51:06.725: INFO: Pod "pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326": Phase="Running", Reason="", readiness=true. Elapsed: 2.007490821s
Nov  5 12:51:06.725: INFO: The phase of Pod pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326 is Running (Ready = true)
Nov  5 12:51:06.725: INFO: Pod "pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-926578ac-05a1-4d22-8157-dd6d0d107286 11/05/22 12:51:06.735
STEP: waiting to observe update in volume 11/05/22 12:51:06.74
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov  5 12:51:08.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5727" for this suite. 11/05/22 12:51:08.757
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":222,"skipped":4013,"failed":0}
------------------------------
• [4.096 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:04.67
    Nov  5 12:51:04.670: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:51:04.671
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:04.689
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:04.693
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-926578ac-05a1-4d22-8157-dd6d0d107286 11/05/22 12:51:04.703
    STEP: Creating the pod 11/05/22 12:51:04.708
    Nov  5 12:51:04.717: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326" in namespace "projected-5727" to be "running and ready"
    Nov  5 12:51:04.721: INFO: Pod "pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326": Phase="Pending", Reason="", readiness=false. Elapsed: 3.361324ms
    Nov  5 12:51:04.721: INFO: The phase of Pod pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:51:06.725: INFO: Pod "pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326": Phase="Running", Reason="", readiness=true. Elapsed: 2.007490821s
    Nov  5 12:51:06.725: INFO: The phase of Pod pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326 is Running (Ready = true)
    Nov  5 12:51:06.725: INFO: Pod "pod-projected-configmaps-9f0e02b6-3fd6-496a-b793-bfd886458326" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-926578ac-05a1-4d22-8157-dd6d0d107286 11/05/22 12:51:06.735
    STEP: waiting to observe update in volume 11/05/22 12:51:06.74
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov  5 12:51:08.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5727" for this suite. 11/05/22 12:51:08.757
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:08.77
Nov  5 12:51:08.770: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 12:51:08.771
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:08.789
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:08.793
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641
STEP: creating a collection of services 11/05/22 12:51:08.797
Nov  5 12:51:08.797: INFO: Creating e2e-svc-a-v2mg6
Nov  5 12:51:08.808: INFO: Creating e2e-svc-b-7mr7q
Nov  5 12:51:08.819: INFO: Creating e2e-svc-c-k9lmf
STEP: deleting service collection 11/05/22 12:51:08.834
Nov  5 12:51:08.864: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 12:51:08.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9362" for this suite. 11/05/22 12:51:08.868
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":223,"skipped":4043,"failed":0}
------------------------------
• [0.105 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3641

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:08.77
    Nov  5 12:51:08.770: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 12:51:08.771
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:08.789
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:08.793
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3641
    STEP: creating a collection of services 11/05/22 12:51:08.797
    Nov  5 12:51:08.797: INFO: Creating e2e-svc-a-v2mg6
    Nov  5 12:51:08.808: INFO: Creating e2e-svc-b-7mr7q
    Nov  5 12:51:08.819: INFO: Creating e2e-svc-c-k9lmf
    STEP: deleting service collection 11/05/22 12:51:08.834
    Nov  5 12:51:08.864: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 12:51:08.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9362" for this suite. 11/05/22 12:51:08.868
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:08.876
Nov  5 12:51:08.876: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 12:51:08.877
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:08.891
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:08.896
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231
STEP: creating an Endpoint 11/05/22 12:51:08.905
STEP: waiting for available Endpoint 11/05/22 12:51:08.91
STEP: listing all Endpoints 11/05/22 12:51:08.912
STEP: updating the Endpoint 11/05/22 12:51:08.915
STEP: fetching the Endpoint 11/05/22 12:51:08.922
STEP: patching the Endpoint 11/05/22 12:51:08.925
STEP: fetching the Endpoint 11/05/22 12:51:08.933
STEP: deleting the Endpoint by Collection 11/05/22 12:51:08.937
STEP: waiting for Endpoint deletion 11/05/22 12:51:08.944
STEP: fetching the Endpoint 11/05/22 12:51:08.946
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 12:51:08.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4551" for this suite. 11/05/22 12:51:08.953
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":224,"skipped":4044,"failed":0}
------------------------------
• [0.084 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:08.876
    Nov  5 12:51:08.876: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 12:51:08.877
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:08.891
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:08.896
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3231
    STEP: creating an Endpoint 11/05/22 12:51:08.905
    STEP: waiting for available Endpoint 11/05/22 12:51:08.91
    STEP: listing all Endpoints 11/05/22 12:51:08.912
    STEP: updating the Endpoint 11/05/22 12:51:08.915
    STEP: fetching the Endpoint 11/05/22 12:51:08.922
    STEP: patching the Endpoint 11/05/22 12:51:08.925
    STEP: fetching the Endpoint 11/05/22 12:51:08.933
    STEP: deleting the Endpoint by Collection 11/05/22 12:51:08.937
    STEP: waiting for Endpoint deletion 11/05/22 12:51:08.944
    STEP: fetching the Endpoint 11/05/22 12:51:08.946
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 12:51:08.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4551" for this suite. 11/05/22 12:51:08.953
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:08.96
Nov  5 12:51:08.960: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replicaset 11/05/22 12:51:08.961
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:08.976
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:08.979
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 11/05/22 12:51:08.987
STEP: Verify that the required pods have come up. 11/05/22 12:51:08.992
Nov  5 12:51:08.996: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  5 12:51:14.000: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/05/22 12:51:14
STEP: Getting /status 11/05/22 12:51:14
Nov  5 12:51:14.005: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 11/05/22 12:51:14.005
Nov  5 12:51:14.015: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 11/05/22 12:51:14.015
Nov  5 12:51:14.018: INFO: Observed &ReplicaSet event: ADDED
Nov  5 12:51:14.018: INFO: Observed &ReplicaSet event: MODIFIED
Nov  5 12:51:14.018: INFO: Observed &ReplicaSet event: MODIFIED
Nov  5 12:51:14.018: INFO: Observed &ReplicaSet event: MODIFIED
Nov  5 12:51:14.018: INFO: Found replicaset test-rs in namespace replicaset-4152 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov  5 12:51:14.018: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 11/05/22 12:51:14.018
Nov  5 12:51:14.018: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov  5 12:51:14.028: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 11/05/22 12:51:14.028
Nov  5 12:51:14.031: INFO: Observed &ReplicaSet event: ADDED
Nov  5 12:51:14.031: INFO: Observed &ReplicaSet event: MODIFIED
Nov  5 12:51:14.031: INFO: Observed &ReplicaSet event: MODIFIED
Nov  5 12:51:14.031: INFO: Observed &ReplicaSet event: MODIFIED
Nov  5 12:51:14.031: INFO: Observed replicaset test-rs in namespace replicaset-4152 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov  5 12:51:14.031: INFO: Observed &ReplicaSet event: MODIFIED
Nov  5 12:51:14.031: INFO: Found replicaset test-rs in namespace replicaset-4152 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Nov  5 12:51:14.031: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov  5 12:51:14.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4152" for this suite. 11/05/22 12:51:14.036
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":225,"skipped":4045,"failed":0}
------------------------------
• [SLOW TEST] [5.083 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:08.96
    Nov  5 12:51:08.960: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replicaset 11/05/22 12:51:08.961
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:08.976
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:08.979
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 11/05/22 12:51:08.987
    STEP: Verify that the required pods have come up. 11/05/22 12:51:08.992
    Nov  5 12:51:08.996: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov  5 12:51:14.000: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/05/22 12:51:14
    STEP: Getting /status 11/05/22 12:51:14
    Nov  5 12:51:14.005: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 11/05/22 12:51:14.005
    Nov  5 12:51:14.015: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 11/05/22 12:51:14.015
    Nov  5 12:51:14.018: INFO: Observed &ReplicaSet event: ADDED
    Nov  5 12:51:14.018: INFO: Observed &ReplicaSet event: MODIFIED
    Nov  5 12:51:14.018: INFO: Observed &ReplicaSet event: MODIFIED
    Nov  5 12:51:14.018: INFO: Observed &ReplicaSet event: MODIFIED
    Nov  5 12:51:14.018: INFO: Found replicaset test-rs in namespace replicaset-4152 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov  5 12:51:14.018: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 11/05/22 12:51:14.018
    Nov  5 12:51:14.018: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov  5 12:51:14.028: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 11/05/22 12:51:14.028
    Nov  5 12:51:14.031: INFO: Observed &ReplicaSet event: ADDED
    Nov  5 12:51:14.031: INFO: Observed &ReplicaSet event: MODIFIED
    Nov  5 12:51:14.031: INFO: Observed &ReplicaSet event: MODIFIED
    Nov  5 12:51:14.031: INFO: Observed &ReplicaSet event: MODIFIED
    Nov  5 12:51:14.031: INFO: Observed replicaset test-rs in namespace replicaset-4152 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov  5 12:51:14.031: INFO: Observed &ReplicaSet event: MODIFIED
    Nov  5 12:51:14.031: INFO: Found replicaset test-rs in namespace replicaset-4152 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Nov  5 12:51:14.031: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov  5 12:51:14.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4152" for this suite. 11/05/22 12:51:14.036
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:14.044
Nov  5 12:51:14.044: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename runtimeclass 11/05/22 12:51:14.044
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:14.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:14.067
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov  5 12:51:14.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2992" for this suite. 11/05/22 12:51:14.088
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":226,"skipped":4055,"failed":0}
------------------------------
• [0.052 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:14.044
    Nov  5 12:51:14.044: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename runtimeclass 11/05/22 12:51:14.044
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:14.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:14.067
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov  5 12:51:14.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-2992" for this suite. 11/05/22 12:51:14.088
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:14.106
Nov  5 12:51:14.106: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 12:51:14.106
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:14.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:14.124
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 11/05/22 12:51:14.129
STEP: Creating a ResourceQuota 11/05/22 12:51:19.134
STEP: Ensuring resource quota status is calculated 11/05/22 12:51:19.141
STEP: Creating a Service 11/05/22 12:51:21.145
STEP: Creating a NodePort Service 11/05/22 12:51:21.16
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 11/05/22 12:51:21.186
STEP: Ensuring resource quota status captures service creation 11/05/22 12:51:21.205
STEP: Deleting Services 11/05/22 12:51:23.21
STEP: Ensuring resource quota status released usage 11/05/22 12:51:23.249
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 12:51:25.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6950" for this suite. 11/05/22 12:51:25.259
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":227,"skipped":4175,"failed":0}
------------------------------
• [SLOW TEST] [11.160 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:14.106
    Nov  5 12:51:14.106: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 12:51:14.106
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:14.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:14.124
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 11/05/22 12:51:14.129
    STEP: Creating a ResourceQuota 11/05/22 12:51:19.134
    STEP: Ensuring resource quota status is calculated 11/05/22 12:51:19.141
    STEP: Creating a Service 11/05/22 12:51:21.145
    STEP: Creating a NodePort Service 11/05/22 12:51:21.16
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 11/05/22 12:51:21.186
    STEP: Ensuring resource quota status captures service creation 11/05/22 12:51:21.205
    STEP: Deleting Services 11/05/22 12:51:23.21
    STEP: Ensuring resource quota status released usage 11/05/22 12:51:23.249
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 12:51:25.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6950" for this suite. 11/05/22 12:51:25.259
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:25.267
Nov  5 12:51:25.267: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 12:51:25.267
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:25.331
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:25.335
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-aab0b043-bbe4-4b9a-8d29-5eda9184c3ca 11/05/22 12:51:25.339
STEP: Creating a pod to test consume configMaps 11/05/22 12:51:25.344
Nov  5 12:51:25.352: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3" in namespace "projected-7819" to be "Succeeded or Failed"
Nov  5 12:51:25.358: INFO: Pod "pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.755251ms
Nov  5 12:51:27.363: INFO: Pod "pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010408348s
Nov  5 12:51:29.364: INFO: Pod "pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011533642s
STEP: Saw pod success 11/05/22 12:51:29.364
Nov  5 12:51:29.364: INFO: Pod "pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3" satisfied condition "Succeeded or Failed"
Nov  5 12:51:29.367: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3 container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:51:29.374
Nov  5 12:51:29.387: INFO: Waiting for pod pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3 to disappear
Nov  5 12:51:29.390: INFO: Pod pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov  5 12:51:29.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7819" for this suite. 11/05/22 12:51:29.394
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":228,"skipped":4209,"failed":0}
------------------------------
• [4.134 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:25.267
    Nov  5 12:51:25.267: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 12:51:25.267
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:25.331
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:25.335
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-aab0b043-bbe4-4b9a-8d29-5eda9184c3ca 11/05/22 12:51:25.339
    STEP: Creating a pod to test consume configMaps 11/05/22 12:51:25.344
    Nov  5 12:51:25.352: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3" in namespace "projected-7819" to be "Succeeded or Failed"
    Nov  5 12:51:25.358: INFO: Pod "pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.755251ms
    Nov  5 12:51:27.363: INFO: Pod "pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010408348s
    Nov  5 12:51:29.364: INFO: Pod "pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011533642s
    STEP: Saw pod success 11/05/22 12:51:29.364
    Nov  5 12:51:29.364: INFO: Pod "pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3" satisfied condition "Succeeded or Failed"
    Nov  5 12:51:29.367: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3 container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:51:29.374
    Nov  5 12:51:29.387: INFO: Waiting for pod pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3 to disappear
    Nov  5 12:51:29.390: INFO: Pod pod-projected-configmaps-67d8036e-3548-48cc-a371-871f02370fb3 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov  5 12:51:29.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7819" for this suite. 11/05/22 12:51:29.394
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:29.403
Nov  5 12:51:29.403: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 12:51:29.403
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:29.416
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:29.421
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 11/05/22 12:51:29.425
Nov  5 12:51:29.434: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11" in namespace "downward-api-5577" to be "Succeeded or Failed"
Nov  5 12:51:29.438: INFO: Pod "downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11": Phase="Pending", Reason="", readiness=false. Elapsed: 4.517944ms
Nov  5 12:51:31.443: INFO: Pod "downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008829867s
Nov  5 12:51:33.444: INFO: Pod "downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009655317s
STEP: Saw pod success 11/05/22 12:51:33.444
Nov  5 12:51:33.444: INFO: Pod "downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11" satisfied condition "Succeeded or Failed"
Nov  5 12:51:33.447: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11 container client-container: <nil>
STEP: delete the pod 11/05/22 12:51:33.453
Nov  5 12:51:33.469: INFO: Waiting for pod downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11 to disappear
Nov  5 12:51:33.471: INFO: Pod downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 12:51:33.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5577" for this suite. 11/05/22 12:51:33.476
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":229,"skipped":4214,"failed":0}
------------------------------
• [4.082 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:29.403
    Nov  5 12:51:29.403: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 12:51:29.403
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:29.416
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:29.421
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 11/05/22 12:51:29.425
    Nov  5 12:51:29.434: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11" in namespace "downward-api-5577" to be "Succeeded or Failed"
    Nov  5 12:51:29.438: INFO: Pod "downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11": Phase="Pending", Reason="", readiness=false. Elapsed: 4.517944ms
    Nov  5 12:51:31.443: INFO: Pod "downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008829867s
    Nov  5 12:51:33.444: INFO: Pod "downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009655317s
    STEP: Saw pod success 11/05/22 12:51:33.444
    Nov  5 12:51:33.444: INFO: Pod "downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11" satisfied condition "Succeeded or Failed"
    Nov  5 12:51:33.447: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11 container client-container: <nil>
    STEP: delete the pod 11/05/22 12:51:33.453
    Nov  5 12:51:33.469: INFO: Waiting for pod downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11 to disappear
    Nov  5 12:51:33.471: INFO: Pod downwardapi-volume-50ce4ab2-8995-41f4-8792-6481c4833c11 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 12:51:33.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5577" for this suite. 11/05/22 12:51:33.476
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:33.485
Nov  5 12:51:33.485: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 12:51:33.485
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:33.512
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:33.517
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Nov  5 12:51:33.521: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 11/05/22 12:51:37.129
Nov  5 12:51:37.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 create -f -'
Nov  5 12:51:37.755: INFO: stderr: ""
Nov  5 12:51:37.755: INFO: stdout: "e2e-test-crd-publish-openapi-333-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  5 12:51:37.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 delete e2e-test-crd-publish-openapi-333-crds test-foo'
Nov  5 12:51:37.820: INFO: stderr: ""
Nov  5 12:51:37.820: INFO: stdout: "e2e-test-crd-publish-openapi-333-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov  5 12:51:37.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 apply -f -'
Nov  5 12:51:38.440: INFO: stderr: ""
Nov  5 12:51:38.440: INFO: stdout: "e2e-test-crd-publish-openapi-333-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  5 12:51:38.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 delete e2e-test-crd-publish-openapi-333-crds test-foo'
Nov  5 12:51:38.512: INFO: stderr: ""
Nov  5 12:51:38.512: INFO: stdout: "e2e-test-crd-publish-openapi-333-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 11/05/22 12:51:38.512
Nov  5 12:51:38.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 create -f -'
Nov  5 12:51:38.745: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 11/05/22 12:51:38.745
Nov  5 12:51:38.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 create -f -'
Nov  5 12:51:38.975: INFO: rc: 1
Nov  5 12:51:38.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 apply -f -'
Nov  5 12:51:39.164: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 11/05/22 12:51:39.164
Nov  5 12:51:39.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 create -f -'
Nov  5 12:51:39.335: INFO: rc: 1
Nov  5 12:51:39.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 apply -f -'
Nov  5 12:51:39.562: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 11/05/22 12:51:39.563
Nov  5 12:51:39.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 explain e2e-test-crd-publish-openapi-333-crds'
Nov  5 12:51:39.790: INFO: stderr: ""
Nov  5 12:51:39.790: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-333-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 11/05/22 12:51:39.791
Nov  5 12:51:39.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 explain e2e-test-crd-publish-openapi-333-crds.metadata'
Nov  5 12:51:40.011: INFO: stderr: ""
Nov  5 12:51:40.011: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-333-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov  5 12:51:40.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 explain e2e-test-crd-publish-openapi-333-crds.spec'
Nov  5 12:51:40.238: INFO: stderr: ""
Nov  5 12:51:40.238: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-333-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov  5 12:51:40.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 explain e2e-test-crd-publish-openapi-333-crds.spec.bars'
Nov  5 12:51:40.407: INFO: stderr: ""
Nov  5 12:51:40.408: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-333-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 11/05/22 12:51:40.408
Nov  5 12:51:40.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 explain e2e-test-crd-publish-openapi-333-crds.spec.bars2'
Nov  5 12:51:40.641: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 12:51:42.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1002" for this suite. 11/05/22 12:51:42.818
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":230,"skipped":4226,"failed":0}
------------------------------
• [SLOW TEST] [9.340 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:33.485
    Nov  5 12:51:33.485: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 12:51:33.485
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:33.512
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:33.517
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Nov  5 12:51:33.521: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 11/05/22 12:51:37.129
    Nov  5 12:51:37.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 create -f -'
    Nov  5 12:51:37.755: INFO: stderr: ""
    Nov  5 12:51:37.755: INFO: stdout: "e2e-test-crd-publish-openapi-333-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Nov  5 12:51:37.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 delete e2e-test-crd-publish-openapi-333-crds test-foo'
    Nov  5 12:51:37.820: INFO: stderr: ""
    Nov  5 12:51:37.820: INFO: stdout: "e2e-test-crd-publish-openapi-333-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Nov  5 12:51:37.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 apply -f -'
    Nov  5 12:51:38.440: INFO: stderr: ""
    Nov  5 12:51:38.440: INFO: stdout: "e2e-test-crd-publish-openapi-333-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Nov  5 12:51:38.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 delete e2e-test-crd-publish-openapi-333-crds test-foo'
    Nov  5 12:51:38.512: INFO: stderr: ""
    Nov  5 12:51:38.512: INFO: stdout: "e2e-test-crd-publish-openapi-333-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 11/05/22 12:51:38.512
    Nov  5 12:51:38.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 create -f -'
    Nov  5 12:51:38.745: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 11/05/22 12:51:38.745
    Nov  5 12:51:38.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 create -f -'
    Nov  5 12:51:38.975: INFO: rc: 1
    Nov  5 12:51:38.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 apply -f -'
    Nov  5 12:51:39.164: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 11/05/22 12:51:39.164
    Nov  5 12:51:39.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 create -f -'
    Nov  5 12:51:39.335: INFO: rc: 1
    Nov  5 12:51:39.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 --namespace=crd-publish-openapi-1002 apply -f -'
    Nov  5 12:51:39.562: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 11/05/22 12:51:39.563
    Nov  5 12:51:39.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 explain e2e-test-crd-publish-openapi-333-crds'
    Nov  5 12:51:39.790: INFO: stderr: ""
    Nov  5 12:51:39.790: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-333-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 11/05/22 12:51:39.791
    Nov  5 12:51:39.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 explain e2e-test-crd-publish-openapi-333-crds.metadata'
    Nov  5 12:51:40.011: INFO: stderr: ""
    Nov  5 12:51:40.011: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-333-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Nov  5 12:51:40.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 explain e2e-test-crd-publish-openapi-333-crds.spec'
    Nov  5 12:51:40.238: INFO: stderr: ""
    Nov  5 12:51:40.238: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-333-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Nov  5 12:51:40.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 explain e2e-test-crd-publish-openapi-333-crds.spec.bars'
    Nov  5 12:51:40.407: INFO: stderr: ""
    Nov  5 12:51:40.408: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-333-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 11/05/22 12:51:40.408
    Nov  5 12:51:40.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1002 explain e2e-test-crd-publish-openapi-333-crds.spec.bars2'
    Nov  5 12:51:40.641: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 12:51:42.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1002" for this suite. 11/05/22 12:51:42.818
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:42.826
Nov  5 12:51:42.826: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename gc 11/05/22 12:51:42.827
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:42.841
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:42.847
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 11/05/22 12:51:42.85
STEP: delete the rc 11/05/22 12:51:47.863
STEP: wait for all pods to be garbage collected 11/05/22 12:51:47.869
STEP: Gathering metrics 11/05/22 12:51:52.877
W1105 12:51:52.882011      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov  5 12:51:52.882: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov  5 12:51:52.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6097" for this suite. 11/05/22 12:51:52.885
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":231,"skipped":4228,"failed":0}
------------------------------
• [SLOW TEST] [10.066 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:42.826
    Nov  5 12:51:42.826: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename gc 11/05/22 12:51:42.827
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:42.841
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:42.847
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 11/05/22 12:51:42.85
    STEP: delete the rc 11/05/22 12:51:47.863
    STEP: wait for all pods to be garbage collected 11/05/22 12:51:47.869
    STEP: Gathering metrics 11/05/22 12:51:52.877
    W1105 12:51:52.882011      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov  5 12:51:52.882: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov  5 12:51:52.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-6097" for this suite. 11/05/22 12:51:52.885
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:52.893
Nov  5 12:51:52.893: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 12:51:52.894
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:52.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:52.911
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 11/05/22 12:51:52.919
Nov  5 12:51:52.926: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e" in namespace "downward-api-9937" to be "Succeeded or Failed"
Nov  5 12:51:52.930: INFO: Pod "downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.495069ms
Nov  5 12:51:54.934: INFO: Pod "downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007993435s
Nov  5 12:51:56.935: INFO: Pod "downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008749389s
STEP: Saw pod success 11/05/22 12:51:56.935
Nov  5 12:51:56.935: INFO: Pod "downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e" satisfied condition "Succeeded or Failed"
Nov  5 12:51:56.939: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e container client-container: <nil>
STEP: delete the pod 11/05/22 12:51:56.945
Nov  5 12:51:56.955: INFO: Waiting for pod downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e to disappear
Nov  5 12:51:56.959: INFO: Pod downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 12:51:56.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9937" for this suite. 11/05/22 12:51:56.962
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":232,"skipped":4246,"failed":0}
------------------------------
• [4.077 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:52.893
    Nov  5 12:51:52.893: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 12:51:52.894
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:52.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:52.911
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 11/05/22 12:51:52.919
    Nov  5 12:51:52.926: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e" in namespace "downward-api-9937" to be "Succeeded or Failed"
    Nov  5 12:51:52.930: INFO: Pod "downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.495069ms
    Nov  5 12:51:54.934: INFO: Pod "downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007993435s
    Nov  5 12:51:56.935: INFO: Pod "downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008749389s
    STEP: Saw pod success 11/05/22 12:51:56.935
    Nov  5 12:51:56.935: INFO: Pod "downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e" satisfied condition "Succeeded or Failed"
    Nov  5 12:51:56.939: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e container client-container: <nil>
    STEP: delete the pod 11/05/22 12:51:56.945
    Nov  5 12:51:56.955: INFO: Waiting for pod downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e to disappear
    Nov  5 12:51:56.959: INFO: Pod downwardapi-volume-6a1386d2-2097-4d2f-ba48-71c412ab444e no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 12:51:56.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9937" for this suite. 11/05/22 12:51:56.962
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:51:56.971
Nov  5 12:51:56.971: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-probe 11/05/22 12:51:56.971
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:56.984
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:56.989
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Nov  5 12:51:57.001: INFO: Waiting up to 5m0s for pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e" in namespace "container-probe-7053" to be "running and ready"
Nov  5 12:51:57.007: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.32384ms
Nov  5 12:51:57.007: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:51:59.011: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 2.009732467s
Nov  5 12:51:59.011: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
Nov  5 12:52:01.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 4.010586121s
Nov  5 12:52:01.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
Nov  5 12:52:03.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 6.011089633s
Nov  5 12:52:03.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
Nov  5 12:52:05.013: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 8.011495692s
Nov  5 12:52:05.013: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
Nov  5 12:52:07.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 10.010339892s
Nov  5 12:52:07.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
Nov  5 12:52:09.013: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 12.011596392s
Nov  5 12:52:09.013: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
Nov  5 12:52:11.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 14.010494924s
Nov  5 12:52:11.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
Nov  5 12:52:13.011: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 16.009812022s
Nov  5 12:52:13.011: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
Nov  5 12:52:15.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 18.010487599s
Nov  5 12:52:15.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
Nov  5 12:52:17.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 20.01053507s
Nov  5 12:52:17.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
Nov  5 12:52:19.011: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=true. Elapsed: 22.0100901s
Nov  5 12:52:19.011: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = true)
Nov  5 12:52:19.011: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e" satisfied condition "running and ready"
Nov  5 12:52:19.015: INFO: Container started at 2022-11-05 12:51:57 +0000 UTC, pod became ready at 2022-11-05 12:52:17 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov  5 12:52:19.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7053" for this suite. 11/05/22 12:52:19.019
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":233,"skipped":4259,"failed":0}
------------------------------
• [SLOW TEST] [22.056 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:51:56.971
    Nov  5 12:51:56.971: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-probe 11/05/22 12:51:56.971
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:51:56.984
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:51:56.989
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Nov  5 12:51:57.001: INFO: Waiting up to 5m0s for pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e" in namespace "container-probe-7053" to be "running and ready"
    Nov  5 12:51:57.007: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.32384ms
    Nov  5 12:51:57.007: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:51:59.011: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 2.009732467s
    Nov  5 12:51:59.011: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
    Nov  5 12:52:01.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 4.010586121s
    Nov  5 12:52:01.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
    Nov  5 12:52:03.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 6.011089633s
    Nov  5 12:52:03.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
    Nov  5 12:52:05.013: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 8.011495692s
    Nov  5 12:52:05.013: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
    Nov  5 12:52:07.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 10.010339892s
    Nov  5 12:52:07.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
    Nov  5 12:52:09.013: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 12.011596392s
    Nov  5 12:52:09.013: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
    Nov  5 12:52:11.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 14.010494924s
    Nov  5 12:52:11.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
    Nov  5 12:52:13.011: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 16.009812022s
    Nov  5 12:52:13.011: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
    Nov  5 12:52:15.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 18.010487599s
    Nov  5 12:52:15.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
    Nov  5 12:52:17.012: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=false. Elapsed: 20.01053507s
    Nov  5 12:52:17.012: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = false)
    Nov  5 12:52:19.011: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e": Phase="Running", Reason="", readiness=true. Elapsed: 22.0100901s
    Nov  5 12:52:19.011: INFO: The phase of Pod test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e is Running (Ready = true)
    Nov  5 12:52:19.011: INFO: Pod "test-webserver-ab953ed1-0f93-4a61-b3b0-d1c70d91f14e" satisfied condition "running and ready"
    Nov  5 12:52:19.015: INFO: Container started at 2022-11-05 12:51:57 +0000 UTC, pod became ready at 2022-11-05 12:52:17 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov  5 12:52:19.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7053" for this suite. 11/05/22 12:52:19.019
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:52:19.029
Nov  5 12:52:19.030: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename var-expansion 11/05/22 12:52:19.03
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:52:19.047
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:52:19.05
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 11/05/22 12:52:19.054
Nov  5 12:52:19.062: INFO: Waiting up to 2m0s for pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d" in namespace "var-expansion-1042" to be "running"
Nov  5 12:52:19.068: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.335567ms
Nov  5 12:52:21.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010114869s
Nov  5 12:52:23.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010276684s
Nov  5 12:52:25.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010394304s
Nov  5 12:52:27.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010173561s
Nov  5 12:52:29.075: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012932244s
Nov  5 12:52:31.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.010302822s
Nov  5 12:52:33.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.011193324s
Nov  5 12:52:35.075: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.012837937s
Nov  5 12:52:37.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.011006944s
Nov  5 12:52:39.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.012096338s
Nov  5 12:52:41.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 22.010108424s
Nov  5 12:52:43.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.011189237s
Nov  5 12:52:45.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 26.010243819s
Nov  5 12:52:47.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.010478741s
Nov  5 12:52:49.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 30.010931579s
Nov  5 12:52:51.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 32.010787471s
Nov  5 12:52:53.075: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 34.012700839s
Nov  5 12:52:55.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 36.010045575s
Nov  5 12:52:57.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 38.010432383s
Nov  5 12:52:59.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 40.010746888s
Nov  5 12:53:01.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 42.011488634s
Nov  5 12:53:03.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 44.011359055s
Nov  5 12:53:05.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 46.011151501s
Nov  5 12:53:07.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 48.010431364s
Nov  5 12:53:09.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 50.011395743s
Nov  5 12:53:11.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 52.010509356s
Nov  5 12:53:13.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 54.010535213s
Nov  5 12:53:15.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 56.01110626s
Nov  5 12:53:17.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 58.010612405s
Nov  5 12:53:19.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.010699947s
Nov  5 12:53:21.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.010136907s
Nov  5 12:53:23.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.010731253s
Nov  5 12:53:25.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.010141571s
Nov  5 12:53:27.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.01126621s
Nov  5 12:53:29.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.011805351s
Nov  5 12:53:31.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.010357265s
Nov  5 12:53:33.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.011528221s
Nov  5 12:53:35.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.011314081s
Nov  5 12:53:37.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.010376928s
Nov  5 12:53:39.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.010369312s
Nov  5 12:53:41.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.010261304s
Nov  5 12:53:43.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.012089336s
Nov  5 12:53:45.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.01178367s
Nov  5 12:53:47.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.010013534s
Nov  5 12:53:49.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.010262589s
Nov  5 12:53:51.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.011132654s
Nov  5 12:53:53.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.010351416s
Nov  5 12:53:55.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.012300286s
Nov  5 12:53:57.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.010637004s
Nov  5 12:53:59.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.010132834s
Nov  5 12:54:01.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.010526165s
Nov  5 12:54:03.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.011277379s
Nov  5 12:54:05.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.010558326s
Nov  5 12:54:07.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.010186203s
Nov  5 12:54:09.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.011793856s
Nov  5 12:54:11.075: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.013144497s
Nov  5 12:54:13.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.011699174s
Nov  5 12:54:15.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.011057246s
Nov  5 12:54:17.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.010724137s
Nov  5 12:54:19.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.010791292s
Nov  5 12:54:19.076: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.014635436s
STEP: updating the pod 11/05/22 12:54:19.077
Nov  5 12:54:19.589: INFO: Successfully updated pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d"
STEP: waiting for pod running 11/05/22 12:54:19.589
Nov  5 12:54:19.589: INFO: Waiting up to 2m0s for pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d" in namespace "var-expansion-1042" to be "running"
Nov  5 12:54:19.593: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.290749ms
Nov  5 12:54:21.597: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Running", Reason="", readiness=true. Elapsed: 2.007199003s
Nov  5 12:54:21.597: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d" satisfied condition "running"
STEP: deleting the pod gracefully 11/05/22 12:54:21.597
Nov  5 12:54:21.597: INFO: Deleting pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d" in namespace "var-expansion-1042"
Nov  5 12:54:21.605: INFO: Wait up to 5m0s for pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Nov  5 12:54:53.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1042" for this suite. 11/05/22 12:54:53.617
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":234,"skipped":4300,"failed":0}
------------------------------
• [SLOW TEST] [154.594 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:52:19.029
    Nov  5 12:52:19.030: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename var-expansion 11/05/22 12:52:19.03
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:52:19.047
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:52:19.05
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 11/05/22 12:52:19.054
    Nov  5 12:52:19.062: INFO: Waiting up to 2m0s for pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d" in namespace "var-expansion-1042" to be "running"
    Nov  5 12:52:19.068: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.335567ms
    Nov  5 12:52:21.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010114869s
    Nov  5 12:52:23.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010276684s
    Nov  5 12:52:25.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010394304s
    Nov  5 12:52:27.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010173561s
    Nov  5 12:52:29.075: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012932244s
    Nov  5 12:52:31.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.010302822s
    Nov  5 12:52:33.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.011193324s
    Nov  5 12:52:35.075: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.012837937s
    Nov  5 12:52:37.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.011006944s
    Nov  5 12:52:39.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.012096338s
    Nov  5 12:52:41.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 22.010108424s
    Nov  5 12:52:43.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.011189237s
    Nov  5 12:52:45.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 26.010243819s
    Nov  5 12:52:47.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 28.010478741s
    Nov  5 12:52:49.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 30.010931579s
    Nov  5 12:52:51.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 32.010787471s
    Nov  5 12:52:53.075: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 34.012700839s
    Nov  5 12:52:55.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 36.010045575s
    Nov  5 12:52:57.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 38.010432383s
    Nov  5 12:52:59.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 40.010746888s
    Nov  5 12:53:01.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 42.011488634s
    Nov  5 12:53:03.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 44.011359055s
    Nov  5 12:53:05.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 46.011151501s
    Nov  5 12:53:07.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 48.010431364s
    Nov  5 12:53:09.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 50.011395743s
    Nov  5 12:53:11.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 52.010509356s
    Nov  5 12:53:13.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 54.010535213s
    Nov  5 12:53:15.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 56.01110626s
    Nov  5 12:53:17.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 58.010612405s
    Nov  5 12:53:19.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.010699947s
    Nov  5 12:53:21.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.010136907s
    Nov  5 12:53:23.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.010731253s
    Nov  5 12:53:25.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.010141571s
    Nov  5 12:53:27.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.01126621s
    Nov  5 12:53:29.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.011805351s
    Nov  5 12:53:31.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.010357265s
    Nov  5 12:53:33.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.011528221s
    Nov  5 12:53:35.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.011314081s
    Nov  5 12:53:37.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.010376928s
    Nov  5 12:53:39.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.010369312s
    Nov  5 12:53:41.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.010261304s
    Nov  5 12:53:43.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.012089336s
    Nov  5 12:53:45.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.01178367s
    Nov  5 12:53:47.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.010013534s
    Nov  5 12:53:49.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.010262589s
    Nov  5 12:53:51.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.011132654s
    Nov  5 12:53:53.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.010351416s
    Nov  5 12:53:55.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.012300286s
    Nov  5 12:53:57.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.010637004s
    Nov  5 12:53:59.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.010132834s
    Nov  5 12:54:01.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.010526165s
    Nov  5 12:54:03.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.011277379s
    Nov  5 12:54:05.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.010558326s
    Nov  5 12:54:07.072: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.010186203s
    Nov  5 12:54:09.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.011793856s
    Nov  5 12:54:11.075: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.013144497s
    Nov  5 12:54:13.074: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.011699174s
    Nov  5 12:54:15.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.011057246s
    Nov  5 12:54:17.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.010724137s
    Nov  5 12:54:19.073: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.010791292s
    Nov  5 12:54:19.076: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.014635436s
    STEP: updating the pod 11/05/22 12:54:19.077
    Nov  5 12:54:19.589: INFO: Successfully updated pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d"
    STEP: waiting for pod running 11/05/22 12:54:19.589
    Nov  5 12:54:19.589: INFO: Waiting up to 2m0s for pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d" in namespace "var-expansion-1042" to be "running"
    Nov  5 12:54:19.593: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.290749ms
    Nov  5 12:54:21.597: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d": Phase="Running", Reason="", readiness=true. Elapsed: 2.007199003s
    Nov  5 12:54:21.597: INFO: Pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d" satisfied condition "running"
    STEP: deleting the pod gracefully 11/05/22 12:54:21.597
    Nov  5 12:54:21.597: INFO: Deleting pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d" in namespace "var-expansion-1042"
    Nov  5 12:54:21.605: INFO: Wait up to 5m0s for pod "var-expansion-9f1472dd-b6c3-45d1-a09c-4257a777e27d" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Nov  5 12:54:53.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1042" for this suite. 11/05/22 12:54:53.617
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:54:53.624
Nov  5 12:54:53.624: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 12:54:53.625
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:54:53.64
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:54:53.645
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Nov  5 12:54:53.649: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: creating the pod 11/05/22 12:54:53.65
STEP: submitting the pod to kubernetes 11/05/22 12:54:53.65
Nov  5 12:54:53.659: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e" in namespace "pods-3524" to be "running and ready"
Nov  5 12:54:53.663: INFO: Pod "pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.23793ms
Nov  5 12:54:53.663: INFO: The phase of Pod pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e is Pending, waiting for it to be Running (with Ready = true)
Nov  5 12:54:55.668: INFO: Pod "pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e": Phase="Running", Reason="", readiness=true. Elapsed: 2.008386409s
Nov  5 12:54:55.668: INFO: The phase of Pod pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e is Running (Ready = true)
Nov  5 12:54:55.668: INFO: Pod "pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov  5 12:54:55.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3524" for this suite. 11/05/22 12:54:55.777
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":235,"skipped":4309,"failed":0}
------------------------------
• [2.159 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:54:53.624
    Nov  5 12:54:53.624: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 12:54:53.625
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:54:53.64
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:54:53.645
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Nov  5 12:54:53.649: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: creating the pod 11/05/22 12:54:53.65
    STEP: submitting the pod to kubernetes 11/05/22 12:54:53.65
    Nov  5 12:54:53.659: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e" in namespace "pods-3524" to be "running and ready"
    Nov  5 12:54:53.663: INFO: Pod "pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.23793ms
    Nov  5 12:54:53.663: INFO: The phase of Pod pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 12:54:55.668: INFO: Pod "pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e": Phase="Running", Reason="", readiness=true. Elapsed: 2.008386409s
    Nov  5 12:54:55.668: INFO: The phase of Pod pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e is Running (Ready = true)
    Nov  5 12:54:55.668: INFO: Pod "pod-exec-websocket-fdbafcda-2344-491d-8ed3-86687338be1e" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov  5 12:54:55.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3524" for this suite. 11/05/22 12:54:55.777
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:54:55.787
Nov  5 12:54:55.787: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename gc 11/05/22 12:54:55.788
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:54:55.802
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:54:55.807
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 11/05/22 12:54:55.818
STEP: delete the rc 11/05/22 12:55:00.828
STEP: wait for the rc to be deleted 11/05/22 12:55:00.839
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 11/05/22 12:55:05.843
STEP: Gathering metrics 11/05/22 12:55:35.855
W1105 12:55:35.859315      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov  5 12:55:35.859: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Nov  5 12:55:35.859: INFO: Deleting pod "simpletest.rc-2cmsx" in namespace "gc-1937"
Nov  5 12:55:35.873: INFO: Deleting pod "simpletest.rc-2zzb8" in namespace "gc-1937"
Nov  5 12:55:35.885: INFO: Deleting pod "simpletest.rc-49tv5" in namespace "gc-1937"
Nov  5 12:55:35.919: INFO: Deleting pod "simpletest.rc-4v4hs" in namespace "gc-1937"
Nov  5 12:55:35.939: INFO: Deleting pod "simpletest.rc-4z9ds" in namespace "gc-1937"
Nov  5 12:55:35.952: INFO: Deleting pod "simpletest.rc-4zt8p" in namespace "gc-1937"
Nov  5 12:55:35.962: INFO: Deleting pod "simpletest.rc-5bfqz" in namespace "gc-1937"
Nov  5 12:55:35.975: INFO: Deleting pod "simpletest.rc-5fmws" in namespace "gc-1937"
Nov  5 12:55:35.989: INFO: Deleting pod "simpletest.rc-5k6fz" in namespace "gc-1937"
Nov  5 12:55:35.999: INFO: Deleting pod "simpletest.rc-5kzxx" in namespace "gc-1937"
Nov  5 12:55:36.010: INFO: Deleting pod "simpletest.rc-5mf2b" in namespace "gc-1937"
Nov  5 12:55:36.021: INFO: Deleting pod "simpletest.rc-5rflb" in namespace "gc-1937"
Nov  5 12:55:36.032: INFO: Deleting pod "simpletest.rc-62wgd" in namespace "gc-1937"
Nov  5 12:55:36.050: INFO: Deleting pod "simpletest.rc-64p4q" in namespace "gc-1937"
Nov  5 12:55:36.062: INFO: Deleting pod "simpletest.rc-6hmxp" in namespace "gc-1937"
Nov  5 12:55:36.072: INFO: Deleting pod "simpletest.rc-72lg2" in namespace "gc-1937"
Nov  5 12:55:36.087: INFO: Deleting pod "simpletest.rc-74d6z" in namespace "gc-1937"
Nov  5 12:55:36.097: INFO: Deleting pod "simpletest.rc-78clk" in namespace "gc-1937"
Nov  5 12:55:36.121: INFO: Deleting pod "simpletest.rc-7cvnw" in namespace "gc-1937"
Nov  5 12:55:36.133: INFO: Deleting pod "simpletest.rc-7cxhn" in namespace "gc-1937"
Nov  5 12:55:36.145: INFO: Deleting pod "simpletest.rc-84nk5" in namespace "gc-1937"
Nov  5 12:55:36.157: INFO: Deleting pod "simpletest.rc-85zn4" in namespace "gc-1937"
Nov  5 12:55:36.168: INFO: Deleting pod "simpletest.rc-8brw5" in namespace "gc-1937"
Nov  5 12:55:36.182: INFO: Deleting pod "simpletest.rc-8w849" in namespace "gc-1937"
Nov  5 12:55:36.195: INFO: Deleting pod "simpletest.rc-95q9c" in namespace "gc-1937"
Nov  5 12:55:36.207: INFO: Deleting pod "simpletest.rc-966lk" in namespace "gc-1937"
Nov  5 12:55:36.218: INFO: Deleting pod "simpletest.rc-9ks57" in namespace "gc-1937"
Nov  5 12:55:36.228: INFO: Deleting pod "simpletest.rc-9vbkr" in namespace "gc-1937"
Nov  5 12:55:36.239: INFO: Deleting pod "simpletest.rc-b9whk" in namespace "gc-1937"
Nov  5 12:55:36.252: INFO: Deleting pod "simpletest.rc-bjc4z" in namespace "gc-1937"
Nov  5 12:55:36.266: INFO: Deleting pod "simpletest.rc-brgzd" in namespace "gc-1937"
Nov  5 12:55:36.278: INFO: Deleting pod "simpletest.rc-bt7sq" in namespace "gc-1937"
Nov  5 12:55:36.290: INFO: Deleting pod "simpletest.rc-bz78l" in namespace "gc-1937"
Nov  5 12:55:36.303: INFO: Deleting pod "simpletest.rc-cxwpv" in namespace "gc-1937"
Nov  5 12:55:36.314: INFO: Deleting pod "simpletest.rc-d49bh" in namespace "gc-1937"
Nov  5 12:55:36.327: INFO: Deleting pod "simpletest.rc-d6lhz" in namespace "gc-1937"
Nov  5 12:55:36.339: INFO: Deleting pod "simpletest.rc-drnhf" in namespace "gc-1937"
Nov  5 12:55:36.353: INFO: Deleting pod "simpletest.rc-dw89x" in namespace "gc-1937"
Nov  5 12:55:36.364: INFO: Deleting pod "simpletest.rc-f89d9" in namespace "gc-1937"
Nov  5 12:55:36.453: INFO: Deleting pod "simpletest.rc-ffjtp" in namespace "gc-1937"
Nov  5 12:55:36.465: INFO: Deleting pod "simpletest.rc-g5rw5" in namespace "gc-1937"
Nov  5 12:55:36.478: INFO: Deleting pod "simpletest.rc-g8jnj" in namespace "gc-1937"
Nov  5 12:55:36.491: INFO: Deleting pod "simpletest.rc-gqdff" in namespace "gc-1937"
Nov  5 12:55:36.505: INFO: Deleting pod "simpletest.rc-h5nsc" in namespace "gc-1937"
Nov  5 12:55:36.520: INFO: Deleting pod "simpletest.rc-h6mbx" in namespace "gc-1937"
Nov  5 12:55:36.529: INFO: Deleting pod "simpletest.rc-h7ph8" in namespace "gc-1937"
Nov  5 12:55:36.540: INFO: Deleting pod "simpletest.rc-hcpzs" in namespace "gc-1937"
Nov  5 12:55:36.552: INFO: Deleting pod "simpletest.rc-hnlmn" in namespace "gc-1937"
Nov  5 12:55:36.566: INFO: Deleting pod "simpletest.rc-j82tc" in namespace "gc-1937"
Nov  5 12:55:36.578: INFO: Deleting pod "simpletest.rc-jkdr9" in namespace "gc-1937"
Nov  5 12:55:36.589: INFO: Deleting pod "simpletest.rc-k2f42" in namespace "gc-1937"
Nov  5 12:55:36.604: INFO: Deleting pod "simpletest.rc-k4xzz" in namespace "gc-1937"
Nov  5 12:55:36.614: INFO: Deleting pod "simpletest.rc-k6hfh" in namespace "gc-1937"
Nov  5 12:55:36.626: INFO: Deleting pod "simpletest.rc-kf67m" in namespace "gc-1937"
Nov  5 12:55:36.637: INFO: Deleting pod "simpletest.rc-kggx5" in namespace "gc-1937"
Nov  5 12:55:36.650: INFO: Deleting pod "simpletest.rc-kh2gz" in namespace "gc-1937"
Nov  5 12:55:36.663: INFO: Deleting pod "simpletest.rc-lq58n" in namespace "gc-1937"
Nov  5 12:55:36.673: INFO: Deleting pod "simpletest.rc-lxsqr" in namespace "gc-1937"
Nov  5 12:55:36.691: INFO: Deleting pod "simpletest.rc-mr9zj" in namespace "gc-1937"
Nov  5 12:55:36.705: INFO: Deleting pod "simpletest.rc-mrb5f" in namespace "gc-1937"
Nov  5 12:55:36.717: INFO: Deleting pod "simpletest.rc-mvxds" in namespace "gc-1937"
Nov  5 12:55:36.729: INFO: Deleting pod "simpletest.rc-mzqnz" in namespace "gc-1937"
Nov  5 12:55:36.751: INFO: Deleting pod "simpletest.rc-mzz2v" in namespace "gc-1937"
Nov  5 12:55:36.764: INFO: Deleting pod "simpletest.rc-n2tmq" in namespace "gc-1937"
Nov  5 12:55:36.774: INFO: Deleting pod "simpletest.rc-n65c2" in namespace "gc-1937"
Nov  5 12:55:36.783: INFO: Deleting pod "simpletest.rc-n95td" in namespace "gc-1937"
Nov  5 12:55:36.796: INFO: Deleting pod "simpletest.rc-n9799" in namespace "gc-1937"
Nov  5 12:55:36.810: INFO: Deleting pod "simpletest.rc-ndgrh" in namespace "gc-1937"
Nov  5 12:55:36.857: INFO: Deleting pod "simpletest.rc-nvs8h" in namespace "gc-1937"
Nov  5 12:55:36.909: INFO: Deleting pod "simpletest.rc-pc2ch" in namespace "gc-1937"
Nov  5 12:55:36.958: INFO: Deleting pod "simpletest.rc-pdvg4" in namespace "gc-1937"
Nov  5 12:55:37.008: INFO: Deleting pod "simpletest.rc-plc5c" in namespace "gc-1937"
Nov  5 12:55:37.059: INFO: Deleting pod "simpletest.rc-pqmfc" in namespace "gc-1937"
Nov  5 12:55:37.105: INFO: Deleting pod "simpletest.rc-prd6j" in namespace "gc-1937"
Nov  5 12:55:37.170: INFO: Deleting pod "simpletest.rc-q58bk" in namespace "gc-1937"
Nov  5 12:55:37.207: INFO: Deleting pod "simpletest.rc-q5c6v" in namespace "gc-1937"
Nov  5 12:55:37.259: INFO: Deleting pod "simpletest.rc-qfz2s" in namespace "gc-1937"
Nov  5 12:55:37.308: INFO: Deleting pod "simpletest.rc-qzq8d" in namespace "gc-1937"
Nov  5 12:55:37.356: INFO: Deleting pod "simpletest.rc-rgjh7" in namespace "gc-1937"
Nov  5 12:55:37.406: INFO: Deleting pod "simpletest.rc-rmr89" in namespace "gc-1937"
Nov  5 12:55:37.458: INFO: Deleting pod "simpletest.rc-rx6zs" in namespace "gc-1937"
Nov  5 12:55:37.507: INFO: Deleting pod "simpletest.rc-rz84s" in namespace "gc-1937"
Nov  5 12:55:37.559: INFO: Deleting pod "simpletest.rc-s2knm" in namespace "gc-1937"
Nov  5 12:55:37.607: INFO: Deleting pod "simpletest.rc-s5dtv" in namespace "gc-1937"
Nov  5 12:55:37.657: INFO: Deleting pod "simpletest.rc-sk6cg" in namespace "gc-1937"
Nov  5 12:55:37.714: INFO: Deleting pod "simpletest.rc-t22n4" in namespace "gc-1937"
Nov  5 12:55:37.759: INFO: Deleting pod "simpletest.rc-t2zch" in namespace "gc-1937"
Nov  5 12:55:37.808: INFO: Deleting pod "simpletest.rc-tgjbz" in namespace "gc-1937"
Nov  5 12:55:37.856: INFO: Deleting pod "simpletest.rc-twznd" in namespace "gc-1937"
Nov  5 12:55:37.907: INFO: Deleting pod "simpletest.rc-v5plk" in namespace "gc-1937"
Nov  5 12:55:37.956: INFO: Deleting pod "simpletest.rc-v997n" in namespace "gc-1937"
Nov  5 12:55:38.012: INFO: Deleting pod "simpletest.rc-vljtc" in namespace "gc-1937"
Nov  5 12:55:38.058: INFO: Deleting pod "simpletest.rc-w6gs8" in namespace "gc-1937"
Nov  5 12:55:38.109: INFO: Deleting pod "simpletest.rc-x2np8" in namespace "gc-1937"
Nov  5 12:55:38.158: INFO: Deleting pod "simpletest.rc-x69rm" in namespace "gc-1937"
Nov  5 12:55:38.207: INFO: Deleting pod "simpletest.rc-x6f5l" in namespace "gc-1937"
Nov  5 12:55:38.259: INFO: Deleting pod "simpletest.rc-xf298" in namespace "gc-1937"
Nov  5 12:55:38.307: INFO: Deleting pod "simpletest.rc-z8vmq" in namespace "gc-1937"
Nov  5 12:55:38.364: INFO: Deleting pod "simpletest.rc-zd9z2" in namespace "gc-1937"
Nov  5 12:55:38.410: INFO: Deleting pod "simpletest.rc-zmfth" in namespace "gc-1937"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov  5 12:55:38.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1937" for this suite. 11/05/22 12:55:38.499
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":236,"skipped":4345,"failed":0}
------------------------------
• [SLOW TEST] [42.766 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:54:55.787
    Nov  5 12:54:55.787: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename gc 11/05/22 12:54:55.788
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:54:55.802
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:54:55.807
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 11/05/22 12:54:55.818
    STEP: delete the rc 11/05/22 12:55:00.828
    STEP: wait for the rc to be deleted 11/05/22 12:55:00.839
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 11/05/22 12:55:05.843
    STEP: Gathering metrics 11/05/22 12:55:35.855
    W1105 12:55:35.859315      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov  5 12:55:35.859: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Nov  5 12:55:35.859: INFO: Deleting pod "simpletest.rc-2cmsx" in namespace "gc-1937"
    Nov  5 12:55:35.873: INFO: Deleting pod "simpletest.rc-2zzb8" in namespace "gc-1937"
    Nov  5 12:55:35.885: INFO: Deleting pod "simpletest.rc-49tv5" in namespace "gc-1937"
    Nov  5 12:55:35.919: INFO: Deleting pod "simpletest.rc-4v4hs" in namespace "gc-1937"
    Nov  5 12:55:35.939: INFO: Deleting pod "simpletest.rc-4z9ds" in namespace "gc-1937"
    Nov  5 12:55:35.952: INFO: Deleting pod "simpletest.rc-4zt8p" in namespace "gc-1937"
    Nov  5 12:55:35.962: INFO: Deleting pod "simpletest.rc-5bfqz" in namespace "gc-1937"
    Nov  5 12:55:35.975: INFO: Deleting pod "simpletest.rc-5fmws" in namespace "gc-1937"
    Nov  5 12:55:35.989: INFO: Deleting pod "simpletest.rc-5k6fz" in namespace "gc-1937"
    Nov  5 12:55:35.999: INFO: Deleting pod "simpletest.rc-5kzxx" in namespace "gc-1937"
    Nov  5 12:55:36.010: INFO: Deleting pod "simpletest.rc-5mf2b" in namespace "gc-1937"
    Nov  5 12:55:36.021: INFO: Deleting pod "simpletest.rc-5rflb" in namespace "gc-1937"
    Nov  5 12:55:36.032: INFO: Deleting pod "simpletest.rc-62wgd" in namespace "gc-1937"
    Nov  5 12:55:36.050: INFO: Deleting pod "simpletest.rc-64p4q" in namespace "gc-1937"
    Nov  5 12:55:36.062: INFO: Deleting pod "simpletest.rc-6hmxp" in namespace "gc-1937"
    Nov  5 12:55:36.072: INFO: Deleting pod "simpletest.rc-72lg2" in namespace "gc-1937"
    Nov  5 12:55:36.087: INFO: Deleting pod "simpletest.rc-74d6z" in namespace "gc-1937"
    Nov  5 12:55:36.097: INFO: Deleting pod "simpletest.rc-78clk" in namespace "gc-1937"
    Nov  5 12:55:36.121: INFO: Deleting pod "simpletest.rc-7cvnw" in namespace "gc-1937"
    Nov  5 12:55:36.133: INFO: Deleting pod "simpletest.rc-7cxhn" in namespace "gc-1937"
    Nov  5 12:55:36.145: INFO: Deleting pod "simpletest.rc-84nk5" in namespace "gc-1937"
    Nov  5 12:55:36.157: INFO: Deleting pod "simpletest.rc-85zn4" in namespace "gc-1937"
    Nov  5 12:55:36.168: INFO: Deleting pod "simpletest.rc-8brw5" in namespace "gc-1937"
    Nov  5 12:55:36.182: INFO: Deleting pod "simpletest.rc-8w849" in namespace "gc-1937"
    Nov  5 12:55:36.195: INFO: Deleting pod "simpletest.rc-95q9c" in namespace "gc-1937"
    Nov  5 12:55:36.207: INFO: Deleting pod "simpletest.rc-966lk" in namespace "gc-1937"
    Nov  5 12:55:36.218: INFO: Deleting pod "simpletest.rc-9ks57" in namespace "gc-1937"
    Nov  5 12:55:36.228: INFO: Deleting pod "simpletest.rc-9vbkr" in namespace "gc-1937"
    Nov  5 12:55:36.239: INFO: Deleting pod "simpletest.rc-b9whk" in namespace "gc-1937"
    Nov  5 12:55:36.252: INFO: Deleting pod "simpletest.rc-bjc4z" in namespace "gc-1937"
    Nov  5 12:55:36.266: INFO: Deleting pod "simpletest.rc-brgzd" in namespace "gc-1937"
    Nov  5 12:55:36.278: INFO: Deleting pod "simpletest.rc-bt7sq" in namespace "gc-1937"
    Nov  5 12:55:36.290: INFO: Deleting pod "simpletest.rc-bz78l" in namespace "gc-1937"
    Nov  5 12:55:36.303: INFO: Deleting pod "simpletest.rc-cxwpv" in namespace "gc-1937"
    Nov  5 12:55:36.314: INFO: Deleting pod "simpletest.rc-d49bh" in namespace "gc-1937"
    Nov  5 12:55:36.327: INFO: Deleting pod "simpletest.rc-d6lhz" in namespace "gc-1937"
    Nov  5 12:55:36.339: INFO: Deleting pod "simpletest.rc-drnhf" in namespace "gc-1937"
    Nov  5 12:55:36.353: INFO: Deleting pod "simpletest.rc-dw89x" in namespace "gc-1937"
    Nov  5 12:55:36.364: INFO: Deleting pod "simpletest.rc-f89d9" in namespace "gc-1937"
    Nov  5 12:55:36.453: INFO: Deleting pod "simpletest.rc-ffjtp" in namespace "gc-1937"
    Nov  5 12:55:36.465: INFO: Deleting pod "simpletest.rc-g5rw5" in namespace "gc-1937"
    Nov  5 12:55:36.478: INFO: Deleting pod "simpletest.rc-g8jnj" in namespace "gc-1937"
    Nov  5 12:55:36.491: INFO: Deleting pod "simpletest.rc-gqdff" in namespace "gc-1937"
    Nov  5 12:55:36.505: INFO: Deleting pod "simpletest.rc-h5nsc" in namespace "gc-1937"
    Nov  5 12:55:36.520: INFO: Deleting pod "simpletest.rc-h6mbx" in namespace "gc-1937"
    Nov  5 12:55:36.529: INFO: Deleting pod "simpletest.rc-h7ph8" in namespace "gc-1937"
    Nov  5 12:55:36.540: INFO: Deleting pod "simpletest.rc-hcpzs" in namespace "gc-1937"
    Nov  5 12:55:36.552: INFO: Deleting pod "simpletest.rc-hnlmn" in namespace "gc-1937"
    Nov  5 12:55:36.566: INFO: Deleting pod "simpletest.rc-j82tc" in namespace "gc-1937"
    Nov  5 12:55:36.578: INFO: Deleting pod "simpletest.rc-jkdr9" in namespace "gc-1937"
    Nov  5 12:55:36.589: INFO: Deleting pod "simpletest.rc-k2f42" in namespace "gc-1937"
    Nov  5 12:55:36.604: INFO: Deleting pod "simpletest.rc-k4xzz" in namespace "gc-1937"
    Nov  5 12:55:36.614: INFO: Deleting pod "simpletest.rc-k6hfh" in namespace "gc-1937"
    Nov  5 12:55:36.626: INFO: Deleting pod "simpletest.rc-kf67m" in namespace "gc-1937"
    Nov  5 12:55:36.637: INFO: Deleting pod "simpletest.rc-kggx5" in namespace "gc-1937"
    Nov  5 12:55:36.650: INFO: Deleting pod "simpletest.rc-kh2gz" in namespace "gc-1937"
    Nov  5 12:55:36.663: INFO: Deleting pod "simpletest.rc-lq58n" in namespace "gc-1937"
    Nov  5 12:55:36.673: INFO: Deleting pod "simpletest.rc-lxsqr" in namespace "gc-1937"
    Nov  5 12:55:36.691: INFO: Deleting pod "simpletest.rc-mr9zj" in namespace "gc-1937"
    Nov  5 12:55:36.705: INFO: Deleting pod "simpletest.rc-mrb5f" in namespace "gc-1937"
    Nov  5 12:55:36.717: INFO: Deleting pod "simpletest.rc-mvxds" in namespace "gc-1937"
    Nov  5 12:55:36.729: INFO: Deleting pod "simpletest.rc-mzqnz" in namespace "gc-1937"
    Nov  5 12:55:36.751: INFO: Deleting pod "simpletest.rc-mzz2v" in namespace "gc-1937"
    Nov  5 12:55:36.764: INFO: Deleting pod "simpletest.rc-n2tmq" in namespace "gc-1937"
    Nov  5 12:55:36.774: INFO: Deleting pod "simpletest.rc-n65c2" in namespace "gc-1937"
    Nov  5 12:55:36.783: INFO: Deleting pod "simpletest.rc-n95td" in namespace "gc-1937"
    Nov  5 12:55:36.796: INFO: Deleting pod "simpletest.rc-n9799" in namespace "gc-1937"
    Nov  5 12:55:36.810: INFO: Deleting pod "simpletest.rc-ndgrh" in namespace "gc-1937"
    Nov  5 12:55:36.857: INFO: Deleting pod "simpletest.rc-nvs8h" in namespace "gc-1937"
    Nov  5 12:55:36.909: INFO: Deleting pod "simpletest.rc-pc2ch" in namespace "gc-1937"
    Nov  5 12:55:36.958: INFO: Deleting pod "simpletest.rc-pdvg4" in namespace "gc-1937"
    Nov  5 12:55:37.008: INFO: Deleting pod "simpletest.rc-plc5c" in namespace "gc-1937"
    Nov  5 12:55:37.059: INFO: Deleting pod "simpletest.rc-pqmfc" in namespace "gc-1937"
    Nov  5 12:55:37.105: INFO: Deleting pod "simpletest.rc-prd6j" in namespace "gc-1937"
    Nov  5 12:55:37.170: INFO: Deleting pod "simpletest.rc-q58bk" in namespace "gc-1937"
    Nov  5 12:55:37.207: INFO: Deleting pod "simpletest.rc-q5c6v" in namespace "gc-1937"
    Nov  5 12:55:37.259: INFO: Deleting pod "simpletest.rc-qfz2s" in namespace "gc-1937"
    Nov  5 12:55:37.308: INFO: Deleting pod "simpletest.rc-qzq8d" in namespace "gc-1937"
    Nov  5 12:55:37.356: INFO: Deleting pod "simpletest.rc-rgjh7" in namespace "gc-1937"
    Nov  5 12:55:37.406: INFO: Deleting pod "simpletest.rc-rmr89" in namespace "gc-1937"
    Nov  5 12:55:37.458: INFO: Deleting pod "simpletest.rc-rx6zs" in namespace "gc-1937"
    Nov  5 12:55:37.507: INFO: Deleting pod "simpletest.rc-rz84s" in namespace "gc-1937"
    Nov  5 12:55:37.559: INFO: Deleting pod "simpletest.rc-s2knm" in namespace "gc-1937"
    Nov  5 12:55:37.607: INFO: Deleting pod "simpletest.rc-s5dtv" in namespace "gc-1937"
    Nov  5 12:55:37.657: INFO: Deleting pod "simpletest.rc-sk6cg" in namespace "gc-1937"
    Nov  5 12:55:37.714: INFO: Deleting pod "simpletest.rc-t22n4" in namespace "gc-1937"
    Nov  5 12:55:37.759: INFO: Deleting pod "simpletest.rc-t2zch" in namespace "gc-1937"
    Nov  5 12:55:37.808: INFO: Deleting pod "simpletest.rc-tgjbz" in namespace "gc-1937"
    Nov  5 12:55:37.856: INFO: Deleting pod "simpletest.rc-twznd" in namespace "gc-1937"
    Nov  5 12:55:37.907: INFO: Deleting pod "simpletest.rc-v5plk" in namespace "gc-1937"
    Nov  5 12:55:37.956: INFO: Deleting pod "simpletest.rc-v997n" in namespace "gc-1937"
    Nov  5 12:55:38.012: INFO: Deleting pod "simpletest.rc-vljtc" in namespace "gc-1937"
    Nov  5 12:55:38.058: INFO: Deleting pod "simpletest.rc-w6gs8" in namespace "gc-1937"
    Nov  5 12:55:38.109: INFO: Deleting pod "simpletest.rc-x2np8" in namespace "gc-1937"
    Nov  5 12:55:38.158: INFO: Deleting pod "simpletest.rc-x69rm" in namespace "gc-1937"
    Nov  5 12:55:38.207: INFO: Deleting pod "simpletest.rc-x6f5l" in namespace "gc-1937"
    Nov  5 12:55:38.259: INFO: Deleting pod "simpletest.rc-xf298" in namespace "gc-1937"
    Nov  5 12:55:38.307: INFO: Deleting pod "simpletest.rc-z8vmq" in namespace "gc-1937"
    Nov  5 12:55:38.364: INFO: Deleting pod "simpletest.rc-zd9z2" in namespace "gc-1937"
    Nov  5 12:55:38.410: INFO: Deleting pod "simpletest.rc-zmfth" in namespace "gc-1937"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov  5 12:55:38.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1937" for this suite. 11/05/22 12:55:38.499
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:55:38.555
Nov  5 12:55:38.555: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename svcaccounts 11/05/22 12:55:38.556
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:55:38.582
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:55:38.587
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  11/05/22 12:55:38.597
Nov  5 12:55:38.606: INFO: Waiting up to 5m0s for pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86" in namespace "svcaccounts-1220" to be "Succeeded or Failed"
Nov  5 12:55:38.611: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Pending", Reason="", readiness=false. Elapsed: 5.397913ms
Nov  5 12:55:40.616: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010305788s
Nov  5 12:55:42.616: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010149515s
Nov  5 12:55:44.616: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01022512s
Nov  5 12:55:46.618: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012095342s
Nov  5 12:55:48.616: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.009863408s
STEP: Saw pod success 11/05/22 12:55:48.616
Nov  5 12:55:48.616: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86" satisfied condition "Succeeded or Failed"
Nov  5 12:55:48.619: INFO: Trying to get logs from node ip-172-31-0-255 pod test-pod-379b8b15-4785-445c-83ab-b90c76336e86 container agnhost-container: <nil>
STEP: delete the pod 11/05/22 12:55:48.636
Nov  5 12:55:48.646: INFO: Waiting for pod test-pod-379b8b15-4785-445c-83ab-b90c76336e86 to disappear
Nov  5 12:55:48.649: INFO: Pod test-pod-379b8b15-4785-445c-83ab-b90c76336e86 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov  5 12:55:48.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1220" for this suite. 11/05/22 12:55:48.653
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":237,"skipped":4350,"failed":0}
------------------------------
• [SLOW TEST] [10.105 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:55:38.555
    Nov  5 12:55:38.555: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename svcaccounts 11/05/22 12:55:38.556
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:55:38.582
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:55:38.587
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  11/05/22 12:55:38.597
    Nov  5 12:55:38.606: INFO: Waiting up to 5m0s for pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86" in namespace "svcaccounts-1220" to be "Succeeded or Failed"
    Nov  5 12:55:38.611: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Pending", Reason="", readiness=false. Elapsed: 5.397913ms
    Nov  5 12:55:40.616: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010305788s
    Nov  5 12:55:42.616: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010149515s
    Nov  5 12:55:44.616: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01022512s
    Nov  5 12:55:46.618: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012095342s
    Nov  5 12:55:48.616: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.009863408s
    STEP: Saw pod success 11/05/22 12:55:48.616
    Nov  5 12:55:48.616: INFO: Pod "test-pod-379b8b15-4785-445c-83ab-b90c76336e86" satisfied condition "Succeeded or Failed"
    Nov  5 12:55:48.619: INFO: Trying to get logs from node ip-172-31-0-255 pod test-pod-379b8b15-4785-445c-83ab-b90c76336e86 container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 12:55:48.636
    Nov  5 12:55:48.646: INFO: Waiting for pod test-pod-379b8b15-4785-445c-83ab-b90c76336e86 to disappear
    Nov  5 12:55:48.649: INFO: Pod test-pod-379b8b15-4785-445c-83ab-b90c76336e86 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov  5 12:55:48.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1220" for this suite. 11/05/22 12:55:48.653
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:55:48.661
Nov  5 12:55:48.661: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename gc 11/05/22 12:55:48.662
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:55:48.674
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:55:48.678
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 11/05/22 12:55:48.685
STEP: delete the rc 11/05/22 12:55:53.7
STEP: wait for the rc to be deleted 11/05/22 12:55:53.712
Nov  5 12:55:54.728: INFO: 80 pods remaining
Nov  5 12:55:54.728: INFO: 80 pods has nil DeletionTimestamp
Nov  5 12:55:54.728: INFO: 
Nov  5 12:55:55.726: INFO: 71 pods remaining
Nov  5 12:55:55.726: INFO: 71 pods has nil DeletionTimestamp
Nov  5 12:55:55.726: INFO: 
Nov  5 12:55:56.724: INFO: 60 pods remaining
Nov  5 12:55:56.724: INFO: 60 pods has nil DeletionTimestamp
Nov  5 12:55:56.724: INFO: 
Nov  5 12:55:57.725: INFO: 40 pods remaining
Nov  5 12:55:57.725: INFO: 40 pods has nil DeletionTimestamp
Nov  5 12:55:57.725: INFO: 
Nov  5 12:55:58.722: INFO: 31 pods remaining
Nov  5 12:55:58.722: INFO: 31 pods has nil DeletionTimestamp
Nov  5 12:55:58.722: INFO: 
Nov  5 12:55:59.724: INFO: 20 pods remaining
Nov  5 12:55:59.724: INFO: 20 pods has nil DeletionTimestamp
Nov  5 12:55:59.724: INFO: 
STEP: Gathering metrics 11/05/22 12:56:00.72
W1105 12:56:00.725284      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Nov  5 12:56:00.725: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov  5 12:56:00.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7132" for this suite. 11/05/22 12:56:00.729
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":238,"skipped":4377,"failed":0}
------------------------------
• [SLOW TEST] [12.075 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:55:48.661
    Nov  5 12:55:48.661: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename gc 11/05/22 12:55:48.662
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:55:48.674
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:55:48.678
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 11/05/22 12:55:48.685
    STEP: delete the rc 11/05/22 12:55:53.7
    STEP: wait for the rc to be deleted 11/05/22 12:55:53.712
    Nov  5 12:55:54.728: INFO: 80 pods remaining
    Nov  5 12:55:54.728: INFO: 80 pods has nil DeletionTimestamp
    Nov  5 12:55:54.728: INFO: 
    Nov  5 12:55:55.726: INFO: 71 pods remaining
    Nov  5 12:55:55.726: INFO: 71 pods has nil DeletionTimestamp
    Nov  5 12:55:55.726: INFO: 
    Nov  5 12:55:56.724: INFO: 60 pods remaining
    Nov  5 12:55:56.724: INFO: 60 pods has nil DeletionTimestamp
    Nov  5 12:55:56.724: INFO: 
    Nov  5 12:55:57.725: INFO: 40 pods remaining
    Nov  5 12:55:57.725: INFO: 40 pods has nil DeletionTimestamp
    Nov  5 12:55:57.725: INFO: 
    Nov  5 12:55:58.722: INFO: 31 pods remaining
    Nov  5 12:55:58.722: INFO: 31 pods has nil DeletionTimestamp
    Nov  5 12:55:58.722: INFO: 
    Nov  5 12:55:59.724: INFO: 20 pods remaining
    Nov  5 12:55:59.724: INFO: 20 pods has nil DeletionTimestamp
    Nov  5 12:55:59.724: INFO: 
    STEP: Gathering metrics 11/05/22 12:56:00.72
    W1105 12:56:00.725284      20 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Nov  5 12:56:00.725: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov  5 12:56:00.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-7132" for this suite. 11/05/22 12:56:00.729
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:56:00.737
Nov  5 12:56:00.737: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename statefulset 11/05/22 12:56:00.738
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:56:00.761
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:56:00.764
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6290 11/05/22 12:56:00.768
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-6290 11/05/22 12:56:00.776
Nov  5 12:56:00.786: INFO: Found 0 stateful pods, waiting for 1
Nov  5 12:56:10.791: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Nov  5 12:56:20.790: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 11/05/22 12:56:20.797
STEP: updating a scale subresource 11/05/22 12:56:20.801
STEP: verifying the statefulset Spec.Replicas was modified 11/05/22 12:56:20.805
STEP: Patch a scale subresource 11/05/22 12:56:20.809
STEP: verifying the statefulset Spec.Replicas was modified 11/05/22 12:56:20.817
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov  5 12:56:20.824: INFO: Deleting all statefulset in ns statefulset-6290
Nov  5 12:56:20.827: INFO: Scaling statefulset ss to 0
Nov  5 12:56:30.844: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 12:56:30.848: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov  5 12:56:30.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6290" for this suite. 11/05/22 12:56:30.887
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":239,"skipped":4407,"failed":0}
------------------------------
• [SLOW TEST] [30.158 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:56:00.737
    Nov  5 12:56:00.737: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename statefulset 11/05/22 12:56:00.738
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:56:00.761
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:56:00.764
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6290 11/05/22 12:56:00.768
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-6290 11/05/22 12:56:00.776
    Nov  5 12:56:00.786: INFO: Found 0 stateful pods, waiting for 1
    Nov  5 12:56:10.791: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
    Nov  5 12:56:20.790: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 11/05/22 12:56:20.797
    STEP: updating a scale subresource 11/05/22 12:56:20.801
    STEP: verifying the statefulset Spec.Replicas was modified 11/05/22 12:56:20.805
    STEP: Patch a scale subresource 11/05/22 12:56:20.809
    STEP: verifying the statefulset Spec.Replicas was modified 11/05/22 12:56:20.817
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov  5 12:56:20.824: INFO: Deleting all statefulset in ns statefulset-6290
    Nov  5 12:56:20.827: INFO: Scaling statefulset ss to 0
    Nov  5 12:56:30.844: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 12:56:30.848: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov  5 12:56:30.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6290" for this suite. 11/05/22 12:56:30.887
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:56:30.896
Nov  5 12:56:30.896: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 12:56:30.897
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:56:30.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:56:30.915
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 11/05/22 12:56:30.919
Nov  5 12:56:30.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 create -f -'
Nov  5 12:56:31.127: INFO: stderr: ""
Nov  5 12:56:31.127: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 11/05/22 12:56:31.127
Nov  5 12:56:31.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov  5 12:56:31.192: INFO: stderr: ""
Nov  5 12:56:31.192: INFO: stdout: "update-demo-nautilus-bd7s8 update-demo-nautilus-pv26r "
Nov  5 12:56:31.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods update-demo-nautilus-bd7s8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov  5 12:56:31.248: INFO: stderr: ""
Nov  5 12:56:31.248: INFO: stdout: ""
Nov  5 12:56:31.248: INFO: update-demo-nautilus-bd7s8 is created but not running
Nov  5 12:56:36.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Nov  5 12:56:36.310: INFO: stderr: ""
Nov  5 12:56:36.310: INFO: stdout: "update-demo-nautilus-bd7s8 update-demo-nautilus-pv26r "
Nov  5 12:56:36.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods update-demo-nautilus-bd7s8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov  5 12:56:36.364: INFO: stderr: ""
Nov  5 12:56:36.364: INFO: stdout: "true"
Nov  5 12:56:36.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods update-demo-nautilus-bd7s8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov  5 12:56:36.422: INFO: stderr: ""
Nov  5 12:56:36.422: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov  5 12:56:36.422: INFO: validating pod update-demo-nautilus-bd7s8
Nov  5 12:56:36.429: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 12:56:36.429: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 12:56:36.429: INFO: update-demo-nautilus-bd7s8 is verified up and running
Nov  5 12:56:36.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods update-demo-nautilus-pv26r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Nov  5 12:56:36.486: INFO: stderr: ""
Nov  5 12:56:36.486: INFO: stdout: "true"
Nov  5 12:56:36.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods update-demo-nautilus-pv26r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Nov  5 12:56:36.543: INFO: stderr: ""
Nov  5 12:56:36.543: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Nov  5 12:56:36.543: INFO: validating pod update-demo-nautilus-pv26r
Nov  5 12:56:36.549: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  5 12:56:36.549: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  5 12:56:36.549: INFO: update-demo-nautilus-pv26r is verified up and running
STEP: using delete to clean up resources 11/05/22 12:56:36.549
Nov  5 12:56:36.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 delete --grace-period=0 --force -f -'
Nov  5 12:56:36.611: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 12:56:36.611: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  5 12:56:36.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get rc,svc -l name=update-demo --no-headers'
Nov  5 12:56:36.691: INFO: stderr: "No resources found in kubectl-2450 namespace.\n"
Nov  5 12:56:36.691: INFO: stdout: ""
Nov  5 12:56:36.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  5 12:56:36.782: INFO: stderr: ""
Nov  5 12:56:36.782: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 12:56:36.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2450" for this suite. 11/05/22 12:56:36.787
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":240,"skipped":4411,"failed":0}
------------------------------
• [SLOW TEST] [5.898 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:56:30.896
    Nov  5 12:56:30.896: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 12:56:30.897
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:56:30.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:56:30.915
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 11/05/22 12:56:30.919
    Nov  5 12:56:30.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 create -f -'
    Nov  5 12:56:31.127: INFO: stderr: ""
    Nov  5 12:56:31.127: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 11/05/22 12:56:31.127
    Nov  5 12:56:31.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov  5 12:56:31.192: INFO: stderr: ""
    Nov  5 12:56:31.192: INFO: stdout: "update-demo-nautilus-bd7s8 update-demo-nautilus-pv26r "
    Nov  5 12:56:31.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods update-demo-nautilus-bd7s8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov  5 12:56:31.248: INFO: stderr: ""
    Nov  5 12:56:31.248: INFO: stdout: ""
    Nov  5 12:56:31.248: INFO: update-demo-nautilus-bd7s8 is created but not running
    Nov  5 12:56:36.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Nov  5 12:56:36.310: INFO: stderr: ""
    Nov  5 12:56:36.310: INFO: stdout: "update-demo-nautilus-bd7s8 update-demo-nautilus-pv26r "
    Nov  5 12:56:36.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods update-demo-nautilus-bd7s8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov  5 12:56:36.364: INFO: stderr: ""
    Nov  5 12:56:36.364: INFO: stdout: "true"
    Nov  5 12:56:36.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods update-demo-nautilus-bd7s8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov  5 12:56:36.422: INFO: stderr: ""
    Nov  5 12:56:36.422: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov  5 12:56:36.422: INFO: validating pod update-demo-nautilus-bd7s8
    Nov  5 12:56:36.429: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov  5 12:56:36.429: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov  5 12:56:36.429: INFO: update-demo-nautilus-bd7s8 is verified up and running
    Nov  5 12:56:36.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods update-demo-nautilus-pv26r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Nov  5 12:56:36.486: INFO: stderr: ""
    Nov  5 12:56:36.486: INFO: stdout: "true"
    Nov  5 12:56:36.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods update-demo-nautilus-pv26r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Nov  5 12:56:36.543: INFO: stderr: ""
    Nov  5 12:56:36.543: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Nov  5 12:56:36.543: INFO: validating pod update-demo-nautilus-pv26r
    Nov  5 12:56:36.549: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Nov  5 12:56:36.549: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Nov  5 12:56:36.549: INFO: update-demo-nautilus-pv26r is verified up and running
    STEP: using delete to clean up resources 11/05/22 12:56:36.549
    Nov  5 12:56:36.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 delete --grace-period=0 --force -f -'
    Nov  5 12:56:36.611: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov  5 12:56:36.611: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Nov  5 12:56:36.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get rc,svc -l name=update-demo --no-headers'
    Nov  5 12:56:36.691: INFO: stderr: "No resources found in kubectl-2450 namespace.\n"
    Nov  5 12:56:36.691: INFO: stdout: ""
    Nov  5 12:56:36.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-2450 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Nov  5 12:56:36.782: INFO: stderr: ""
    Nov  5 12:56:36.782: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 12:56:36.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2450" for this suite. 11/05/22 12:56:36.787
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 12:56:36.795
Nov  5 12:56:36.795: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename cronjob 11/05/22 12:56:36.796
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:56:36.807
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:56:36.811
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 11/05/22 12:56:36.815
STEP: Ensuring a job is scheduled 11/05/22 12:56:36.821
STEP: Ensuring exactly one is scheduled 11/05/22 12:57:00.825
STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/05/22 12:57:00.829
STEP: Ensuring no more jobs are scheduled 11/05/22 12:57:00.832
STEP: Removing cronjob 11/05/22 13:02:00.841
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov  5 13:02:00.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9064" for this suite. 11/05/22 13:02:00.862
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":241,"skipped":4427,"failed":0}
------------------------------
• [SLOW TEST] [324.075 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 12:56:36.795
    Nov  5 12:56:36.795: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename cronjob 11/05/22 12:56:36.796
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 12:56:36.807
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 12:56:36.811
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 11/05/22 12:56:36.815
    STEP: Ensuring a job is scheduled 11/05/22 12:56:36.821
    STEP: Ensuring exactly one is scheduled 11/05/22 12:57:00.825
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/05/22 12:57:00.829
    STEP: Ensuring no more jobs are scheduled 11/05/22 12:57:00.832
    STEP: Removing cronjob 11/05/22 13:02:00.841
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov  5 13:02:00.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9064" for this suite. 11/05/22 13:02:00.862
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:02:00.871
Nov  5 13:02:00.871: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 13:02:00.872
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:00.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:00.904
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206
STEP: fetching services 11/05/22 13:02:00.909
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 13:02:00.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1548" for this suite. 11/05/22 13:02:00.917
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":242,"skipped":4439,"failed":0}
------------------------------
• [0.052 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:02:00.871
    Nov  5 13:02:00.871: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 13:02:00.872
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:00.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:00.904
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3206
    STEP: fetching services 11/05/22 13:02:00.909
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 13:02:00.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1548" for this suite. 11/05/22 13:02:00.917
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:02:00.927
Nov  5 13:02:00.928: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 13:02:00.928
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:00.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:00.946
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 13:02:00.969
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 13:02:01.274
STEP: Deploying the webhook pod 11/05/22 13:02:01.282
STEP: Wait for the deployment to be ready 11/05/22 13:02:01.295
Nov  5 13:02:01.311: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 13:02:03.323
STEP: Verifying the service has paired with the endpoint 11/05/22 13:02:03.333
Nov  5 13:02:04.333: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Nov  5 13:02:04.338: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-483-crds.webhook.example.com via the AdmissionRegistration API 11/05/22 13:02:04.851
STEP: Creating a custom resource that should be mutated by the webhook 11/05/22 13:02:04.867
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:02:07.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9184" for this suite. 11/05/22 13:02:07.432
STEP: Destroying namespace "webhook-9184-markers" for this suite. 11/05/22 13:02:07.439
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":243,"skipped":4506,"failed":0}
------------------------------
• [SLOW TEST] [6.566 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:02:00.927
    Nov  5 13:02:00.928: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 13:02:00.928
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:00.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:00.946
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 13:02:00.969
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 13:02:01.274
    STEP: Deploying the webhook pod 11/05/22 13:02:01.282
    STEP: Wait for the deployment to be ready 11/05/22 13:02:01.295
    Nov  5 13:02:01.311: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 13:02:03.323
    STEP: Verifying the service has paired with the endpoint 11/05/22 13:02:03.333
    Nov  5 13:02:04.333: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Nov  5 13:02:04.338: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-483-crds.webhook.example.com via the AdmissionRegistration API 11/05/22 13:02:04.851
    STEP: Creating a custom resource that should be mutated by the webhook 11/05/22 13:02:04.867
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:02:07.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9184" for this suite. 11/05/22 13:02:07.432
    STEP: Destroying namespace "webhook-9184-markers" for this suite. 11/05/22 13:02:07.439
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:02:07.495
Nov  5 13:02:07.495: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename disruption 11/05/22 13:02:07.496
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:07.52
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:07.529
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 11/05/22 13:02:07.534
STEP: Waiting for the pdb to be processed 11/05/22 13:02:07.539
STEP: updating the pdb 11/05/22 13:02:09.55
STEP: Waiting for the pdb to be processed 11/05/22 13:02:09.561
STEP: patching the pdb 11/05/22 13:02:11.572
STEP: Waiting for the pdb to be processed 11/05/22 13:02:11.586
STEP: Waiting for the pdb to be deleted 11/05/22 13:02:11.602
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Nov  5 13:02:11.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-4936" for this suite. 11/05/22 13:02:11.61
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":244,"skipped":4508,"failed":0}
------------------------------
• [4.122 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:02:07.495
    Nov  5 13:02:07.495: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename disruption 11/05/22 13:02:07.496
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:07.52
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:07.529
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 11/05/22 13:02:07.534
    STEP: Waiting for the pdb to be processed 11/05/22 13:02:07.539
    STEP: updating the pdb 11/05/22 13:02:09.55
    STEP: Waiting for the pdb to be processed 11/05/22 13:02:09.561
    STEP: patching the pdb 11/05/22 13:02:11.572
    STEP: Waiting for the pdb to be processed 11/05/22 13:02:11.586
    STEP: Waiting for the pdb to be deleted 11/05/22 13:02:11.602
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Nov  5 13:02:11.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-4936" for this suite. 11/05/22 13:02:11.61
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:02:11.617
Nov  5 13:02:11.617: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 13:02:11.618
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:11.638
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:11.642
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 11/05/22 13:02:11.647
STEP: fetching the ConfigMap 11/05/22 13:02:11.652
STEP: patching the ConfigMap 11/05/22 13:02:11.656
STEP: listing all ConfigMaps in all namespaces with a label selector 11/05/22 13:02:11.667
STEP: deleting the ConfigMap by collection with a label selector 11/05/22 13:02:11.671
STEP: listing all ConfigMaps in test namespace 11/05/22 13:02:11.68
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 13:02:11.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3429" for this suite. 11/05/22 13:02:11.688
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":245,"skipped":4514,"failed":0}
------------------------------
• [0.079 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:02:11.617
    Nov  5 13:02:11.617: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 13:02:11.618
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:11.638
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:11.642
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 11/05/22 13:02:11.647
    STEP: fetching the ConfigMap 11/05/22 13:02:11.652
    STEP: patching the ConfigMap 11/05/22 13:02:11.656
    STEP: listing all ConfigMaps in all namespaces with a label selector 11/05/22 13:02:11.667
    STEP: deleting the ConfigMap by collection with a label selector 11/05/22 13:02:11.671
    STEP: listing all ConfigMaps in test namespace 11/05/22 13:02:11.68
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 13:02:11.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3429" for this suite. 11/05/22 13:02:11.688
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:02:11.698
Nov  5 13:02:11.698: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:02:11.699
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:11.717
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:11.729
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 11/05/22 13:02:11.737
Nov  5 13:02:11.748: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be" in namespace "projected-5194" to be "Succeeded or Failed"
Nov  5 13:02:11.760: INFO: Pod "downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be": Phase="Pending", Reason="", readiness=false. Elapsed: 11.920464ms
Nov  5 13:02:13.764: INFO: Pod "downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016076415s
Nov  5 13:02:15.765: INFO: Pod "downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017258441s
STEP: Saw pod success 11/05/22 13:02:15.765
Nov  5 13:02:15.765: INFO: Pod "downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be" satisfied condition "Succeeded or Failed"
Nov  5 13:02:15.769: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be container client-container: <nil>
STEP: delete the pod 11/05/22 13:02:15.788
Nov  5 13:02:15.807: INFO: Waiting for pod downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be to disappear
Nov  5 13:02:15.811: INFO: Pod downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 13:02:15.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5194" for this suite. 11/05/22 13:02:15.816
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":246,"skipped":4538,"failed":0}
------------------------------
• [4.124 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:02:11.698
    Nov  5 13:02:11.698: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:02:11.699
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:11.717
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:11.729
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 11/05/22 13:02:11.737
    Nov  5 13:02:11.748: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be" in namespace "projected-5194" to be "Succeeded or Failed"
    Nov  5 13:02:11.760: INFO: Pod "downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be": Phase="Pending", Reason="", readiness=false. Elapsed: 11.920464ms
    Nov  5 13:02:13.764: INFO: Pod "downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016076415s
    Nov  5 13:02:15.765: INFO: Pod "downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017258441s
    STEP: Saw pod success 11/05/22 13:02:15.765
    Nov  5 13:02:15.765: INFO: Pod "downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be" satisfied condition "Succeeded or Failed"
    Nov  5 13:02:15.769: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be container client-container: <nil>
    STEP: delete the pod 11/05/22 13:02:15.788
    Nov  5 13:02:15.807: INFO: Waiting for pod downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be to disappear
    Nov  5 13:02:15.811: INFO: Pod downwardapi-volume-b0c60216-4703-466f-b649-23a80c1e05be no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 13:02:15.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5194" for this suite. 11/05/22 13:02:15.816
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:02:15.824
Nov  5 13:02:15.824: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:02:15.825
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:15.837
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:15.842
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-fed08c00-6d9d-4c47-887f-c02eea576faa 11/05/22 13:02:15.85
STEP: Creating secret with name s-test-opt-upd-48433f8f-d904-4938-9969-1e723896a5f6 11/05/22 13:02:15.856
STEP: Creating the pod 11/05/22 13:02:15.86
Nov  5 13:02:15.872: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b" in namespace "projected-9646" to be "running and ready"
Nov  5 13:02:15.882: INFO: Pod "pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.743932ms
Nov  5 13:02:15.882: INFO: The phase of Pod pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:02:17.887: INFO: Pod "pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b": Phase="Running", Reason="", readiness=true. Elapsed: 2.014666021s
Nov  5 13:02:17.887: INFO: The phase of Pod pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b is Running (Ready = true)
Nov  5 13:02:17.887: INFO: Pod "pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-fed08c00-6d9d-4c47-887f-c02eea576faa 11/05/22 13:02:17.911
STEP: Updating secret s-test-opt-upd-48433f8f-d904-4938-9969-1e723896a5f6 11/05/22 13:02:17.918
STEP: Creating secret with name s-test-opt-create-19d81bf9-9c05-4515-bbc2-5a99e5c05a32 11/05/22 13:02:17.923
STEP: waiting to observe update in volume 11/05/22 13:02:17.927
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov  5 13:02:19.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9646" for this suite. 11/05/22 13:02:19.962
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":247,"skipped":4567,"failed":0}
------------------------------
• [4.146 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:02:15.824
    Nov  5 13:02:15.824: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:02:15.825
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:15.837
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:15.842
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-fed08c00-6d9d-4c47-887f-c02eea576faa 11/05/22 13:02:15.85
    STEP: Creating secret with name s-test-opt-upd-48433f8f-d904-4938-9969-1e723896a5f6 11/05/22 13:02:15.856
    STEP: Creating the pod 11/05/22 13:02:15.86
    Nov  5 13:02:15.872: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b" in namespace "projected-9646" to be "running and ready"
    Nov  5 13:02:15.882: INFO: Pod "pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.743932ms
    Nov  5 13:02:15.882: INFO: The phase of Pod pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:02:17.887: INFO: Pod "pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b": Phase="Running", Reason="", readiness=true. Elapsed: 2.014666021s
    Nov  5 13:02:17.887: INFO: The phase of Pod pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b is Running (Ready = true)
    Nov  5 13:02:17.887: INFO: Pod "pod-projected-secrets-53e03882-aa39-46e3-9f1a-bb827adb6b1b" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-fed08c00-6d9d-4c47-887f-c02eea576faa 11/05/22 13:02:17.911
    STEP: Updating secret s-test-opt-upd-48433f8f-d904-4938-9969-1e723896a5f6 11/05/22 13:02:17.918
    STEP: Creating secret with name s-test-opt-create-19d81bf9-9c05-4515-bbc2-5a99e5c05a32 11/05/22 13:02:17.923
    STEP: waiting to observe update in volume 11/05/22 13:02:17.927
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov  5 13:02:19.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9646" for this suite. 11/05/22 13:02:19.962
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:02:19.972
Nov  5 13:02:19.972: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename security-context-test 11/05/22 13:02:19.972
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:19.99
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:19.997
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Nov  5 13:02:20.013: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f" in namespace "security-context-test-8051" to be "Succeeded or Failed"
Nov  5 13:02:20.017: INFO: Pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.467429ms
Nov  5 13:02:22.021: INFO: Pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f": Phase="Running", Reason="", readiness=false. Elapsed: 2.007946144s
Nov  5 13:02:24.021: INFO: Pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007821441s
Nov  5 13:02:24.021: INFO: Pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f" satisfied condition "Succeeded or Failed"
Nov  5 13:02:24.040: INFO: Got logs for pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov  5 13:02:24.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8051" for this suite. 11/05/22 13:02:24.044
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":248,"skipped":4582,"failed":0}
------------------------------
• [4.081 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:02:19.972
    Nov  5 13:02:19.972: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename security-context-test 11/05/22 13:02:19.972
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:19.99
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:19.997
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Nov  5 13:02:20.013: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f" in namespace "security-context-test-8051" to be "Succeeded or Failed"
    Nov  5 13:02:20.017: INFO: Pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.467429ms
    Nov  5 13:02:22.021: INFO: Pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f": Phase="Running", Reason="", readiness=false. Elapsed: 2.007946144s
    Nov  5 13:02:24.021: INFO: Pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007821441s
    Nov  5 13:02:24.021: INFO: Pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f" satisfied condition "Succeeded or Failed"
    Nov  5 13:02:24.040: INFO: Got logs for pod "busybox-privileged-false-06cde5b5-cde2-4c78-b744-cb0285c5535f": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov  5 13:02:24.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-8051" for this suite. 11/05/22 13:02:24.044
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:02:24.054
Nov  5 13:02:24.055: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename limitrange 11/05/22 13:02:24.055
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:24.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:24.073
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 11/05/22 13:02:24.076
STEP: Setting up watch 11/05/22 13:02:24.076
STEP: Submitting a LimitRange 11/05/22 13:02:24.18
STEP: Verifying LimitRange creation was observed 11/05/22 13:02:24.187
STEP: Fetching the LimitRange to ensure it has proper values 11/05/22 13:02:24.187
Nov  5 13:02:24.190: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov  5 13:02:24.190: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 11/05/22 13:02:24.19
STEP: Ensuring Pod has resource requirements applied from LimitRange 11/05/22 13:02:24.29
Nov  5 13:02:24.295: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Nov  5 13:02:24.295: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 11/05/22 13:02:24.295
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 11/05/22 13:02:24.301
Nov  5 13:02:24.306: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Nov  5 13:02:24.306: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 11/05/22 13:02:24.306
STEP: Failing to create a Pod with more than max resources 11/05/22 13:02:24.309
STEP: Updating a LimitRange 11/05/22 13:02:24.311
STEP: Verifying LimitRange updating is effective 11/05/22 13:02:24.317
STEP: Creating a Pod with less than former min resources 11/05/22 13:02:26.322
STEP: Failing to create a Pod with more than max resources 11/05/22 13:02:26.327
STEP: Deleting a LimitRange 11/05/22 13:02:26.33
STEP: Verifying the LimitRange was deleted 11/05/22 13:02:26.338
Nov  5 13:02:31.343: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 11/05/22 13:02:31.343
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Nov  5 13:02:31.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-4232" for this suite. 11/05/22 13:02:31.356
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":249,"skipped":4617,"failed":0}
------------------------------
• [SLOW TEST] [7.310 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:02:24.054
    Nov  5 13:02:24.055: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename limitrange 11/05/22 13:02:24.055
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:24.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:24.073
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 11/05/22 13:02:24.076
    STEP: Setting up watch 11/05/22 13:02:24.076
    STEP: Submitting a LimitRange 11/05/22 13:02:24.18
    STEP: Verifying LimitRange creation was observed 11/05/22 13:02:24.187
    STEP: Fetching the LimitRange to ensure it has proper values 11/05/22 13:02:24.187
    Nov  5 13:02:24.190: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Nov  5 13:02:24.190: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 11/05/22 13:02:24.19
    STEP: Ensuring Pod has resource requirements applied from LimitRange 11/05/22 13:02:24.29
    Nov  5 13:02:24.295: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Nov  5 13:02:24.295: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 11/05/22 13:02:24.295
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 11/05/22 13:02:24.301
    Nov  5 13:02:24.306: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Nov  5 13:02:24.306: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 11/05/22 13:02:24.306
    STEP: Failing to create a Pod with more than max resources 11/05/22 13:02:24.309
    STEP: Updating a LimitRange 11/05/22 13:02:24.311
    STEP: Verifying LimitRange updating is effective 11/05/22 13:02:24.317
    STEP: Creating a Pod with less than former min resources 11/05/22 13:02:26.322
    STEP: Failing to create a Pod with more than max resources 11/05/22 13:02:26.327
    STEP: Deleting a LimitRange 11/05/22 13:02:26.33
    STEP: Verifying the LimitRange was deleted 11/05/22 13:02:26.338
    Nov  5 13:02:31.343: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 11/05/22 13:02:31.343
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Nov  5 13:02:31.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-4232" for this suite. 11/05/22 13:02:31.356
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:02:31.369
Nov  5 13:02:31.370: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-probe 11/05/22 13:02:31.37
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:31.383
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:31.388
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5 in namespace container-probe-4998 11/05/22 13:02:31.392
Nov  5 13:02:31.399: INFO: Waiting up to 5m0s for pod "liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5" in namespace "container-probe-4998" to be "not pending"
Nov  5 13:02:31.403: INFO: Pod "liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.48447ms
Nov  5 13:02:33.408: INFO: Pod "liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008143419s
Nov  5 13:02:33.408: INFO: Pod "liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5" satisfied condition "not pending"
Nov  5 13:02:33.408: INFO: Started pod liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5 in namespace container-probe-4998
STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 13:02:33.408
Nov  5 13:02:33.411: INFO: Initial restart count of pod liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5 is 0
Nov  5 13:02:53.461: INFO: Restart count of pod container-probe-4998/liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5 is now 1 (20.049667882s elapsed)
STEP: deleting the pod 11/05/22 13:02:53.461
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov  5 13:02:53.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4998" for this suite. 11/05/22 13:02:53.477
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":250,"skipped":4663,"failed":0}
------------------------------
• [SLOW TEST] [22.114 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:02:31.369
    Nov  5 13:02:31.370: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-probe 11/05/22 13:02:31.37
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:31.383
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:31.388
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5 in namespace container-probe-4998 11/05/22 13:02:31.392
    Nov  5 13:02:31.399: INFO: Waiting up to 5m0s for pod "liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5" in namespace "container-probe-4998" to be "not pending"
    Nov  5 13:02:31.403: INFO: Pod "liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.48447ms
    Nov  5 13:02:33.408: INFO: Pod "liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008143419s
    Nov  5 13:02:33.408: INFO: Pod "liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5" satisfied condition "not pending"
    Nov  5 13:02:33.408: INFO: Started pod liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5 in namespace container-probe-4998
    STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 13:02:33.408
    Nov  5 13:02:33.411: INFO: Initial restart count of pod liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5 is 0
    Nov  5 13:02:53.461: INFO: Restart count of pod container-probe-4998/liveness-7e9f7d6a-d5a9-49f8-b6db-c6fed54392f5 is now 1 (20.049667882s elapsed)
    STEP: deleting the pod 11/05/22 13:02:53.461
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov  5 13:02:53.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4998" for this suite. 11/05/22 13:02:53.477
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:02:53.485
Nov  5 13:02:53.485: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:02:53.486
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:53.501
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:53.505
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 11/05/22 13:02:53.508
Nov  5 13:02:53.509: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:02:55.611: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:03:04.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6066" for this suite. 11/05/22 13:03:04.624
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":251,"skipped":4670,"failed":0}
------------------------------
• [SLOW TEST] [11.144 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:02:53.485
    Nov  5 13:02:53.485: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:02:53.486
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:02:53.501
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:02:53.505
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 11/05/22 13:02:53.508
    Nov  5 13:02:53.509: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:02:55.611: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:03:04.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6066" for this suite. 11/05/22 13:03:04.624
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:03:04.631
Nov  5 13:03:04.631: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 13:03:04.631
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:03:04.653
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:03:04.656
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-1b49c6dc-325c-4dbe-9a5d-62399340d1fc 11/05/22 13:03:04.659
STEP: Creating a pod to test consume secrets 11/05/22 13:03:04.664
Nov  5 13:03:04.671: INFO: Waiting up to 5m0s for pod "pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a" in namespace "secrets-1217" to be "Succeeded or Failed"
Nov  5 13:03:04.678: INFO: Pod "pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.017074ms
Nov  5 13:03:06.683: INFO: Pod "pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a": Phase="Running", Reason="", readiness=false. Elapsed: 2.012220158s
Nov  5 13:03:08.683: INFO: Pod "pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011410219s
STEP: Saw pod success 11/05/22 13:03:08.683
Nov  5 13:03:08.683: INFO: Pod "pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a" satisfied condition "Succeeded or Failed"
Nov  5 13:03:08.686: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a container secret-volume-test: <nil>
STEP: delete the pod 11/05/22 13:03:08.697
Nov  5 13:03:08.710: INFO: Waiting for pod pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a to disappear
Nov  5 13:03:08.712: INFO: Pod pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov  5 13:03:08.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1217" for this suite. 11/05/22 13:03:08.722
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":252,"skipped":4672,"failed":0}
------------------------------
• [4.098 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:03:04.631
    Nov  5 13:03:04.631: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 13:03:04.631
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:03:04.653
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:03:04.656
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-1b49c6dc-325c-4dbe-9a5d-62399340d1fc 11/05/22 13:03:04.659
    STEP: Creating a pod to test consume secrets 11/05/22 13:03:04.664
    Nov  5 13:03:04.671: INFO: Waiting up to 5m0s for pod "pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a" in namespace "secrets-1217" to be "Succeeded or Failed"
    Nov  5 13:03:04.678: INFO: Pod "pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.017074ms
    Nov  5 13:03:06.683: INFO: Pod "pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a": Phase="Running", Reason="", readiness=false. Elapsed: 2.012220158s
    Nov  5 13:03:08.683: INFO: Pod "pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011410219s
    STEP: Saw pod success 11/05/22 13:03:08.683
    Nov  5 13:03:08.683: INFO: Pod "pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a" satisfied condition "Succeeded or Failed"
    Nov  5 13:03:08.686: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a container secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 13:03:08.697
    Nov  5 13:03:08.710: INFO: Waiting for pod pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a to disappear
    Nov  5 13:03:08.712: INFO: Pod pod-secrets-b54acada-9f17-4eda-9fae-fd908b6f561a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 13:03:08.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1217" for this suite. 11/05/22 13:03:08.722
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:03:08.729
Nov  5 13:03:08.729: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename statefulset 11/05/22 13:03:08.73
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:03:08.751
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:03:08.754
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7445 11/05/22 13:03:08.757
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 11/05/22 13:03:08.762
Nov  5 13:03:08.775: INFO: Found 0 stateful pods, waiting for 3
Nov  5 13:03:18.783: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 13:03:18.783: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 13:03:18.783: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/05/22 13:03:18.8
Nov  5 13:03:18.834: INFO: Updating stateful set ss2
STEP: Creating a new revision 11/05/22 13:03:18.834
STEP: Not applying an update when the partition is greater than the number of replicas 11/05/22 13:03:28.853
STEP: Performing a canary update 11/05/22 13:03:28.854
Nov  5 13:03:28.873: INFO: Updating stateful set ss2
Nov  5 13:03:28.880: INFO: Waiting for Pod statefulset-7445/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 11/05/22 13:03:38.889
Nov  5 13:03:38.924: INFO: Found 2 stateful pods, waiting for 3
Nov  5 13:03:48.929: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 13:03:48.929: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 13:03:48.929: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 11/05/22 13:03:48.934
Nov  5 13:03:48.954: INFO: Updating stateful set ss2
Nov  5 13:03:48.960: INFO: Waiting for Pod statefulset-7445/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Nov  5 13:03:58.990: INFO: Updating stateful set ss2
Nov  5 13:03:58.999: INFO: Waiting for StatefulSet statefulset-7445/ss2 to complete update
Nov  5 13:03:58.999: INFO: Waiting for Pod statefulset-7445/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov  5 13:04:09.014: INFO: Deleting all statefulset in ns statefulset-7445
Nov  5 13:04:09.016: INFO: Scaling statefulset ss2 to 0
Nov  5 13:04:19.035: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 13:04:19.038: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov  5 13:04:19.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7445" for this suite. 11/05/22 13:04:19.055
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":253,"skipped":4672,"failed":0}
------------------------------
• [SLOW TEST] [70.333 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:03:08.729
    Nov  5 13:03:08.729: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename statefulset 11/05/22 13:03:08.73
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:03:08.751
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:03:08.754
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7445 11/05/22 13:03:08.757
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 11/05/22 13:03:08.762
    Nov  5 13:03:08.775: INFO: Found 0 stateful pods, waiting for 3
    Nov  5 13:03:18.783: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 13:03:18.783: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 13:03:18.783: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/05/22 13:03:18.8
    Nov  5 13:03:18.834: INFO: Updating stateful set ss2
    STEP: Creating a new revision 11/05/22 13:03:18.834
    STEP: Not applying an update when the partition is greater than the number of replicas 11/05/22 13:03:28.853
    STEP: Performing a canary update 11/05/22 13:03:28.854
    Nov  5 13:03:28.873: INFO: Updating stateful set ss2
    Nov  5 13:03:28.880: INFO: Waiting for Pod statefulset-7445/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 11/05/22 13:03:38.889
    Nov  5 13:03:38.924: INFO: Found 2 stateful pods, waiting for 3
    Nov  5 13:03:48.929: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 13:03:48.929: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 13:03:48.929: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 11/05/22 13:03:48.934
    Nov  5 13:03:48.954: INFO: Updating stateful set ss2
    Nov  5 13:03:48.960: INFO: Waiting for Pod statefulset-7445/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Nov  5 13:03:58.990: INFO: Updating stateful set ss2
    Nov  5 13:03:58.999: INFO: Waiting for StatefulSet statefulset-7445/ss2 to complete update
    Nov  5 13:03:58.999: INFO: Waiting for Pod statefulset-7445/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov  5 13:04:09.014: INFO: Deleting all statefulset in ns statefulset-7445
    Nov  5 13:04:09.016: INFO: Scaling statefulset ss2 to 0
    Nov  5 13:04:19.035: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 13:04:19.038: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov  5 13:04:19.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7445" for this suite. 11/05/22 13:04:19.055
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:04:19.063
Nov  5 13:04:19.063: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename deployment 11/05/22 13:04:19.064
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:19.08
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:19.084
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 11/05/22 13:04:19.091
Nov  5 13:04:19.091: INFO: Creating simple deployment test-deployment-4jlr9
Nov  5 13:04:19.102: INFO: deployment "test-deployment-4jlr9" doesn't have the required revision set
STEP: Getting /status 11/05/22 13:04:21.116
Nov  5 13:04:21.120: INFO: Deployment test-deployment-4jlr9 has Conditions: [{Available True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jlr9-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 11/05/22 13:04:21.12
Nov  5 13:04:21.129: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 13, 4, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 13, 4, 20, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 13, 4, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 13, 4, 19, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-4jlr9-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 11/05/22 13:04:21.129
Nov  5 13:04:21.131: INFO: Observed &Deployment event: ADDED
Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jlr9-777898ffcc"}
Nov  5 13:04:21.131: INFO: Observed &Deployment event: MODIFIED
Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jlr9-777898ffcc"}
Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov  5 13:04:21.131: INFO: Observed &Deployment event: MODIFIED
Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4jlr9-777898ffcc" is progressing.}
Nov  5 13:04:21.131: INFO: Observed &Deployment event: MODIFIED
Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jlr9-777898ffcc" has successfully progressed.}
Nov  5 13:04:21.131: INFO: Observed &Deployment event: MODIFIED
Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jlr9-777898ffcc" has successfully progressed.}
Nov  5 13:04:21.131: INFO: Found Deployment test-deployment-4jlr9 in namespace deployment-9890 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov  5 13:04:21.131: INFO: Deployment test-deployment-4jlr9 has an updated status
STEP: patching the Statefulset Status 11/05/22 13:04:21.131
Nov  5 13:04:21.132: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Nov  5 13:04:21.139: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 11/05/22 13:04:21.139
Nov  5 13:04:21.141: INFO: Observed &Deployment event: ADDED
Nov  5 13:04:21.141: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jlr9-777898ffcc"}
Nov  5 13:04:21.141: INFO: Observed &Deployment event: MODIFIED
Nov  5 13:04:21.141: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jlr9-777898ffcc"}
Nov  5 13:04:21.141: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov  5 13:04:21.141: INFO: Observed &Deployment event: MODIFIED
Nov  5 13:04:21.141: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Nov  5 13:04:21.141: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4jlr9-777898ffcc" is progressing.}
Nov  5 13:04:21.142: INFO: Observed &Deployment event: MODIFIED
Nov  5 13:04:21.142: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov  5 13:04:21.142: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jlr9-777898ffcc" has successfully progressed.}
Nov  5 13:04:21.142: INFO: Observed &Deployment event: MODIFIED
Nov  5 13:04:21.142: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Nov  5 13:04:21.142: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jlr9-777898ffcc" has successfully progressed.}
Nov  5 13:04:21.142: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Nov  5 13:04:21.142: INFO: Observed &Deployment event: MODIFIED
Nov  5 13:04:21.142: INFO: Found deployment test-deployment-4jlr9 in namespace deployment-9890 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Nov  5 13:04:21.142: INFO: Deployment test-deployment-4jlr9 has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Nov  5 13:04:21.145: INFO: Deployment "test-deployment-4jlr9":
&Deployment{ObjectMeta:{test-deployment-4jlr9  deployment-9890  3743e632-343c-4c3c-9a1d-dac3ab6b8032 32097 1 2022-11-05 13:04:19 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-05 13:04:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-11-05 13:04:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-11-05 13:04:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049c0318 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-4jlr9-777898ffcc",LastUpdateTime:2022-11-05 13:04:21 +0000 UTC,LastTransitionTime:2022-11-05 13:04:21 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  5 13:04:21.148: INFO: New ReplicaSet "test-deployment-4jlr9-777898ffcc" of Deployment "test-deployment-4jlr9":
&ReplicaSet{ObjectMeta:{test-deployment-4jlr9-777898ffcc  deployment-9890  b03ce4a3-a919-40fa-a791-4d93d7a267ab 32090 1 2022-11-05 13:04:19 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-4jlr9 3743e632-343c-4c3c-9a1d-dac3ab6b8032 0xc0049c0720 0xc0049c0721}] [] [{kube-controller-manager Update apps/v1 2022-11-05 13:04:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3743e632-343c-4c3c-9a1d-dac3ab6b8032\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 13:04:20 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049c07c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  5 13:04:21.152: INFO: Pod "test-deployment-4jlr9-777898ffcc-nd8sc" is available:
&Pod{ObjectMeta:{test-deployment-4jlr9-777898ffcc-nd8sc test-deployment-4jlr9-777898ffcc- deployment-9890  082fb10f-b57e-49ef-ad17-754453fea926 32089 0 2022-11-05 13:04:19 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-4jlr9-777898ffcc b03ce4a3-a919-40fa-a791-4d93d7a267ab 0xc004986e40 0xc004986e41}] [] [{kube-controller-manager Update v1 2022-11-05 13:04:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b03ce4a3-a919-40fa-a791-4d93d7a267ab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 13:04:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.188\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z4hwz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z4hwz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 13:04:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 13:04:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 13:04:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 13:04:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.188,StartTime:2022-11-05 13:04:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 13:04:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bb2e71476cca8d8bd821d48026c912780361c00c8f3298d08980f12f2bcef507,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.188,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Nov  5 13:04:21.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9890" for this suite. 11/05/22 13:04:21.159
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":254,"skipped":4676,"failed":0}
------------------------------
• [2.102 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:04:19.063
    Nov  5 13:04:19.063: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename deployment 11/05/22 13:04:19.064
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:19.08
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:19.084
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 11/05/22 13:04:19.091
    Nov  5 13:04:19.091: INFO: Creating simple deployment test-deployment-4jlr9
    Nov  5 13:04:19.102: INFO: deployment "test-deployment-4jlr9" doesn't have the required revision set
    STEP: Getting /status 11/05/22 13:04:21.116
    Nov  5 13:04:21.120: INFO: Deployment test-deployment-4jlr9 has Conditions: [{Available True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jlr9-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 11/05/22 13:04:21.12
    Nov  5 13:04:21.129: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 13, 4, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 13, 4, 20, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2022, time.November, 5, 13, 4, 20, 0, time.Local), LastTransitionTime:time.Date(2022, time.November, 5, 13, 4, 19, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-4jlr9-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 11/05/22 13:04:21.129
    Nov  5 13:04:21.131: INFO: Observed &Deployment event: ADDED
    Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jlr9-777898ffcc"}
    Nov  5 13:04:21.131: INFO: Observed &Deployment event: MODIFIED
    Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jlr9-777898ffcc"}
    Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov  5 13:04:21.131: INFO: Observed &Deployment event: MODIFIED
    Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4jlr9-777898ffcc" is progressing.}
    Nov  5 13:04:21.131: INFO: Observed &Deployment event: MODIFIED
    Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jlr9-777898ffcc" has successfully progressed.}
    Nov  5 13:04:21.131: INFO: Observed &Deployment event: MODIFIED
    Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov  5 13:04:21.131: INFO: Observed Deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jlr9-777898ffcc" has successfully progressed.}
    Nov  5 13:04:21.131: INFO: Found Deployment test-deployment-4jlr9 in namespace deployment-9890 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov  5 13:04:21.131: INFO: Deployment test-deployment-4jlr9 has an updated status
    STEP: patching the Statefulset Status 11/05/22 13:04:21.131
    Nov  5 13:04:21.132: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Nov  5 13:04:21.139: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 11/05/22 13:04:21.139
    Nov  5 13:04:21.141: INFO: Observed &Deployment event: ADDED
    Nov  5 13:04:21.141: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jlr9-777898ffcc"}
    Nov  5 13:04:21.141: INFO: Observed &Deployment event: MODIFIED
    Nov  5 13:04:21.141: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-4jlr9-777898ffcc"}
    Nov  5 13:04:21.141: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov  5 13:04:21.141: INFO: Observed &Deployment event: MODIFIED
    Nov  5 13:04:21.141: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Nov  5 13:04:21.141: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:19 +0000 UTC 2022-11-05 13:04:19 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-4jlr9-777898ffcc" is progressing.}
    Nov  5 13:04:21.142: INFO: Observed &Deployment event: MODIFIED
    Nov  5 13:04:21.142: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov  5 13:04:21.142: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jlr9-777898ffcc" has successfully progressed.}
    Nov  5 13:04:21.142: INFO: Observed &Deployment event: MODIFIED
    Nov  5 13:04:21.142: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:20 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Nov  5 13:04:21.142: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2022-11-05 13:04:20 +0000 UTC 2022-11-05 13:04:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-4jlr9-777898ffcc" has successfully progressed.}
    Nov  5 13:04:21.142: INFO: Observed deployment test-deployment-4jlr9 in namespace deployment-9890 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Nov  5 13:04:21.142: INFO: Observed &Deployment event: MODIFIED
    Nov  5 13:04:21.142: INFO: Found deployment test-deployment-4jlr9 in namespace deployment-9890 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Nov  5 13:04:21.142: INFO: Deployment test-deployment-4jlr9 has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Nov  5 13:04:21.145: INFO: Deployment "test-deployment-4jlr9":
    &Deployment{ObjectMeta:{test-deployment-4jlr9  deployment-9890  3743e632-343c-4c3c-9a1d-dac3ab6b8032 32097 1 2022-11-05 13:04:19 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2022-11-05 13:04:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2022-11-05 13:04:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2022-11-05 13:04:21 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049c0318 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-4jlr9-777898ffcc",LastUpdateTime:2022-11-05 13:04:21 +0000 UTC,LastTransitionTime:2022-11-05 13:04:21 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Nov  5 13:04:21.148: INFO: New ReplicaSet "test-deployment-4jlr9-777898ffcc" of Deployment "test-deployment-4jlr9":
    &ReplicaSet{ObjectMeta:{test-deployment-4jlr9-777898ffcc  deployment-9890  b03ce4a3-a919-40fa-a791-4d93d7a267ab 32090 1 2022-11-05 13:04:19 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-4jlr9 3743e632-343c-4c3c-9a1d-dac3ab6b8032 0xc0049c0720 0xc0049c0721}] [] [{kube-controller-manager Update apps/v1 2022-11-05 13:04:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3743e632-343c-4c3c-9a1d-dac3ab6b8032\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2022-11-05 13:04:20 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0049c07c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Nov  5 13:04:21.152: INFO: Pod "test-deployment-4jlr9-777898ffcc-nd8sc" is available:
    &Pod{ObjectMeta:{test-deployment-4jlr9-777898ffcc-nd8sc test-deployment-4jlr9-777898ffcc- deployment-9890  082fb10f-b57e-49ef-ad17-754453fea926 32089 0 2022-11-05 13:04:19 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [{apps/v1 ReplicaSet test-deployment-4jlr9-777898ffcc b03ce4a3-a919-40fa-a791-4d93d7a267ab 0xc004986e40 0xc004986e41}] [] [{kube-controller-manager Update v1 2022-11-05 13:04:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b03ce4a3-a919-40fa-a791-4d93d7a267ab\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2022-11-05 13:04:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"192.168.206.188\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z4hwz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z4hwz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-172-31-0-255,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 13:04:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 13:04:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 13:04:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2022-11-05 13:04:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.31.0.255,PodIP:192.168.206.188,StartTime:2022-11-05 13:04:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2022-11-05 13:04:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://bb2e71476cca8d8bd821d48026c912780361c00c8f3298d08980f12f2bcef507,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.206.188,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Nov  5 13:04:21.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9890" for this suite. 11/05/22 13:04:21.159
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:04:21.167
Nov  5 13:04:21.168: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replicaset 11/05/22 13:04:21.168
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:21.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:21.187
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 11/05/22 13:04:21.191
Nov  5 13:04:21.199: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-5184" to be "running and ready"
Nov  5 13:04:21.202: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 3.075554ms
Nov  5 13:04:21.202: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:04:23.207: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.008313896s
Nov  5 13:04:23.207: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Nov  5 13:04:23.207: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 11/05/22 13:04:23.211
STEP: Then the orphan pod is adopted 11/05/22 13:04:23.217
STEP: When the matched label of one of its pods change 11/05/22 13:04:24.223
Nov  5 13:04:24.227: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 11/05/22 13:04:24.236
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov  5 13:04:25.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5184" for this suite. 11/05/22 13:04:25.25
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":255,"skipped":4700,"failed":0}
------------------------------
• [4.089 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:04:21.167
    Nov  5 13:04:21.168: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replicaset 11/05/22 13:04:21.168
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:21.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:21.187
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 11/05/22 13:04:21.191
    Nov  5 13:04:21.199: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-5184" to be "running and ready"
    Nov  5 13:04:21.202: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 3.075554ms
    Nov  5 13:04:21.202: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:04:23.207: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.008313896s
    Nov  5 13:04:23.207: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Nov  5 13:04:23.207: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 11/05/22 13:04:23.211
    STEP: Then the orphan pod is adopted 11/05/22 13:04:23.217
    STEP: When the matched label of one of its pods change 11/05/22 13:04:24.223
    Nov  5 13:04:24.227: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 11/05/22 13:04:24.236
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov  5 13:04:25.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5184" for this suite. 11/05/22 13:04:25.25
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:04:25.257
Nov  5 13:04:25.257: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename endpointslice 11/05/22 13:04:25.258
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:25.277
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:25.28
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 11/05/22 13:04:30.424
STEP: referencing matching pods with named port 11/05/22 13:04:35.436
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 11/05/22 13:04:40.448
STEP: recreating EndpointSlices after they've been deleted 11/05/22 13:04:45.46
Nov  5 13:04:45.478: INFO: EndpointSlice for Service endpointslice-2471/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov  5 13:04:55.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2471" for this suite. 11/05/22 13:04:55.492
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":256,"skipped":4701,"failed":0}
------------------------------
• [SLOW TEST] [30.241 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:04:25.257
    Nov  5 13:04:25.257: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename endpointslice 11/05/22 13:04:25.258
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:25.277
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:25.28
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 11/05/22 13:04:30.424
    STEP: referencing matching pods with named port 11/05/22 13:04:35.436
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 11/05/22 13:04:40.448
    STEP: recreating EndpointSlices after they've been deleted 11/05/22 13:04:45.46
    Nov  5 13:04:45.478: INFO: EndpointSlice for Service endpointslice-2471/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov  5 13:04:55.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-2471" for this suite. 11/05/22 13:04:55.492
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:04:55.499
Nov  5 13:04:55.499: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename proxy 11/05/22 13:04:55.5
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:55.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:55.521
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Nov  5 13:04:55.524: INFO: Creating pod...
Nov  5 13:04:55.533: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-422" to be "running"
Nov  5 13:04:55.538: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 4.773392ms
Nov  5 13:04:57.542: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.009384905s
Nov  5 13:04:57.542: INFO: Pod "agnhost" satisfied condition "running"
Nov  5 13:04:57.542: INFO: Creating service...
Nov  5 13:04:57.553: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=DELETE
Nov  5 13:04:57.559: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov  5 13:04:57.559: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=OPTIONS
Nov  5 13:04:57.563: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov  5 13:04:57.563: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=PATCH
Nov  5 13:04:57.568: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov  5 13:04:57.568: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=POST
Nov  5 13:04:57.572: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov  5 13:04:57.572: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=PUT
Nov  5 13:04:57.575: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov  5 13:04:57.575: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=DELETE
Nov  5 13:04:57.581: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov  5 13:04:57.581: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=OPTIONS
Nov  5 13:04:57.587: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov  5 13:04:57.587: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=PATCH
Nov  5 13:04:57.592: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov  5 13:04:57.593: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=POST
Nov  5 13:04:57.598: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov  5 13:04:57.598: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=PUT
Nov  5 13:04:57.604: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov  5 13:04:57.604: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=GET
Nov  5 13:04:57.607: INFO: http.Client request:GET StatusCode:301
Nov  5 13:04:57.607: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=GET
Nov  5 13:04:57.612: INFO: http.Client request:GET StatusCode:301
Nov  5 13:04:57.613: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=HEAD
Nov  5 13:04:57.616: INFO: http.Client request:HEAD StatusCode:301
Nov  5 13:04:57.616: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=HEAD
Nov  5 13:04:57.620: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov  5 13:04:57.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-422" for this suite. 11/05/22 13:04:57.624
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":257,"skipped":4714,"failed":0}
------------------------------
• [2.132 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:04:55.499
    Nov  5 13:04:55.499: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename proxy 11/05/22 13:04:55.5
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:55.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:55.521
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Nov  5 13:04:55.524: INFO: Creating pod...
    Nov  5 13:04:55.533: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-422" to be "running"
    Nov  5 13:04:55.538: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 4.773392ms
    Nov  5 13:04:57.542: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.009384905s
    Nov  5 13:04:57.542: INFO: Pod "agnhost" satisfied condition "running"
    Nov  5 13:04:57.542: INFO: Creating service...
    Nov  5 13:04:57.553: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=DELETE
    Nov  5 13:04:57.559: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov  5 13:04:57.559: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=OPTIONS
    Nov  5 13:04:57.563: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov  5 13:04:57.563: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=PATCH
    Nov  5 13:04:57.568: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov  5 13:04:57.568: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=POST
    Nov  5 13:04:57.572: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov  5 13:04:57.572: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=PUT
    Nov  5 13:04:57.575: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov  5 13:04:57.575: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=DELETE
    Nov  5 13:04:57.581: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov  5 13:04:57.581: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Nov  5 13:04:57.587: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov  5 13:04:57.587: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=PATCH
    Nov  5 13:04:57.592: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov  5 13:04:57.593: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=POST
    Nov  5 13:04:57.598: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov  5 13:04:57.598: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=PUT
    Nov  5 13:04:57.604: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov  5 13:04:57.604: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=GET
    Nov  5 13:04:57.607: INFO: http.Client request:GET StatusCode:301
    Nov  5 13:04:57.607: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=GET
    Nov  5 13:04:57.612: INFO: http.Client request:GET StatusCode:301
    Nov  5 13:04:57.613: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/pods/agnhost/proxy?method=HEAD
    Nov  5 13:04:57.616: INFO: http.Client request:HEAD StatusCode:301
    Nov  5 13:04:57.616: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-422/services/e2e-proxy-test-service/proxy?method=HEAD
    Nov  5 13:04:57.620: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov  5 13:04:57.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-422" for this suite. 11/05/22 13:04:57.624
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:04:57.633
Nov  5 13:04:57.633: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename certificates 11/05/22 13:04:57.633
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:57.652
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:57.656
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 11/05/22 13:04:58.169
STEP: getting /apis/certificates.k8s.io 11/05/22 13:04:58.172
STEP: getting /apis/certificates.k8s.io/v1 11/05/22 13:04:58.173
STEP: creating 11/05/22 13:04:58.174
STEP: getting 11/05/22 13:04:58.189
STEP: listing 11/05/22 13:04:58.193
STEP: watching 11/05/22 13:04:58.196
Nov  5 13:04:58.196: INFO: starting watch
STEP: patching 11/05/22 13:04:58.198
STEP: updating 11/05/22 13:04:58.202
Nov  5 13:04:58.323: INFO: waiting for watch events with expected annotations
Nov  5 13:04:58.323: INFO: saw patched and updated annotations
STEP: getting /approval 11/05/22 13:04:58.323
STEP: patching /approval 11/05/22 13:04:58.326
STEP: updating /approval 11/05/22 13:04:58.332
STEP: getting /status 11/05/22 13:04:58.337
STEP: patching /status 11/05/22 13:04:58.341
STEP: updating /status 11/05/22 13:04:58.348
STEP: deleting 11/05/22 13:04:58.355
STEP: deleting a collection 11/05/22 13:04:58.365
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:04:58.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-3859" for this suite. 11/05/22 13:04:58.382
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":258,"skipped":4743,"failed":0}
------------------------------
• [0.755 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:04:57.633
    Nov  5 13:04:57.633: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename certificates 11/05/22 13:04:57.633
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:57.652
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:57.656
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 11/05/22 13:04:58.169
    STEP: getting /apis/certificates.k8s.io 11/05/22 13:04:58.172
    STEP: getting /apis/certificates.k8s.io/v1 11/05/22 13:04:58.173
    STEP: creating 11/05/22 13:04:58.174
    STEP: getting 11/05/22 13:04:58.189
    STEP: listing 11/05/22 13:04:58.193
    STEP: watching 11/05/22 13:04:58.196
    Nov  5 13:04:58.196: INFO: starting watch
    STEP: patching 11/05/22 13:04:58.198
    STEP: updating 11/05/22 13:04:58.202
    Nov  5 13:04:58.323: INFO: waiting for watch events with expected annotations
    Nov  5 13:04:58.323: INFO: saw patched and updated annotations
    STEP: getting /approval 11/05/22 13:04:58.323
    STEP: patching /approval 11/05/22 13:04:58.326
    STEP: updating /approval 11/05/22 13:04:58.332
    STEP: getting /status 11/05/22 13:04:58.337
    STEP: patching /status 11/05/22 13:04:58.341
    STEP: updating /status 11/05/22 13:04:58.348
    STEP: deleting 11/05/22 13:04:58.355
    STEP: deleting a collection 11/05/22 13:04:58.365
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:04:58.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-3859" for this suite. 11/05/22 13:04:58.382
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:04:58.389
Nov  5 13:04:58.389: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:04:58.39
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:58.405
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:58.408
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-4127fbf3-4929-4e56-9e43-d05f9081828c 11/05/22 13:04:58.415
STEP: Creating configMap with name cm-test-opt-upd-0aa5d38e-c9c6-4517-b2b6-72bb184c3d3e 11/05/22 13:04:58.418
STEP: Creating the pod 11/05/22 13:04:58.424
Nov  5 13:04:58.431: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c" in namespace "projected-7565" to be "running and ready"
Nov  5 13:04:58.434: INFO: Pod "pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.41021ms
Nov  5 13:04:58.434: INFO: The phase of Pod pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:05:00.440: INFO: Pod "pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c": Phase="Running", Reason="", readiness=true. Elapsed: 2.008762216s
Nov  5 13:05:00.440: INFO: The phase of Pod pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c is Running (Ready = true)
Nov  5 13:05:00.440: INFO: Pod "pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-4127fbf3-4929-4e56-9e43-d05f9081828c 11/05/22 13:05:00.466
STEP: Updating configmap cm-test-opt-upd-0aa5d38e-c9c6-4517-b2b6-72bb184c3d3e 11/05/22 13:05:00.471
STEP: Creating configMap with name cm-test-opt-create-b9ca4d7a-baf3-4596-aa5b-b526f834121d 11/05/22 13:05:00.476
STEP: waiting to observe update in volume 11/05/22 13:05:00.481
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov  5 13:05:02.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7565" for this suite. 11/05/22 13:05:02.51
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":259,"skipped":4783,"failed":0}
------------------------------
• [4.127 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:04:58.389
    Nov  5 13:04:58.389: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:04:58.39
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:04:58.405
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:04:58.408
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-4127fbf3-4929-4e56-9e43-d05f9081828c 11/05/22 13:04:58.415
    STEP: Creating configMap with name cm-test-opt-upd-0aa5d38e-c9c6-4517-b2b6-72bb184c3d3e 11/05/22 13:04:58.418
    STEP: Creating the pod 11/05/22 13:04:58.424
    Nov  5 13:04:58.431: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c" in namespace "projected-7565" to be "running and ready"
    Nov  5 13:04:58.434: INFO: Pod "pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.41021ms
    Nov  5 13:04:58.434: INFO: The phase of Pod pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:05:00.440: INFO: Pod "pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c": Phase="Running", Reason="", readiness=true. Elapsed: 2.008762216s
    Nov  5 13:05:00.440: INFO: The phase of Pod pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c is Running (Ready = true)
    Nov  5 13:05:00.440: INFO: Pod "pod-projected-configmaps-141d1802-3fb5-470a-a67c-ef0927e8a79c" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-4127fbf3-4929-4e56-9e43-d05f9081828c 11/05/22 13:05:00.466
    STEP: Updating configmap cm-test-opt-upd-0aa5d38e-c9c6-4517-b2b6-72bb184c3d3e 11/05/22 13:05:00.471
    STEP: Creating configMap with name cm-test-opt-create-b9ca4d7a-baf3-4596-aa5b-b526f834121d 11/05/22 13:05:00.476
    STEP: waiting to observe update in volume 11/05/22 13:05:00.481
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov  5 13:05:02.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7565" for this suite. 11/05/22 13:05:02.51
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:05:02.517
Nov  5 13:05:02.517: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename proxy 11/05/22 13:05:02.518
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:05:02.534
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:05:02.538
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 11/05/22 13:05:02.551
STEP: creating replication controller proxy-service-6tk5b in namespace proxy-9066 11/05/22 13:05:02.551
I1105 13:05:02.559686      20 runners.go:193] Created replication controller with name: proxy-service-6tk5b, namespace: proxy-9066, replica count: 1
I1105 13:05:03.611694      20 runners.go:193] proxy-service-6tk5b Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1105 13:05:04.612708      20 runners.go:193] proxy-service-6tk5b Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 13:05:04.616: INFO: setup took 2.075179451s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 11/05/22 13:05:04.616
Nov  5 13:05:04.624: INFO: (0) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 6.971995ms)
Nov  5 13:05:04.628: INFO: (0) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 11.425449ms)
Nov  5 13:05:04.628: INFO: (0) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 11.347438ms)
Nov  5 13:05:04.628: INFO: (0) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 11.054156ms)
Nov  5 13:05:04.629: INFO: (0) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 12.130187ms)
Nov  5 13:05:04.635: INFO: (0) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 18.42647ms)
Nov  5 13:05:04.635: INFO: (0) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 18.263058ms)
Nov  5 13:05:04.636: INFO: (0) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 18.724754ms)
Nov  5 13:05:04.636: INFO: (0) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 19.597389ms)
Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 19.737586ms)
Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 19.731014ms)
Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 20.173216ms)
Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 20.182686ms)
Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 20.187995ms)
Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 20.677806ms)
Nov  5 13:05:04.638: INFO: (0) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 21.17513ms)
Nov  5 13:05:04.650: INFO: (1) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 11.800911ms)
Nov  5 13:05:04.652: INFO: (1) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 13.062972ms)
Nov  5 13:05:04.652: INFO: (1) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 12.971517ms)
Nov  5 13:05:04.652: INFO: (1) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 13.585409ms)
Nov  5 13:05:04.652: INFO: (1) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 13.740413ms)
Nov  5 13:05:04.652: INFO: (1) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 13.90413ms)
Nov  5 13:05:04.653: INFO: (1) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 14.730063ms)
Nov  5 13:05:04.654: INFO: (1) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 15.041776ms)
Nov  5 13:05:04.654: INFO: (1) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 15.505257ms)
Nov  5 13:05:04.654: INFO: (1) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 15.501077ms)
Nov  5 13:05:04.654: INFO: (1) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 15.407092ms)
Nov  5 13:05:04.654: INFO: (1) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 15.769675ms)
Nov  5 13:05:04.655: INFO: (1) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 15.845681ms)
Nov  5 13:05:04.655: INFO: (1) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 16.221045ms)
Nov  5 13:05:04.655: INFO: (1) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 16.422352ms)
Nov  5 13:05:04.655: INFO: (1) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 16.430486ms)
Nov  5 13:05:04.660: INFO: (2) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 4.167048ms)
Nov  5 13:05:04.660: INFO: (2) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 5.191641ms)
Nov  5 13:05:04.661: INFO: (2) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 5.601101ms)
Nov  5 13:05:04.662: INFO: (2) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 6.06971ms)
Nov  5 13:05:04.663: INFO: (2) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.26095ms)
Nov  5 13:05:04.664: INFO: (2) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 7.776862ms)
Nov  5 13:05:04.664: INFO: (2) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.955382ms)
Nov  5 13:05:04.664: INFO: (2) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 8.376677ms)
Nov  5 13:05:04.664: INFO: (2) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 8.507007ms)
Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.221422ms)
Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 9.079161ms)
Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 8.867843ms)
Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 9.245385ms)
Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.394326ms)
Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 9.38647ms)
Nov  5 13:05:04.667: INFO: (2) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.206973ms)
Nov  5 13:05:04.671: INFO: (3) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 4.08093ms)
Nov  5 13:05:04.674: INFO: (3) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 6.756788ms)
Nov  5 13:05:04.674: INFO: (3) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 6.586582ms)
Nov  5 13:05:04.674: INFO: (3) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 6.636648ms)
Nov  5 13:05:04.674: INFO: (3) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 7.421491ms)
Nov  5 13:05:04.674: INFO: (3) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 7.448273ms)
Nov  5 13:05:04.676: INFO: (3) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.645692ms)
Nov  5 13:05:04.676: INFO: (3) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 8.778823ms)
Nov  5 13:05:04.676: INFO: (3) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 8.965129ms)
Nov  5 13:05:04.677: INFO: (3) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 9.684691ms)
Nov  5 13:05:04.677: INFO: (3) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.423634ms)
Nov  5 13:05:04.677: INFO: (3) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 10.104985ms)
Nov  5 13:05:04.677: INFO: (3) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 10.414159ms)
Nov  5 13:05:04.678: INFO: (3) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 10.916303ms)
Nov  5 13:05:04.681: INFO: (3) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 14.549382ms)
Nov  5 13:05:04.684: INFO: (3) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 16.891787ms)
Nov  5 13:05:04.689: INFO: (4) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 4.8637ms)
Nov  5 13:05:04.690: INFO: (4) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 6.229892ms)
Nov  5 13:05:04.691: INFO: (4) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 6.814919ms)
Nov  5 13:05:04.692: INFO: (4) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 7.229167ms)
Nov  5 13:05:04.693: INFO: (4) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.950536ms)
Nov  5 13:05:04.693: INFO: (4) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 9.214549ms)
Nov  5 13:05:04.694: INFO: (4) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 9.329449ms)
Nov  5 13:05:04.694: INFO: (4) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.190054ms)
Nov  5 13:05:04.694: INFO: (4) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 9.52491ms)
Nov  5 13:05:04.694: INFO: (4) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 9.716483ms)
Nov  5 13:05:04.694: INFO: (4) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 9.602182ms)
Nov  5 13:05:04.695: INFO: (4) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 9.96929ms)
Nov  5 13:05:04.695: INFO: (4) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.113182ms)
Nov  5 13:05:04.695: INFO: (4) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 10.4454ms)
Nov  5 13:05:04.695: INFO: (4) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.246693ms)
Nov  5 13:05:04.695: INFO: (4) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 10.586163ms)
Nov  5 13:05:04.700: INFO: (5) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 5.269072ms)
Nov  5 13:05:04.701: INFO: (5) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 5.920089ms)
Nov  5 13:05:04.701: INFO: (5) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 6.10526ms)
Nov  5 13:05:04.702: INFO: (5) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 6.13281ms)
Nov  5 13:05:04.703: INFO: (5) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.530328ms)
Nov  5 13:05:04.703: INFO: (5) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 7.272878ms)
Nov  5 13:05:04.703: INFO: (5) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 7.951831ms)
Nov  5 13:05:04.704: INFO: (5) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 8.577655ms)
Nov  5 13:05:04.704: INFO: (5) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 8.673659ms)
Nov  5 13:05:04.704: INFO: (5) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 8.571544ms)
Nov  5 13:05:04.704: INFO: (5) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.626274ms)
Nov  5 13:05:04.705: INFO: (5) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 9.132426ms)
Nov  5 13:05:04.705: INFO: (5) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.189917ms)
Nov  5 13:05:04.705: INFO: (5) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.569891ms)
Nov  5 13:05:04.706: INFO: (5) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.103817ms)
Nov  5 13:05:04.706: INFO: (5) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 10.074889ms)
Nov  5 13:05:04.710: INFO: (6) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 4.247075ms)
Nov  5 13:05:04.711: INFO: (6) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 5.08785ms)
Nov  5 13:05:04.712: INFO: (6) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 5.84353ms)
Nov  5 13:05:04.712: INFO: (6) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 6.255595ms)
Nov  5 13:05:04.713: INFO: (6) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 7.48969ms)
Nov  5 13:05:04.714: INFO: (6) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.685752ms)
Nov  5 13:05:04.715: INFO: (6) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 8.3607ms)
Nov  5 13:05:04.715: INFO: (6) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 8.563546ms)
Nov  5 13:05:04.715: INFO: (6) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 8.505321ms)
Nov  5 13:05:04.715: INFO: (6) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 8.85509ms)
Nov  5 13:05:04.716: INFO: (6) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 9.520043ms)
Nov  5 13:05:04.716: INFO: (6) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 9.562228ms)
Nov  5 13:05:04.716: INFO: (6) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 9.841533ms)
Nov  5 13:05:04.716: INFO: (6) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 9.955815ms)
Nov  5 13:05:04.716: INFO: (6) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 10.396774ms)
Nov  5 13:05:04.717: INFO: (6) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 10.061708ms)
Nov  5 13:05:04.721: INFO: (7) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 4.544653ms)
Nov  5 13:05:04.722: INFO: (7) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 5.15674ms)
Nov  5 13:05:04.724: INFO: (7) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 6.472622ms)
Nov  5 13:05:04.724: INFO: (7) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 6.684736ms)
Nov  5 13:05:04.724: INFO: (7) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 6.978214ms)
Nov  5 13:05:04.724: INFO: (7) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 7.372161ms)
Nov  5 13:05:04.725: INFO: (7) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.26011ms)
Nov  5 13:05:04.725: INFO: (7) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.24829ms)
Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 8.814638ms)
Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 8.544009ms)
Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 8.921707ms)
Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 9.415465ms)
Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 9.161914ms)
Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 9.540282ms)
Nov  5 13:05:04.727: INFO: (7) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.083905ms)
Nov  5 13:05:04.727: INFO: (7) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.337744ms)
Nov  5 13:05:04.732: INFO: (8) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 5.188507ms)
Nov  5 13:05:04.733: INFO: (8) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 5.687884ms)
Nov  5 13:05:04.733: INFO: (8) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 5.760984ms)
Nov  5 13:05:04.734: INFO: (8) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 6.083232ms)
Nov  5 13:05:04.734: INFO: (8) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 6.618845ms)
Nov  5 13:05:04.735: INFO: (8) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 7.717839ms)
Nov  5 13:05:04.735: INFO: (8) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.861181ms)
Nov  5 13:05:04.736: INFO: (8) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 8.243411ms)
Nov  5 13:05:04.736: INFO: (8) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 8.577533ms)
Nov  5 13:05:04.736: INFO: (8) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 8.604554ms)
Nov  5 13:05:04.737: INFO: (8) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 9.524846ms)
Nov  5 13:05:04.737: INFO: (8) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.543818ms)
Nov  5 13:05:04.737: INFO: (8) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.295554ms)
Nov  5 13:05:04.737: INFO: (8) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 9.347772ms)
Nov  5 13:05:04.737: INFO: (8) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 9.40781ms)
Nov  5 13:05:04.738: INFO: (8) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.992136ms)
Nov  5 13:05:04.748: INFO: (9) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 9.318503ms)
Nov  5 13:05:04.750: INFO: (9) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 11.125906ms)
Nov  5 13:05:04.752: INFO: (9) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 13.049738ms)
Nov  5 13:05:04.752: INFO: (9) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 13.776502ms)
Nov  5 13:05:04.752: INFO: (9) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 13.568143ms)
Nov  5 13:05:04.753: INFO: (9) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 14.633822ms)
Nov  5 13:05:04.754: INFO: (9) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 15.331003ms)
Nov  5 13:05:04.754: INFO: (9) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 15.880527ms)
Nov  5 13:05:04.755: INFO: (9) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 15.71673ms)
Nov  5 13:05:04.755: INFO: (9) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 16.013498ms)
Nov  5 13:05:04.755: INFO: (9) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 15.894932ms)
Nov  5 13:05:04.755: INFO: (9) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 16.3531ms)
Nov  5 13:05:04.755: INFO: (9) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 16.481523ms)
Nov  5 13:05:04.756: INFO: (9) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 17.274505ms)
Nov  5 13:05:04.756: INFO: (9) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 17.400102ms)
Nov  5 13:05:04.757: INFO: (9) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 17.723902ms)
Nov  5 13:05:04.765: INFO: (10) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.347994ms)
Nov  5 13:05:04.765: INFO: (10) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 8.338212ms)
Nov  5 13:05:04.766: INFO: (10) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.141731ms)
Nov  5 13:05:04.767: INFO: (10) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 9.820145ms)
Nov  5 13:05:04.767: INFO: (10) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 9.763164ms)
Nov  5 13:05:04.768: INFO: (10) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 10.816036ms)
Nov  5 13:05:04.769: INFO: (10) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.657794ms)
Nov  5 13:05:04.770: INFO: (10) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 12.312052ms)
Nov  5 13:05:04.771: INFO: (10) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 14.43713ms)
Nov  5 13:05:04.771: INFO: (10) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 14.020974ms)
Nov  5 13:05:04.771: INFO: (10) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 14.328253ms)
Nov  5 13:05:04.773: INFO: (10) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 16.038604ms)
Nov  5 13:05:04.773: INFO: (10) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 15.944744ms)
Nov  5 13:05:04.774: INFO: (10) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 16.391382ms)
Nov  5 13:05:04.774: INFO: (10) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 16.763604ms)
Nov  5 13:05:04.776: INFO: (10) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 18.404336ms)
Nov  5 13:05:04.783: INFO: (11) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 7.180714ms)
Nov  5 13:05:04.784: INFO: (11) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.187636ms)
Nov  5 13:05:04.784: INFO: (11) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 8.05423ms)
Nov  5 13:05:04.791: INFO: (11) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 14.840693ms)
Nov  5 13:05:04.791: INFO: (11) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 14.79513ms)
Nov  5 13:05:04.791: INFO: (11) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 14.98958ms)
Nov  5 13:05:04.791: INFO: (11) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 15.086079ms)
Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 15.179062ms)
Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 15.867308ms)
Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 15.291788ms)
Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 15.025396ms)
Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 15.375105ms)
Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 15.444806ms)
Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 15.650128ms)
Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 15.554457ms)
Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 15.839658ms)
Nov  5 13:05:04.799: INFO: (12) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 7.574204ms)
Nov  5 13:05:04.800: INFO: (12) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.259527ms)
Nov  5 13:05:04.801: INFO: (12) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 8.844426ms)
Nov  5 13:05:04.801: INFO: (12) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 9.251613ms)
Nov  5 13:05:04.802: INFO: (12) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.764601ms)
Nov  5 13:05:04.802: INFO: (12) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 10.617854ms)
Nov  5 13:05:04.803: INFO: (12) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 10.584702ms)
Nov  5 13:05:04.803: INFO: (12) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 10.987629ms)
Nov  5 13:05:04.803: INFO: (12) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 11.365191ms)
Nov  5 13:05:04.804: INFO: (12) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.653335ms)
Nov  5 13:05:04.804: INFO: (12) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 11.832989ms)
Nov  5 13:05:04.804: INFO: (12) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 12.277445ms)
Nov  5 13:05:04.805: INFO: (12) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 13.181545ms)
Nov  5 13:05:04.805: INFO: (12) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 13.441788ms)
Nov  5 13:05:04.805: INFO: (12) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 13.600266ms)
Nov  5 13:05:04.806: INFO: (12) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 13.959423ms)
Nov  5 13:05:04.810: INFO: (13) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 4.104839ms)
Nov  5 13:05:04.812: INFO: (13) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 5.635441ms)
Nov  5 13:05:04.812: INFO: (13) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 5.764534ms)
Nov  5 13:05:04.813: INFO: (13) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 6.812815ms)
Nov  5 13:05:04.814: INFO: (13) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 7.06175ms)
Nov  5 13:05:04.814: INFO: (13) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.089011ms)
Nov  5 13:05:04.814: INFO: (13) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 7.942464ms)
Nov  5 13:05:04.814: INFO: (13) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 7.958418ms)
Nov  5 13:05:04.815: INFO: (13) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 8.970523ms)
Nov  5 13:05:04.815: INFO: (13) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 9.086896ms)
Nov  5 13:05:04.815: INFO: (13) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.315794ms)
Nov  5 13:05:04.816: INFO: (13) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.923421ms)
Nov  5 13:05:04.816: INFO: (13) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 9.228887ms)
Nov  5 13:05:04.818: INFO: (13) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 11.843129ms)
Nov  5 13:05:04.819: INFO: (13) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 12.420847ms)
Nov  5 13:05:04.819: INFO: (13) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 12.550352ms)
Nov  5 13:05:04.824: INFO: (14) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 4.550338ms)
Nov  5 13:05:04.826: INFO: (14) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 6.491034ms)
Nov  5 13:05:04.826: INFO: (14) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 7.011605ms)
Nov  5 13:05:04.827: INFO: (14) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 7.765985ms)
Nov  5 13:05:04.827: INFO: (14) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 8.018181ms)
Nov  5 13:05:04.828: INFO: (14) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 8.69856ms)
Nov  5 13:05:04.828: INFO: (14) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.766434ms)
Nov  5 13:05:04.828: INFO: (14) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.836784ms)
Nov  5 13:05:04.828: INFO: (14) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 9.249815ms)
Nov  5 13:05:04.829: INFO: (14) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 9.728335ms)
Nov  5 13:05:04.829: INFO: (14) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 9.983422ms)
Nov  5 13:05:04.830: INFO: (14) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 10.237056ms)
Nov  5 13:05:04.830: INFO: (14) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.522081ms)
Nov  5 13:05:04.830: INFO: (14) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 10.773189ms)
Nov  5 13:05:04.830: INFO: (14) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 11.039782ms)
Nov  5 13:05:04.830: INFO: (14) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.029378ms)
Nov  5 13:05:04.836: INFO: (15) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 5.301607ms)
Nov  5 13:05:04.837: INFO: (15) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 6.307197ms)
Nov  5 13:05:04.838: INFO: (15) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 7.083322ms)
Nov  5 13:05:04.838: INFO: (15) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 7.150639ms)
Nov  5 13:05:04.838: INFO: (15) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.413001ms)
Nov  5 13:05:04.839: INFO: (15) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 7.92058ms)
Nov  5 13:05:04.839: INFO: (15) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.691786ms)
Nov  5 13:05:04.840: INFO: (15) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 9.384465ms)
Nov  5 13:05:04.840: INFO: (15) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 9.904755ms)
Nov  5 13:05:04.840: INFO: (15) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 9.653737ms)
Nov  5 13:05:04.841: INFO: (15) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 10.142389ms)
Nov  5 13:05:04.841: INFO: (15) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 10.547363ms)
Nov  5 13:05:04.841: INFO: (15) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 10.491245ms)
Nov  5 13:05:04.842: INFO: (15) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.915999ms)
Nov  5 13:05:04.842: INFO: (15) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.096466ms)
Nov  5 13:05:04.842: INFO: (15) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 11.141461ms)
Nov  5 13:05:04.848: INFO: (16) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 5.784728ms)
Nov  5 13:05:04.848: INFO: (16) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 5.882575ms)
Nov  5 13:05:04.848: INFO: (16) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 6.168071ms)
Nov  5 13:05:04.849: INFO: (16) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 6.487314ms)
Nov  5 13:05:04.850: INFO: (16) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 7.622987ms)
Nov  5 13:05:04.850: INFO: (16) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 7.752207ms)
Nov  5 13:05:04.850: INFO: (16) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 7.791652ms)
Nov  5 13:05:04.850: INFO: (16) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.150108ms)
Nov  5 13:05:04.851: INFO: (16) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 8.42188ms)
Nov  5 13:05:04.852: INFO: (16) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 9.373228ms)
Nov  5 13:05:04.852: INFO: (16) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 9.608279ms)
Nov  5 13:05:04.852: INFO: (16) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.433623ms)
Nov  5 13:05:04.853: INFO: (16) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 10.111267ms)
Nov  5 13:05:04.853: INFO: (16) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 10.334651ms)
Nov  5 13:05:04.853: INFO: (16) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.942662ms)
Nov  5 13:05:04.854: INFO: (16) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.736645ms)
Nov  5 13:05:04.859: INFO: (17) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 5.174773ms)
Nov  5 13:05:04.859: INFO: (17) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 5.402627ms)
Nov  5 13:05:04.860: INFO: (17) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 6.077689ms)
Nov  5 13:05:04.860: INFO: (17) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 6.122537ms)
Nov  5 13:05:04.861: INFO: (17) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 6.433811ms)
Nov  5 13:05:04.861: INFO: (17) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.027576ms)
Nov  5 13:05:04.862: INFO: (17) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 7.185158ms)
Nov  5 13:05:04.862: INFO: (17) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.92894ms)
Nov  5 13:05:04.862: INFO: (17) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 8.359187ms)
Nov  5 13:05:04.863: INFO: (17) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.496354ms)
Nov  5 13:05:04.863: INFO: (17) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.892015ms)
Nov  5 13:05:04.863: INFO: (17) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 9.046907ms)
Nov  5 13:05:04.864: INFO: (17) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.394724ms)
Nov  5 13:05:04.864: INFO: (17) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 9.445705ms)
Nov  5 13:05:04.865: INFO: (17) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 10.175494ms)
Nov  5 13:05:04.865: INFO: (17) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.292236ms)
Nov  5 13:05:04.872: INFO: (18) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 7.327589ms)
Nov  5 13:05:04.872: INFO: (18) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.209332ms)
Nov  5 13:05:04.873: INFO: (18) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.527193ms)
Nov  5 13:05:04.874: INFO: (18) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 8.868803ms)
Nov  5 13:05:04.874: INFO: (18) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.035247ms)
Nov  5 13:05:04.875: INFO: (18) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 10.119767ms)
Nov  5 13:05:04.875: INFO: (18) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 10.271274ms)
Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 10.611862ms)
Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 10.881306ms)
Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 10.726584ms)
Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 10.893619ms)
Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 11.342819ms)
Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 11.589635ms)
Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 11.695534ms)
Nov  5 13:05:04.877: INFO: (18) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 11.356475ms)
Nov  5 13:05:04.877: INFO: (18) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.717784ms)
Nov  5 13:05:04.882: INFO: (19) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 4.702029ms)
Nov  5 13:05:04.883: INFO: (19) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 6.027819ms)
Nov  5 13:05:04.883: INFO: (19) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 5.998989ms)
Nov  5 13:05:04.883: INFO: (19) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 6.297733ms)
Nov  5 13:05:04.884: INFO: (19) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 6.823274ms)
Nov  5 13:05:04.884: INFO: (19) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 7.344388ms)
Nov  5 13:05:04.885: INFO: (19) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.944169ms)
Nov  5 13:05:04.885: INFO: (19) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.950993ms)
Nov  5 13:05:04.886: INFO: (19) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 8.727762ms)
Nov  5 13:05:04.886: INFO: (19) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 8.704358ms)
Nov  5 13:05:04.887: INFO: (19) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 9.952749ms)
Nov  5 13:05:04.887: INFO: (19) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 9.903299ms)
Nov  5 13:05:04.887: INFO: (19) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 10.167355ms)
Nov  5 13:05:04.887: INFO: (19) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.327252ms)
Nov  5 13:05:04.887: INFO: (19) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.645847ms)
Nov  5 13:05:04.888: INFO: (19) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 10.754297ms)
STEP: deleting ReplicationController proxy-service-6tk5b in namespace proxy-9066, will wait for the garbage collector to delete the pods 11/05/22 13:05:04.888
Nov  5 13:05:04.949: INFO: Deleting ReplicationController proxy-service-6tk5b took: 6.93703ms
Nov  5 13:05:05.050: INFO: Terminating ReplicationController proxy-service-6tk5b pods took: 100.584332ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov  5 13:05:07.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9066" for this suite. 11/05/22 13:05:07.154
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":260,"skipped":4787,"failed":0}
------------------------------
• [4.643 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:05:02.517
    Nov  5 13:05:02.517: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename proxy 11/05/22 13:05:02.518
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:05:02.534
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:05:02.538
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 11/05/22 13:05:02.551
    STEP: creating replication controller proxy-service-6tk5b in namespace proxy-9066 11/05/22 13:05:02.551
    I1105 13:05:02.559686      20 runners.go:193] Created replication controller with name: proxy-service-6tk5b, namespace: proxy-9066, replica count: 1
    I1105 13:05:03.611694      20 runners.go:193] proxy-service-6tk5b Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I1105 13:05:04.612708      20 runners.go:193] proxy-service-6tk5b Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 13:05:04.616: INFO: setup took 2.075179451s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 11/05/22 13:05:04.616
    Nov  5 13:05:04.624: INFO: (0) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 6.971995ms)
    Nov  5 13:05:04.628: INFO: (0) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 11.425449ms)
    Nov  5 13:05:04.628: INFO: (0) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 11.347438ms)
    Nov  5 13:05:04.628: INFO: (0) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 11.054156ms)
    Nov  5 13:05:04.629: INFO: (0) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 12.130187ms)
    Nov  5 13:05:04.635: INFO: (0) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 18.42647ms)
    Nov  5 13:05:04.635: INFO: (0) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 18.263058ms)
    Nov  5 13:05:04.636: INFO: (0) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 18.724754ms)
    Nov  5 13:05:04.636: INFO: (0) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 19.597389ms)
    Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 19.737586ms)
    Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 19.731014ms)
    Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 20.173216ms)
    Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 20.182686ms)
    Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 20.187995ms)
    Nov  5 13:05:04.637: INFO: (0) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 20.677806ms)
    Nov  5 13:05:04.638: INFO: (0) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 21.17513ms)
    Nov  5 13:05:04.650: INFO: (1) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 11.800911ms)
    Nov  5 13:05:04.652: INFO: (1) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 13.062972ms)
    Nov  5 13:05:04.652: INFO: (1) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 12.971517ms)
    Nov  5 13:05:04.652: INFO: (1) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 13.585409ms)
    Nov  5 13:05:04.652: INFO: (1) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 13.740413ms)
    Nov  5 13:05:04.652: INFO: (1) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 13.90413ms)
    Nov  5 13:05:04.653: INFO: (1) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 14.730063ms)
    Nov  5 13:05:04.654: INFO: (1) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 15.041776ms)
    Nov  5 13:05:04.654: INFO: (1) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 15.505257ms)
    Nov  5 13:05:04.654: INFO: (1) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 15.501077ms)
    Nov  5 13:05:04.654: INFO: (1) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 15.407092ms)
    Nov  5 13:05:04.654: INFO: (1) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 15.769675ms)
    Nov  5 13:05:04.655: INFO: (1) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 15.845681ms)
    Nov  5 13:05:04.655: INFO: (1) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 16.221045ms)
    Nov  5 13:05:04.655: INFO: (1) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 16.422352ms)
    Nov  5 13:05:04.655: INFO: (1) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 16.430486ms)
    Nov  5 13:05:04.660: INFO: (2) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 4.167048ms)
    Nov  5 13:05:04.660: INFO: (2) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 5.191641ms)
    Nov  5 13:05:04.661: INFO: (2) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 5.601101ms)
    Nov  5 13:05:04.662: INFO: (2) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 6.06971ms)
    Nov  5 13:05:04.663: INFO: (2) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.26095ms)
    Nov  5 13:05:04.664: INFO: (2) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 7.776862ms)
    Nov  5 13:05:04.664: INFO: (2) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.955382ms)
    Nov  5 13:05:04.664: INFO: (2) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 8.376677ms)
    Nov  5 13:05:04.664: INFO: (2) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 8.507007ms)
    Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.221422ms)
    Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 9.079161ms)
    Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 8.867843ms)
    Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 9.245385ms)
    Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.394326ms)
    Nov  5 13:05:04.665: INFO: (2) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 9.38647ms)
    Nov  5 13:05:04.667: INFO: (2) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.206973ms)
    Nov  5 13:05:04.671: INFO: (3) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 4.08093ms)
    Nov  5 13:05:04.674: INFO: (3) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 6.756788ms)
    Nov  5 13:05:04.674: INFO: (3) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 6.586582ms)
    Nov  5 13:05:04.674: INFO: (3) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 6.636648ms)
    Nov  5 13:05:04.674: INFO: (3) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 7.421491ms)
    Nov  5 13:05:04.674: INFO: (3) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 7.448273ms)
    Nov  5 13:05:04.676: INFO: (3) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.645692ms)
    Nov  5 13:05:04.676: INFO: (3) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 8.778823ms)
    Nov  5 13:05:04.676: INFO: (3) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 8.965129ms)
    Nov  5 13:05:04.677: INFO: (3) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 9.684691ms)
    Nov  5 13:05:04.677: INFO: (3) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.423634ms)
    Nov  5 13:05:04.677: INFO: (3) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 10.104985ms)
    Nov  5 13:05:04.677: INFO: (3) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 10.414159ms)
    Nov  5 13:05:04.678: INFO: (3) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 10.916303ms)
    Nov  5 13:05:04.681: INFO: (3) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 14.549382ms)
    Nov  5 13:05:04.684: INFO: (3) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 16.891787ms)
    Nov  5 13:05:04.689: INFO: (4) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 4.8637ms)
    Nov  5 13:05:04.690: INFO: (4) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 6.229892ms)
    Nov  5 13:05:04.691: INFO: (4) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 6.814919ms)
    Nov  5 13:05:04.692: INFO: (4) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 7.229167ms)
    Nov  5 13:05:04.693: INFO: (4) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.950536ms)
    Nov  5 13:05:04.693: INFO: (4) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 9.214549ms)
    Nov  5 13:05:04.694: INFO: (4) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 9.329449ms)
    Nov  5 13:05:04.694: INFO: (4) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.190054ms)
    Nov  5 13:05:04.694: INFO: (4) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 9.52491ms)
    Nov  5 13:05:04.694: INFO: (4) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 9.716483ms)
    Nov  5 13:05:04.694: INFO: (4) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 9.602182ms)
    Nov  5 13:05:04.695: INFO: (4) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 9.96929ms)
    Nov  5 13:05:04.695: INFO: (4) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.113182ms)
    Nov  5 13:05:04.695: INFO: (4) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 10.4454ms)
    Nov  5 13:05:04.695: INFO: (4) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.246693ms)
    Nov  5 13:05:04.695: INFO: (4) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 10.586163ms)
    Nov  5 13:05:04.700: INFO: (5) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 5.269072ms)
    Nov  5 13:05:04.701: INFO: (5) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 5.920089ms)
    Nov  5 13:05:04.701: INFO: (5) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 6.10526ms)
    Nov  5 13:05:04.702: INFO: (5) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 6.13281ms)
    Nov  5 13:05:04.703: INFO: (5) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.530328ms)
    Nov  5 13:05:04.703: INFO: (5) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 7.272878ms)
    Nov  5 13:05:04.703: INFO: (5) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 7.951831ms)
    Nov  5 13:05:04.704: INFO: (5) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 8.577655ms)
    Nov  5 13:05:04.704: INFO: (5) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 8.673659ms)
    Nov  5 13:05:04.704: INFO: (5) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 8.571544ms)
    Nov  5 13:05:04.704: INFO: (5) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.626274ms)
    Nov  5 13:05:04.705: INFO: (5) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 9.132426ms)
    Nov  5 13:05:04.705: INFO: (5) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.189917ms)
    Nov  5 13:05:04.705: INFO: (5) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.569891ms)
    Nov  5 13:05:04.706: INFO: (5) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.103817ms)
    Nov  5 13:05:04.706: INFO: (5) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 10.074889ms)
    Nov  5 13:05:04.710: INFO: (6) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 4.247075ms)
    Nov  5 13:05:04.711: INFO: (6) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 5.08785ms)
    Nov  5 13:05:04.712: INFO: (6) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 5.84353ms)
    Nov  5 13:05:04.712: INFO: (6) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 6.255595ms)
    Nov  5 13:05:04.713: INFO: (6) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 7.48969ms)
    Nov  5 13:05:04.714: INFO: (6) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.685752ms)
    Nov  5 13:05:04.715: INFO: (6) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 8.3607ms)
    Nov  5 13:05:04.715: INFO: (6) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 8.563546ms)
    Nov  5 13:05:04.715: INFO: (6) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 8.505321ms)
    Nov  5 13:05:04.715: INFO: (6) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 8.85509ms)
    Nov  5 13:05:04.716: INFO: (6) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 9.520043ms)
    Nov  5 13:05:04.716: INFO: (6) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 9.562228ms)
    Nov  5 13:05:04.716: INFO: (6) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 9.841533ms)
    Nov  5 13:05:04.716: INFO: (6) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 9.955815ms)
    Nov  5 13:05:04.716: INFO: (6) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 10.396774ms)
    Nov  5 13:05:04.717: INFO: (6) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 10.061708ms)
    Nov  5 13:05:04.721: INFO: (7) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 4.544653ms)
    Nov  5 13:05:04.722: INFO: (7) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 5.15674ms)
    Nov  5 13:05:04.724: INFO: (7) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 6.472622ms)
    Nov  5 13:05:04.724: INFO: (7) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 6.684736ms)
    Nov  5 13:05:04.724: INFO: (7) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 6.978214ms)
    Nov  5 13:05:04.724: INFO: (7) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 7.372161ms)
    Nov  5 13:05:04.725: INFO: (7) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.26011ms)
    Nov  5 13:05:04.725: INFO: (7) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.24829ms)
    Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 8.814638ms)
    Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 8.544009ms)
    Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 8.921707ms)
    Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 9.415465ms)
    Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 9.161914ms)
    Nov  5 13:05:04.726: INFO: (7) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 9.540282ms)
    Nov  5 13:05:04.727: INFO: (7) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.083905ms)
    Nov  5 13:05:04.727: INFO: (7) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.337744ms)
    Nov  5 13:05:04.732: INFO: (8) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 5.188507ms)
    Nov  5 13:05:04.733: INFO: (8) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 5.687884ms)
    Nov  5 13:05:04.733: INFO: (8) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 5.760984ms)
    Nov  5 13:05:04.734: INFO: (8) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 6.083232ms)
    Nov  5 13:05:04.734: INFO: (8) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 6.618845ms)
    Nov  5 13:05:04.735: INFO: (8) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 7.717839ms)
    Nov  5 13:05:04.735: INFO: (8) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.861181ms)
    Nov  5 13:05:04.736: INFO: (8) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 8.243411ms)
    Nov  5 13:05:04.736: INFO: (8) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 8.577533ms)
    Nov  5 13:05:04.736: INFO: (8) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 8.604554ms)
    Nov  5 13:05:04.737: INFO: (8) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 9.524846ms)
    Nov  5 13:05:04.737: INFO: (8) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.543818ms)
    Nov  5 13:05:04.737: INFO: (8) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.295554ms)
    Nov  5 13:05:04.737: INFO: (8) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 9.347772ms)
    Nov  5 13:05:04.737: INFO: (8) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 9.40781ms)
    Nov  5 13:05:04.738: INFO: (8) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.992136ms)
    Nov  5 13:05:04.748: INFO: (9) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 9.318503ms)
    Nov  5 13:05:04.750: INFO: (9) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 11.125906ms)
    Nov  5 13:05:04.752: INFO: (9) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 13.049738ms)
    Nov  5 13:05:04.752: INFO: (9) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 13.776502ms)
    Nov  5 13:05:04.752: INFO: (9) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 13.568143ms)
    Nov  5 13:05:04.753: INFO: (9) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 14.633822ms)
    Nov  5 13:05:04.754: INFO: (9) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 15.331003ms)
    Nov  5 13:05:04.754: INFO: (9) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 15.880527ms)
    Nov  5 13:05:04.755: INFO: (9) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 15.71673ms)
    Nov  5 13:05:04.755: INFO: (9) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 16.013498ms)
    Nov  5 13:05:04.755: INFO: (9) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 15.894932ms)
    Nov  5 13:05:04.755: INFO: (9) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 16.3531ms)
    Nov  5 13:05:04.755: INFO: (9) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 16.481523ms)
    Nov  5 13:05:04.756: INFO: (9) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 17.274505ms)
    Nov  5 13:05:04.756: INFO: (9) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 17.400102ms)
    Nov  5 13:05:04.757: INFO: (9) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 17.723902ms)
    Nov  5 13:05:04.765: INFO: (10) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.347994ms)
    Nov  5 13:05:04.765: INFO: (10) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 8.338212ms)
    Nov  5 13:05:04.766: INFO: (10) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.141731ms)
    Nov  5 13:05:04.767: INFO: (10) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 9.820145ms)
    Nov  5 13:05:04.767: INFO: (10) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 9.763164ms)
    Nov  5 13:05:04.768: INFO: (10) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 10.816036ms)
    Nov  5 13:05:04.769: INFO: (10) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.657794ms)
    Nov  5 13:05:04.770: INFO: (10) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 12.312052ms)
    Nov  5 13:05:04.771: INFO: (10) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 14.43713ms)
    Nov  5 13:05:04.771: INFO: (10) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 14.020974ms)
    Nov  5 13:05:04.771: INFO: (10) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 14.328253ms)
    Nov  5 13:05:04.773: INFO: (10) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 16.038604ms)
    Nov  5 13:05:04.773: INFO: (10) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 15.944744ms)
    Nov  5 13:05:04.774: INFO: (10) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 16.391382ms)
    Nov  5 13:05:04.774: INFO: (10) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 16.763604ms)
    Nov  5 13:05:04.776: INFO: (10) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 18.404336ms)
    Nov  5 13:05:04.783: INFO: (11) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 7.180714ms)
    Nov  5 13:05:04.784: INFO: (11) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.187636ms)
    Nov  5 13:05:04.784: INFO: (11) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 8.05423ms)
    Nov  5 13:05:04.791: INFO: (11) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 14.840693ms)
    Nov  5 13:05:04.791: INFO: (11) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 14.79513ms)
    Nov  5 13:05:04.791: INFO: (11) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 14.98958ms)
    Nov  5 13:05:04.791: INFO: (11) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 15.086079ms)
    Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 15.179062ms)
    Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 15.867308ms)
    Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 15.291788ms)
    Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 15.025396ms)
    Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 15.375105ms)
    Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 15.444806ms)
    Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 15.650128ms)
    Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 15.554457ms)
    Nov  5 13:05:04.792: INFO: (11) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 15.839658ms)
    Nov  5 13:05:04.799: INFO: (12) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 7.574204ms)
    Nov  5 13:05:04.800: INFO: (12) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.259527ms)
    Nov  5 13:05:04.801: INFO: (12) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 8.844426ms)
    Nov  5 13:05:04.801: INFO: (12) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 9.251613ms)
    Nov  5 13:05:04.802: INFO: (12) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.764601ms)
    Nov  5 13:05:04.802: INFO: (12) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 10.617854ms)
    Nov  5 13:05:04.803: INFO: (12) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 10.584702ms)
    Nov  5 13:05:04.803: INFO: (12) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 10.987629ms)
    Nov  5 13:05:04.803: INFO: (12) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 11.365191ms)
    Nov  5 13:05:04.804: INFO: (12) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.653335ms)
    Nov  5 13:05:04.804: INFO: (12) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 11.832989ms)
    Nov  5 13:05:04.804: INFO: (12) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 12.277445ms)
    Nov  5 13:05:04.805: INFO: (12) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 13.181545ms)
    Nov  5 13:05:04.805: INFO: (12) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 13.441788ms)
    Nov  5 13:05:04.805: INFO: (12) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 13.600266ms)
    Nov  5 13:05:04.806: INFO: (12) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 13.959423ms)
    Nov  5 13:05:04.810: INFO: (13) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 4.104839ms)
    Nov  5 13:05:04.812: INFO: (13) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 5.635441ms)
    Nov  5 13:05:04.812: INFO: (13) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 5.764534ms)
    Nov  5 13:05:04.813: INFO: (13) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 6.812815ms)
    Nov  5 13:05:04.814: INFO: (13) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 7.06175ms)
    Nov  5 13:05:04.814: INFO: (13) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.089011ms)
    Nov  5 13:05:04.814: INFO: (13) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 7.942464ms)
    Nov  5 13:05:04.814: INFO: (13) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 7.958418ms)
    Nov  5 13:05:04.815: INFO: (13) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 8.970523ms)
    Nov  5 13:05:04.815: INFO: (13) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 9.086896ms)
    Nov  5 13:05:04.815: INFO: (13) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 9.315794ms)
    Nov  5 13:05:04.816: INFO: (13) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.923421ms)
    Nov  5 13:05:04.816: INFO: (13) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 9.228887ms)
    Nov  5 13:05:04.818: INFO: (13) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 11.843129ms)
    Nov  5 13:05:04.819: INFO: (13) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 12.420847ms)
    Nov  5 13:05:04.819: INFO: (13) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 12.550352ms)
    Nov  5 13:05:04.824: INFO: (14) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 4.550338ms)
    Nov  5 13:05:04.826: INFO: (14) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 6.491034ms)
    Nov  5 13:05:04.826: INFO: (14) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 7.011605ms)
    Nov  5 13:05:04.827: INFO: (14) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 7.765985ms)
    Nov  5 13:05:04.827: INFO: (14) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 8.018181ms)
    Nov  5 13:05:04.828: INFO: (14) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 8.69856ms)
    Nov  5 13:05:04.828: INFO: (14) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.766434ms)
    Nov  5 13:05:04.828: INFO: (14) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.836784ms)
    Nov  5 13:05:04.828: INFO: (14) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 9.249815ms)
    Nov  5 13:05:04.829: INFO: (14) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 9.728335ms)
    Nov  5 13:05:04.829: INFO: (14) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 9.983422ms)
    Nov  5 13:05:04.830: INFO: (14) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 10.237056ms)
    Nov  5 13:05:04.830: INFO: (14) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.522081ms)
    Nov  5 13:05:04.830: INFO: (14) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 10.773189ms)
    Nov  5 13:05:04.830: INFO: (14) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 11.039782ms)
    Nov  5 13:05:04.830: INFO: (14) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.029378ms)
    Nov  5 13:05:04.836: INFO: (15) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 5.301607ms)
    Nov  5 13:05:04.837: INFO: (15) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 6.307197ms)
    Nov  5 13:05:04.838: INFO: (15) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 7.083322ms)
    Nov  5 13:05:04.838: INFO: (15) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 7.150639ms)
    Nov  5 13:05:04.838: INFO: (15) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.413001ms)
    Nov  5 13:05:04.839: INFO: (15) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 7.92058ms)
    Nov  5 13:05:04.839: INFO: (15) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.691786ms)
    Nov  5 13:05:04.840: INFO: (15) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 9.384465ms)
    Nov  5 13:05:04.840: INFO: (15) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 9.904755ms)
    Nov  5 13:05:04.840: INFO: (15) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 9.653737ms)
    Nov  5 13:05:04.841: INFO: (15) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 10.142389ms)
    Nov  5 13:05:04.841: INFO: (15) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 10.547363ms)
    Nov  5 13:05:04.841: INFO: (15) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 10.491245ms)
    Nov  5 13:05:04.842: INFO: (15) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.915999ms)
    Nov  5 13:05:04.842: INFO: (15) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.096466ms)
    Nov  5 13:05:04.842: INFO: (15) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 11.141461ms)
    Nov  5 13:05:04.848: INFO: (16) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 5.784728ms)
    Nov  5 13:05:04.848: INFO: (16) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 5.882575ms)
    Nov  5 13:05:04.848: INFO: (16) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 6.168071ms)
    Nov  5 13:05:04.849: INFO: (16) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 6.487314ms)
    Nov  5 13:05:04.850: INFO: (16) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 7.622987ms)
    Nov  5 13:05:04.850: INFO: (16) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 7.752207ms)
    Nov  5 13:05:04.850: INFO: (16) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 7.791652ms)
    Nov  5 13:05:04.850: INFO: (16) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.150108ms)
    Nov  5 13:05:04.851: INFO: (16) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 8.42188ms)
    Nov  5 13:05:04.852: INFO: (16) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 9.373228ms)
    Nov  5 13:05:04.852: INFO: (16) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 9.608279ms)
    Nov  5 13:05:04.852: INFO: (16) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.433623ms)
    Nov  5 13:05:04.853: INFO: (16) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 10.111267ms)
    Nov  5 13:05:04.853: INFO: (16) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 10.334651ms)
    Nov  5 13:05:04.853: INFO: (16) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.942662ms)
    Nov  5 13:05:04.854: INFO: (16) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.736645ms)
    Nov  5 13:05:04.859: INFO: (17) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 5.174773ms)
    Nov  5 13:05:04.859: INFO: (17) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 5.402627ms)
    Nov  5 13:05:04.860: INFO: (17) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 6.077689ms)
    Nov  5 13:05:04.860: INFO: (17) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 6.122537ms)
    Nov  5 13:05:04.861: INFO: (17) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 6.433811ms)
    Nov  5 13:05:04.861: INFO: (17) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.027576ms)
    Nov  5 13:05:04.862: INFO: (17) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 7.185158ms)
    Nov  5 13:05:04.862: INFO: (17) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.92894ms)
    Nov  5 13:05:04.862: INFO: (17) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 8.359187ms)
    Nov  5 13:05:04.863: INFO: (17) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 8.496354ms)
    Nov  5 13:05:04.863: INFO: (17) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 8.892015ms)
    Nov  5 13:05:04.863: INFO: (17) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 9.046907ms)
    Nov  5 13:05:04.864: INFO: (17) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.394724ms)
    Nov  5 13:05:04.864: INFO: (17) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 9.445705ms)
    Nov  5 13:05:04.865: INFO: (17) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 10.175494ms)
    Nov  5 13:05:04.865: INFO: (17) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.292236ms)
    Nov  5 13:05:04.872: INFO: (18) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 7.327589ms)
    Nov  5 13:05:04.872: INFO: (18) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.209332ms)
    Nov  5 13:05:04.873: INFO: (18) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 7.527193ms)
    Nov  5 13:05:04.874: INFO: (18) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 8.868803ms)
    Nov  5 13:05:04.874: INFO: (18) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 9.035247ms)
    Nov  5 13:05:04.875: INFO: (18) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 10.119767ms)
    Nov  5 13:05:04.875: INFO: (18) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 10.271274ms)
    Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 10.611862ms)
    Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 10.881306ms)
    Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 10.726584ms)
    Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 10.893619ms)
    Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 11.342819ms)
    Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 11.589635ms)
    Nov  5 13:05:04.876: INFO: (18) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 11.695534ms)
    Nov  5 13:05:04.877: INFO: (18) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 11.356475ms)
    Nov  5 13:05:04.877: INFO: (18) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 11.717784ms)
    Nov  5 13:05:04.882: INFO: (19) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:1080/proxy/rewriteme">test<... (200; 4.702029ms)
    Nov  5 13:05:04.883: INFO: (19) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:462/proxy/: tls qux (200; 6.027819ms)
    Nov  5 13:05:04.883: INFO: (19) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t/proxy/rewriteme">test</a> (200; 5.998989ms)
    Nov  5 13:05:04.883: INFO: (19) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:160/proxy/: foo (200; 6.297733ms)
    Nov  5 13:05:04.884: INFO: (19) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:160/proxy/: foo (200; 6.823274ms)
    Nov  5 13:05:04.884: INFO: (19) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:1080/proxy/rewriteme">... (200; 7.344388ms)
    Nov  5 13:05:04.885: INFO: (19) /api/v1/namespaces/proxy-9066/pods/proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.944169ms)
    Nov  5 13:05:04.885: INFO: (19) /api/v1/namespaces/proxy-9066/pods/http:proxy-service-6tk5b-9689t:162/proxy/: bar (200; 7.950993ms)
    Nov  5 13:05:04.886: INFO: (19) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:460/proxy/: tls baz (200; 8.727762ms)
    Nov  5 13:05:04.886: INFO: (19) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname1/proxy/: foo (200; 8.704358ms)
    Nov  5 13:05:04.887: INFO: (19) /api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/: <a href="/api/v1/namespaces/proxy-9066/pods/https:proxy-service-6tk5b-9689t:443/proxy/tlsrewritem... (200; 9.952749ms)
    Nov  5 13:05:04.887: INFO: (19) /api/v1/namespaces/proxy-9066/services/proxy-service-6tk5b:portname2/proxy/: bar (200; 9.903299ms)
    Nov  5 13:05:04.887: INFO: (19) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname1/proxy/: tls baz (200; 10.167355ms)
    Nov  5 13:05:04.887: INFO: (19) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname1/proxy/: foo (200; 10.327252ms)
    Nov  5 13:05:04.887: INFO: (19) /api/v1/namespaces/proxy-9066/services/https:proxy-service-6tk5b:tlsportname2/proxy/: tls qux (200; 10.645847ms)
    Nov  5 13:05:04.888: INFO: (19) /api/v1/namespaces/proxy-9066/services/http:proxy-service-6tk5b:portname2/proxy/: bar (200; 10.754297ms)
    STEP: deleting ReplicationController proxy-service-6tk5b in namespace proxy-9066, will wait for the garbage collector to delete the pods 11/05/22 13:05:04.888
    Nov  5 13:05:04.949: INFO: Deleting ReplicationController proxy-service-6tk5b took: 6.93703ms
    Nov  5 13:05:05.050: INFO: Terminating ReplicationController proxy-service-6tk5b pods took: 100.584332ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov  5 13:05:07.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-9066" for this suite. 11/05/22 13:05:07.154
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:05:07.161
Nov  5 13:05:07.161: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:05:07.162
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:05:07.179
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:05:07.182
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 11/05/22 13:05:07.186
Nov  5 13:05:07.186: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: mark a version not serverd 11/05/22 13:05:13.089
STEP: check the unserved version gets removed 11/05/22 13:05:13.105
STEP: check the other version is not changed 11/05/22 13:05:14.772
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:05:19.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4643" for this suite. 11/05/22 13:05:19.455
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":261,"skipped":4825,"failed":0}
------------------------------
• [SLOW TEST] [12.300 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:05:07.161
    Nov  5 13:05:07.161: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:05:07.162
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:05:07.179
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:05:07.182
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 11/05/22 13:05:07.186
    Nov  5 13:05:07.186: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: mark a version not serverd 11/05/22 13:05:13.089
    STEP: check the unserved version gets removed 11/05/22 13:05:13.105
    STEP: check the other version is not changed 11/05/22 13:05:14.772
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:05:19.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4643" for this suite. 11/05/22 13:05:19.455
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:05:19.462
Nov  5 13:05:19.462: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename namespaces 11/05/22 13:05:19.463
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:05:19.479
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:05:19.482
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 11/05/22 13:05:19.486
Nov  5 13:05:19.489: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 11/05/22 13:05:19.489
Nov  5 13:05:19.495: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 11/05/22 13:05:19.495
Nov  5 13:05:19.503: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov  5 13:05:19.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2960" for this suite. 11/05/22 13:05:19.507
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":262,"skipped":4842,"failed":0}
------------------------------
• [0.051 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:05:19.462
    Nov  5 13:05:19.462: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename namespaces 11/05/22 13:05:19.463
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:05:19.479
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:05:19.482
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 11/05/22 13:05:19.486
    Nov  5 13:05:19.489: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 11/05/22 13:05:19.489
    Nov  5 13:05:19.495: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 11/05/22 13:05:19.495
    Nov  5 13:05:19.503: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 13:05:19.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-2960" for this suite. 11/05/22 13:05:19.507
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:05:19.515
Nov  5 13:05:19.515: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 13:05:19.516
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:05:19.531
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:05:19.534
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-5ad0e93a-ca7a-41b7-a8fd-9baac20d3207 11/05/22 13:05:19.538
STEP: Creating a pod to test consume configMaps 11/05/22 13:05:19.542
Nov  5 13:05:19.551: INFO: Waiting up to 5m0s for pod "pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94" in namespace "configmap-8895" to be "Succeeded or Failed"
Nov  5 13:05:19.555: INFO: Pod "pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94": Phase="Pending", Reason="", readiness=false. Elapsed: 3.80861ms
Nov  5 13:05:21.559: INFO: Pod "pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007839022s
Nov  5 13:05:23.560: INFO: Pod "pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008936102s
STEP: Saw pod success 11/05/22 13:05:23.56
Nov  5 13:05:23.560: INFO: Pod "pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94" satisfied condition "Succeeded or Failed"
Nov  5 13:05:23.563: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94 container agnhost-container: <nil>
STEP: delete the pod 11/05/22 13:05:23.569
Nov  5 13:05:23.578: INFO: Waiting for pod pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94 to disappear
Nov  5 13:05:23.581: INFO: Pod pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 13:05:23.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8895" for this suite. 11/05/22 13:05:23.585
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":263,"skipped":4859,"failed":0}
------------------------------
• [4.076 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:05:19.515
    Nov  5 13:05:19.515: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 13:05:19.516
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:05:19.531
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:05:19.534
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-5ad0e93a-ca7a-41b7-a8fd-9baac20d3207 11/05/22 13:05:19.538
    STEP: Creating a pod to test consume configMaps 11/05/22 13:05:19.542
    Nov  5 13:05:19.551: INFO: Waiting up to 5m0s for pod "pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94" in namespace "configmap-8895" to be "Succeeded or Failed"
    Nov  5 13:05:19.555: INFO: Pod "pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94": Phase="Pending", Reason="", readiness=false. Elapsed: 3.80861ms
    Nov  5 13:05:21.559: INFO: Pod "pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007839022s
    Nov  5 13:05:23.560: INFO: Pod "pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008936102s
    STEP: Saw pod success 11/05/22 13:05:23.56
    Nov  5 13:05:23.560: INFO: Pod "pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94" satisfied condition "Succeeded or Failed"
    Nov  5 13:05:23.563: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94 container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 13:05:23.569
    Nov  5 13:05:23.578: INFO: Waiting for pod pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94 to disappear
    Nov  5 13:05:23.581: INFO: Pod pod-configmaps-cc0a4fd9-d151-4609-baef-ae825bfe1e94 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 13:05:23.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8895" for this suite. 11/05/22 13:05:23.585
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:05:23.592
Nov  5 13:05:23.592: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename cronjob 11/05/22 13:05:23.592
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:05:23.608
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:05:23.611
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 11/05/22 13:05:23.614
STEP: Ensuring a job is scheduled 11/05/22 13:05:23.62
STEP: Ensuring exactly one is scheduled 11/05/22 13:06:01.624
STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/05/22 13:06:01.627
STEP: Ensuring the job is replaced with a new one 11/05/22 13:06:01.63
STEP: Removing cronjob 11/05/22 13:07:01.634
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov  5 13:07:01.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-3108" for this suite. 11/05/22 13:07:01.645
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":264,"skipped":4862,"failed":0}
------------------------------
• [SLOW TEST] [98.060 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:05:23.592
    Nov  5 13:05:23.592: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename cronjob 11/05/22 13:05:23.592
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:05:23.608
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:05:23.611
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 11/05/22 13:05:23.614
    STEP: Ensuring a job is scheduled 11/05/22 13:05:23.62
    STEP: Ensuring exactly one is scheduled 11/05/22 13:06:01.624
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 11/05/22 13:06:01.627
    STEP: Ensuring the job is replaced with a new one 11/05/22 13:06:01.63
    STEP: Removing cronjob 11/05/22 13:07:01.634
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov  5 13:07:01.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-3108" for this suite. 11/05/22 13:07:01.645
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:07:01.652
Nov  5 13:07:01.653: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 13:07:01.653
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:01.68
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:01.683
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 11/05/22 13:07:01.686
Nov  5 13:07:01.693: INFO: Waiting up to 5m0s for pod "pod-8b060fa2-c58a-4119-b93d-b667b0622c88" in namespace "emptydir-9296" to be "Succeeded or Failed"
Nov  5 13:07:01.696: INFO: Pod "pod-8b060fa2-c58a-4119-b93d-b667b0622c88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.580718ms
Nov  5 13:07:03.701: INFO: Pod "pod-8b060fa2-c58a-4119-b93d-b667b0622c88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007962195s
Nov  5 13:07:05.701: INFO: Pod "pod-8b060fa2-c58a-4119-b93d-b667b0622c88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0075778s
STEP: Saw pod success 11/05/22 13:07:05.701
Nov  5 13:07:05.701: INFO: Pod "pod-8b060fa2-c58a-4119-b93d-b667b0622c88" satisfied condition "Succeeded or Failed"
Nov  5 13:07:05.704: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-8b060fa2-c58a-4119-b93d-b667b0622c88 container test-container: <nil>
STEP: delete the pod 11/05/22 13:07:05.716
Nov  5 13:07:05.728: INFO: Waiting for pod pod-8b060fa2-c58a-4119-b93d-b667b0622c88 to disappear
Nov  5 13:07:05.731: INFO: Pod pod-8b060fa2-c58a-4119-b93d-b667b0622c88 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 13:07:05.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9296" for this suite. 11/05/22 13:07:05.736
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":265,"skipped":4862,"failed":0}
------------------------------
• [4.090 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:07:01.652
    Nov  5 13:07:01.653: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 13:07:01.653
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:01.68
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:01.683
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 11/05/22 13:07:01.686
    Nov  5 13:07:01.693: INFO: Waiting up to 5m0s for pod "pod-8b060fa2-c58a-4119-b93d-b667b0622c88" in namespace "emptydir-9296" to be "Succeeded or Failed"
    Nov  5 13:07:01.696: INFO: Pod "pod-8b060fa2-c58a-4119-b93d-b667b0622c88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.580718ms
    Nov  5 13:07:03.701: INFO: Pod "pod-8b060fa2-c58a-4119-b93d-b667b0622c88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007962195s
    Nov  5 13:07:05.701: INFO: Pod "pod-8b060fa2-c58a-4119-b93d-b667b0622c88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0075778s
    STEP: Saw pod success 11/05/22 13:07:05.701
    Nov  5 13:07:05.701: INFO: Pod "pod-8b060fa2-c58a-4119-b93d-b667b0622c88" satisfied condition "Succeeded or Failed"
    Nov  5 13:07:05.704: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-8b060fa2-c58a-4119-b93d-b667b0622c88 container test-container: <nil>
    STEP: delete the pod 11/05/22 13:07:05.716
    Nov  5 13:07:05.728: INFO: Waiting for pod pod-8b060fa2-c58a-4119-b93d-b667b0622c88 to disappear
    Nov  5 13:07:05.731: INFO: Pod pod-8b060fa2-c58a-4119-b93d-b667b0622c88 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 13:07:05.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9296" for this suite. 11/05/22 13:07:05.736
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:07:05.744
Nov  5 13:07:05.744: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:07:05.745
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:05.769
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:05.772
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-20571d20-b0e7-49f5-9e82-7d7f66773b4e 11/05/22 13:07:05.776
STEP: Creating a pod to test consume configMaps 11/05/22 13:07:05.781
Nov  5 13:07:05.790: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3" in namespace "projected-8673" to be "Succeeded or Failed"
Nov  5 13:07:05.793: INFO: Pod "pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.255926ms
Nov  5 13:07:07.798: INFO: Pod "pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008169244s
Nov  5 13:07:09.798: INFO: Pod "pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007641857s
STEP: Saw pod success 11/05/22 13:07:09.798
Nov  5 13:07:09.798: INFO: Pod "pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3" satisfied condition "Succeeded or Failed"
Nov  5 13:07:09.801: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3 container agnhost-container: <nil>
STEP: delete the pod 11/05/22 13:07:09.807
Nov  5 13:07:09.820: INFO: Waiting for pod pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3 to disappear
Nov  5 13:07:09.823: INFO: Pod pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov  5 13:07:09.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8673" for this suite. 11/05/22 13:07:09.827
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":266,"skipped":4901,"failed":0}
------------------------------
• [4.088 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:07:05.744
    Nov  5 13:07:05.744: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:07:05.745
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:05.769
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:05.772
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-20571d20-b0e7-49f5-9e82-7d7f66773b4e 11/05/22 13:07:05.776
    STEP: Creating a pod to test consume configMaps 11/05/22 13:07:05.781
    Nov  5 13:07:05.790: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3" in namespace "projected-8673" to be "Succeeded or Failed"
    Nov  5 13:07:05.793: INFO: Pod "pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.255926ms
    Nov  5 13:07:07.798: INFO: Pod "pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008169244s
    Nov  5 13:07:09.798: INFO: Pod "pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007641857s
    STEP: Saw pod success 11/05/22 13:07:09.798
    Nov  5 13:07:09.798: INFO: Pod "pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3" satisfied condition "Succeeded or Failed"
    Nov  5 13:07:09.801: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3 container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 13:07:09.807
    Nov  5 13:07:09.820: INFO: Waiting for pod pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3 to disappear
    Nov  5 13:07:09.823: INFO: Pod pod-projected-configmaps-6fb54712-b07a-488d-8fbf-9e90fc42dcf3 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov  5 13:07:09.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8673" for this suite. 11/05/22 13:07:09.827
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:07:09.834
Nov  5 13:07:09.835: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replicaset 11/05/22 13:07:09.835
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:09.909
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:09.913
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 11/05/22 13:07:09.916
Nov  5 13:07:09.925: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  5 13:07:14.932: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 11/05/22 13:07:14.932
STEP: getting scale subresource 11/05/22 13:07:14.932
STEP: updating a scale subresource 11/05/22 13:07:14.937
STEP: verifying the replicaset Spec.Replicas was modified 11/05/22 13:07:14.941
STEP: Patch a scale subresource 11/05/22 13:07:14.945
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Nov  5 13:07:14.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7637" for this suite. 11/05/22 13:07:14.963
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":267,"skipped":4939,"failed":0}
------------------------------
• [SLOW TEST] [5.136 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:07:09.834
    Nov  5 13:07:09.835: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replicaset 11/05/22 13:07:09.835
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:09.909
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:09.913
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 11/05/22 13:07:09.916
    Nov  5 13:07:09.925: INFO: Pod name sample-pod: Found 0 pods out of 1
    Nov  5 13:07:14.932: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 11/05/22 13:07:14.932
    STEP: getting scale subresource 11/05/22 13:07:14.932
    STEP: updating a scale subresource 11/05/22 13:07:14.937
    STEP: verifying the replicaset Spec.Replicas was modified 11/05/22 13:07:14.941
    STEP: Patch a scale subresource 11/05/22 13:07:14.945
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Nov  5 13:07:14.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-7637" for this suite. 11/05/22 13:07:14.963
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:07:14.973
Nov  5 13:07:14.973: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename sched-pred 11/05/22 13:07:14.974
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:15.008
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:15.011
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Nov  5 13:07:15.015: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  5 13:07:15.024: INFO: Waiting for terminating namespaces to be deleted...
Nov  5 13:07:15.028: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-0-255 before test
Nov  5 13:07:15.046: INFO: replace-27794226-rr27m from cronjob-3108 started at 2022-11-05 13:06:00 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.046: INFO: 	Container c ready: true, restart count 0
Nov  5 13:07:15.046: INFO: nginx-ingress-controller-kubernetes-worker-v9666 from ingress-nginx-kubernetes-worker started at 2022-11-05 12:07:51 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.046: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 13:07:15.046: INFO: test-rs-96nxp from replicaset-7637 started at 2022-11-05 13:07:09 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.046: INFO: 	Container httpd ready: true, restart count 0
Nov  5 13:07:15.046: INFO: sonobuoy from sonobuoy started at 2022-11-05 11:55:13 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.046: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  5 13:07:15.046: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 13:07:15.046: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 13:07:15.046: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 13:07:15.046: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-27-199 before test
Nov  5 13:07:15.050: INFO: default-http-backend-kubernetes-worker-6546b9855c-tdc5h from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.050: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
Nov  5 13:07:15.050: INFO: nginx-ingress-controller-kubernetes-worker-l6972 from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.050: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 13:07:15.050: INFO: calico-kube-controllers-b5bd6849d-zg9jq from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.050: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  5 13:07:15.050: INFO: coredns-6bcf44f4cc-ddkx4 from kube-system started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.050: INFO: 	Container coredns ready: true, restart count 0
Nov  5 13:07:15.050: INFO: kube-state-metrics-74f5d549cc-cc4bl from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.050: INFO: 	Container kube-state-metrics ready: true, restart count 0
Nov  5 13:07:15.050: INFO: metrics-server-v0.5.2-6b48dc6f97-cp95w from kube-system started at 2022-11-05 11:49:10 +0000 UTC (2 container statuses recorded)
Nov  5 13:07:15.050: INFO: 	Container metrics-server ready: true, restart count 1
Nov  5 13:07:15.050: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Nov  5 13:07:15.050: INFO: dashboard-metrics-scraper-85d45476c6-4v4zk from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.050: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  5 13:07:15.050: INFO: kubernetes-dashboard-7fb574cb-6lhg6 from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.050: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Nov  5 13:07:15.050: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-w6fxs from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 13:07:15.050: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 13:07:15.050: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  5 13:07:15.050: INFO: 
Logging pods the apiserver thinks is on node ip-172-31-41-19 before test
Nov  5 13:07:15.055: INFO: replace-27794227-vbpfx from cronjob-3108 started at 2022-11-05 13:07:00 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.055: INFO: 	Container c ready: true, restart count 0
Nov  5 13:07:15.055: INFO: nginx-ingress-controller-kubernetes-worker-879hx from ingress-nginx-kubernetes-worker started at 2022-11-05 11:50:52 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.055: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
Nov  5 13:07:15.055: INFO: test-rs-pqb7w from replicaset-7637 started at 2022-11-05 13:07:14 +0000 UTC (1 container statuses recorded)
Nov  5 13:07:15.055: INFO: 	Container httpd ready: false, restart count 0
Nov  5 13:07:15.055: INFO: sonobuoy-e2e-job-b878a59025e244cf from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
Nov  5 13:07:15.055: INFO: 	Container e2e ready: true, restart count 0
Nov  5 13:07:15.055: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 13:07:15.055: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-zjsjg from sonobuoy started at 2022-11-05 11:55:17 +0000 UTC (2 container statuses recorded)
Nov  5 13:07:15.055: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  5 13:07:15.055: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 11/05/22 13:07:15.055
Nov  5 13:07:15.065: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9015" to be "running"
Nov  5 13:07:15.069: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.332145ms
Nov  5 13:07:17.073: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.007628557s
Nov  5 13:07:17.073: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 11/05/22 13:07:17.077
STEP: Trying to apply a random label on the found node. 11/05/22 13:07:17.086
STEP: verifying the node has the label kubernetes.io/e2e-a4050ba6-7498-4c30-86cb-8211309d13b3 42 11/05/22 13:07:17.096
STEP: Trying to relaunch the pod, now with labels. 11/05/22 13:07:17.099
Nov  5 13:07:17.106: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-9015" to be "not pending"
Nov  5 13:07:17.111: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 5.291679ms
Nov  5 13:07:19.116: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.010352641s
Nov  5 13:07:19.116: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-a4050ba6-7498-4c30-86cb-8211309d13b3 off the node ip-172-31-0-255 11/05/22 13:07:19.119
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a4050ba6-7498-4c30-86cb-8211309d13b3 11/05/22 13:07:19.13
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Nov  5 13:07:19.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9015" for this suite. 11/05/22 13:07:19.138
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":268,"skipped":4959,"failed":0}
------------------------------
• [4.173 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:07:14.973
    Nov  5 13:07:14.973: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename sched-pred 11/05/22 13:07:14.974
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:15.008
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:15.011
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Nov  5 13:07:15.015: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Nov  5 13:07:15.024: INFO: Waiting for terminating namespaces to be deleted...
    Nov  5 13:07:15.028: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-0-255 before test
    Nov  5 13:07:15.046: INFO: replace-27794226-rr27m from cronjob-3108 started at 2022-11-05 13:06:00 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.046: INFO: 	Container c ready: true, restart count 0
    Nov  5 13:07:15.046: INFO: nginx-ingress-controller-kubernetes-worker-v9666 from ingress-nginx-kubernetes-worker started at 2022-11-05 12:07:51 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.046: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 13:07:15.046: INFO: test-rs-96nxp from replicaset-7637 started at 2022-11-05 13:07:09 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.046: INFO: 	Container httpd ready: true, restart count 0
    Nov  5 13:07:15.046: INFO: sonobuoy from sonobuoy started at 2022-11-05 11:55:13 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.046: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Nov  5 13:07:15.046: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-6s9fl from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 13:07:15.046: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 13:07:15.046: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov  5 13:07:15.046: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-27-199 before test
    Nov  5 13:07:15.050: INFO: default-http-backend-kubernetes-worker-6546b9855c-tdc5h from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.050: INFO: 	Container default-http-backend-kubernetes-worker ready: true, restart count 0
    Nov  5 13:07:15.050: INFO: nginx-ingress-controller-kubernetes-worker-l6972 from ingress-nginx-kubernetes-worker started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.050: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 13:07:15.050: INFO: calico-kube-controllers-b5bd6849d-zg9jq from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.050: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Nov  5 13:07:15.050: INFO: coredns-6bcf44f4cc-ddkx4 from kube-system started at 2022-11-05 11:49:15 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.050: INFO: 	Container coredns ready: true, restart count 0
    Nov  5 13:07:15.050: INFO: kube-state-metrics-74f5d549cc-cc4bl from kube-system started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.050: INFO: 	Container kube-state-metrics ready: true, restart count 0
    Nov  5 13:07:15.050: INFO: metrics-server-v0.5.2-6b48dc6f97-cp95w from kube-system started at 2022-11-05 11:49:10 +0000 UTC (2 container statuses recorded)
    Nov  5 13:07:15.050: INFO: 	Container metrics-server ready: true, restart count 1
    Nov  5 13:07:15.050: INFO: 	Container metrics-server-nanny ready: true, restart count 0
    Nov  5 13:07:15.050: INFO: dashboard-metrics-scraper-85d45476c6-4v4zk from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.050: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
    Nov  5 13:07:15.050: INFO: kubernetes-dashboard-7fb574cb-6lhg6 from kubernetes-dashboard started at 2022-11-05 11:49:10 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.050: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
    Nov  5 13:07:15.050: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-w6fxs from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 13:07:15.050: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 13:07:15.050: INFO: 	Container systemd-logs ready: true, restart count 0
    Nov  5 13:07:15.050: INFO: 
    Logging pods the apiserver thinks is on node ip-172-31-41-19 before test
    Nov  5 13:07:15.055: INFO: replace-27794227-vbpfx from cronjob-3108 started at 2022-11-05 13:07:00 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.055: INFO: 	Container c ready: true, restart count 0
    Nov  5 13:07:15.055: INFO: nginx-ingress-controller-kubernetes-worker-879hx from ingress-nginx-kubernetes-worker started at 2022-11-05 11:50:52 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.055: INFO: 	Container nginx-ingress-controllerkubernetes-worker ready: true, restart count 0
    Nov  5 13:07:15.055: INFO: test-rs-pqb7w from replicaset-7637 started at 2022-11-05 13:07:14 +0000 UTC (1 container statuses recorded)
    Nov  5 13:07:15.055: INFO: 	Container httpd ready: false, restart count 0
    Nov  5 13:07:15.055: INFO: sonobuoy-e2e-job-b878a59025e244cf from sonobuoy started at 2022-11-05 11:55:16 +0000 UTC (2 container statuses recorded)
    Nov  5 13:07:15.055: INFO: 	Container e2e ready: true, restart count 0
    Nov  5 13:07:15.055: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 13:07:15.055: INFO: sonobuoy-systemd-logs-daemon-set-49dd201efbeb443c-zjsjg from sonobuoy started at 2022-11-05 11:55:17 +0000 UTC (2 container statuses recorded)
    Nov  5 13:07:15.055: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Nov  5 13:07:15.055: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 11/05/22 13:07:15.055
    Nov  5 13:07:15.065: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9015" to be "running"
    Nov  5 13:07:15.069: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 3.332145ms
    Nov  5 13:07:17.073: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.007628557s
    Nov  5 13:07:17.073: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 11/05/22 13:07:17.077
    STEP: Trying to apply a random label on the found node. 11/05/22 13:07:17.086
    STEP: verifying the node has the label kubernetes.io/e2e-a4050ba6-7498-4c30-86cb-8211309d13b3 42 11/05/22 13:07:17.096
    STEP: Trying to relaunch the pod, now with labels. 11/05/22 13:07:17.099
    Nov  5 13:07:17.106: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-9015" to be "not pending"
    Nov  5 13:07:17.111: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 5.291679ms
    Nov  5 13:07:19.116: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.010352641s
    Nov  5 13:07:19.116: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-a4050ba6-7498-4c30-86cb-8211309d13b3 off the node ip-172-31-0-255 11/05/22 13:07:19.119
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-a4050ba6-7498-4c30-86cb-8211309d13b3 11/05/22 13:07:19.13
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 13:07:19.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-9015" for this suite. 11/05/22 13:07:19.138
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:07:19.148
Nov  5 13:07:19.148: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 13:07:19.149
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:19.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:19.166
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 11/05/22 13:07:19.17
Nov  5 13:07:19.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7263 api-versions'
Nov  5 13:07:19.224: INFO: stderr: ""
Nov  5 13:07:19.224: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 13:07:19.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7263" for this suite. 11/05/22 13:07:19.228
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":269,"skipped":4997,"failed":0}
------------------------------
• [0.087 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:07:19.148
    Nov  5 13:07:19.148: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 13:07:19.149
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:19.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:19.166
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 11/05/22 13:07:19.17
    Nov  5 13:07:19.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7263 api-versions'
    Nov  5 13:07:19.224: INFO: stderr: ""
    Nov  5 13:07:19.224: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 13:07:19.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7263" for this suite. 11/05/22 13:07:19.228
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:07:19.235
Nov  5 13:07:19.235: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubelet-test 11/05/22 13:07:19.236
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:19.252
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:19.255
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 11/05/22 13:07:19.265
Nov  5 13:07:19.266: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases48e87092-c3cc-47d5-932b-0934f94c38de" in namespace "kubelet-test-883" to be "completed"
Nov  5 13:07:19.271: INFO: Pod "agnhost-host-aliases48e87092-c3cc-47d5-932b-0934f94c38de": Phase="Pending", Reason="", readiness=false. Elapsed: 5.3499ms
Nov  5 13:07:21.275: INFO: Pod "agnhost-host-aliases48e87092-c3cc-47d5-932b-0934f94c38de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009221493s
Nov  5 13:07:23.276: INFO: Pod "agnhost-host-aliases48e87092-c3cc-47d5-932b-0934f94c38de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010481419s
Nov  5 13:07:23.276: INFO: Pod "agnhost-host-aliases48e87092-c3cc-47d5-932b-0934f94c38de" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Nov  5 13:07:23.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-883" for this suite. 11/05/22 13:07:23.293
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":270,"skipped":5004,"failed":0}
------------------------------
• [4.065 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:07:19.235
    Nov  5 13:07:19.235: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubelet-test 11/05/22 13:07:19.236
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:19.252
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:19.255
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 11/05/22 13:07:19.265
    Nov  5 13:07:19.266: INFO: Waiting up to 3m0s for pod "agnhost-host-aliases48e87092-c3cc-47d5-932b-0934f94c38de" in namespace "kubelet-test-883" to be "completed"
    Nov  5 13:07:19.271: INFO: Pod "agnhost-host-aliases48e87092-c3cc-47d5-932b-0934f94c38de": Phase="Pending", Reason="", readiness=false. Elapsed: 5.3499ms
    Nov  5 13:07:21.275: INFO: Pod "agnhost-host-aliases48e87092-c3cc-47d5-932b-0934f94c38de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009221493s
    Nov  5 13:07:23.276: INFO: Pod "agnhost-host-aliases48e87092-c3cc-47d5-932b-0934f94c38de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010481419s
    Nov  5 13:07:23.276: INFO: Pod "agnhost-host-aliases48e87092-c3cc-47d5-932b-0934f94c38de" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Nov  5 13:07:23.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-883" for this suite. 11/05/22 13:07:23.293
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:07:23.301
Nov  5 13:07:23.302: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-probe 11/05/22 13:07:23.302
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:23.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:23.322
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov  5 13:08:23.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4440" for this suite. 11/05/22 13:08:23.343
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":271,"skipped":5011,"failed":0}
------------------------------
• [SLOW TEST] [60.048 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:07:23.301
    Nov  5 13:07:23.302: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-probe 11/05/22 13:07:23.302
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:07:23.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:07:23.322
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov  5 13:08:23.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-4440" for this suite. 11/05/22 13:08:23.343
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:08:23.351
Nov  5 13:08:23.351: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:08:23.352
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:23.367
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:23.371
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-4ec5b347-9ad1-43f1-8abc-6d9940423adc 11/05/22 13:08:23.374
STEP: Creating a pod to test consume secrets 11/05/22 13:08:23.379
Nov  5 13:08:23.386: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7" in namespace "projected-9571" to be "Succeeded or Failed"
Nov  5 13:08:23.389: INFO: Pod "pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.274587ms
Nov  5 13:08:25.394: INFO: Pod "pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007581926s
Nov  5 13:08:27.393: INFO: Pod "pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007301683s
STEP: Saw pod success 11/05/22 13:08:27.393
Nov  5 13:08:27.393: INFO: Pod "pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7" satisfied condition "Succeeded or Failed"
Nov  5 13:08:27.396: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7 container projected-secret-volume-test: <nil>
STEP: delete the pod 11/05/22 13:08:27.408
Nov  5 13:08:27.420: INFO: Waiting for pod pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7 to disappear
Nov  5 13:08:27.422: INFO: Pod pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov  5 13:08:27.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9571" for this suite. 11/05/22 13:08:27.425
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":272,"skipped":5020,"failed":0}
------------------------------
• [4.080 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:08:23.351
    Nov  5 13:08:23.351: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:08:23.352
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:23.367
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:23.371
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-4ec5b347-9ad1-43f1-8abc-6d9940423adc 11/05/22 13:08:23.374
    STEP: Creating a pod to test consume secrets 11/05/22 13:08:23.379
    Nov  5 13:08:23.386: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7" in namespace "projected-9571" to be "Succeeded or Failed"
    Nov  5 13:08:23.389: INFO: Pod "pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.274587ms
    Nov  5 13:08:25.394: INFO: Pod "pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007581926s
    Nov  5 13:08:27.393: INFO: Pod "pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007301683s
    STEP: Saw pod success 11/05/22 13:08:27.393
    Nov  5 13:08:27.393: INFO: Pod "pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7" satisfied condition "Succeeded or Failed"
    Nov  5 13:08:27.396: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7 container projected-secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 13:08:27.408
    Nov  5 13:08:27.420: INFO: Waiting for pod pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7 to disappear
    Nov  5 13:08:27.422: INFO: Pod pod-projected-secrets-81a4fb33-565d-461e-ada0-fd952c00e9c7 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov  5 13:08:27.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9571" for this suite. 11/05/22 13:08:27.425
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:08:27.434
Nov  5 13:08:27.435: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 13:08:27.435
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:27.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:27.455
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 13:08:27.469
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 13:08:27.879
STEP: Deploying the webhook pod 11/05/22 13:08:27.888
STEP: Wait for the deployment to be ready 11/05/22 13:08:27.899
Nov  5 13:08:27.906: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 13:08:29.918
STEP: Verifying the service has paired with the endpoint 11/05/22 13:08:29.929
Nov  5 13:08:30.930: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Nov  5 13:08:30.934: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2244-crds.webhook.example.com via the AdmissionRegistration API 11/05/22 13:08:31.447
STEP: Creating a custom resource that should be mutated by the webhook 11/05/22 13:08:31.463
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:08:34.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-875" for this suite. 11/05/22 13:08:34.046
STEP: Destroying namespace "webhook-875-markers" for this suite. 11/05/22 13:08:34.052
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":273,"skipped":5072,"failed":0}
------------------------------
• [SLOW TEST] [6.657 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:08:27.434
    Nov  5 13:08:27.435: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 13:08:27.435
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:27.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:27.455
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 13:08:27.469
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 13:08:27.879
    STEP: Deploying the webhook pod 11/05/22 13:08:27.888
    STEP: Wait for the deployment to be ready 11/05/22 13:08:27.899
    Nov  5 13:08:27.906: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 13:08:29.918
    STEP: Verifying the service has paired with the endpoint 11/05/22 13:08:29.929
    Nov  5 13:08:30.930: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Nov  5 13:08:30.934: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2244-crds.webhook.example.com via the AdmissionRegistration API 11/05/22 13:08:31.447
    STEP: Creating a custom resource that should be mutated by the webhook 11/05/22 13:08:31.463
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:08:34.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-875" for this suite. 11/05/22 13:08:34.046
    STEP: Destroying namespace "webhook-875-markers" for this suite. 11/05/22 13:08:34.052
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:08:34.094
Nov  5 13:08:34.094: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:08:34.094
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:34.117
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:34.12
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 11/05/22 13:08:34.124
Nov  5 13:08:34.124: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:08:36.326: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:08:46.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5091" for this suite. 11/05/22 13:08:46.779
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":274,"skipped":5124,"failed":0}
------------------------------
• [SLOW TEST] [12.691 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:08:34.094
    Nov  5 13:08:34.094: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:08:34.094
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:34.117
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:34.12
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 11/05/22 13:08:34.124
    Nov  5 13:08:34.124: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:08:36.326: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:08:46.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5091" for this suite. 11/05/22 13:08:46.779
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:08:46.785
Nov  5 13:08:46.785: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename events 11/05/22 13:08:46.786
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:46.803
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:46.807
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 11/05/22 13:08:46.81
STEP: listing events in all namespaces 11/05/22 13:08:46.817
STEP: listing events in test namespace 11/05/22 13:08:46.821
STEP: listing events with field selection filtering on source 11/05/22 13:08:46.824
STEP: listing events with field selection filtering on reportingController 11/05/22 13:08:46.828
STEP: getting the test event 11/05/22 13:08:46.83
STEP: patching the test event 11/05/22 13:08:46.833
STEP: getting the test event 11/05/22 13:08:46.842
STEP: updating the test event 11/05/22 13:08:46.845
STEP: getting the test event 11/05/22 13:08:46.851
STEP: deleting the test event 11/05/22 13:08:46.854
STEP: listing events in all namespaces 11/05/22 13:08:46.861
STEP: listing events in test namespace 11/05/22 13:08:46.864
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Nov  5 13:08:46.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6575" for this suite. 11/05/22 13:08:46.87
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":275,"skipped":5125,"failed":0}
------------------------------
• [0.090 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:08:46.785
    Nov  5 13:08:46.785: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename events 11/05/22 13:08:46.786
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:46.803
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:46.807
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 11/05/22 13:08:46.81
    STEP: listing events in all namespaces 11/05/22 13:08:46.817
    STEP: listing events in test namespace 11/05/22 13:08:46.821
    STEP: listing events with field selection filtering on source 11/05/22 13:08:46.824
    STEP: listing events with field selection filtering on reportingController 11/05/22 13:08:46.828
    STEP: getting the test event 11/05/22 13:08:46.83
    STEP: patching the test event 11/05/22 13:08:46.833
    STEP: getting the test event 11/05/22 13:08:46.842
    STEP: updating the test event 11/05/22 13:08:46.845
    STEP: getting the test event 11/05/22 13:08:46.851
    STEP: deleting the test event 11/05/22 13:08:46.854
    STEP: listing events in all namespaces 11/05/22 13:08:46.861
    STEP: listing events in test namespace 11/05/22 13:08:46.864
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Nov  5 13:08:46.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-6575" for this suite. 11/05/22 13:08:46.87
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:08:46.876
Nov  5 13:08:46.876: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pods 11/05/22 13:08:46.877
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:46.895
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:46.898
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Nov  5 13:08:46.909: INFO: Waiting up to 5m0s for pod "server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55" in namespace "pods-2237" to be "running and ready"
Nov  5 13:08:46.913: INFO: Pod "server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.381621ms
Nov  5 13:08:46.913: INFO: The phase of Pod server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:08:48.918: INFO: Pod "server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55": Phase="Running", Reason="", readiness=true. Elapsed: 2.008279434s
Nov  5 13:08:48.918: INFO: The phase of Pod server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55 is Running (Ready = true)
Nov  5 13:08:48.918: INFO: Pod "server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55" satisfied condition "running and ready"
Nov  5 13:08:48.941: INFO: Waiting up to 5m0s for pod "client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d" in namespace "pods-2237" to be "Succeeded or Failed"
Nov  5 13:08:48.948: INFO: Pod "client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.273986ms
Nov  5 13:08:50.953: INFO: Pod "client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011376611s
Nov  5 13:08:52.951: INFO: Pod "client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009998328s
STEP: Saw pod success 11/05/22 13:08:52.951
Nov  5 13:08:52.952: INFO: Pod "client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d" satisfied condition "Succeeded or Failed"
Nov  5 13:08:52.955: INFO: Trying to get logs from node ip-172-31-41-19 pod client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d container env3cont: <nil>
STEP: delete the pod 11/05/22 13:08:52.966
Nov  5 13:08:52.977: INFO: Waiting for pod client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d to disappear
Nov  5 13:08:52.979: INFO: Pod client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Nov  5 13:08:52.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2237" for this suite. 11/05/22 13:08:52.982
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":276,"skipped":5136,"failed":0}
------------------------------
• [SLOW TEST] [6.113 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:08:46.876
    Nov  5 13:08:46.876: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pods 11/05/22 13:08:46.877
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:46.895
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:46.898
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Nov  5 13:08:46.909: INFO: Waiting up to 5m0s for pod "server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55" in namespace "pods-2237" to be "running and ready"
    Nov  5 13:08:46.913: INFO: Pod "server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55": Phase="Pending", Reason="", readiness=false. Elapsed: 3.381621ms
    Nov  5 13:08:46.913: INFO: The phase of Pod server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:08:48.918: INFO: Pod "server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55": Phase="Running", Reason="", readiness=true. Elapsed: 2.008279434s
    Nov  5 13:08:48.918: INFO: The phase of Pod server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55 is Running (Ready = true)
    Nov  5 13:08:48.918: INFO: Pod "server-envvars-dedd0c1b-ed74-4d42-b28a-e542dbd3aa55" satisfied condition "running and ready"
    Nov  5 13:08:48.941: INFO: Waiting up to 5m0s for pod "client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d" in namespace "pods-2237" to be "Succeeded or Failed"
    Nov  5 13:08:48.948: INFO: Pod "client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.273986ms
    Nov  5 13:08:50.953: INFO: Pod "client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011376611s
    Nov  5 13:08:52.951: INFO: Pod "client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009998328s
    STEP: Saw pod success 11/05/22 13:08:52.951
    Nov  5 13:08:52.952: INFO: Pod "client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d" satisfied condition "Succeeded or Failed"
    Nov  5 13:08:52.955: INFO: Trying to get logs from node ip-172-31-41-19 pod client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d container env3cont: <nil>
    STEP: delete the pod 11/05/22 13:08:52.966
    Nov  5 13:08:52.977: INFO: Waiting for pod client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d to disappear
    Nov  5 13:08:52.979: INFO: Pod client-envvars-6cf78113-411e-45c9-9f7f-617e8fcdfa4d no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Nov  5 13:08:52.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2237" for this suite. 11/05/22 13:08:52.982
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:08:52.99
Nov  5 13:08:52.990: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:08:52.991
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:53.006
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:53.011
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 11/05/22 13:08:53.014
Nov  5 13:08:53.028: INFO: Waiting up to 5m0s for pod "downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c" in namespace "projected-9306" to be "Succeeded or Failed"
Nov  5 13:08:53.031: INFO: Pod "downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.317896ms
Nov  5 13:08:55.036: INFO: Pod "downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008024506s
Nov  5 13:08:57.036: INFO: Pod "downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008282994s
STEP: Saw pod success 11/05/22 13:08:57.036
Nov  5 13:08:57.036: INFO: Pod "downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c" satisfied condition "Succeeded or Failed"
Nov  5 13:08:57.040: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c container client-container: <nil>
STEP: delete the pod 11/05/22 13:08:57.045
Nov  5 13:08:57.058: INFO: Waiting for pod downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c to disappear
Nov  5 13:08:57.061: INFO: Pod downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 13:08:57.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9306" for this suite. 11/05/22 13:08:57.065
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":277,"skipped":5175,"failed":0}
------------------------------
• [4.080 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:08:52.99
    Nov  5 13:08:52.990: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:08:52.991
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:53.006
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:53.011
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 11/05/22 13:08:53.014
    Nov  5 13:08:53.028: INFO: Waiting up to 5m0s for pod "downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c" in namespace "projected-9306" to be "Succeeded or Failed"
    Nov  5 13:08:53.031: INFO: Pod "downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.317896ms
    Nov  5 13:08:55.036: INFO: Pod "downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008024506s
    Nov  5 13:08:57.036: INFO: Pod "downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008282994s
    STEP: Saw pod success 11/05/22 13:08:57.036
    Nov  5 13:08:57.036: INFO: Pod "downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c" satisfied condition "Succeeded or Failed"
    Nov  5 13:08:57.040: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c container client-container: <nil>
    STEP: delete the pod 11/05/22 13:08:57.045
    Nov  5 13:08:57.058: INFO: Waiting for pod downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c to disappear
    Nov  5 13:08:57.061: INFO: Pod downwardapi-volume-49dfecb6-637c-4797-ad87-05288c96e34c no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 13:08:57.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9306" for this suite. 11/05/22 13:08:57.065
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:08:57.071
Nov  5 13:08:57.072: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 13:08:57.072
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:57.092
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:57.095
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-c261d561-fa93-41b9-b3dd-2e91b37f6db4 11/05/22 13:08:57.099
STEP: Creating a pod to test consume secrets 11/05/22 13:08:57.107
Nov  5 13:08:57.114: INFO: Waiting up to 5m0s for pod "pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2" in namespace "secrets-7845" to be "Succeeded or Failed"
Nov  5 13:08:57.117: INFO: Pod "pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.193525ms
Nov  5 13:08:59.122: INFO: Pod "pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008357222s
Nov  5 13:09:01.122: INFO: Pod "pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007972069s
STEP: Saw pod success 11/05/22 13:09:01.122
Nov  5 13:09:01.122: INFO: Pod "pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2" satisfied condition "Succeeded or Failed"
Nov  5 13:09:01.125: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2 container secret-volume-test: <nil>
STEP: delete the pod 11/05/22 13:09:01.131
Nov  5 13:09:01.143: INFO: Waiting for pod pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2 to disappear
Nov  5 13:09:01.146: INFO: Pod pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov  5 13:09:01.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7845" for this suite. 11/05/22 13:09:01.15
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":278,"skipped":5189,"failed":0}
------------------------------
• [4.084 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:08:57.071
    Nov  5 13:08:57.072: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 13:08:57.072
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:08:57.092
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:08:57.095
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-c261d561-fa93-41b9-b3dd-2e91b37f6db4 11/05/22 13:08:57.099
    STEP: Creating a pod to test consume secrets 11/05/22 13:08:57.107
    Nov  5 13:08:57.114: INFO: Waiting up to 5m0s for pod "pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2" in namespace "secrets-7845" to be "Succeeded or Failed"
    Nov  5 13:08:57.117: INFO: Pod "pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.193525ms
    Nov  5 13:08:59.122: INFO: Pod "pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008357222s
    Nov  5 13:09:01.122: INFO: Pod "pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007972069s
    STEP: Saw pod success 11/05/22 13:09:01.122
    Nov  5 13:09:01.122: INFO: Pod "pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2" satisfied condition "Succeeded or Failed"
    Nov  5 13:09:01.125: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2 container secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 13:09:01.131
    Nov  5 13:09:01.143: INFO: Waiting for pod pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2 to disappear
    Nov  5 13:09:01.146: INFO: Pod pod-secrets-c912e7b9-b596-4067-b277-f7d3d45e81a2 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 13:09:01.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7845" for this suite. 11/05/22 13:09:01.15
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:09:01.158
Nov  5 13:09:01.158: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 13:09:01.159
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:09:01.174
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:09:01.177
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-f77b3af4-3614-4948-9625-1fd0bb246fc5 11/05/22 13:09:01.181
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Nov  5 13:09:01.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4648" for this suite. 11/05/22 13:09:01.186
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":279,"skipped":5233,"failed":0}
------------------------------
• [0.033 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:09:01.158
    Nov  5 13:09:01.158: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 13:09:01.159
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:09:01.174
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:09:01.177
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-f77b3af4-3614-4948-9625-1fd0bb246fc5 11/05/22 13:09:01.181
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 13:09:01.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4648" for this suite. 11/05/22 13:09:01.186
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:09:01.192
Nov  5 13:09:01.192: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 13:09:01.193
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:09:01.207
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:09:01.21
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221
STEP: creating service in namespace services-4807 11/05/22 13:09:01.214
Nov  5 13:09:01.220: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-4807" to be "running and ready"
Nov  5 13:09:01.225: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 4.703643ms
Nov  5 13:09:01.225: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:09:03.230: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.009574964s
Nov  5 13:09:03.230: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
Nov  5 13:09:03.230: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
Nov  5 13:09:03.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
Nov  5 13:09:03.390: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
Nov  5 13:09:03.390: INFO: stdout: "iptables"
Nov  5 13:09:03.390: INFO: proxyMode: iptables
Nov  5 13:09:03.403: INFO: Waiting for pod kube-proxy-mode-detector to disappear
Nov  5 13:09:03.406: INFO: Pod kube-proxy-mode-detector no longer exists
STEP: creating service affinity-nodeport-timeout in namespace services-4807 11/05/22 13:09:03.406
STEP: creating replication controller affinity-nodeport-timeout in namespace services-4807 11/05/22 13:09:03.422
I1105 13:09:03.429135      20 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-4807, replica count: 3
I1105 13:09:06.480381      20 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 13:09:06.491: INFO: Creating new exec pod
Nov  5 13:09:06.496: INFO: Waiting up to 5m0s for pod "execpod-affinityzjltb" in namespace "services-4807" to be "running"
Nov  5 13:09:06.576: INFO: Pod "execpod-affinityzjltb": Phase="Pending", Reason="", readiness=false. Elapsed: 79.713021ms
Nov  5 13:09:08.580: INFO: Pod "execpod-affinityzjltb": Phase="Running", Reason="", readiness=true. Elapsed: 2.083653199s
Nov  5 13:09:08.580: INFO: Pod "execpod-affinityzjltb" satisfied condition "running"
Nov  5 13:09:09.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
Nov  5 13:09:09.734: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
Nov  5 13:09:09.734: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:09:09.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.138 80'
Nov  5 13:09:09.849: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.138 80\nConnection to 10.152.183.138 80 port [tcp/http] succeeded!\n"
Nov  5 13:09:09.849: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:09:09.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 31539'
Nov  5 13:09:09.973: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.41.19 31539\nConnection to 172.31.41.19 31539 port [tcp/*] succeeded!\n"
Nov  5 13:09:09.973: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:09:09.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.255 31539'
Nov  5 13:09:10.100: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 172.31.0.255 31539\nConnection to 172.31.0.255 31539 port [tcp/*] succeeded!\n"
Nov  5 13:09:10.100: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:09:10.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.255:31539/ ; done'
Nov  5 13:09:10.284: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n"
Nov  5 13:09:10.284: INFO: stdout: "\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v"
Nov  5 13:09:10.284: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.284: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.284: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.284: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
Nov  5 13:09:10.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.0.255:31539/'
Nov  5 13:09:10.406: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n"
Nov  5 13:09:10.406: INFO: stdout: "affinity-nodeport-timeout-q5v6v"
Nov  5 13:09:30.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.0.255:31539/'
Nov  5 13:09:30.554: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n"
Nov  5 13:09:30.554: INFO: stdout: "affinity-nodeport-timeout-q5v6v"
Nov  5 13:09:50.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.0.255:31539/'
Nov  5 13:09:50.693: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n"
Nov  5 13:09:50.693: INFO: stdout: "affinity-nodeport-timeout-fkdg5"
Nov  5 13:09:50.693: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-4807, will wait for the garbage collector to delete the pods 11/05/22 13:09:50.707
Nov  5 13:09:50.769: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 5.379497ms
Nov  5 13:09:50.869: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.742674ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 13:09:52.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4807" for this suite. 11/05/22 13:09:52.797
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]","completed":280,"skipped":5249,"failed":0}
------------------------------
• [SLOW TEST] [51.612 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2221

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:09:01.192
    Nov  5 13:09:01.192: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 13:09:01.193
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:09:01.207
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:09:01.21
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity timeout work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2221
    STEP: creating service in namespace services-4807 11/05/22 13:09:01.214
    Nov  5 13:09:01.220: INFO: Waiting up to 5m0s for pod "kube-proxy-mode-detector" in namespace "services-4807" to be "running and ready"
    Nov  5 13:09:01.225: INFO: Pod "kube-proxy-mode-detector": Phase="Pending", Reason="", readiness=false. Elapsed: 4.703643ms
    Nov  5 13:09:01.225: INFO: The phase of Pod kube-proxy-mode-detector is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:09:03.230: INFO: Pod "kube-proxy-mode-detector": Phase="Running", Reason="", readiness=true. Elapsed: 2.009574964s
    Nov  5 13:09:03.230: INFO: The phase of Pod kube-proxy-mode-detector is Running (Ready = true)
    Nov  5 13:09:03.230: INFO: Pod "kube-proxy-mode-detector" satisfied condition "running and ready"
    Nov  5 13:09:03.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec kube-proxy-mode-detector -- /bin/sh -x -c curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode'
    Nov  5 13:09:03.390: INFO: stderr: "+ curl -q -s --connect-timeout 1 http://localhost:10249/proxyMode\n"
    Nov  5 13:09:03.390: INFO: stdout: "iptables"
    Nov  5 13:09:03.390: INFO: proxyMode: iptables
    Nov  5 13:09:03.403: INFO: Waiting for pod kube-proxy-mode-detector to disappear
    Nov  5 13:09:03.406: INFO: Pod kube-proxy-mode-detector no longer exists
    STEP: creating service affinity-nodeport-timeout in namespace services-4807 11/05/22 13:09:03.406
    STEP: creating replication controller affinity-nodeport-timeout in namespace services-4807 11/05/22 13:09:03.422
    I1105 13:09:03.429135      20 runners.go:193] Created replication controller with name: affinity-nodeport-timeout, namespace: services-4807, replica count: 3
    I1105 13:09:06.480381      20 runners.go:193] affinity-nodeport-timeout Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 13:09:06.491: INFO: Creating new exec pod
    Nov  5 13:09:06.496: INFO: Waiting up to 5m0s for pod "execpod-affinityzjltb" in namespace "services-4807" to be "running"
    Nov  5 13:09:06.576: INFO: Pod "execpod-affinityzjltb": Phase="Pending", Reason="", readiness=false. Elapsed: 79.713021ms
    Nov  5 13:09:08.580: INFO: Pod "execpod-affinityzjltb": Phase="Running", Reason="", readiness=true. Elapsed: 2.083653199s
    Nov  5 13:09:08.580: INFO: Pod "execpod-affinityzjltb" satisfied condition "running"
    Nov  5 13:09:09.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-timeout 80'
    Nov  5 13:09:09.734: INFO: stderr: "+ + ncecho -v hostName -t\n -w 2 affinity-nodeport-timeout 80\nConnection to affinity-nodeport-timeout 80 port [tcp/http] succeeded!\n"
    Nov  5 13:09:09.734: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:09:09.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.138 80'
    Nov  5 13:09:09.849: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.138 80\nConnection to 10.152.183.138 80 port [tcp/http] succeeded!\n"
    Nov  5 13:09:09.849: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:09:09.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 31539'
    Nov  5 13:09:09.973: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.41.19 31539\nConnection to 172.31.41.19 31539 port [tcp/*] succeeded!\n"
    Nov  5 13:09:09.973: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:09:09.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.255 31539'
    Nov  5 13:09:10.100: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 172.31.0.255 31539\nConnection to 172.31.0.255 31539 port [tcp/*] succeeded!\n"
    Nov  5 13:09:10.100: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:09:10.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.255:31539/ ; done'
    Nov  5 13:09:10.284: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n"
    Nov  5 13:09:10.284: INFO: stdout: "\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v\naffinity-nodeport-timeout-q5v6v"
    Nov  5 13:09:10.284: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.284: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.284: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.284: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Received response from host: affinity-nodeport-timeout-q5v6v
    Nov  5 13:09:10.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.0.255:31539/'
    Nov  5 13:09:10.406: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n"
    Nov  5 13:09:10.406: INFO: stdout: "affinity-nodeport-timeout-q5v6v"
    Nov  5 13:09:30.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.0.255:31539/'
    Nov  5 13:09:30.554: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n"
    Nov  5 13:09:30.554: INFO: stdout: "affinity-nodeport-timeout-q5v6v"
    Nov  5 13:09:50.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4807 exec execpod-affinityzjltb -- /bin/sh -x -c curl -q -s --connect-timeout 2 http://172.31.0.255:31539/'
    Nov  5 13:09:50.693: INFO: stderr: "+ curl -q -s --connect-timeout 2 http://172.31.0.255:31539/\n"
    Nov  5 13:09:50.693: INFO: stdout: "affinity-nodeport-timeout-fkdg5"
    Nov  5 13:09:50.693: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-timeout in namespace services-4807, will wait for the garbage collector to delete the pods 11/05/22 13:09:50.707
    Nov  5 13:09:50.769: INFO: Deleting ReplicationController affinity-nodeport-timeout took: 5.379497ms
    Nov  5 13:09:50.869: INFO: Terminating ReplicationController affinity-nodeport-timeout pods took: 100.742674ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 13:09:52.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4807" for this suite. 11/05/22 13:09:52.797
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:09:52.804
Nov  5 13:09:52.804: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:09:52.805
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:09:52.823
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:09:52.826
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Nov  5 13:09:52.830: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/05/22 13:09:54.98
Nov  5 13:09:54.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1140 --namespace=crd-publish-openapi-1140 create -f -'
Nov  5 13:09:55.482: INFO: stderr: ""
Nov  5 13:09:55.482: INFO: stdout: "e2e-test-crd-publish-openapi-7179-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  5 13:09:55.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1140 --namespace=crd-publish-openapi-1140 delete e2e-test-crd-publish-openapi-7179-crds test-cr'
Nov  5 13:09:55.547: INFO: stderr: ""
Nov  5 13:09:55.547: INFO: stdout: "e2e-test-crd-publish-openapi-7179-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov  5 13:09:55.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1140 --namespace=crd-publish-openapi-1140 apply -f -'
Nov  5 13:09:55.823: INFO: stderr: ""
Nov  5 13:09:55.823: INFO: stdout: "e2e-test-crd-publish-openapi-7179-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  5 13:09:55.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1140 --namespace=crd-publish-openapi-1140 delete e2e-test-crd-publish-openapi-7179-crds test-cr'
Nov  5 13:09:55.889: INFO: stderr: ""
Nov  5 13:09:55.889: INFO: stdout: "e2e-test-crd-publish-openapi-7179-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 11/05/22 13:09:55.889
Nov  5 13:09:55.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1140 explain e2e-test-crd-publish-openapi-7179-crds'
Nov  5 13:09:56.367: INFO: stderr: ""
Nov  5 13:09:56.367: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7179-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:09:58.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1140" for this suite. 11/05/22 13:09:58.433
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":281,"skipped":5267,"failed":0}
------------------------------
• [SLOW TEST] [5.635 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:09:52.804
    Nov  5 13:09:52.804: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:09:52.805
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:09:52.823
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:09:52.826
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Nov  5 13:09:52.830: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/05/22 13:09:54.98
    Nov  5 13:09:54.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1140 --namespace=crd-publish-openapi-1140 create -f -'
    Nov  5 13:09:55.482: INFO: stderr: ""
    Nov  5 13:09:55.482: INFO: stdout: "e2e-test-crd-publish-openapi-7179-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Nov  5 13:09:55.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1140 --namespace=crd-publish-openapi-1140 delete e2e-test-crd-publish-openapi-7179-crds test-cr'
    Nov  5 13:09:55.547: INFO: stderr: ""
    Nov  5 13:09:55.547: INFO: stdout: "e2e-test-crd-publish-openapi-7179-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Nov  5 13:09:55.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1140 --namespace=crd-publish-openapi-1140 apply -f -'
    Nov  5 13:09:55.823: INFO: stderr: ""
    Nov  5 13:09:55.823: INFO: stdout: "e2e-test-crd-publish-openapi-7179-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Nov  5 13:09:55.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1140 --namespace=crd-publish-openapi-1140 delete e2e-test-crd-publish-openapi-7179-crds test-cr'
    Nov  5 13:09:55.889: INFO: stderr: ""
    Nov  5 13:09:55.889: INFO: stdout: "e2e-test-crd-publish-openapi-7179-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 11/05/22 13:09:55.889
    Nov  5 13:09:55.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-1140 explain e2e-test-crd-publish-openapi-7179-crds'
    Nov  5 13:09:56.367: INFO: stderr: ""
    Nov  5 13:09:56.367: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-7179-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:09:58.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-1140" for this suite. 11/05/22 13:09:58.433
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:09:58.44
Nov  5 13:09:58.440: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename gc 11/05/22 13:09:58.441
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:09:58.457
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:09:58.461
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Nov  5 13:09:58.500: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"fc14d652-e0dc-4bfb-90a3-20e401f54f06", Controller:(*bool)(0xc00444584e), BlockOwnerDeletion:(*bool)(0xc00444584f)}}
Nov  5 13:09:58.508: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"31cbf59e-028e-4651-bea5-27a5de92db78", Controller:(*bool)(0xc0043878c6), BlockOwnerDeletion:(*bool)(0xc0043878c7)}}
Nov  5 13:09:58.516: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"265e0d1f-075c-426b-8509-6e8b2a73da40", Controller:(*bool)(0xc004387bee), BlockOwnerDeletion:(*bool)(0xc004387bef)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Nov  5 13:10:03.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6322" for this suite. 11/05/22 13:10:03.53
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":282,"skipped":5271,"failed":0}
------------------------------
• [SLOW TEST] [5.097 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:09:58.44
    Nov  5 13:09:58.440: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename gc 11/05/22 13:09:58.441
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:09:58.457
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:09:58.461
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Nov  5 13:09:58.500: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"fc14d652-e0dc-4bfb-90a3-20e401f54f06", Controller:(*bool)(0xc00444584e), BlockOwnerDeletion:(*bool)(0xc00444584f)}}
    Nov  5 13:09:58.508: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"31cbf59e-028e-4651-bea5-27a5de92db78", Controller:(*bool)(0xc0043878c6), BlockOwnerDeletion:(*bool)(0xc0043878c7)}}
    Nov  5 13:09:58.516: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"265e0d1f-075c-426b-8509-6e8b2a73da40", Controller:(*bool)(0xc004387bee), BlockOwnerDeletion:(*bool)(0xc004387bef)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Nov  5 13:10:03.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-6322" for this suite. 11/05/22 13:10:03.53
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:10:03.538
Nov  5 13:10:03.538: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:10:03.538
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:10:03.558
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:10:03.561
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Nov  5 13:10:03.564: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/05/22 13:10:05.813
Nov  5 13:10:05.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-6834 --namespace=crd-publish-openapi-6834 create -f -'
Nov  5 13:10:06.433: INFO: stderr: ""
Nov  5 13:10:06.433: INFO: stdout: "e2e-test-crd-publish-openapi-9684-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  5 13:10:06.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-6834 --namespace=crd-publish-openapi-6834 delete e2e-test-crd-publish-openapi-9684-crds test-cr'
Nov  5 13:10:06.523: INFO: stderr: ""
Nov  5 13:10:06.523: INFO: stdout: "e2e-test-crd-publish-openapi-9684-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov  5 13:10:06.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-6834 --namespace=crd-publish-openapi-6834 apply -f -'
Nov  5 13:10:06.956: INFO: stderr: ""
Nov  5 13:10:06.956: INFO: stdout: "e2e-test-crd-publish-openapi-9684-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  5 13:10:06.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-6834 --namespace=crd-publish-openapi-6834 delete e2e-test-crd-publish-openapi-9684-crds test-cr'
Nov  5 13:10:07.020: INFO: stderr: ""
Nov  5 13:10:07.020: INFO: stdout: "e2e-test-crd-publish-openapi-9684-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 11/05/22 13:10:07.02
Nov  5 13:10:07.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-6834 explain e2e-test-crd-publish-openapi-9684-crds'
Nov  5 13:10:07.204: INFO: stderr: ""
Nov  5 13:10:07.204: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9684-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:10:09.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6834" for this suite. 11/05/22 13:10:09.362
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":283,"skipped":5299,"failed":0}
------------------------------
• [SLOW TEST] [5.832 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:10:03.538
    Nov  5 13:10:03.538: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:10:03.538
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:10:03.558
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:10:03.561
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Nov  5 13:10:03.564: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 11/05/22 13:10:05.813
    Nov  5 13:10:05.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-6834 --namespace=crd-publish-openapi-6834 create -f -'
    Nov  5 13:10:06.433: INFO: stderr: ""
    Nov  5 13:10:06.433: INFO: stdout: "e2e-test-crd-publish-openapi-9684-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Nov  5 13:10:06.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-6834 --namespace=crd-publish-openapi-6834 delete e2e-test-crd-publish-openapi-9684-crds test-cr'
    Nov  5 13:10:06.523: INFO: stderr: ""
    Nov  5 13:10:06.523: INFO: stdout: "e2e-test-crd-publish-openapi-9684-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Nov  5 13:10:06.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-6834 --namespace=crd-publish-openapi-6834 apply -f -'
    Nov  5 13:10:06.956: INFO: stderr: ""
    Nov  5 13:10:06.956: INFO: stdout: "e2e-test-crd-publish-openapi-9684-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Nov  5 13:10:06.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-6834 --namespace=crd-publish-openapi-6834 delete e2e-test-crd-publish-openapi-9684-crds test-cr'
    Nov  5 13:10:07.020: INFO: stderr: ""
    Nov  5 13:10:07.020: INFO: stdout: "e2e-test-crd-publish-openapi-9684-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 11/05/22 13:10:07.02
    Nov  5 13:10:07.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=crd-publish-openapi-6834 explain e2e-test-crd-publish-openapi-9684-crds'
    Nov  5 13:10:07.204: INFO: stderr: ""
    Nov  5 13:10:07.204: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-9684-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:10:09.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6834" for this suite. 11/05/22 13:10:09.362
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:10:09.37
Nov  5 13:10:09.370: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 13:10:09.371
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:10:09.384
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:10:09.387
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-8e5d5589-0d5b-4cad-837c-ea8918147a3d 11/05/22 13:10:09.395
STEP: Creating configMap with name cm-test-opt-upd-3f8b3d89-1407-472e-9fbe-4023b8dfb761 11/05/22 13:10:09.399
STEP: Creating the pod 11/05/22 13:10:09.404
Nov  5 13:10:09.413: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9" in namespace "configmap-5146" to be "running and ready"
Nov  5 13:10:09.416: INFO: Pod "pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.535205ms
Nov  5 13:10:09.416: INFO: The phase of Pod pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:10:11.422: INFO: Pod "pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.008911663s
Nov  5 13:10:11.422: INFO: The phase of Pod pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9 is Running (Ready = true)
Nov  5 13:10:11.422: INFO: Pod "pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-8e5d5589-0d5b-4cad-837c-ea8918147a3d 11/05/22 13:10:11.45
STEP: Updating configmap cm-test-opt-upd-3f8b3d89-1407-472e-9fbe-4023b8dfb761 11/05/22 13:10:11.457
STEP: Creating configMap with name cm-test-opt-create-d4b2c73d-5c60-4386-9c52-46336d18b3c3 11/05/22 13:10:11.464
STEP: waiting to observe update in volume 11/05/22 13:10:11.469
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 13:10:15.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5146" for this suite. 11/05/22 13:10:15.506
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":284,"skipped":5302,"failed":0}
------------------------------
• [SLOW TEST] [6.143 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:10:09.37
    Nov  5 13:10:09.370: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 13:10:09.371
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:10:09.384
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:10:09.387
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-8e5d5589-0d5b-4cad-837c-ea8918147a3d 11/05/22 13:10:09.395
    STEP: Creating configMap with name cm-test-opt-upd-3f8b3d89-1407-472e-9fbe-4023b8dfb761 11/05/22 13:10:09.399
    STEP: Creating the pod 11/05/22 13:10:09.404
    Nov  5 13:10:09.413: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9" in namespace "configmap-5146" to be "running and ready"
    Nov  5 13:10:09.416: INFO: Pod "pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.535205ms
    Nov  5 13:10:09.416: INFO: The phase of Pod pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:10:11.422: INFO: Pod "pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9": Phase="Running", Reason="", readiness=true. Elapsed: 2.008911663s
    Nov  5 13:10:11.422: INFO: The phase of Pod pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9 is Running (Ready = true)
    Nov  5 13:10:11.422: INFO: Pod "pod-configmaps-c1ea0a96-3521-4720-afb2-6ea702f544b9" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-8e5d5589-0d5b-4cad-837c-ea8918147a3d 11/05/22 13:10:11.45
    STEP: Updating configmap cm-test-opt-upd-3f8b3d89-1407-472e-9fbe-4023b8dfb761 11/05/22 13:10:11.457
    STEP: Creating configMap with name cm-test-opt-create-d4b2c73d-5c60-4386-9c52-46336d18b3c3 11/05/22 13:10:11.464
    STEP: waiting to observe update in volume 11/05/22 13:10:11.469
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 13:10:15.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5146" for this suite. 11/05/22 13:10:15.506
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:10:15.513
Nov  5 13:10:15.513: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 13:10:15.514
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:10:15.528
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:10:15.534
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 11/05/22 13:10:15.538
Nov  5 13:10:15.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-4132 cluster-info'
Nov  5 13:10:15.599: INFO: stderr: ""
Nov  5 13:10:15.599: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 13:10:15.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4132" for this suite. 11/05/22 13:10:15.604
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":285,"skipped":5302,"failed":0}
------------------------------
• [0.098 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:10:15.513
    Nov  5 13:10:15.513: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 13:10:15.514
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:10:15.528
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:10:15.534
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 11/05/22 13:10:15.538
    Nov  5 13:10:15.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-4132 cluster-info'
    Nov  5 13:10:15.599: INFO: stderr: ""
    Nov  5 13:10:15.599: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://10.152.183.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 13:10:15.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4132" for this suite. 11/05/22 13:10:15.604
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:10:15.611
Nov  5 13:10:15.611: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pod-network-test 11/05/22 13:10:15.612
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:10:15.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:10:15.632
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-3007 11/05/22 13:10:15.636
STEP: creating a selector 11/05/22 13:10:15.636
STEP: Creating the service pods in kubernetes 11/05/22 13:10:15.636
Nov  5 13:10:15.636: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov  5 13:10:15.668: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3007" to be "running and ready"
Nov  5 13:10:15.675: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.893515ms
Nov  5 13:10:15.675: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:10:17.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.011429337s
Nov  5 13:10:17.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:10:19.681: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.012304747s
Nov  5 13:10:19.681: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:10:21.679: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.010914211s
Nov  5 13:10:21.679: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:10:23.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.011464747s
Nov  5 13:10:23.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:10:25.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.0117998s
Nov  5 13:10:25.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:10:27.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.011555827s
Nov  5 13:10:27.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:10:29.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.011246548s
Nov  5 13:10:29.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:10:31.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.011449075s
Nov  5 13:10:31.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:10:33.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.011597174s
Nov  5 13:10:33.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:10:35.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.011372202s
Nov  5 13:10:35.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:10:37.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.011425729s
Nov  5 13:10:37.680: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov  5 13:10:37.680: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov  5 13:10:37.683: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3007" to be "running and ready"
Nov  5 13:10:37.687: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.313168ms
Nov  5 13:10:37.687: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov  5 13:10:37.687: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov  5 13:10:37.690: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3007" to be "running and ready"
Nov  5 13:10:37.693: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.06825ms
Nov  5 13:10:37.693: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov  5 13:10:37.693: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/05/22 13:10:37.696
Nov  5 13:10:37.711: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3007" to be "running"
Nov  5 13:10:37.715: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.532641ms
Nov  5 13:10:39.719: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008042862s
Nov  5 13:10:39.719: INFO: Pod "test-container-pod" satisfied condition "running"
Nov  5 13:10:39.729: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-3007" to be "running"
Nov  5 13:10:39.733: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.315266ms
Nov  5 13:10:39.733: INFO: Pod "host-test-container-pod" satisfied condition "running"
Nov  5 13:10:39.736: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov  5 13:10:39.736: INFO: Going to poll 192.168.206.139 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov  5 13:10:39.741: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.206.139 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3007 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:10:39.741: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:10:39.741: INFO: ExecWithOptions: Clientset creation
Nov  5 13:10:39.741: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3007/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.206.139+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov  5 13:10:40.835: INFO: Found all 1 expected endpoints: [netserver-0]
Nov  5 13:10:40.835: INFO: Going to poll 192.168.242.43 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov  5 13:10:40.839: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.242.43 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3007 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:10:40.839: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:10:40.840: INFO: ExecWithOptions: Clientset creation
Nov  5 13:10:40.840: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3007/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.242.43+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov  5 13:10:41.922: INFO: Found all 1 expected endpoints: [netserver-1]
Nov  5 13:10:41.922: INFO: Going to poll 192.168.90.89 on port 8081 at least 0 times, with a maximum of 39 tries before failing
Nov  5 13:10:41.925: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.90.89 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3007 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:10:41.925: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:10:41.926: INFO: ExecWithOptions: Clientset creation
Nov  5 13:10:41.926: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3007/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.90.89+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov  5 13:10:43.011: INFO: Found all 1 expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov  5 13:10:43.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3007" for this suite. 11/05/22 13:10:43.016
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":286,"skipped":5303,"failed":0}
------------------------------
• [SLOW TEST] [27.412 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:10:15.611
    Nov  5 13:10:15.611: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pod-network-test 11/05/22 13:10:15.612
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:10:15.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:10:15.632
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-3007 11/05/22 13:10:15.636
    STEP: creating a selector 11/05/22 13:10:15.636
    STEP: Creating the service pods in kubernetes 11/05/22 13:10:15.636
    Nov  5 13:10:15.636: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov  5 13:10:15.668: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3007" to be "running and ready"
    Nov  5 13:10:15.675: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.893515ms
    Nov  5 13:10:15.675: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:10:17.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.011429337s
    Nov  5 13:10:17.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:10:19.681: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.012304747s
    Nov  5 13:10:19.681: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:10:21.679: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.010914211s
    Nov  5 13:10:21.679: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:10:23.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.011464747s
    Nov  5 13:10:23.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:10:25.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.0117998s
    Nov  5 13:10:25.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:10:27.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.011555827s
    Nov  5 13:10:27.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:10:29.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.011246548s
    Nov  5 13:10:29.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:10:31.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.011449075s
    Nov  5 13:10:31.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:10:33.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.011597174s
    Nov  5 13:10:33.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:10:35.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.011372202s
    Nov  5 13:10:35.680: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:10:37.680: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.011425729s
    Nov  5 13:10:37.680: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov  5 13:10:37.680: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov  5 13:10:37.683: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3007" to be "running and ready"
    Nov  5 13:10:37.687: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.313168ms
    Nov  5 13:10:37.687: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov  5 13:10:37.687: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov  5 13:10:37.690: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3007" to be "running and ready"
    Nov  5 13:10:37.693: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.06825ms
    Nov  5 13:10:37.693: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov  5 13:10:37.693: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/05/22 13:10:37.696
    Nov  5 13:10:37.711: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3007" to be "running"
    Nov  5 13:10:37.715: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.532641ms
    Nov  5 13:10:39.719: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008042862s
    Nov  5 13:10:39.719: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov  5 13:10:39.729: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-3007" to be "running"
    Nov  5 13:10:39.733: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.315266ms
    Nov  5 13:10:39.733: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Nov  5 13:10:39.736: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov  5 13:10:39.736: INFO: Going to poll 192.168.206.139 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov  5 13:10:39.741: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.206.139 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3007 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:10:39.741: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:10:39.741: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:10:39.741: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3007/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.206.139+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov  5 13:10:40.835: INFO: Found all 1 expected endpoints: [netserver-0]
    Nov  5 13:10:40.835: INFO: Going to poll 192.168.242.43 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov  5 13:10:40.839: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.242.43 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3007 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:10:40.839: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:10:40.840: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:10:40.840: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3007/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.242.43+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov  5 13:10:41.922: INFO: Found all 1 expected endpoints: [netserver-1]
    Nov  5 13:10:41.922: INFO: Going to poll 192.168.90.89 on port 8081 at least 0 times, with a maximum of 39 tries before failing
    Nov  5 13:10:41.925: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.90.89 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3007 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:10:41.925: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:10:41.926: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:10:41.926: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-3007/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+192.168.90.89+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov  5 13:10:43.011: INFO: Found all 1 expected endpoints: [netserver-2]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov  5 13:10:43.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3007" for this suite. 11/05/22 13:10:43.016
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:10:43.028
Nov  5 13:10:43.028: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename watch 11/05/22 13:10:43.029
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:10:43.041
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:10:43.046
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 11/05/22 13:10:43.049
STEP: creating a watch on configmaps with label B 11/05/22 13:10:43.051
STEP: creating a watch on configmaps with label A or B 11/05/22 13:10:43.053
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 11/05/22 13:10:43.054
Nov  5 13:10:43.059: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34356 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 13:10:43.059: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34356 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 11/05/22 13:10:43.059
Nov  5 13:10:43.067: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34357 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 13:10:43.068: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34357 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 11/05/22 13:10:43.068
Nov  5 13:10:43.075: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34358 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 13:10:43.075: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34358 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 11/05/22 13:10:43.075
Nov  5 13:10:43.081: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34359 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 13:10:43.081: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34359 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 11/05/22 13:10:43.081
Nov  5 13:10:43.086: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8276  4610dfe2-6ee6-4a0d-b6a1-dbfa0a512a6a 34360 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 13:10:43.086: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8276  4610dfe2-6ee6-4a0d-b6a1-dbfa0a512a6a 34360 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 11/05/22 13:10:53.088
Nov  5 13:10:53.095: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8276  4610dfe2-6ee6-4a0d-b6a1-dbfa0a512a6a 34433 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Nov  5 13:10:53.095: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8276  4610dfe2-6ee6-4a0d-b6a1-dbfa0a512a6a 34433 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Nov  5 13:11:03.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8276" for this suite. 11/05/22 13:11:03.1
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":287,"skipped":5338,"failed":0}
------------------------------
• [SLOW TEST] [20.079 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:10:43.028
    Nov  5 13:10:43.028: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename watch 11/05/22 13:10:43.029
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:10:43.041
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:10:43.046
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 11/05/22 13:10:43.049
    STEP: creating a watch on configmaps with label B 11/05/22 13:10:43.051
    STEP: creating a watch on configmaps with label A or B 11/05/22 13:10:43.053
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 11/05/22 13:10:43.054
    Nov  5 13:10:43.059: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34356 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 13:10:43.059: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34356 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 11/05/22 13:10:43.059
    Nov  5 13:10:43.067: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34357 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 13:10:43.068: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34357 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 11/05/22 13:10:43.068
    Nov  5 13:10:43.075: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34358 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 13:10:43.075: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34358 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 11/05/22 13:10:43.075
    Nov  5 13:10:43.081: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34359 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 13:10:43.081: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8276  f25df627-9d28-4d10-be1b-0852fceebcd4 34359 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 11/05/22 13:10:43.081
    Nov  5 13:10:43.086: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8276  4610dfe2-6ee6-4a0d-b6a1-dbfa0a512a6a 34360 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 13:10:43.086: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8276  4610dfe2-6ee6-4a0d-b6a1-dbfa0a512a6a 34360 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 11/05/22 13:10:53.088
    Nov  5 13:10:53.095: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8276  4610dfe2-6ee6-4a0d-b6a1-dbfa0a512a6a 34433 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Nov  5 13:10:53.095: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8276  4610dfe2-6ee6-4a0d-b6a1-dbfa0a512a6a 34433 0 2022-11-05 13:10:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2022-11-05 13:10:43 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Nov  5 13:11:03.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8276" for this suite. 11/05/22 13:11:03.1
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:11:03.11
Nov  5 13:11:03.110: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:11:03.111
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:11:03.13
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:11:03.134
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 11/05/22 13:11:03.139
Nov  5 13:11:03.148: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b" in namespace "projected-5774" to be "Succeeded or Failed"
Nov  5 13:11:03.154: INFO: Pod "downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.098415ms
Nov  5 13:11:05.158: INFO: Pod "downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009819166s
Nov  5 13:11:07.158: INFO: Pod "downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009648811s
STEP: Saw pod success 11/05/22 13:11:07.158
Nov  5 13:11:07.158: INFO: Pod "downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b" satisfied condition "Succeeded or Failed"
Nov  5 13:11:07.162: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b container client-container: <nil>
STEP: delete the pod 11/05/22 13:11:07.169
Nov  5 13:11:07.180: INFO: Waiting for pod downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b to disappear
Nov  5 13:11:07.183: INFO: Pod downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 13:11:07.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5774" for this suite. 11/05/22 13:11:07.187
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":288,"skipped":5368,"failed":0}
------------------------------
• [4.083 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:11:03.11
    Nov  5 13:11:03.110: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:11:03.111
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:11:03.13
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:11:03.134
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 11/05/22 13:11:03.139
    Nov  5 13:11:03.148: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b" in namespace "projected-5774" to be "Succeeded or Failed"
    Nov  5 13:11:03.154: INFO: Pod "downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.098415ms
    Nov  5 13:11:05.158: INFO: Pod "downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009819166s
    Nov  5 13:11:07.158: INFO: Pod "downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009648811s
    STEP: Saw pod success 11/05/22 13:11:07.158
    Nov  5 13:11:07.158: INFO: Pod "downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b" satisfied condition "Succeeded or Failed"
    Nov  5 13:11:07.162: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b container client-container: <nil>
    STEP: delete the pod 11/05/22 13:11:07.169
    Nov  5 13:11:07.180: INFO: Waiting for pod downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b to disappear
    Nov  5 13:11:07.183: INFO: Pod downwardapi-volume-b0036799-eb29-4150-9308-5e6cddd7572b no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 13:11:07.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5774" for this suite. 11/05/22 13:11:07.187
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:11:07.195
Nov  5 13:11:07.195: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 13:11:07.196
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:11:07.208
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:11:07.212
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415
STEP: creating a Service 11/05/22 13:11:07.219
STEP: watching for the Service to be added 11/05/22 13:11:07.232
Nov  5 13:11:07.234: INFO: Found Service test-service-fkkdw in namespace services-9252 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Nov  5 13:11:07.235: INFO: Service test-service-fkkdw created
STEP: Getting /status 11/05/22 13:11:07.235
Nov  5 13:11:07.239: INFO: Service test-service-fkkdw has LoadBalancer: {[]}
STEP: patching the ServiceStatus 11/05/22 13:11:07.239
STEP: watching for the Service to be patched 11/05/22 13:11:07.248
Nov  5 13:11:07.250: INFO: observed Service test-service-fkkdw in namespace services-9252 with annotations: map[] & LoadBalancer: {[]}
Nov  5 13:11:07.250: INFO: Found Service test-service-fkkdw in namespace services-9252 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Nov  5 13:11:07.250: INFO: Service test-service-fkkdw has service status patched
STEP: updating the ServiceStatus 11/05/22 13:11:07.25
Nov  5 13:11:07.260: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 11/05/22 13:11:07.261
Nov  5 13:11:07.263: INFO: Observed Service test-service-fkkdw in namespace services-9252 with annotations: map[] & Conditions: {[]}
Nov  5 13:11:07.263: INFO: Observed event: &Service{ObjectMeta:{test-service-fkkdw  services-9252  04119692-05fe-430f-a6cf-cce482f626c8 34495 0 2022-11-05 13:11:07 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-11-05 13:11:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-11-05 13:11:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.56,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.56],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Nov  5 13:11:07.263: INFO: Found Service test-service-fkkdw in namespace services-9252 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Nov  5 13:11:07.263: INFO: Service test-service-fkkdw has service status updated
STEP: patching the service 11/05/22 13:11:07.263
STEP: watching for the Service to be patched 11/05/22 13:11:07.278
Nov  5 13:11:07.281: INFO: observed Service test-service-fkkdw in namespace services-9252 with labels: map[test-service-static:true]
Nov  5 13:11:07.281: INFO: observed Service test-service-fkkdw in namespace services-9252 with labels: map[test-service-static:true]
Nov  5 13:11:07.281: INFO: observed Service test-service-fkkdw in namespace services-9252 with labels: map[test-service-static:true]
Nov  5 13:11:07.281: INFO: Found Service test-service-fkkdw in namespace services-9252 with labels: map[test-service:patched test-service-static:true]
Nov  5 13:11:07.281: INFO: Service test-service-fkkdw patched
STEP: deleting the service 11/05/22 13:11:07.281
STEP: watching for the Service to be deleted 11/05/22 13:11:07.295
Nov  5 13:11:07.297: INFO: Observed event: ADDED
Nov  5 13:11:07.297: INFO: Observed event: MODIFIED
Nov  5 13:11:07.297: INFO: Observed event: MODIFIED
Nov  5 13:11:07.297: INFO: Observed event: MODIFIED
Nov  5 13:11:07.297: INFO: Found Service test-service-fkkdw in namespace services-9252 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Nov  5 13:11:07.297: INFO: Service test-service-fkkdw deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 13:11:07.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9252" for this suite. 11/05/22 13:11:07.302
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":289,"skipped":5377,"failed":0}
------------------------------
• [0.115 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3415

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:11:07.195
    Nov  5 13:11:07.195: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 13:11:07.196
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:11:07.208
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:11:07.212
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3415
    STEP: creating a Service 11/05/22 13:11:07.219
    STEP: watching for the Service to be added 11/05/22 13:11:07.232
    Nov  5 13:11:07.234: INFO: Found Service test-service-fkkdw in namespace services-9252 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Nov  5 13:11:07.235: INFO: Service test-service-fkkdw created
    STEP: Getting /status 11/05/22 13:11:07.235
    Nov  5 13:11:07.239: INFO: Service test-service-fkkdw has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 11/05/22 13:11:07.239
    STEP: watching for the Service to be patched 11/05/22 13:11:07.248
    Nov  5 13:11:07.250: INFO: observed Service test-service-fkkdw in namespace services-9252 with annotations: map[] & LoadBalancer: {[]}
    Nov  5 13:11:07.250: INFO: Found Service test-service-fkkdw in namespace services-9252 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Nov  5 13:11:07.250: INFO: Service test-service-fkkdw has service status patched
    STEP: updating the ServiceStatus 11/05/22 13:11:07.25
    Nov  5 13:11:07.260: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 11/05/22 13:11:07.261
    Nov  5 13:11:07.263: INFO: Observed Service test-service-fkkdw in namespace services-9252 with annotations: map[] & Conditions: {[]}
    Nov  5 13:11:07.263: INFO: Observed event: &Service{ObjectMeta:{test-service-fkkdw  services-9252  04119692-05fe-430f-a6cf-cce482f626c8 34495 0 2022-11-05 13:11:07 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2022-11-05 13:11:07 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2022-11-05 13:11:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:10.152.183.56,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[10.152.183.56],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Nov  5 13:11:07.263: INFO: Found Service test-service-fkkdw in namespace services-9252 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Nov  5 13:11:07.263: INFO: Service test-service-fkkdw has service status updated
    STEP: patching the service 11/05/22 13:11:07.263
    STEP: watching for the Service to be patched 11/05/22 13:11:07.278
    Nov  5 13:11:07.281: INFO: observed Service test-service-fkkdw in namespace services-9252 with labels: map[test-service-static:true]
    Nov  5 13:11:07.281: INFO: observed Service test-service-fkkdw in namespace services-9252 with labels: map[test-service-static:true]
    Nov  5 13:11:07.281: INFO: observed Service test-service-fkkdw in namespace services-9252 with labels: map[test-service-static:true]
    Nov  5 13:11:07.281: INFO: Found Service test-service-fkkdw in namespace services-9252 with labels: map[test-service:patched test-service-static:true]
    Nov  5 13:11:07.281: INFO: Service test-service-fkkdw patched
    STEP: deleting the service 11/05/22 13:11:07.281
    STEP: watching for the Service to be deleted 11/05/22 13:11:07.295
    Nov  5 13:11:07.297: INFO: Observed event: ADDED
    Nov  5 13:11:07.297: INFO: Observed event: MODIFIED
    Nov  5 13:11:07.297: INFO: Observed event: MODIFIED
    Nov  5 13:11:07.297: INFO: Observed event: MODIFIED
    Nov  5 13:11:07.297: INFO: Found Service test-service-fkkdw in namespace services-9252 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Nov  5 13:11:07.297: INFO: Service test-service-fkkdw deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 13:11:07.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9252" for this suite. 11/05/22 13:11:07.302
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:11:07.31
Nov  5 13:11:07.311: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename cronjob 11/05/22 13:11:07.311
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:11:07.327
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:11:07.331
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 11/05/22 13:11:07.335
STEP: Ensuring more than one job is running at a time 11/05/22 13:11:07.34
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 11/05/22 13:13:01.345
STEP: Removing cronjob 11/05/22 13:13:01.348
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov  5 13:13:01.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-2608" for this suite. 11/05/22 13:13:01.367
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":290,"skipped":5379,"failed":0}
------------------------------
• [SLOW TEST] [114.065 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:11:07.31
    Nov  5 13:11:07.311: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename cronjob 11/05/22 13:11:07.311
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:11:07.327
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:11:07.331
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 11/05/22 13:11:07.335
    STEP: Ensuring more than one job is running at a time 11/05/22 13:11:07.34
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 11/05/22 13:13:01.345
    STEP: Removing cronjob 11/05/22 13:13:01.348
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov  5 13:13:01.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-2608" for this suite. 11/05/22 13:13:01.367
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:01.376
Nov  5 13:13:01.376: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 13:13:01.377
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:01.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:01.4
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 13:13:01.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5611" for this suite. 11/05/22 13:13:01.451
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":291,"skipped":5387,"failed":0}
------------------------------
• [0.081 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:01.376
    Nov  5 13:13:01.376: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 13:13:01.377
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:01.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:01.4
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 13:13:01.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5611" for this suite. 11/05/22 13:13:01.451
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:01.458
Nov  5 13:13:01.458: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 13:13:01.458
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:01.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:01.473
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 11/05/22 13:13:01.477
Nov  5 13:13:01.486: INFO: Waiting up to 5m0s for pod "pod-8159a84c-f749-4393-955e-a8ac089276cb" in namespace "emptydir-8638" to be "Succeeded or Failed"
Nov  5 13:13:01.493: INFO: Pod "pod-8159a84c-f749-4393-955e-a8ac089276cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.801485ms
Nov  5 13:13:03.498: INFO: Pod "pod-8159a84c-f749-4393-955e-a8ac089276cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011529493s
Nov  5 13:13:05.499: INFO: Pod "pod-8159a84c-f749-4393-955e-a8ac089276cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012606513s
STEP: Saw pod success 11/05/22 13:13:05.499
Nov  5 13:13:05.499: INFO: Pod "pod-8159a84c-f749-4393-955e-a8ac089276cb" satisfied condition "Succeeded or Failed"
Nov  5 13:13:05.502: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-8159a84c-f749-4393-955e-a8ac089276cb container test-container: <nil>
STEP: delete the pod 11/05/22 13:13:05.516
Nov  5 13:13:05.527: INFO: Waiting for pod pod-8159a84c-f749-4393-955e-a8ac089276cb to disappear
Nov  5 13:13:05.530: INFO: Pod pod-8159a84c-f749-4393-955e-a8ac089276cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 13:13:05.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8638" for this suite. 11/05/22 13:13:05.534
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":292,"skipped":5389,"failed":0}
------------------------------
• [4.082 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:01.458
    Nov  5 13:13:01.458: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 13:13:01.458
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:01.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:01.473
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 11/05/22 13:13:01.477
    Nov  5 13:13:01.486: INFO: Waiting up to 5m0s for pod "pod-8159a84c-f749-4393-955e-a8ac089276cb" in namespace "emptydir-8638" to be "Succeeded or Failed"
    Nov  5 13:13:01.493: INFO: Pod "pod-8159a84c-f749-4393-955e-a8ac089276cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.801485ms
    Nov  5 13:13:03.498: INFO: Pod "pod-8159a84c-f749-4393-955e-a8ac089276cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011529493s
    Nov  5 13:13:05.499: INFO: Pod "pod-8159a84c-f749-4393-955e-a8ac089276cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012606513s
    STEP: Saw pod success 11/05/22 13:13:05.499
    Nov  5 13:13:05.499: INFO: Pod "pod-8159a84c-f749-4393-955e-a8ac089276cb" satisfied condition "Succeeded or Failed"
    Nov  5 13:13:05.502: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-8159a84c-f749-4393-955e-a8ac089276cb container test-container: <nil>
    STEP: delete the pod 11/05/22 13:13:05.516
    Nov  5 13:13:05.527: INFO: Waiting for pod pod-8159a84c-f749-4393-955e-a8ac089276cb to disappear
    Nov  5 13:13:05.530: INFO: Pod pod-8159a84c-f749-4393-955e-a8ac089276cb no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 13:13:05.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8638" for this suite. 11/05/22 13:13:05.534
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:05.542
Nov  5 13:13:05.542: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:13:05.543
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:05.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:05.609
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-05201217-41ca-457a-a57b-2e0ea06442db 11/05/22 13:13:05.613
STEP: Creating a pod to test consume secrets 11/05/22 13:13:05.618
Nov  5 13:13:05.626: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b" in namespace "projected-7824" to be "Succeeded or Failed"
Nov  5 13:13:05.632: INFO: Pod "pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.56979ms
Nov  5 13:13:07.637: INFO: Pod "pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010554909s
Nov  5 13:13:09.637: INFO: Pod "pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010492101s
STEP: Saw pod success 11/05/22 13:13:09.637
Nov  5 13:13:09.637: INFO: Pod "pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b" satisfied condition "Succeeded or Failed"
Nov  5 13:13:09.641: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b container secret-volume-test: <nil>
STEP: delete the pod 11/05/22 13:13:09.648
Nov  5 13:13:09.661: INFO: Waiting for pod pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b to disappear
Nov  5 13:13:09.669: INFO: Pod pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Nov  5 13:13:09.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7824" for this suite. 11/05/22 13:13:09.673
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":293,"skipped":5421,"failed":0}
------------------------------
• [4.138 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:05.542
    Nov  5 13:13:05.542: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:13:05.543
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:05.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:05.609
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-05201217-41ca-457a-a57b-2e0ea06442db 11/05/22 13:13:05.613
    STEP: Creating a pod to test consume secrets 11/05/22 13:13:05.618
    Nov  5 13:13:05.626: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b" in namespace "projected-7824" to be "Succeeded or Failed"
    Nov  5 13:13:05.632: INFO: Pod "pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.56979ms
    Nov  5 13:13:07.637: INFO: Pod "pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010554909s
    Nov  5 13:13:09.637: INFO: Pod "pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010492101s
    STEP: Saw pod success 11/05/22 13:13:09.637
    Nov  5 13:13:09.637: INFO: Pod "pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b" satisfied condition "Succeeded or Failed"
    Nov  5 13:13:09.641: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b container secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 13:13:09.648
    Nov  5 13:13:09.661: INFO: Waiting for pod pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b to disappear
    Nov  5 13:13:09.669: INFO: Pod pod-projected-secrets-a5010a22-9ae2-470f-80b7-7230db787d1b no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Nov  5 13:13:09.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7824" for this suite. 11/05/22 13:13:09.673
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:09.681
Nov  5 13:13:09.681: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 13:13:09.681
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:09.694
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:09.698
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 11/05/22 13:13:09.702
Nov  5 13:13:09.702: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Nov  5 13:13:09.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
Nov  5 13:13:10.167: INFO: stderr: ""
Nov  5 13:13:10.167: INFO: stdout: "service/agnhost-replica created\n"
Nov  5 13:13:10.167: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Nov  5 13:13:10.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
Nov  5 13:13:10.403: INFO: stderr: ""
Nov  5 13:13:10.403: INFO: stdout: "service/agnhost-primary created\n"
Nov  5 13:13:10.403: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov  5 13:13:10.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
Nov  5 13:13:10.588: INFO: stderr: ""
Nov  5 13:13:10.588: INFO: stdout: "service/frontend created\n"
Nov  5 13:13:10.588: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Nov  5 13:13:10.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
Nov  5 13:13:10.756: INFO: stderr: ""
Nov  5 13:13:10.756: INFO: stdout: "deployment.apps/frontend created\n"
Nov  5 13:13:10.756: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  5 13:13:10.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
Nov  5 13:13:10.938: INFO: stderr: ""
Nov  5 13:13:10.938: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Nov  5 13:13:10.938: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  5 13:13:10.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
Nov  5 13:13:11.194: INFO: stderr: ""
Nov  5 13:13:11.194: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 11/05/22 13:13:11.194
Nov  5 13:13:11.194: INFO: Waiting for all frontend pods to be Running.
Nov  5 13:13:16.244: INFO: Waiting for frontend to serve content.
Nov  5 13:13:16.255: INFO: Trying to add a new entry to the guestbook.
Nov  5 13:13:16.266: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources 11/05/22 13:13:16.277
Nov  5 13:13:16.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
Nov  5 13:13:16.362: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 13:13:16.362: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 11/05/22 13:13:16.363
Nov  5 13:13:16.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
Nov  5 13:13:16.458: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 13:13:16.458: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 11/05/22 13:13:16.458
Nov  5 13:13:16.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
Nov  5 13:13:16.530: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 13:13:16.530: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 11/05/22 13:13:16.53
Nov  5 13:13:16.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
Nov  5 13:13:16.591: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 13:13:16.591: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 11/05/22 13:13:16.591
Nov  5 13:13:16.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
Nov  5 13:13:16.659: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 13:13:16.659: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 11/05/22 13:13:16.659
Nov  5 13:13:16.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
Nov  5 13:13:16.753: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  5 13:13:16.753: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 13:13:16.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-371" for this suite. 11/05/22 13:13:16.758
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":294,"skipped":5424,"failed":0}
------------------------------
• [SLOW TEST] [7.087 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:09.681
    Nov  5 13:13:09.681: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 13:13:09.681
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:09.694
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:09.698
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 11/05/22 13:13:09.702
    Nov  5 13:13:09.702: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Nov  5 13:13:09.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
    Nov  5 13:13:10.167: INFO: stderr: ""
    Nov  5 13:13:10.167: INFO: stdout: "service/agnhost-replica created\n"
    Nov  5 13:13:10.167: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Nov  5 13:13:10.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
    Nov  5 13:13:10.403: INFO: stderr: ""
    Nov  5 13:13:10.403: INFO: stdout: "service/agnhost-primary created\n"
    Nov  5 13:13:10.403: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Nov  5 13:13:10.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
    Nov  5 13:13:10.588: INFO: stderr: ""
    Nov  5 13:13:10.588: INFO: stdout: "service/frontend created\n"
    Nov  5 13:13:10.588: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Nov  5 13:13:10.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
    Nov  5 13:13:10.756: INFO: stderr: ""
    Nov  5 13:13:10.756: INFO: stdout: "deployment.apps/frontend created\n"
    Nov  5 13:13:10.756: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Nov  5 13:13:10.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
    Nov  5 13:13:10.938: INFO: stderr: ""
    Nov  5 13:13:10.938: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Nov  5 13:13:10.938: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Nov  5 13:13:10.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 create -f -'
    Nov  5 13:13:11.194: INFO: stderr: ""
    Nov  5 13:13:11.194: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 11/05/22 13:13:11.194
    Nov  5 13:13:11.194: INFO: Waiting for all frontend pods to be Running.
    Nov  5 13:13:16.244: INFO: Waiting for frontend to serve content.
    Nov  5 13:13:16.255: INFO: Trying to add a new entry to the guestbook.
    Nov  5 13:13:16.266: INFO: Verifying that added entry can be retrieved.
    STEP: using delete to clean up resources 11/05/22 13:13:16.277
    Nov  5 13:13:16.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
    Nov  5 13:13:16.362: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov  5 13:13:16.362: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 11/05/22 13:13:16.363
    Nov  5 13:13:16.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
    Nov  5 13:13:16.458: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov  5 13:13:16.458: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 11/05/22 13:13:16.458
    Nov  5 13:13:16.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
    Nov  5 13:13:16.530: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov  5 13:13:16.530: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 11/05/22 13:13:16.53
    Nov  5 13:13:16.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
    Nov  5 13:13:16.591: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov  5 13:13:16.591: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 11/05/22 13:13:16.591
    Nov  5 13:13:16.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
    Nov  5 13:13:16.659: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov  5 13:13:16.659: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 11/05/22 13:13:16.659
    Nov  5 13:13:16.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-371 delete --grace-period=0 --force -f -'
    Nov  5 13:13:16.753: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Nov  5 13:13:16.753: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 13:13:16.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-371" for this suite. 11/05/22 13:13:16.758
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:16.768
Nov  5 13:13:16.768: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename containers 11/05/22 13:13:16.769
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:16.785
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:16.789
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Nov  5 13:13:16.803: INFO: Waiting up to 5m0s for pod "client-containers-983a976a-d4a6-4346-99d8-6fbab1dc70b7" in namespace "containers-1961" to be "running"
Nov  5 13:13:16.808: INFO: Pod "client-containers-983a976a-d4a6-4346-99d8-6fbab1dc70b7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.702412ms
Nov  5 13:13:18.813: INFO: Pod "client-containers-983a976a-d4a6-4346-99d8-6fbab1dc70b7": Phase="Running", Reason="", readiness=true. Elapsed: 2.00949078s
Nov  5 13:13:18.813: INFO: Pod "client-containers-983a976a-d4a6-4346-99d8-6fbab1dc70b7" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Nov  5 13:13:18.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1961" for this suite. 11/05/22 13:13:18.829
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":295,"skipped":5426,"failed":0}
------------------------------
• [2.069 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:16.768
    Nov  5 13:13:16.768: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename containers 11/05/22 13:13:16.769
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:16.785
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:16.789
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Nov  5 13:13:16.803: INFO: Waiting up to 5m0s for pod "client-containers-983a976a-d4a6-4346-99d8-6fbab1dc70b7" in namespace "containers-1961" to be "running"
    Nov  5 13:13:16.808: INFO: Pod "client-containers-983a976a-d4a6-4346-99d8-6fbab1dc70b7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.702412ms
    Nov  5 13:13:18.813: INFO: Pod "client-containers-983a976a-d4a6-4346-99d8-6fbab1dc70b7": Phase="Running", Reason="", readiness=true. Elapsed: 2.00949078s
    Nov  5 13:13:18.813: INFO: Pod "client-containers-983a976a-d4a6-4346-99d8-6fbab1dc70b7" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Nov  5 13:13:18.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-1961" for this suite. 11/05/22 13:13:18.829
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:18.837
Nov  5 13:13:18.837: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename subpath 11/05/22 13:13:18.838
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:18.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:18.854
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/05/22 13:13:18.858
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-jrtr 11/05/22 13:13:18.867
STEP: Creating a pod to test atomic-volume-subpath 11/05/22 13:13:18.867
Nov  5 13:13:18.874: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-jrtr" in namespace "subpath-718" to be "Succeeded or Failed"
Nov  5 13:13:18.877: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Pending", Reason="", readiness=false. Elapsed: 3.265059ms
Nov  5 13:13:20.883: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008404469s
Nov  5 13:13:22.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 4.008055416s
Nov  5 13:13:24.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 6.007493294s
Nov  5 13:13:26.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 8.007639848s
Nov  5 13:13:28.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 10.008076682s
Nov  5 13:13:30.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 12.008035481s
Nov  5 13:13:32.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 14.007642528s
Nov  5 13:13:34.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 16.007484331s
Nov  5 13:13:36.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 18.007414738s
Nov  5 13:13:38.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 20.007414539s
Nov  5 13:13:40.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 22.00784757s
Nov  5 13:13:42.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=false. Elapsed: 24.007432521s
Nov  5 13:13:44.881: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.00733283s
STEP: Saw pod success 11/05/22 13:13:44.881
Nov  5 13:13:44.882: INFO: Pod "pod-subpath-test-secret-jrtr" satisfied condition "Succeeded or Failed"
Nov  5 13:13:44.885: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-subpath-test-secret-jrtr container test-container-subpath-secret-jrtr: <nil>
STEP: delete the pod 11/05/22 13:13:44.892
Nov  5 13:13:44.906: INFO: Waiting for pod pod-subpath-test-secret-jrtr to disappear
Nov  5 13:13:44.910: INFO: Pod pod-subpath-test-secret-jrtr no longer exists
STEP: Deleting pod pod-subpath-test-secret-jrtr 11/05/22 13:13:44.91
Nov  5 13:13:44.910: INFO: Deleting pod "pod-subpath-test-secret-jrtr" in namespace "subpath-718"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov  5 13:13:44.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-718" for this suite. 11/05/22 13:13:44.917
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":296,"skipped":5428,"failed":0}
------------------------------
• [SLOW TEST] [26.087 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:18.837
    Nov  5 13:13:18.837: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename subpath 11/05/22 13:13:18.838
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:18.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:18.854
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/05/22 13:13:18.858
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-jrtr 11/05/22 13:13:18.867
    STEP: Creating a pod to test atomic-volume-subpath 11/05/22 13:13:18.867
    Nov  5 13:13:18.874: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-jrtr" in namespace "subpath-718" to be "Succeeded or Failed"
    Nov  5 13:13:18.877: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Pending", Reason="", readiness=false. Elapsed: 3.265059ms
    Nov  5 13:13:20.883: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008404469s
    Nov  5 13:13:22.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 4.008055416s
    Nov  5 13:13:24.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 6.007493294s
    Nov  5 13:13:26.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 8.007639848s
    Nov  5 13:13:28.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 10.008076682s
    Nov  5 13:13:30.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 12.008035481s
    Nov  5 13:13:32.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 14.007642528s
    Nov  5 13:13:34.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 16.007484331s
    Nov  5 13:13:36.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 18.007414738s
    Nov  5 13:13:38.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 20.007414539s
    Nov  5 13:13:40.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=true. Elapsed: 22.00784757s
    Nov  5 13:13:42.882: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Running", Reason="", readiness=false. Elapsed: 24.007432521s
    Nov  5 13:13:44.881: INFO: Pod "pod-subpath-test-secret-jrtr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.00733283s
    STEP: Saw pod success 11/05/22 13:13:44.881
    Nov  5 13:13:44.882: INFO: Pod "pod-subpath-test-secret-jrtr" satisfied condition "Succeeded or Failed"
    Nov  5 13:13:44.885: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-subpath-test-secret-jrtr container test-container-subpath-secret-jrtr: <nil>
    STEP: delete the pod 11/05/22 13:13:44.892
    Nov  5 13:13:44.906: INFO: Waiting for pod pod-subpath-test-secret-jrtr to disappear
    Nov  5 13:13:44.910: INFO: Pod pod-subpath-test-secret-jrtr no longer exists
    STEP: Deleting pod pod-subpath-test-secret-jrtr 11/05/22 13:13:44.91
    Nov  5 13:13:44.910: INFO: Deleting pod "pod-subpath-test-secret-jrtr" in namespace "subpath-718"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov  5 13:13:44.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-718" for this suite. 11/05/22 13:13:44.917
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:44.924
Nov  5 13:13:44.924: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename endpointslice 11/05/22 13:13:44.925
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:44.939
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:44.943
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Nov  5 13:13:49.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-5539" for this suite. 11/05/22 13:13:49.03
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":297,"skipped":5433,"failed":0}
------------------------------
• [4.112 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:44.924
    Nov  5 13:13:44.924: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename endpointslice 11/05/22 13:13:44.925
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:44.939
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:44.943
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Nov  5 13:13:49.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-5539" for this suite. 11/05/22 13:13:49.03
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:49.038
Nov  5 13:13:49.038: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 13:13:49.039
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:49.052
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:49.058
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov  5 13:13:49.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5345" for this suite. 11/05/22 13:13:49.102
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":298,"skipped":5470,"failed":0}
------------------------------
• [0.070 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:49.038
    Nov  5 13:13:49.038: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 13:13:49.039
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:49.052
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:49.058
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 13:13:49.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5345" for this suite. 11/05/22 13:13:49.102
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:49.11
Nov  5 13:13:49.110: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename conformance-tests 11/05/22 13:13:49.111
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:49.121
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:49.126
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 11/05/22 13:13:49.129
Nov  5 13:13:49.130: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Nov  5 13:13:49.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-1009" for this suite. 11/05/22 13:13:49.139
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":299,"skipped":5486,"failed":0}
------------------------------
• [0.036 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:49.11
    Nov  5 13:13:49.110: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename conformance-tests 11/05/22 13:13:49.111
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:49.121
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:49.126
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 11/05/22 13:13:49.129
    Nov  5 13:13:49.130: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Nov  5 13:13:49.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-1009" for this suite. 11/05/22 13:13:49.139
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:49.147
Nov  5 13:13:49.147: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename custom-resource-definition 11/05/22 13:13:49.148
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:49.16
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:49.163
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 11/05/22 13:13:49.167
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 11/05/22 13:13:49.169
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 11/05/22 13:13:49.169
STEP: fetching the /apis/apiextensions.k8s.io discovery document 11/05/22 13:13:49.169
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 11/05/22 13:13:49.171
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 11/05/22 13:13:49.171
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 11/05/22 13:13:49.172
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:13:49.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7753" for this suite. 11/05/22 13:13:49.176
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":300,"skipped":5491,"failed":0}
------------------------------
• [0.035 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:49.147
    Nov  5 13:13:49.147: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename custom-resource-definition 11/05/22 13:13:49.148
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:49.16
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:49.163
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 11/05/22 13:13:49.167
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 11/05/22 13:13:49.169
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 11/05/22 13:13:49.169
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 11/05/22 13:13:49.169
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 11/05/22 13:13:49.171
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 11/05/22 13:13:49.171
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 11/05/22 13:13:49.172
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:13:49.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-7753" for this suite. 11/05/22 13:13:49.176
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:49.183
Nov  5 13:13:49.183: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-runtime 11/05/22 13:13:49.184
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:49.195
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:49.199
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 11/05/22 13:13:49.203
STEP: wait for the container to reach Succeeded 11/05/22 13:13:49.211
STEP: get the container status 11/05/22 13:13:53.233
STEP: the container should be terminated 11/05/22 13:13:53.237
STEP: the termination message should be set 11/05/22 13:13:53.237
Nov  5 13:13:53.237: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 11/05/22 13:13:53.237
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Nov  5 13:13:53.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4111" for this suite. 11/05/22 13:13:53.26
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":301,"skipped":5496,"failed":0}
------------------------------
• [4.084 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:49.183
    Nov  5 13:13:49.183: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-runtime 11/05/22 13:13:49.184
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:49.195
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:49.199
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 11/05/22 13:13:49.203
    STEP: wait for the container to reach Succeeded 11/05/22 13:13:49.211
    STEP: get the container status 11/05/22 13:13:53.233
    STEP: the container should be terminated 11/05/22 13:13:53.237
    STEP: the termination message should be set 11/05/22 13:13:53.237
    Nov  5 13:13:53.237: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 11/05/22 13:13:53.237
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Nov  5 13:13:53.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4111" for this suite. 11/05/22 13:13:53.26
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:53.268
Nov  5 13:13:53.268: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 13:13:53.268
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:53.281
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:53.285
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 11/05/22 13:13:53.289
Nov  5 13:13:53.298: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a" in namespace "downward-api-6372" to be "Succeeded or Failed"
Nov  5 13:13:53.303: INFO: Pod "downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.815274ms
Nov  5 13:13:55.307: INFO: Pod "downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008630281s
Nov  5 13:13:57.308: INFO: Pod "downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009740576s
STEP: Saw pod success 11/05/22 13:13:57.308
Nov  5 13:13:57.308: INFO: Pod "downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a" satisfied condition "Succeeded or Failed"
Nov  5 13:13:57.311: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a container client-container: <nil>
STEP: delete the pod 11/05/22 13:13:57.323
Nov  5 13:13:57.336: INFO: Waiting for pod downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a to disappear
Nov  5 13:13:57.339: INFO: Pod downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 13:13:57.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6372" for this suite. 11/05/22 13:13:57.344
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":302,"skipped":5509,"failed":0}
------------------------------
• [4.083 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:53.268
    Nov  5 13:13:53.268: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 13:13:53.268
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:53.281
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:53.285
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 11/05/22 13:13:53.289
    Nov  5 13:13:53.298: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a" in namespace "downward-api-6372" to be "Succeeded or Failed"
    Nov  5 13:13:53.303: INFO: Pod "downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.815274ms
    Nov  5 13:13:55.307: INFO: Pod "downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008630281s
    Nov  5 13:13:57.308: INFO: Pod "downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009740576s
    STEP: Saw pod success 11/05/22 13:13:57.308
    Nov  5 13:13:57.308: INFO: Pod "downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a" satisfied condition "Succeeded or Failed"
    Nov  5 13:13:57.311: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a container client-container: <nil>
    STEP: delete the pod 11/05/22 13:13:57.323
    Nov  5 13:13:57.336: INFO: Waiting for pod downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a to disappear
    Nov  5 13:13:57.339: INFO: Pod downwardapi-volume-44d02c55-96ed-456a-90c5-2a2c6695fd4a no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 13:13:57.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6372" for this suite. 11/05/22 13:13:57.344
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:13:57.354
Nov  5 13:13:57.354: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename daemonsets 11/05/22 13:13:57.355
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:57.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:57.374
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 11/05/22 13:13:57.397
STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 13:13:57.404
Nov  5 13:13:57.409: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:13:57.409: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:13:57.413: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 13:13:57.413: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 13:13:58.418: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:13:58.418: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:13:58.422: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 13:13:58.422: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 13:13:59.418: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:13:59.418: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:13:59.422: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov  5 13:13:59.422: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 11/05/22 13:13:59.425
Nov  5 13:13:59.440: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:13:59.440: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:13:59.446: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov  5 13:13:59.446: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 13:14:00.450: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:14:00.451: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:14:00.454: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Nov  5 13:14:00.454: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
Nov  5 13:14:01.450: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:14:01.451: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov  5 13:14:01.454: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Nov  5 13:14:01.454: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 11/05/22 13:14:01.454
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 11/05/22 13:14:01.461
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8482, will wait for the garbage collector to delete the pods 11/05/22 13:14:01.462
Nov  5 13:14:01.522: INFO: Deleting DaemonSet.extensions daemon-set took: 6.584645ms
Nov  5 13:14:01.623: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.867159ms
Nov  5 13:14:03.828: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Nov  5 13:14:03.828: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Nov  5 13:14:03.831: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35555"},"items":null}

Nov  5 13:14:03.834: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35555"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Nov  5 13:14:03.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8482" for this suite. 11/05/22 13:14:03.852
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":303,"skipped":5542,"failed":0}
------------------------------
• [SLOW TEST] [6.505 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:13:57.354
    Nov  5 13:13:57.354: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename daemonsets 11/05/22 13:13:57.355
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:13:57.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:13:57.374
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 11/05/22 13:13:57.397
    STEP: Check that daemon pods launch on every node of the cluster. 11/05/22 13:13:57.404
    Nov  5 13:13:57.409: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:13:57.409: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:13:57.413: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 13:13:57.413: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 13:13:58.418: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:13:58.418: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:13:58.422: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 13:13:58.422: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 13:13:59.418: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:13:59.418: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:13:59.422: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov  5 13:13:59.422: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 11/05/22 13:13:59.425
    Nov  5 13:13:59.440: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:13:59.440: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:13:59.446: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov  5 13:13:59.446: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 13:14:00.450: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:14:00.451: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:14:00.454: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Nov  5 13:14:00.454: INFO: Node ip-172-31-0-255 is running 0 daemon pod, expected 1
    Nov  5 13:14:01.450: INFO: DaemonSet pods can't tolerate node ip-172-31-23-198 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:14:01.451: INFO: DaemonSet pods can't tolerate node ip-172-31-83-205 with taints [{Key:node-role.kubernetes.io/control-plane Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
    Nov  5 13:14:01.454: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Nov  5 13:14:01.454: INFO: Number of running nodes: 3, number of available pods: 3 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 11/05/22 13:14:01.454
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 11/05/22 13:14:01.461
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8482, will wait for the garbage collector to delete the pods 11/05/22 13:14:01.462
    Nov  5 13:14:01.522: INFO: Deleting DaemonSet.extensions daemon-set took: 6.584645ms
    Nov  5 13:14:01.623: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.867159ms
    Nov  5 13:14:03.828: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Nov  5 13:14:03.828: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Nov  5 13:14:03.831: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"35555"},"items":null}

    Nov  5 13:14:03.834: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"35555"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 13:14:03.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-8482" for this suite. 11/05/22 13:14:03.852
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:14:03.86
Nov  5 13:14:03.860: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename namespaces 11/05/22 13:14:03.86
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:14:03.874
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:14:03.878
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 11/05/22 13:14:03.883
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:14:03.895
STEP: Creating a service in the namespace 11/05/22 13:14:03.898
STEP: Deleting the namespace 11/05/22 13:14:03.909
STEP: Waiting for the namespace to be removed. 11/05/22 13:14:03.919
STEP: Recreating the namespace 11/05/22 13:14:09.926
STEP: Verifying there is no service in the namespace 11/05/22 13:14:09.942
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Nov  5 13:14:09.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7807" for this suite. 11/05/22 13:14:09.95
STEP: Destroying namespace "nsdeletetest-589" for this suite. 11/05/22 13:14:09.957
Nov  5 13:14:09.960: INFO: Namespace nsdeletetest-589 was already deleted
STEP: Destroying namespace "nsdeletetest-6603" for this suite. 11/05/22 13:14:09.96
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":304,"skipped":5550,"failed":0}
------------------------------
• [SLOW TEST] [6.107 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:14:03.86
    Nov  5 13:14:03.860: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename namespaces 11/05/22 13:14:03.86
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:14:03.874
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:14:03.878
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 11/05/22 13:14:03.883
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:14:03.895
    STEP: Creating a service in the namespace 11/05/22 13:14:03.898
    STEP: Deleting the namespace 11/05/22 13:14:03.909
    STEP: Waiting for the namespace to be removed. 11/05/22 13:14:03.919
    STEP: Recreating the namespace 11/05/22 13:14:09.926
    STEP: Verifying there is no service in the namespace 11/05/22 13:14:09.942
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Nov  5 13:14:09.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7807" for this suite. 11/05/22 13:14:09.95
    STEP: Destroying namespace "nsdeletetest-589" for this suite. 11/05/22 13:14:09.957
    Nov  5 13:14:09.960: INFO: Namespace nsdeletetest-589 was already deleted
    STEP: Destroying namespace "nsdeletetest-6603" for this suite. 11/05/22 13:14:09.96
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:14:09.968
Nov  5 13:14:09.968: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-probe 11/05/22 13:14:09.969
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:14:09.98
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:14:09.984
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16 in namespace container-probe-3461 11/05/22 13:14:09.988
Nov  5 13:14:09.997: INFO: Waiting up to 5m0s for pod "busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16" in namespace "container-probe-3461" to be "not pending"
Nov  5 13:14:10.002: INFO: Pod "busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16": Phase="Pending", Reason="", readiness=false. Elapsed: 5.208101ms
Nov  5 13:14:12.006: INFO: Pod "busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16": Phase="Running", Reason="", readiness=true. Elapsed: 2.009125482s
Nov  5 13:14:12.006: INFO: Pod "busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16" satisfied condition "not pending"
Nov  5 13:14:12.006: INFO: Started pod busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16 in namespace container-probe-3461
STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 13:14:12.006
Nov  5 13:14:12.010: INFO: Initial restart count of pod busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16 is 0
STEP: deleting the pod 11/05/22 13:18:12.56
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Nov  5 13:18:12.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3461" for this suite. 11/05/22 13:18:12.581
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":305,"skipped":5556,"failed":0}
------------------------------
• [SLOW TEST] [242.621 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:14:09.968
    Nov  5 13:14:09.968: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-probe 11/05/22 13:14:09.969
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:14:09.98
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:14:09.984
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16 in namespace container-probe-3461 11/05/22 13:14:09.988
    Nov  5 13:14:09.997: INFO: Waiting up to 5m0s for pod "busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16" in namespace "container-probe-3461" to be "not pending"
    Nov  5 13:14:10.002: INFO: Pod "busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16": Phase="Pending", Reason="", readiness=false. Elapsed: 5.208101ms
    Nov  5 13:14:12.006: INFO: Pod "busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16": Phase="Running", Reason="", readiness=true. Elapsed: 2.009125482s
    Nov  5 13:14:12.006: INFO: Pod "busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16" satisfied condition "not pending"
    Nov  5 13:14:12.006: INFO: Started pod busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16 in namespace container-probe-3461
    STEP: checking the pod's current state and verifying that restartCount is present 11/05/22 13:14:12.006
    Nov  5 13:14:12.010: INFO: Initial restart count of pod busybox-a84933d9-3e3f-4a82-8a7b-e8bebd6b2f16 is 0
    STEP: deleting the pod 11/05/22 13:18:12.56
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Nov  5 13:18:12.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-3461" for this suite. 11/05/22 13:18:12.581
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:18:12.59
Nov  5 13:18:12.590: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename proxy 11/05/22 13:18:12.591
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:18:12.61
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:18:12.615
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Nov  5 13:18:12.619: INFO: Creating pod...
Nov  5 13:18:12.628: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-468" to be "running"
Nov  5 13:18:12.635: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 6.716915ms
Nov  5 13:18:14.640: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.011779846s
Nov  5 13:18:14.640: INFO: Pod "agnhost" satisfied condition "running"
Nov  5 13:18:14.640: INFO: Creating service...
Nov  5 13:18:14.650: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/DELETE
Nov  5 13:18:14.661: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov  5 13:18:14.661: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/GET
Nov  5 13:18:14.666: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Nov  5 13:18:14.666: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/HEAD
Nov  5 13:18:14.670: INFO: http.Client request:HEAD | StatusCode:200
Nov  5 13:18:14.670: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/OPTIONS
Nov  5 13:18:14.675: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov  5 13:18:14.675: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/PATCH
Nov  5 13:18:14.678: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov  5 13:18:14.678: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/POST
Nov  5 13:18:14.683: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov  5 13:18:14.683: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/PUT
Nov  5 13:18:14.688: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Nov  5 13:18:14.688: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/DELETE
Nov  5 13:18:14.694: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Nov  5 13:18:14.694: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/GET
Nov  5 13:18:14.700: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Nov  5 13:18:14.701: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/HEAD
Nov  5 13:18:14.706: INFO: http.Client request:HEAD | StatusCode:200
Nov  5 13:18:14.706: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/OPTIONS
Nov  5 13:18:14.712: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Nov  5 13:18:14.712: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/PATCH
Nov  5 13:18:14.718: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Nov  5 13:18:14.718: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/POST
Nov  5 13:18:14.724: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Nov  5 13:18:14.724: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/PUT
Nov  5 13:18:14.730: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Nov  5 13:18:14.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-468" for this suite. 11/05/22 13:18:14.734
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":306,"skipped":5588,"failed":0}
------------------------------
• [2.151 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:18:12.59
    Nov  5 13:18:12.590: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename proxy 11/05/22 13:18:12.591
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:18:12.61
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:18:12.615
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Nov  5 13:18:12.619: INFO: Creating pod...
    Nov  5 13:18:12.628: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-468" to be "running"
    Nov  5 13:18:12.635: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 6.716915ms
    Nov  5 13:18:14.640: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.011779846s
    Nov  5 13:18:14.640: INFO: Pod "agnhost" satisfied condition "running"
    Nov  5 13:18:14.640: INFO: Creating service...
    Nov  5 13:18:14.650: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/DELETE
    Nov  5 13:18:14.661: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov  5 13:18:14.661: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/GET
    Nov  5 13:18:14.666: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Nov  5 13:18:14.666: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/HEAD
    Nov  5 13:18:14.670: INFO: http.Client request:HEAD | StatusCode:200
    Nov  5 13:18:14.670: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/OPTIONS
    Nov  5 13:18:14.675: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov  5 13:18:14.675: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/PATCH
    Nov  5 13:18:14.678: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov  5 13:18:14.678: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/POST
    Nov  5 13:18:14.683: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov  5 13:18:14.683: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/pods/agnhost/proxy/some/path/with/PUT
    Nov  5 13:18:14.688: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Nov  5 13:18:14.688: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/DELETE
    Nov  5 13:18:14.694: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Nov  5 13:18:14.694: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/GET
    Nov  5 13:18:14.700: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Nov  5 13:18:14.701: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/HEAD
    Nov  5 13:18:14.706: INFO: http.Client request:HEAD | StatusCode:200
    Nov  5 13:18:14.706: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/OPTIONS
    Nov  5 13:18:14.712: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Nov  5 13:18:14.712: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/PATCH
    Nov  5 13:18:14.718: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Nov  5 13:18:14.718: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/POST
    Nov  5 13:18:14.724: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Nov  5 13:18:14.724: INFO: Starting http.Client for https://10.152.183.1:443/api/v1/namespaces/proxy-468/services/test-service/proxy/some/path/with/PUT
    Nov  5 13:18:14.730: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Nov  5 13:18:14.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-468" for this suite. 11/05/22 13:18:14.734
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:18:14.742
Nov  5 13:18:14.742: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename statefulset 11/05/22 13:18:14.742
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:18:14.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:18:14.76
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1569 11/05/22 13:18:14.764
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 11/05/22 13:18:14.77
STEP: Creating stateful set ss in namespace statefulset-1569 11/05/22 13:18:14.776
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1569 11/05/22 13:18:14.782
Nov  5 13:18:14.785: INFO: Found 0 stateful pods, waiting for 1
Nov  5 13:18:24.793: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 11/05/22 13:18:24.793
Nov  5 13:18:24.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  5 13:18:24.946: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  5 13:18:24.946: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  5 13:18:24.946: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  5 13:18:24.951: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  5 13:18:34.959: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 13:18:34.959: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 13:18:34.976: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999778s
Nov  5 13:18:35.981: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995196791s
Nov  5 13:18:36.985: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990722068s
Nov  5 13:18:37.989: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986592485s
Nov  5 13:18:38.993: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982241184s
Nov  5 13:18:39.998: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.978221472s
Nov  5 13:18:41.002: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.973974438s
Nov  5 13:18:42.007: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.96911931s
Nov  5 13:18:43.011: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964917668s
Nov  5 13:18:44.015: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.684758ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1569 11/05/22 13:18:45.015
Nov  5 13:18:45.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  5 13:18:45.155: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  5 13:18:45.155: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  5 13:18:45.155: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  5 13:18:45.159: INFO: Found 1 stateful pods, waiting for 3
Nov  5 13:18:55.165: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 13:18:55.165: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 13:18:55.165: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 11/05/22 13:18:55.165
STEP: Scale down will halt with unhealthy stateful pod 11/05/22 13:18:55.165
Nov  5 13:18:55.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  5 13:18:55.318: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  5 13:18:55.318: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  5 13:18:55.318: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  5 13:18:55.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  5 13:18:55.467: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  5 13:18:55.467: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  5 13:18:55.467: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  5 13:18:55.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  5 13:18:55.617: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  5 13:18:55.617: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  5 13:18:55.617: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  5 13:18:55.617: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 13:18:55.621: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov  5 13:19:05.634: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 13:19:05.634: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 13:19:05.634: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  5 13:19:05.651: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999778s
Nov  5 13:19:06.655: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992969935s
Nov  5 13:19:07.659: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988829571s
Nov  5 13:19:08.664: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983850794s
Nov  5 13:19:09.669: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979499688s
Nov  5 13:19:10.674: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973891003s
Nov  5 13:19:11.679: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.969658296s
Nov  5 13:19:12.683: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.965136442s
Nov  5 13:19:13.687: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.960906979s
Nov  5 13:19:14.691: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.726435ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1569 11/05/22 13:19:15.691
Nov  5 13:19:15.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  5 13:19:15.835: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  5 13:19:15.835: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  5 13:19:15.835: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  5 13:19:15.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  5 13:19:15.971: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  5 13:19:15.971: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  5 13:19:15.971: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  5 13:19:15.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  5 13:19:16.101: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  5 13:19:16.101: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  5 13:19:16.101: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  5 13:19:16.101: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 11/05/22 13:19:26.117
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov  5 13:19:26.118: INFO: Deleting all statefulset in ns statefulset-1569
Nov  5 13:19:26.121: INFO: Scaling statefulset ss to 0
Nov  5 13:19:26.132: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 13:19:26.135: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov  5 13:19:26.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1569" for this suite. 11/05/22 13:19:26.161
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":307,"skipped":5590,"failed":0}
------------------------------
• [SLOW TEST] [71.426 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:18:14.742
    Nov  5 13:18:14.742: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename statefulset 11/05/22 13:18:14.742
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:18:14.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:18:14.76
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1569 11/05/22 13:18:14.764
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 11/05/22 13:18:14.77
    STEP: Creating stateful set ss in namespace statefulset-1569 11/05/22 13:18:14.776
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1569 11/05/22 13:18:14.782
    Nov  5 13:18:14.785: INFO: Found 0 stateful pods, waiting for 1
    Nov  5 13:18:24.793: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 11/05/22 13:18:24.793
    Nov  5 13:18:24.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov  5 13:18:24.946: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov  5 13:18:24.946: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov  5 13:18:24.946: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov  5 13:18:24.951: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Nov  5 13:18:34.959: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov  5 13:18:34.959: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 13:18:34.976: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999778s
    Nov  5 13:18:35.981: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.995196791s
    Nov  5 13:18:36.985: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990722068s
    Nov  5 13:18:37.989: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986592485s
    Nov  5 13:18:38.993: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.982241184s
    Nov  5 13:18:39.998: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.978221472s
    Nov  5 13:18:41.002: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.973974438s
    Nov  5 13:18:42.007: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.96911931s
    Nov  5 13:18:43.011: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.964917668s
    Nov  5 13:18:44.015: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.684758ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1569 11/05/22 13:18:45.015
    Nov  5 13:18:45.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov  5 13:18:45.155: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov  5 13:18:45.155: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov  5 13:18:45.155: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov  5 13:18:45.159: INFO: Found 1 stateful pods, waiting for 3
    Nov  5 13:18:55.165: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 13:18:55.165: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 13:18:55.165: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 11/05/22 13:18:55.165
    STEP: Scale down will halt with unhealthy stateful pod 11/05/22 13:18:55.165
    Nov  5 13:18:55.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov  5 13:18:55.318: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov  5 13:18:55.318: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov  5 13:18:55.318: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov  5 13:18:55.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov  5 13:18:55.467: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov  5 13:18:55.467: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov  5 13:18:55.467: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov  5 13:18:55.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov  5 13:18:55.617: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov  5 13:18:55.617: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov  5 13:18:55.617: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov  5 13:18:55.617: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 13:18:55.621: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Nov  5 13:19:05.634: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Nov  5 13:19:05.634: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Nov  5 13:19:05.634: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Nov  5 13:19:05.651: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999778s
    Nov  5 13:19:06.655: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992969935s
    Nov  5 13:19:07.659: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988829571s
    Nov  5 13:19:08.664: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983850794s
    Nov  5 13:19:09.669: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979499688s
    Nov  5 13:19:10.674: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973891003s
    Nov  5 13:19:11.679: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.969658296s
    Nov  5 13:19:12.683: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.965136442s
    Nov  5 13:19:13.687: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.960906979s
    Nov  5 13:19:14.691: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.726435ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1569 11/05/22 13:19:15.691
    Nov  5 13:19:15.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov  5 13:19:15.835: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov  5 13:19:15.835: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov  5 13:19:15.835: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov  5 13:19:15.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov  5 13:19:15.971: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov  5 13:19:15.971: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov  5 13:19:15.971: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov  5 13:19:15.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-1569 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov  5 13:19:16.101: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov  5 13:19:16.101: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov  5 13:19:16.101: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Nov  5 13:19:16.101: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 11/05/22 13:19:26.117
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov  5 13:19:26.118: INFO: Deleting all statefulset in ns statefulset-1569
    Nov  5 13:19:26.121: INFO: Scaling statefulset ss to 0
    Nov  5 13:19:26.132: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 13:19:26.135: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov  5 13:19:26.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1569" for this suite. 11/05/22 13:19:26.161
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:19:26.169
Nov  5 13:19:26.170: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 13:19:26.17
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:19:26.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:19:26.188
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 11/05/22 13:19:26.192
Nov  5 13:19:26.200: INFO: Waiting up to 5m0s for pod "pod-6192839b-d78f-4815-8e68-bfc165ab8cec" in namespace "emptydir-3549" to be "Succeeded or Failed"
Nov  5 13:19:26.206: INFO: Pod "pod-6192839b-d78f-4815-8e68-bfc165ab8cec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.505286ms
Nov  5 13:19:28.211: INFO: Pod "pod-6192839b-d78f-4815-8e68-bfc165ab8cec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011371057s
Nov  5 13:19:30.213: INFO: Pod "pod-6192839b-d78f-4815-8e68-bfc165ab8cec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012679258s
STEP: Saw pod success 11/05/22 13:19:30.213
Nov  5 13:19:30.213: INFO: Pod "pod-6192839b-d78f-4815-8e68-bfc165ab8cec" satisfied condition "Succeeded or Failed"
Nov  5 13:19:30.216: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-6192839b-d78f-4815-8e68-bfc165ab8cec container test-container: <nil>
STEP: delete the pod 11/05/22 13:19:30.233
Nov  5 13:19:30.246: INFO: Waiting for pod pod-6192839b-d78f-4815-8e68-bfc165ab8cec to disappear
Nov  5 13:19:30.249: INFO: Pod pod-6192839b-d78f-4815-8e68-bfc165ab8cec no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 13:19:30.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3549" for this suite. 11/05/22 13:19:30.253
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":308,"skipped":5600,"failed":0}
------------------------------
• [4.090 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:19:26.169
    Nov  5 13:19:26.170: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 13:19:26.17
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:19:26.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:19:26.188
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 11/05/22 13:19:26.192
    Nov  5 13:19:26.200: INFO: Waiting up to 5m0s for pod "pod-6192839b-d78f-4815-8e68-bfc165ab8cec" in namespace "emptydir-3549" to be "Succeeded or Failed"
    Nov  5 13:19:26.206: INFO: Pod "pod-6192839b-d78f-4815-8e68-bfc165ab8cec": Phase="Pending", Reason="", readiness=false. Elapsed: 6.505286ms
    Nov  5 13:19:28.211: INFO: Pod "pod-6192839b-d78f-4815-8e68-bfc165ab8cec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011371057s
    Nov  5 13:19:30.213: INFO: Pod "pod-6192839b-d78f-4815-8e68-bfc165ab8cec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012679258s
    STEP: Saw pod success 11/05/22 13:19:30.213
    Nov  5 13:19:30.213: INFO: Pod "pod-6192839b-d78f-4815-8e68-bfc165ab8cec" satisfied condition "Succeeded or Failed"
    Nov  5 13:19:30.216: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-6192839b-d78f-4815-8e68-bfc165ab8cec container test-container: <nil>
    STEP: delete the pod 11/05/22 13:19:30.233
    Nov  5 13:19:30.246: INFO: Waiting for pod pod-6192839b-d78f-4815-8e68-bfc165ab8cec to disappear
    Nov  5 13:19:30.249: INFO: Pod pod-6192839b-d78f-4815-8e68-bfc165ab8cec no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 13:19:30.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3549" for this suite. 11/05/22 13:19:30.253
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:19:30.26
Nov  5 13:19:30.260: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 13:19:30.261
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:19:30.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:19:30.278
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 11/05/22 13:19:30.282
Nov  5 13:19:30.291: INFO: Waiting up to 5m0s for pod "downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f" in namespace "downward-api-982" to be "Succeeded or Failed"
Nov  5 13:19:30.294: INFO: Pod "downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.970591ms
Nov  5 13:19:32.299: INFO: Pod "downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f": Phase="Running", Reason="", readiness=false. Elapsed: 2.007865442s
Nov  5 13:19:34.300: INFO: Pod "downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008538518s
STEP: Saw pod success 11/05/22 13:19:34.3
Nov  5 13:19:34.300: INFO: Pod "downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f" satisfied condition "Succeeded or Failed"
Nov  5 13:19:34.304: INFO: Trying to get logs from node ip-172-31-0-255 pod downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f container dapi-container: <nil>
STEP: delete the pod 11/05/22 13:19:34.311
Nov  5 13:19:34.321: INFO: Waiting for pod downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f to disappear
Nov  5 13:19:34.324: INFO: Pod downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Nov  5 13:19:34.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-982" for this suite. 11/05/22 13:19:34.329
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":309,"skipped":5619,"failed":0}
------------------------------
• [4.075 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:19:30.26
    Nov  5 13:19:30.260: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 13:19:30.261
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:19:30.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:19:30.278
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 11/05/22 13:19:30.282
    Nov  5 13:19:30.291: INFO: Waiting up to 5m0s for pod "downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f" in namespace "downward-api-982" to be "Succeeded or Failed"
    Nov  5 13:19:30.294: INFO: Pod "downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.970591ms
    Nov  5 13:19:32.299: INFO: Pod "downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f": Phase="Running", Reason="", readiness=false. Elapsed: 2.007865442s
    Nov  5 13:19:34.300: INFO: Pod "downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008538518s
    STEP: Saw pod success 11/05/22 13:19:34.3
    Nov  5 13:19:34.300: INFO: Pod "downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f" satisfied condition "Succeeded or Failed"
    Nov  5 13:19:34.304: INFO: Trying to get logs from node ip-172-31-0-255 pod downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f container dapi-container: <nil>
    STEP: delete the pod 11/05/22 13:19:34.311
    Nov  5 13:19:34.321: INFO: Waiting for pod downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f to disappear
    Nov  5 13:19:34.324: INFO: Pod downward-api-04f73cb0-8a69-48f6-919a-9264d33d298f no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Nov  5 13:19:34.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-982" for this suite. 11/05/22 13:19:34.329
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:19:34.338
Nov  5 13:19:34.338: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename statefulset 11/05/22 13:19:34.339
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:19:34.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:19:34.357
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-5465 11/05/22 13:19:34.36
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 11/05/22 13:19:34.368
Nov  5 13:19:34.377: INFO: Found 0 stateful pods, waiting for 3
Nov  5 13:19:44.383: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 13:19:44.383: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 13:19:44.383: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 13:19:44.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-5465 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  5 13:19:44.590: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  5 13:19:44.590: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  5 13:19:44.590: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/05/22 13:19:54.608
Nov  5 13:19:54.628: INFO: Updating stateful set ss2
STEP: Creating a new revision 11/05/22 13:19:54.628
STEP: Updating Pods in reverse ordinal order 11/05/22 13:20:04.644
Nov  5 13:20:04.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-5465 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  5 13:20:04.790: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  5 13:20:04.790: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  5 13:20:04.790: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 11/05/22 13:20:14.813
Nov  5 13:20:14.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-5465 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  5 13:20:14.956: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  5 13:20:14.956: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  5 13:20:14.956: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  5 13:20:24.991: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 11/05/22 13:20:35.008
Nov  5 13:20:35.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-5465 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  5 13:20:35.162: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  5 13:20:35.162: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  5 13:20:35.162: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov  5 13:20:45.183: INFO: Deleting all statefulset in ns statefulset-5465
Nov  5 13:20:45.186: INFO: Scaling statefulset ss2 to 0
Nov  5 13:20:55.204: INFO: Waiting for statefulset status.replicas updated to 0
Nov  5 13:20:55.208: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov  5 13:20:55.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5465" for this suite. 11/05/22 13:20:55.235
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":310,"skipped":5638,"failed":0}
------------------------------
• [SLOW TEST] [80.906 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:19:34.338
    Nov  5 13:19:34.338: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename statefulset 11/05/22 13:19:34.339
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:19:34.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:19:34.357
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-5465 11/05/22 13:19:34.36
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 11/05/22 13:19:34.368
    Nov  5 13:19:34.377: INFO: Found 0 stateful pods, waiting for 3
    Nov  5 13:19:44.383: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 13:19:44.383: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 13:19:44.383: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 13:19:44.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-5465 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov  5 13:19:44.590: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov  5 13:19:44.590: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov  5 13:19:44.590: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 11/05/22 13:19:54.608
    Nov  5 13:19:54.628: INFO: Updating stateful set ss2
    STEP: Creating a new revision 11/05/22 13:19:54.628
    STEP: Updating Pods in reverse ordinal order 11/05/22 13:20:04.644
    Nov  5 13:20:04.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-5465 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov  5 13:20:04.790: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov  5 13:20:04.790: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov  5 13:20:04.790: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 11/05/22 13:20:14.813
    Nov  5 13:20:14.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-5465 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Nov  5 13:20:14.956: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Nov  5 13:20:14.956: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Nov  5 13:20:14.956: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Nov  5 13:20:24.991: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 11/05/22 13:20:35.008
    Nov  5 13:20:35.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=statefulset-5465 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Nov  5 13:20:35.162: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Nov  5 13:20:35.162: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Nov  5 13:20:35.162: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov  5 13:20:45.183: INFO: Deleting all statefulset in ns statefulset-5465
    Nov  5 13:20:45.186: INFO: Scaling statefulset ss2 to 0
    Nov  5 13:20:55.204: INFO: Waiting for statefulset status.replicas updated to 0
    Nov  5 13:20:55.208: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov  5 13:20:55.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-5465" for this suite. 11/05/22 13:20:55.235
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:20:55.246
Nov  5 13:20:55.246: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename subpath 11/05/22 13:20:55.247
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:20:55.262
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:20:55.266
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 11/05/22 13:20:55.269
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-pwms 11/05/22 13:20:55.278
STEP: Creating a pod to test atomic-volume-subpath 11/05/22 13:20:55.278
Nov  5 13:20:55.286: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pwms" in namespace "subpath-2262" to be "Succeeded or Failed"
Nov  5 13:20:55.290: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Pending", Reason="", readiness=false. Elapsed: 4.42232ms
Nov  5 13:20:57.294: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 2.008533421s
Nov  5 13:20:59.296: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 4.010371058s
Nov  5 13:21:01.295: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 6.009015258s
Nov  5 13:21:03.297: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 8.01122849s
Nov  5 13:21:05.294: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 10.008474018s
Nov  5 13:21:07.294: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 12.008400268s
Nov  5 13:21:09.296: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 14.010019231s
Nov  5 13:21:11.295: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 16.009097972s
Nov  5 13:21:13.294: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 18.008398707s
Nov  5 13:21:15.296: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 20.010152396s
Nov  5 13:21:17.295: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=false. Elapsed: 22.00892266s
Nov  5 13:21:19.294: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.008720097s
STEP: Saw pod success 11/05/22 13:21:19.294
Nov  5 13:21:19.295: INFO: Pod "pod-subpath-test-configmap-pwms" satisfied condition "Succeeded or Failed"
Nov  5 13:21:19.298: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-subpath-test-configmap-pwms container test-container-subpath-configmap-pwms: <nil>
STEP: delete the pod 11/05/22 13:21:19.31
Nov  5 13:21:19.324: INFO: Waiting for pod pod-subpath-test-configmap-pwms to disappear
Nov  5 13:21:19.327: INFO: Pod pod-subpath-test-configmap-pwms no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pwms 11/05/22 13:21:19.327
Nov  5 13:21:19.327: INFO: Deleting pod "pod-subpath-test-configmap-pwms" in namespace "subpath-2262"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Nov  5 13:21:19.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2262" for this suite. 11/05/22 13:21:19.334
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":311,"skipped":5678,"failed":0}
------------------------------
• [SLOW TEST] [24.095 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:20:55.246
    Nov  5 13:20:55.246: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename subpath 11/05/22 13:20:55.247
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:20:55.262
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:20:55.266
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 11/05/22 13:20:55.269
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-pwms 11/05/22 13:20:55.278
    STEP: Creating a pod to test atomic-volume-subpath 11/05/22 13:20:55.278
    Nov  5 13:20:55.286: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pwms" in namespace "subpath-2262" to be "Succeeded or Failed"
    Nov  5 13:20:55.290: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Pending", Reason="", readiness=false. Elapsed: 4.42232ms
    Nov  5 13:20:57.294: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 2.008533421s
    Nov  5 13:20:59.296: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 4.010371058s
    Nov  5 13:21:01.295: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 6.009015258s
    Nov  5 13:21:03.297: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 8.01122849s
    Nov  5 13:21:05.294: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 10.008474018s
    Nov  5 13:21:07.294: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 12.008400268s
    Nov  5 13:21:09.296: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 14.010019231s
    Nov  5 13:21:11.295: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 16.009097972s
    Nov  5 13:21:13.294: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 18.008398707s
    Nov  5 13:21:15.296: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=true. Elapsed: 20.010152396s
    Nov  5 13:21:17.295: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Running", Reason="", readiness=false. Elapsed: 22.00892266s
    Nov  5 13:21:19.294: INFO: Pod "pod-subpath-test-configmap-pwms": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.008720097s
    STEP: Saw pod success 11/05/22 13:21:19.294
    Nov  5 13:21:19.295: INFO: Pod "pod-subpath-test-configmap-pwms" satisfied condition "Succeeded or Failed"
    Nov  5 13:21:19.298: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-subpath-test-configmap-pwms container test-container-subpath-configmap-pwms: <nil>
    STEP: delete the pod 11/05/22 13:21:19.31
    Nov  5 13:21:19.324: INFO: Waiting for pod pod-subpath-test-configmap-pwms to disappear
    Nov  5 13:21:19.327: INFO: Pod pod-subpath-test-configmap-pwms no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-pwms 11/05/22 13:21:19.327
    Nov  5 13:21:19.327: INFO: Deleting pod "pod-subpath-test-configmap-pwms" in namespace "subpath-2262"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Nov  5 13:21:19.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2262" for this suite. 11/05/22 13:21:19.334
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:21:19.343
Nov  5 13:21:19.343: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename dns 11/05/22 13:21:19.344
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:19.361
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:19.366
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-708.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-708.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 11/05/22 13:21:19.37
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-708.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-708.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 11/05/22 13:21:19.37
STEP: creating a pod to probe /etc/hosts 11/05/22 13:21:19.37
STEP: submitting the pod to kubernetes 11/05/22 13:21:19.37
Nov  5 13:21:19.380: INFO: Waiting up to 15m0s for pod "dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb" in namespace "dns-708" to be "running"
Nov  5 13:21:19.385: INFO: Pod "dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.595731ms
Nov  5 13:21:21.389: INFO: Pod "dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008861107s
Nov  5 13:21:23.390: INFO: Pod "dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb": Phase="Running", Reason="", readiness=true. Elapsed: 4.009333231s
Nov  5 13:21:23.390: INFO: Pod "dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb" satisfied condition "running"
STEP: retrieving the pod 11/05/22 13:21:23.39
STEP: looking for the results for each expected name from probers 11/05/22 13:21:23.393
Nov  5 13:21:23.411: INFO: DNS probes using dns-708/dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb succeeded

STEP: deleting the pod 11/05/22 13:21:23.411
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov  5 13:21:23.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-708" for this suite. 11/05/22 13:21:23.427
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":312,"skipped":5704,"failed":0}
------------------------------
• [4.090 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:21:19.343
    Nov  5 13:21:19.343: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename dns 11/05/22 13:21:19.344
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:19.361
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:19.366
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-708.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-708.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     11/05/22 13:21:19.37
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-708.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-708.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     11/05/22 13:21:19.37
    STEP: creating a pod to probe /etc/hosts 11/05/22 13:21:19.37
    STEP: submitting the pod to kubernetes 11/05/22 13:21:19.37
    Nov  5 13:21:19.380: INFO: Waiting up to 15m0s for pod "dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb" in namespace "dns-708" to be "running"
    Nov  5 13:21:19.385: INFO: Pod "dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.595731ms
    Nov  5 13:21:21.389: INFO: Pod "dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008861107s
    Nov  5 13:21:23.390: INFO: Pod "dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb": Phase="Running", Reason="", readiness=true. Elapsed: 4.009333231s
    Nov  5 13:21:23.390: INFO: Pod "dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb" satisfied condition "running"
    STEP: retrieving the pod 11/05/22 13:21:23.39
    STEP: looking for the results for each expected name from probers 11/05/22 13:21:23.393
    Nov  5 13:21:23.411: INFO: DNS probes using dns-708/dns-test-3a2f7eff-5df6-4bff-b24d-dac58f0963fb succeeded

    STEP: deleting the pod 11/05/22 13:21:23.411
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov  5 13:21:23.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-708" for this suite. 11/05/22 13:21:23.427
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:21:23.434
Nov  5 13:21:23.434: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 13:21:23.435
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:23.447
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:23.453
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237
STEP: creating service in namespace services-3668 11/05/22 13:21:23.456
STEP: creating service affinity-nodeport-transition in namespace services-3668 11/05/22 13:21:23.457
STEP: creating replication controller affinity-nodeport-transition in namespace services-3668 11/05/22 13:21:23.473
I1105 13:21:23.487323      20 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-3668, replica count: 3
I1105 13:21:26.537923      20 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 13:21:26.549: INFO: Creating new exec pod
Nov  5 13:21:26.555: INFO: Waiting up to 5m0s for pod "execpod-affinitynnz9f" in namespace "services-3668" to be "running"
Nov  5 13:21:26.558: INFO: Pod "execpod-affinitynnz9f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.201202ms
Nov  5 13:21:28.561: INFO: Pod "execpod-affinitynnz9f": Phase="Running", Reason="", readiness=true. Elapsed: 2.006538367s
Nov  5 13:21:28.561: INFO: Pod "execpod-affinitynnz9f" satisfied condition "running"
Nov  5 13:21:29.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Nov  5 13:21:29.721: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Nov  5 13:21:29.721: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:21:29.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.173 80'
Nov  5 13:21:29.851: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.173 80\nConnection to 10.152.183.173 80 port [tcp/http] succeeded!\n"
Nov  5 13:21:29.851: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:21:29.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.27.199 31968'
Nov  5 13:21:29.973: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.27.199 31968\nConnection to 172.31.27.199 31968 port [tcp/*] succeeded!\n"
Nov  5 13:21:29.973: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:21:29.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.255 31968'
Nov  5 13:21:30.096: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.0.255 31968\nConnection to 172.31.0.255 31968 port [tcp/*] succeeded!\n"
Nov  5 13:21:30.096: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:21:30.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.255:31968/ ; done'
Nov  5 13:21:30.331: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n"
Nov  5 13:21:30.331: INFO: stdout: "\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-w9fpz\naffinity-nodeport-transition-w9fpz\naffinity-nodeport-transition-w9fpz\naffinity-nodeport-transition-w9fpz\naffinity-nodeport-transition-dzxtb\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-dzxtb\naffinity-nodeport-transition-dzxtb\naffinity-nodeport-transition-w9fpz\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-dzxtb\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-dzxtb"
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-w9fpz
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-w9fpz
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-w9fpz
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-w9fpz
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-dzxtb
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-dzxtb
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-dzxtb
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-w9fpz
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-dzxtb
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-dzxtb
Nov  5 13:21:30.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.255:31968/ ; done'
Nov  5 13:21:30.545: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n"
Nov  5 13:21:30.545: INFO: stdout: "\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh"
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
Nov  5 13:21:30.546: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3668, will wait for the garbage collector to delete the pods 11/05/22 13:21:30.559
Nov  5 13:21:30.620: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.6853ms
Nov  5 13:21:30.720: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.578081ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 13:21:32.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3668" for this suite. 11/05/22 13:21:32.946
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":313,"skipped":5707,"failed":0}
------------------------------
• [SLOW TEST] [9.518 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2237

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:21:23.434
    Nov  5 13:21:23.434: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 13:21:23.435
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:23.447
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:23.453
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2237
    STEP: creating service in namespace services-3668 11/05/22 13:21:23.456
    STEP: creating service affinity-nodeport-transition in namespace services-3668 11/05/22 13:21:23.457
    STEP: creating replication controller affinity-nodeport-transition in namespace services-3668 11/05/22 13:21:23.473
    I1105 13:21:23.487323      20 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-3668, replica count: 3
    I1105 13:21:26.537923      20 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 13:21:26.549: INFO: Creating new exec pod
    Nov  5 13:21:26.555: INFO: Waiting up to 5m0s for pod "execpod-affinitynnz9f" in namespace "services-3668" to be "running"
    Nov  5 13:21:26.558: INFO: Pod "execpod-affinitynnz9f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.201202ms
    Nov  5 13:21:28.561: INFO: Pod "execpod-affinitynnz9f": Phase="Running", Reason="", readiness=true. Elapsed: 2.006538367s
    Nov  5 13:21:28.561: INFO: Pod "execpod-affinitynnz9f" satisfied condition "running"
    Nov  5 13:21:29.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Nov  5 13:21:29.721: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Nov  5 13:21:29.721: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:21:29.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.173 80'
    Nov  5 13:21:29.851: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.173 80\nConnection to 10.152.183.173 80 port [tcp/http] succeeded!\n"
    Nov  5 13:21:29.851: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:21:29.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.27.199 31968'
    Nov  5 13:21:29.973: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.27.199 31968\nConnection to 172.31.27.199 31968 port [tcp/*] succeeded!\n"
    Nov  5 13:21:29.973: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:21:29.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.0.255 31968'
    Nov  5 13:21:30.096: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.0.255 31968\nConnection to 172.31.0.255 31968 port [tcp/*] succeeded!\n"
    Nov  5 13:21:30.096: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:21:30.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.255:31968/ ; done'
    Nov  5 13:21:30.331: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n"
    Nov  5 13:21:30.331: INFO: stdout: "\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-w9fpz\naffinity-nodeport-transition-w9fpz\naffinity-nodeport-transition-w9fpz\naffinity-nodeport-transition-w9fpz\naffinity-nodeport-transition-dzxtb\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-dzxtb\naffinity-nodeport-transition-dzxtb\naffinity-nodeport-transition-w9fpz\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-dzxtb\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-dzxtb"
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-w9fpz
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-w9fpz
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-w9fpz
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-w9fpz
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-dzxtb
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-dzxtb
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-dzxtb
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-w9fpz
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-dzxtb
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.331: INFO: Received response from host: affinity-nodeport-transition-dzxtb
    Nov  5 13:21:30.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-3668 exec execpod-affinitynnz9f -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://172.31.0.255:31968/ ; done'
    Nov  5 13:21:30.545: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n+ echo\n+ curl -q -s --connect-timeout 2 http://172.31.0.255:31968/\n"
    Nov  5 13:21:30.545: INFO: stdout: "\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh\naffinity-nodeport-transition-cx7sh"
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.545: INFO: Received response from host: affinity-nodeport-transition-cx7sh
    Nov  5 13:21:30.546: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-3668, will wait for the garbage collector to delete the pods 11/05/22 13:21:30.559
    Nov  5 13:21:30.620: INFO: Deleting ReplicationController affinity-nodeport-transition took: 6.6853ms
    Nov  5 13:21:30.720: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 100.578081ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 13:21:32.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3668" for this suite. 11/05/22 13:21:32.946
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:21:32.954
Nov  5 13:21:32.954: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename ingressclass 11/05/22 13:21:32.954
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:32.968
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:32.972
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 11/05/22 13:21:32.976
STEP: getting /apis/networking.k8s.io 11/05/22 13:21:32.979
STEP: getting /apis/networking.k8s.iov1 11/05/22 13:21:32.98
STEP: creating 11/05/22 13:21:32.982
STEP: getting 11/05/22 13:21:32.995
STEP: listing 11/05/22 13:21:32.999
STEP: watching 11/05/22 13:21:33.002
Nov  5 13:21:33.002: INFO: starting watch
STEP: patching 11/05/22 13:21:33.003
STEP: updating 11/05/22 13:21:33.008
Nov  5 13:21:33.013: INFO: waiting for watch events with expected annotations
Nov  5 13:21:33.013: INFO: saw patched and updated annotations
STEP: deleting 11/05/22 13:21:33.013
STEP: deleting a collection 11/05/22 13:21:33.025
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Nov  5 13:21:33.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-3843" for this suite. 11/05/22 13:21:33.044
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":314,"skipped":5730,"failed":0}
------------------------------
• [0.096 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:21:32.954
    Nov  5 13:21:32.954: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename ingressclass 11/05/22 13:21:32.954
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:32.968
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:32.972
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 11/05/22 13:21:32.976
    STEP: getting /apis/networking.k8s.io 11/05/22 13:21:32.979
    STEP: getting /apis/networking.k8s.iov1 11/05/22 13:21:32.98
    STEP: creating 11/05/22 13:21:32.982
    STEP: getting 11/05/22 13:21:32.995
    STEP: listing 11/05/22 13:21:32.999
    STEP: watching 11/05/22 13:21:33.002
    Nov  5 13:21:33.002: INFO: starting watch
    STEP: patching 11/05/22 13:21:33.003
    STEP: updating 11/05/22 13:21:33.008
    Nov  5 13:21:33.013: INFO: waiting for watch events with expected annotations
    Nov  5 13:21:33.013: INFO: saw patched and updated annotations
    STEP: deleting 11/05/22 13:21:33.013
    STEP: deleting a collection 11/05/22 13:21:33.025
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Nov  5 13:21:33.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-3843" for this suite. 11/05/22 13:21:33.044
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:21:33.052
Nov  5 13:21:33.052: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename cronjob 11/05/22 13:21:33.053
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:33.065
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:33.069
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 11/05/22 13:21:33.075
STEP: creating 11/05/22 13:21:33.075
STEP: getting 11/05/22 13:21:33.08
STEP: listing 11/05/22 13:21:33.084
STEP: watching 11/05/22 13:21:33.087
Nov  5 13:21:33.087: INFO: starting watch
STEP: cluster-wide listing 11/05/22 13:21:33.088
STEP: cluster-wide watching 11/05/22 13:21:33.091
Nov  5 13:21:33.092: INFO: starting watch
STEP: patching 11/05/22 13:21:33.093
STEP: updating 11/05/22 13:21:33.1
Nov  5 13:21:33.109: INFO: waiting for watch events with expected annotations
Nov  5 13:21:33.109: INFO: saw patched and updated annotations
STEP: patching /status 11/05/22 13:21:33.109
STEP: updating /status 11/05/22 13:21:33.115
STEP: get /status 11/05/22 13:21:33.122
STEP: deleting 11/05/22 13:21:33.126
STEP: deleting a collection 11/05/22 13:21:33.14
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Nov  5 13:21:33.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5426" for this suite. 11/05/22 13:21:33.154
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":315,"skipped":5748,"failed":0}
------------------------------
• [0.108 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:21:33.052
    Nov  5 13:21:33.052: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename cronjob 11/05/22 13:21:33.053
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:33.065
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:33.069
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 11/05/22 13:21:33.075
    STEP: creating 11/05/22 13:21:33.075
    STEP: getting 11/05/22 13:21:33.08
    STEP: listing 11/05/22 13:21:33.084
    STEP: watching 11/05/22 13:21:33.087
    Nov  5 13:21:33.087: INFO: starting watch
    STEP: cluster-wide listing 11/05/22 13:21:33.088
    STEP: cluster-wide watching 11/05/22 13:21:33.091
    Nov  5 13:21:33.092: INFO: starting watch
    STEP: patching 11/05/22 13:21:33.093
    STEP: updating 11/05/22 13:21:33.1
    Nov  5 13:21:33.109: INFO: waiting for watch events with expected annotations
    Nov  5 13:21:33.109: INFO: saw patched and updated annotations
    STEP: patching /status 11/05/22 13:21:33.109
    STEP: updating /status 11/05/22 13:21:33.115
    STEP: get /status 11/05/22 13:21:33.122
    STEP: deleting 11/05/22 13:21:33.126
    STEP: deleting a collection 11/05/22 13:21:33.14
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Nov  5 13:21:33.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5426" for this suite. 11/05/22 13:21:33.154
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:21:33.161
Nov  5 13:21:33.162: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 13:21:33.162
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:33.174
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:33.178
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 11/05/22 13:21:33.181
Nov  5 13:21:33.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov  5 13:21:33.243: INFO: stderr: ""
Nov  5 13:21:33.243: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 11/05/22 13:21:33.243
Nov  5 13:21:33.243: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov  5 13:21:33.243: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-7480" to be "running and ready, or succeeded"
Nov  5 13:21:33.247: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.658927ms
Nov  5 13:21:33.247: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'ip-172-31-0-255' to be 'Running' but was 'Pending'
Nov  5 13:21:35.252: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.008351099s
Nov  5 13:21:35.252: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov  5 13:21:35.252: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 11/05/22 13:21:35.252
Nov  5 13:21:35.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator'
Nov  5 13:21:35.316: INFO: stderr: ""
Nov  5 13:21:35.316: INFO: stdout: "I1105 13:21:34.206704       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/wn6 343\nI1105 13:21:34.406772       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/hdg 479\nI1105 13:21:34.607135       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/lr2h 478\nI1105 13:21:34.806748       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/mqd6 524\nI1105 13:21:35.007050       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/v49x 563\nI1105 13:21:35.207212       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/4x9 328\n"
STEP: limiting log lines 11/05/22 13:21:35.316
Nov  5 13:21:35.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator --tail=1'
Nov  5 13:21:35.385: INFO: stderr: ""
Nov  5 13:21:35.385: INFO: stdout: "I1105 13:21:35.207212       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/4x9 328\n"
Nov  5 13:21:35.385: INFO: got output "I1105 13:21:35.207212       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/4x9 328\n"
STEP: limiting log bytes 11/05/22 13:21:35.385
Nov  5 13:21:35.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator --limit-bytes=1'
Nov  5 13:21:35.453: INFO: stderr: ""
Nov  5 13:21:35.453: INFO: stdout: "I"
Nov  5 13:21:35.453: INFO: got output "I"
STEP: exposing timestamps 11/05/22 13:21:35.453
Nov  5 13:21:35.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator --tail=1 --timestamps'
Nov  5 13:21:35.518: INFO: stderr: ""
Nov  5 13:21:35.518: INFO: stdout: "2022-11-05T13:21:35.407631477Z I1105 13:21:35.407517       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/p8mv 273\n"
Nov  5 13:21:35.518: INFO: got output "2022-11-05T13:21:35.407631477Z I1105 13:21:35.407517       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/p8mv 273\n"
STEP: restricting to a time range 11/05/22 13:21:35.518
Nov  5 13:21:38.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator --since=1s'
Nov  5 13:21:38.084: INFO: stderr: ""
Nov  5 13:21:38.084: INFO: stdout: "I1105 13:21:37.206878       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/ltpv 477\nI1105 13:21:37.407182       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/5mn 483\nI1105 13:21:37.607443       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/4ptn 406\nI1105 13:21:37.806678       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/tkk 334\nI1105 13:21:38.006974       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/hzm 425\n"
Nov  5 13:21:38.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator --since=24h'
Nov  5 13:21:38.148: INFO: stderr: ""
Nov  5 13:21:38.148: INFO: stdout: "I1105 13:21:34.206704       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/wn6 343\nI1105 13:21:34.406772       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/hdg 479\nI1105 13:21:34.607135       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/lr2h 478\nI1105 13:21:34.806748       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/mqd6 524\nI1105 13:21:35.007050       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/v49x 563\nI1105 13:21:35.207212       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/4x9 328\nI1105 13:21:35.407517       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/p8mv 273\nI1105 13:21:35.606755       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/bn48 252\nI1105 13:21:35.807084       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/gkb 416\nI1105 13:21:36.007359       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/z6n 451\nI1105 13:21:36.207660       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/rqc 530\nI1105 13:21:36.406776       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/t2s5 207\nI1105 13:21:36.607054       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/xjp 200\nI1105 13:21:36.807355       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/f8h 474\nI1105 13:21:37.007653       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/ppd 413\nI1105 13:21:37.206878       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/ltpv 477\nI1105 13:21:37.407182       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/5mn 483\nI1105 13:21:37.607443       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/4ptn 406\nI1105 13:21:37.806678       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/tkk 334\nI1105 13:21:38.006974       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/hzm 425\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Nov  5 13:21:38.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 delete pod logs-generator'
Nov  5 13:21:39.468: INFO: stderr: ""
Nov  5 13:21:39.468: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 13:21:39.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7480" for this suite. 11/05/22 13:21:39.473
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":316,"skipped":5759,"failed":0}
------------------------------
• [SLOW TEST] [6.318 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:21:33.161
    Nov  5 13:21:33.162: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 13:21:33.162
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:33.174
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:33.178
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 11/05/22 13:21:33.181
    Nov  5 13:21:33.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Nov  5 13:21:33.243: INFO: stderr: ""
    Nov  5 13:21:33.243: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 11/05/22 13:21:33.243
    Nov  5 13:21:33.243: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Nov  5 13:21:33.243: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-7480" to be "running and ready, or succeeded"
    Nov  5 13:21:33.247: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.658927ms
    Nov  5 13:21:33.247: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'ip-172-31-0-255' to be 'Running' but was 'Pending'
    Nov  5 13:21:35.252: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.008351099s
    Nov  5 13:21:35.252: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Nov  5 13:21:35.252: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 11/05/22 13:21:35.252
    Nov  5 13:21:35.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator'
    Nov  5 13:21:35.316: INFO: stderr: ""
    Nov  5 13:21:35.316: INFO: stdout: "I1105 13:21:34.206704       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/wn6 343\nI1105 13:21:34.406772       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/hdg 479\nI1105 13:21:34.607135       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/lr2h 478\nI1105 13:21:34.806748       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/mqd6 524\nI1105 13:21:35.007050       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/v49x 563\nI1105 13:21:35.207212       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/4x9 328\n"
    STEP: limiting log lines 11/05/22 13:21:35.316
    Nov  5 13:21:35.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator --tail=1'
    Nov  5 13:21:35.385: INFO: stderr: ""
    Nov  5 13:21:35.385: INFO: stdout: "I1105 13:21:35.207212       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/4x9 328\n"
    Nov  5 13:21:35.385: INFO: got output "I1105 13:21:35.207212       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/4x9 328\n"
    STEP: limiting log bytes 11/05/22 13:21:35.385
    Nov  5 13:21:35.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator --limit-bytes=1'
    Nov  5 13:21:35.453: INFO: stderr: ""
    Nov  5 13:21:35.453: INFO: stdout: "I"
    Nov  5 13:21:35.453: INFO: got output "I"
    STEP: exposing timestamps 11/05/22 13:21:35.453
    Nov  5 13:21:35.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator --tail=1 --timestamps'
    Nov  5 13:21:35.518: INFO: stderr: ""
    Nov  5 13:21:35.518: INFO: stdout: "2022-11-05T13:21:35.407631477Z I1105 13:21:35.407517       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/p8mv 273\n"
    Nov  5 13:21:35.518: INFO: got output "2022-11-05T13:21:35.407631477Z I1105 13:21:35.407517       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/p8mv 273\n"
    STEP: restricting to a time range 11/05/22 13:21:35.518
    Nov  5 13:21:38.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator --since=1s'
    Nov  5 13:21:38.084: INFO: stderr: ""
    Nov  5 13:21:38.084: INFO: stdout: "I1105 13:21:37.206878       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/ltpv 477\nI1105 13:21:37.407182       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/5mn 483\nI1105 13:21:37.607443       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/4ptn 406\nI1105 13:21:37.806678       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/tkk 334\nI1105 13:21:38.006974       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/hzm 425\n"
    Nov  5 13:21:38.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 logs logs-generator logs-generator --since=24h'
    Nov  5 13:21:38.148: INFO: stderr: ""
    Nov  5 13:21:38.148: INFO: stdout: "I1105 13:21:34.206704       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/wn6 343\nI1105 13:21:34.406772       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/hdg 479\nI1105 13:21:34.607135       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/lr2h 478\nI1105 13:21:34.806748       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/mqd6 524\nI1105 13:21:35.007050       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/v49x 563\nI1105 13:21:35.207212       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/4x9 328\nI1105 13:21:35.407517       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/p8mv 273\nI1105 13:21:35.606755       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/bn48 252\nI1105 13:21:35.807084       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/gkb 416\nI1105 13:21:36.007359       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/z6n 451\nI1105 13:21:36.207660       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/rqc 530\nI1105 13:21:36.406776       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/t2s5 207\nI1105 13:21:36.607054       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/xjp 200\nI1105 13:21:36.807355       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/f8h 474\nI1105 13:21:37.007653       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/ppd 413\nI1105 13:21:37.206878       1 logs_generator.go:76] 15 GET /api/v1/namespaces/ns/pods/ltpv 477\nI1105 13:21:37.407182       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/5mn 483\nI1105 13:21:37.607443       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/4ptn 406\nI1105 13:21:37.806678       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/tkk 334\nI1105 13:21:38.006974       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/hzm 425\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Nov  5 13:21:38.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7480 delete pod logs-generator'
    Nov  5 13:21:39.468: INFO: stderr: ""
    Nov  5 13:21:39.468: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 13:21:39.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7480" for this suite. 11/05/22 13:21:39.473
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:21:39.48
Nov  5 13:21:39.480: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 13:21:39.481
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:39.494
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:39.501
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-4714 11/05/22 13:21:39.505
STEP: creating service affinity-clusterip in namespace services-4714 11/05/22 13:21:39.505
STEP: creating replication controller affinity-clusterip in namespace services-4714 11/05/22 13:21:39.519
I1105 13:21:39.531469      20 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-4714, replica count: 3
I1105 13:21:42.583109      20 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 13:21:42.590: INFO: Creating new exec pod
Nov  5 13:21:42.597: INFO: Waiting up to 5m0s for pod "execpod-affinityr4gtl" in namespace "services-4714" to be "running"
Nov  5 13:21:42.601: INFO: Pod "execpod-affinityr4gtl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.508215ms
Nov  5 13:21:44.605: INFO: Pod "execpod-affinityr4gtl": Phase="Running", Reason="", readiness=true. Elapsed: 2.008025973s
Nov  5 13:21:44.605: INFO: Pod "execpod-affinityr4gtl" satisfied condition "running"
Nov  5 13:21:45.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4714 exec execpod-affinityr4gtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Nov  5 13:21:45.748: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Nov  5 13:21:45.749: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:21:45.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4714 exec execpod-affinityr4gtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.122 80'
Nov  5 13:21:45.894: INFO: stderr: "+ nc -v -t -w 2 10.152.183.122 80\n+ echo hostName\nConnection to 10.152.183.122 80 port [tcp/http] succeeded!\n"
Nov  5 13:21:45.894: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:21:45.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4714 exec execpod-affinityr4gtl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.122:80/ ; done'
Nov  5 13:21:46.090: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n"
Nov  5 13:21:46.090: INFO: stdout: "\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7"
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
Nov  5 13:21:46.090: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-4714, will wait for the garbage collector to delete the pods 11/05/22 13:21:46.102
Nov  5 13:21:46.165: INFO: Deleting ReplicationController affinity-clusterip took: 8.233216ms
Nov  5 13:21:46.265: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.542409ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 13:21:48.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4714" for this suite. 11/05/22 13:21:48.585
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":317,"skipped":5767,"failed":0}
------------------------------
• [SLOW TEST] [9.112 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:21:39.48
    Nov  5 13:21:39.480: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 13:21:39.481
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:39.494
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:39.501
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-4714 11/05/22 13:21:39.505
    STEP: creating service affinity-clusterip in namespace services-4714 11/05/22 13:21:39.505
    STEP: creating replication controller affinity-clusterip in namespace services-4714 11/05/22 13:21:39.519
    I1105 13:21:39.531469      20 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-4714, replica count: 3
    I1105 13:21:42.583109      20 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 13:21:42.590: INFO: Creating new exec pod
    Nov  5 13:21:42.597: INFO: Waiting up to 5m0s for pod "execpod-affinityr4gtl" in namespace "services-4714" to be "running"
    Nov  5 13:21:42.601: INFO: Pod "execpod-affinityr4gtl": Phase="Pending", Reason="", readiness=false. Elapsed: 4.508215ms
    Nov  5 13:21:44.605: INFO: Pod "execpod-affinityr4gtl": Phase="Running", Reason="", readiness=true. Elapsed: 2.008025973s
    Nov  5 13:21:44.605: INFO: Pod "execpod-affinityr4gtl" satisfied condition "running"
    Nov  5 13:21:45.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4714 exec execpod-affinityr4gtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Nov  5 13:21:45.748: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Nov  5 13:21:45.749: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:21:45.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4714 exec execpod-affinityr4gtl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.122 80'
    Nov  5 13:21:45.894: INFO: stderr: "+ nc -v -t -w 2 10.152.183.122 80\n+ echo hostName\nConnection to 10.152.183.122 80 port [tcp/http] succeeded!\n"
    Nov  5 13:21:45.894: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:21:45.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4714 exec execpod-affinityr4gtl -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.152.183.122:80/ ; done'
    Nov  5 13:21:46.090: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.152.183.122:80/\n"
    Nov  5 13:21:46.090: INFO: stdout: "\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7\naffinity-clusterip-k9bv7"
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Received response from host: affinity-clusterip-k9bv7
    Nov  5 13:21:46.090: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-4714, will wait for the garbage collector to delete the pods 11/05/22 13:21:46.102
    Nov  5 13:21:46.165: INFO: Deleting ReplicationController affinity-clusterip took: 8.233216ms
    Nov  5 13:21:46.265: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.542409ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 13:21:48.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4714" for this suite. 11/05/22 13:21:48.585
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:21:48.592
Nov  5 13:21:48.592: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename replication-controller 11/05/22 13:21:48.593
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:48.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:48.608
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 11/05/22 13:21:48.612
STEP: When the matched label of one of its pods change 11/05/22 13:21:48.617
Nov  5 13:21:48.622: INFO: Pod name pod-release: Found 0 pods out of 1
Nov  5 13:21:53.628: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 11/05/22 13:21:53.638
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Nov  5 13:21:54.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2225" for this suite. 11/05/22 13:21:54.651
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":318,"skipped":5772,"failed":0}
------------------------------
• [SLOW TEST] [6.065 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:21:48.592
    Nov  5 13:21:48.592: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename replication-controller 11/05/22 13:21:48.593
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:48.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:48.608
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 11/05/22 13:21:48.612
    STEP: When the matched label of one of its pods change 11/05/22 13:21:48.617
    Nov  5 13:21:48.622: INFO: Pod name pod-release: Found 0 pods out of 1
    Nov  5 13:21:53.628: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 11/05/22 13:21:53.638
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Nov  5 13:21:54.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-2225" for this suite. 11/05/22 13:21:54.651
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:21:54.659
Nov  5 13:21:54.659: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename svcaccounts 11/05/22 13:21:54.66
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:54.674
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:54.679
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 11/05/22 13:21:54.682
STEP: watching for the ServiceAccount to be added 11/05/22 13:21:54.692
STEP: patching the ServiceAccount 11/05/22 13:21:54.694
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 11/05/22 13:21:54.7
STEP: deleting the ServiceAccount 11/05/22 13:21:54.703
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Nov  5 13:21:54.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2110" for this suite. 11/05/22 13:21:54.72
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":319,"skipped":5804,"failed":0}
------------------------------
• [0.066 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:21:54.659
    Nov  5 13:21:54.659: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename svcaccounts 11/05/22 13:21:54.66
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:54.674
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:54.679
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 11/05/22 13:21:54.682
    STEP: watching for the ServiceAccount to be added 11/05/22 13:21:54.692
    STEP: patching the ServiceAccount 11/05/22 13:21:54.694
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 11/05/22 13:21:54.7
    STEP: deleting the ServiceAccount 11/05/22 13:21:54.703
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Nov  5 13:21:54.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2110" for this suite. 11/05/22 13:21:54.72
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:21:54.727
Nov  5 13:21:54.727: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 13:21:54.728
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:54.74
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:54.744
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 11/05/22 13:21:54.748
STEP: Counting existing ResourceQuota 11/05/22 13:21:59.751
STEP: Creating a ResourceQuota 11/05/22 13:22:04.756
STEP: Ensuring resource quota status is calculated 11/05/22 13:22:04.761
STEP: Creating a Secret 11/05/22 13:22:06.766
STEP: Ensuring resource quota status captures secret creation 11/05/22 13:22:06.777
STEP: Deleting a secret 11/05/22 13:22:08.781
STEP: Ensuring resource quota status released usage 11/05/22 13:22:08.788
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 13:22:10.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-0" for this suite. 11/05/22 13:22:10.796
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":320,"skipped":5819,"failed":0}
------------------------------
• [SLOW TEST] [16.075 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:21:54.727
    Nov  5 13:21:54.727: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 13:21:54.728
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:21:54.74
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:21:54.744
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 11/05/22 13:21:54.748
    STEP: Counting existing ResourceQuota 11/05/22 13:21:59.751
    STEP: Creating a ResourceQuota 11/05/22 13:22:04.756
    STEP: Ensuring resource quota status is calculated 11/05/22 13:22:04.761
    STEP: Creating a Secret 11/05/22 13:22:06.766
    STEP: Ensuring resource quota status captures secret creation 11/05/22 13:22:06.777
    STEP: Deleting a secret 11/05/22 13:22:08.781
    STEP: Ensuring resource quota status released usage 11/05/22 13:22:08.788
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 13:22:10.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-0" for this suite. 11/05/22 13:22:10.796
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:22:10.804
Nov  5 13:22:10.804: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 13:22:10.805
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:22:10.827
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:22:10.83
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 11/05/22 13:22:10.872
Nov  5 13:22:10.872: INFO: namespace kubectl-7115
Nov  5 13:22:10.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7115 create -f -'
Nov  5 13:22:11.053: INFO: stderr: ""
Nov  5 13:22:11.053: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/05/22 13:22:11.053
Nov  5 13:22:12.057: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  5 13:22:12.057: INFO: Found 0 / 1
Nov  5 13:22:13.058: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  5 13:22:13.058: INFO: Found 1 / 1
Nov  5 13:22:13.058: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  5 13:22:13.061: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  5 13:22:13.061: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  5 13:22:13.061: INFO: wait on agnhost-primary startup in kubectl-7115 
Nov  5 13:22:13.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7115 logs agnhost-primary-c88cg agnhost-primary'
Nov  5 13:22:13.125: INFO: stderr: ""
Nov  5 13:22:13.125: INFO: stdout: "Paused\n"
STEP: exposing RC 11/05/22 13:22:13.125
Nov  5 13:22:13.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7115 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Nov  5 13:22:13.198: INFO: stderr: ""
Nov  5 13:22:13.198: INFO: stdout: "service/rm2 exposed\n"
Nov  5 13:22:13.205: INFO: Service rm2 in namespace kubectl-7115 found.
STEP: exposing service 11/05/22 13:22:15.212
Nov  5 13:22:15.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7115 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Nov  5 13:22:15.284: INFO: stderr: ""
Nov  5 13:22:15.284: INFO: stdout: "service/rm3 exposed\n"
Nov  5 13:22:15.293: INFO: Service rm3 in namespace kubectl-7115 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 13:22:17.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7115" for this suite. 11/05/22 13:22:17.305
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":321,"skipped":5842,"failed":0}
------------------------------
• [SLOW TEST] [6.509 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:22:10.804
    Nov  5 13:22:10.804: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 13:22:10.805
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:22:10.827
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:22:10.83
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 11/05/22 13:22:10.872
    Nov  5 13:22:10.872: INFO: namespace kubectl-7115
    Nov  5 13:22:10.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7115 create -f -'
    Nov  5 13:22:11.053: INFO: stderr: ""
    Nov  5 13:22:11.053: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/05/22 13:22:11.053
    Nov  5 13:22:12.057: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov  5 13:22:12.057: INFO: Found 0 / 1
    Nov  5 13:22:13.058: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov  5 13:22:13.058: INFO: Found 1 / 1
    Nov  5 13:22:13.058: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Nov  5 13:22:13.061: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov  5 13:22:13.061: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov  5 13:22:13.061: INFO: wait on agnhost-primary startup in kubectl-7115 
    Nov  5 13:22:13.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7115 logs agnhost-primary-c88cg agnhost-primary'
    Nov  5 13:22:13.125: INFO: stderr: ""
    Nov  5 13:22:13.125: INFO: stdout: "Paused\n"
    STEP: exposing RC 11/05/22 13:22:13.125
    Nov  5 13:22:13.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7115 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Nov  5 13:22:13.198: INFO: stderr: ""
    Nov  5 13:22:13.198: INFO: stdout: "service/rm2 exposed\n"
    Nov  5 13:22:13.205: INFO: Service rm2 in namespace kubectl-7115 found.
    STEP: exposing service 11/05/22 13:22:15.212
    Nov  5 13:22:15.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-7115 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Nov  5 13:22:15.284: INFO: stderr: ""
    Nov  5 13:22:15.284: INFO: stdout: "service/rm3 exposed\n"
    Nov  5 13:22:15.293: INFO: Service rm3 in namespace kubectl-7115 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 13:22:17.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7115" for this suite. 11/05/22 13:22:17.305
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:22:17.314
Nov  5 13:22:17.314: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename pod-network-test 11/05/22 13:22:17.315
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:22:17.326
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:22:17.33
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-636 11/05/22 13:22:17.333
STEP: creating a selector 11/05/22 13:22:17.333
STEP: Creating the service pods in kubernetes 11/05/22 13:22:17.333
Nov  5 13:22:17.333: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Nov  5 13:22:17.365: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-636" to be "running and ready"
Nov  5 13:22:17.373: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.745785ms
Nov  5 13:22:17.374: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:22:19.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.013718048s
Nov  5 13:22:19.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:22:21.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013189932s
Nov  5 13:22:21.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:22:23.379: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.013826346s
Nov  5 13:22:23.379: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:22:25.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.013522812s
Nov  5 13:22:25.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:22:27.377: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.012646234s
Nov  5 13:22:27.377: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:22:29.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.013557047s
Nov  5 13:22:29.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:22:31.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.013551359s
Nov  5 13:22:31.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:22:33.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.013422307s
Nov  5 13:22:33.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:22:35.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.012889031s
Nov  5 13:22:35.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:22:37.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013386887s
Nov  5 13:22:37.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Nov  5 13:22:39.379: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.0143362s
Nov  5 13:22:39.379: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Nov  5 13:22:39.379: INFO: Pod "netserver-0" satisfied condition "running and ready"
Nov  5 13:22:39.382: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-636" to be "running and ready"
Nov  5 13:22:39.386: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.52627ms
Nov  5 13:22:39.386: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Nov  5 13:22:39.386: INFO: Pod "netserver-1" satisfied condition "running and ready"
Nov  5 13:22:39.389: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-636" to be "running and ready"
Nov  5 13:22:39.393: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.081875ms
Nov  5 13:22:39.393: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Nov  5 13:22:39.393: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 11/05/22 13:22:39.396
Nov  5 13:22:39.401: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-636" to be "running"
Nov  5 13:22:39.404: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.414015ms
Nov  5 13:22:41.409: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007850127s
Nov  5 13:22:41.409: INFO: Pod "test-container-pod" satisfied condition "running"
Nov  5 13:22:41.413: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Nov  5 13:22:41.413: INFO: Breadth first check of 192.168.206.163 on host 172.31.0.255...
Nov  5 13:22:41.416: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.181:9080/dial?request=hostname&protocol=udp&host=192.168.206.163&port=8081&tries=1'] Namespace:pod-network-test-636 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:22:41.416: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:22:41.416: INFO: ExecWithOptions: Clientset creation
Nov  5 13:22:41.416: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-636/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.181%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.206.163%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov  5 13:22:41.508: INFO: Waiting for responses: map[]
Nov  5 13:22:41.508: INFO: reached 192.168.206.163 after 0/1 tries
Nov  5 13:22:41.508: INFO: Breadth first check of 192.168.242.26 on host 172.31.27.199...
Nov  5 13:22:41.512: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.181:9080/dial?request=hostname&protocol=udp&host=192.168.242.26&port=8081&tries=1'] Namespace:pod-network-test-636 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:22:41.512: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:22:41.512: INFO: ExecWithOptions: Clientset creation
Nov  5 13:22:41.512: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-636/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.181%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.242.26%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov  5 13:22:41.594: INFO: Waiting for responses: map[]
Nov  5 13:22:41.594: INFO: reached 192.168.242.26 after 0/1 tries
Nov  5 13:22:41.594: INFO: Breadth first check of 192.168.90.105 on host 172.31.41.19...
Nov  5 13:22:41.598: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.181:9080/dial?request=hostname&protocol=udp&host=192.168.90.105&port=8081&tries=1'] Namespace:pod-network-test-636 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:22:41.598: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:22:41.599: INFO: ExecWithOptions: Clientset creation
Nov  5 13:22:41.599: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-636/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.181%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.90.105%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Nov  5 13:22:41.662: INFO: Waiting for responses: map[]
Nov  5 13:22:41.662: INFO: reached 192.168.90.105 after 0/1 tries
Nov  5 13:22:41.662: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Nov  5 13:22:41.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-636" for this suite. 11/05/22 13:22:41.666
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":322,"skipped":5859,"failed":0}
------------------------------
• [SLOW TEST] [24.359 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:22:17.314
    Nov  5 13:22:17.314: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename pod-network-test 11/05/22 13:22:17.315
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:22:17.326
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:22:17.33
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-636 11/05/22 13:22:17.333
    STEP: creating a selector 11/05/22 13:22:17.333
    STEP: Creating the service pods in kubernetes 11/05/22 13:22:17.333
    Nov  5 13:22:17.333: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Nov  5 13:22:17.365: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-636" to be "running and ready"
    Nov  5 13:22:17.373: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.745785ms
    Nov  5 13:22:17.374: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:22:19.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.013718048s
    Nov  5 13:22:19.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:22:21.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.013189932s
    Nov  5 13:22:21.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:22:23.379: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.013826346s
    Nov  5 13:22:23.379: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:22:25.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.013522812s
    Nov  5 13:22:25.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:22:27.377: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.012646234s
    Nov  5 13:22:27.377: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:22:29.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 12.013557047s
    Nov  5 13:22:29.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:22:31.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 14.013551359s
    Nov  5 13:22:31.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:22:33.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 16.013422307s
    Nov  5 13:22:33.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:22:35.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 18.012889031s
    Nov  5 13:22:35.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:22:37.378: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 20.013386887s
    Nov  5 13:22:37.378: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Nov  5 13:22:39.379: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 22.0143362s
    Nov  5 13:22:39.379: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Nov  5 13:22:39.379: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Nov  5 13:22:39.382: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-636" to be "running and ready"
    Nov  5 13:22:39.386: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 3.52627ms
    Nov  5 13:22:39.386: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Nov  5 13:22:39.386: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Nov  5 13:22:39.389: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-636" to be "running and ready"
    Nov  5 13:22:39.393: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 3.081875ms
    Nov  5 13:22:39.393: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Nov  5 13:22:39.393: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 11/05/22 13:22:39.396
    Nov  5 13:22:39.401: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-636" to be "running"
    Nov  5 13:22:39.404: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.414015ms
    Nov  5 13:22:41.409: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007850127s
    Nov  5 13:22:41.409: INFO: Pod "test-container-pod" satisfied condition "running"
    Nov  5 13:22:41.413: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Nov  5 13:22:41.413: INFO: Breadth first check of 192.168.206.163 on host 172.31.0.255...
    Nov  5 13:22:41.416: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.181:9080/dial?request=hostname&protocol=udp&host=192.168.206.163&port=8081&tries=1'] Namespace:pod-network-test-636 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:22:41.416: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:22:41.416: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:22:41.416: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-636/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.181%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.206.163%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov  5 13:22:41.508: INFO: Waiting for responses: map[]
    Nov  5 13:22:41.508: INFO: reached 192.168.206.163 after 0/1 tries
    Nov  5 13:22:41.508: INFO: Breadth first check of 192.168.242.26 on host 172.31.27.199...
    Nov  5 13:22:41.512: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.181:9080/dial?request=hostname&protocol=udp&host=192.168.242.26&port=8081&tries=1'] Namespace:pod-network-test-636 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:22:41.512: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:22:41.512: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:22:41.512: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-636/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.181%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.242.26%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov  5 13:22:41.594: INFO: Waiting for responses: map[]
    Nov  5 13:22:41.594: INFO: reached 192.168.242.26 after 0/1 tries
    Nov  5 13:22:41.594: INFO: Breadth first check of 192.168.90.105 on host 172.31.41.19...
    Nov  5 13:22:41.598: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.206.181:9080/dial?request=hostname&protocol=udp&host=192.168.90.105&port=8081&tries=1'] Namespace:pod-network-test-636 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:22:41.598: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:22:41.599: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:22:41.599: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/pod-network-test-636/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F192.168.206.181%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D192.168.90.105%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Nov  5 13:22:41.662: INFO: Waiting for responses: map[]
    Nov  5 13:22:41.662: INFO: reached 192.168.90.105 after 0/1 tries
    Nov  5 13:22:41.662: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Nov  5 13:22:41.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-636" for this suite. 11/05/22 13:22:41.666
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:22:41.673
Nov  5 13:22:41.673: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 13:22:41.673
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:22:41.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:22:41.692
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2345 11/05/22 13:22:41.695
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/05/22 13:22:41.704
STEP: creating service externalsvc in namespace services-2345 11/05/22 13:22:41.704
STEP: creating replication controller externalsvc in namespace services-2345 11/05/22 13:22:41.722
I1105 13:22:41.729261      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2345, replica count: 2
I1105 13:22:44.779734      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 11/05/22 13:22:44.783
Nov  5 13:22:44.798: INFO: Creating new exec pod
Nov  5 13:22:44.804: INFO: Waiting up to 5m0s for pod "execpod949sb" in namespace "services-2345" to be "running"
Nov  5 13:22:44.808: INFO: Pod "execpod949sb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.39437ms
Nov  5 13:22:46.811: INFO: Pod "execpod949sb": Phase="Running", Reason="", readiness=true. Elapsed: 2.006802648s
Nov  5 13:22:46.811: INFO: Pod "execpod949sb" satisfied condition "running"
Nov  5 13:22:46.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2345 exec execpod949sb -- /bin/sh -x -c nslookup clusterip-service.services-2345.svc.cluster.local'
Nov  5 13:22:46.988: INFO: stderr: "+ nslookup clusterip-service.services-2345.svc.cluster.local\n"
Nov  5 13:22:46.988: INFO: stdout: "Server:\t\t10.152.183.192\nAddress:\t10.152.183.192#53\n\nclusterip-service.services-2345.svc.cluster.local\tcanonical name = externalsvc.services-2345.svc.cluster.local.\nName:\texternalsvc.services-2345.svc.cluster.local\nAddress: 10.152.183.146\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2345, will wait for the garbage collector to delete the pods 11/05/22 13:22:46.988
Nov  5 13:22:47.052: INFO: Deleting ReplicationController externalsvc took: 7.569687ms
Nov  5 13:22:47.152: INFO: Terminating ReplicationController externalsvc pods took: 100.346883ms
Nov  5 13:22:49.669: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 13:22:49.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2345" for this suite. 11/05/22 13:22:49.689
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":323,"skipped":5865,"failed":0}
------------------------------
• [SLOW TEST] [8.023 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:22:41.673
    Nov  5 13:22:41.673: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 13:22:41.673
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:22:41.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:22:41.692
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2345 11/05/22 13:22:41.695
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/05/22 13:22:41.704
    STEP: creating service externalsvc in namespace services-2345 11/05/22 13:22:41.704
    STEP: creating replication controller externalsvc in namespace services-2345 11/05/22 13:22:41.722
    I1105 13:22:41.729261      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-2345, replica count: 2
    I1105 13:22:44.779734      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 11/05/22 13:22:44.783
    Nov  5 13:22:44.798: INFO: Creating new exec pod
    Nov  5 13:22:44.804: INFO: Waiting up to 5m0s for pod "execpod949sb" in namespace "services-2345" to be "running"
    Nov  5 13:22:44.808: INFO: Pod "execpod949sb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.39437ms
    Nov  5 13:22:46.811: INFO: Pod "execpod949sb": Phase="Running", Reason="", readiness=true. Elapsed: 2.006802648s
    Nov  5 13:22:46.811: INFO: Pod "execpod949sb" satisfied condition "running"
    Nov  5 13:22:46.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-2345 exec execpod949sb -- /bin/sh -x -c nslookup clusterip-service.services-2345.svc.cluster.local'
    Nov  5 13:22:46.988: INFO: stderr: "+ nslookup clusterip-service.services-2345.svc.cluster.local\n"
    Nov  5 13:22:46.988: INFO: stdout: "Server:\t\t10.152.183.192\nAddress:\t10.152.183.192#53\n\nclusterip-service.services-2345.svc.cluster.local\tcanonical name = externalsvc.services-2345.svc.cluster.local.\nName:\texternalsvc.services-2345.svc.cluster.local\nAddress: 10.152.183.146\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-2345, will wait for the garbage collector to delete the pods 11/05/22 13:22:46.988
    Nov  5 13:22:47.052: INFO: Deleting ReplicationController externalsvc took: 7.569687ms
    Nov  5 13:22:47.152: INFO: Terminating ReplicationController externalsvc pods took: 100.346883ms
    Nov  5 13:22:49.669: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 13:22:49.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2345" for this suite. 11/05/22 13:22:49.689
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:22:49.697
Nov  5 13:22:49.697: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-lifecycle-hook 11/05/22 13:22:49.698
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:22:49.709
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:22:49.714
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/05/22 13:22:49.721
Nov  5 13:22:49.730: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8579" to be "running and ready"
Nov  5 13:22:49.737: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.72771ms
Nov  5 13:22:49.737: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:22:51.742: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.012203565s
Nov  5 13:22:51.742: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov  5 13:22:51.742: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 11/05/22 13:22:51.745
Nov  5 13:22:51.751: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-8579" to be "running and ready"
Nov  5 13:22:51.756: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.514075ms
Nov  5 13:22:51.756: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:22:53.763: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011931254s
Nov  5 13:22:53.763: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Nov  5 13:22:53.763: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 11/05/22 13:22:53.767
Nov  5 13:22:53.775: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 13:22:53.778: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 13:22:55.779: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 13:22:55.783: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  5 13:22:57.780: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  5 13:22:57.784: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 11/05/22 13:22:57.784
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov  5 13:22:57.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8579" for this suite. 11/05/22 13:22:57.795
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":324,"skipped":5876,"failed":0}
------------------------------
• [SLOW TEST] [8.104 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:22:49.697
    Nov  5 13:22:49.697: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/05/22 13:22:49.698
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:22:49.709
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:22:49.714
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/05/22 13:22:49.721
    Nov  5 13:22:49.730: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-8579" to be "running and ready"
    Nov  5 13:22:49.737: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 7.72771ms
    Nov  5 13:22:49.737: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:22:51.742: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.012203565s
    Nov  5 13:22:51.742: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov  5 13:22:51.742: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 11/05/22 13:22:51.745
    Nov  5 13:22:51.751: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-8579" to be "running and ready"
    Nov  5 13:22:51.756: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 4.514075ms
    Nov  5 13:22:51.756: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:22:53.763: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.011931254s
    Nov  5 13:22:53.763: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Nov  5 13:22:53.763: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 11/05/22 13:22:53.767
    Nov  5 13:22:53.775: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov  5 13:22:53.778: INFO: Pod pod-with-prestop-exec-hook still exists
    Nov  5 13:22:55.779: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov  5 13:22:55.783: INFO: Pod pod-with-prestop-exec-hook still exists
    Nov  5 13:22:57.780: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Nov  5 13:22:57.784: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 11/05/22 13:22:57.784
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov  5 13:22:57.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-8579" for this suite. 11/05/22 13:22:57.795
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:22:57.802
Nov  5 13:22:57.802: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 13:22:57.802
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:22:57.816
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:22:57.82
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-30ab77a1-301a-42b6-9c13-42f929b61899 11/05/22 13:22:57.827
STEP: Creating secret with name s-test-opt-upd-1cbf48d4-697a-4f3b-b648-3674410e6dd7 11/05/22 13:22:57.833
STEP: Creating the pod 11/05/22 13:22:57.838
Nov  5 13:22:57.847: INFO: Waiting up to 5m0s for pod "pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f" in namespace "secrets-315" to be "running and ready"
Nov  5 13:22:57.854: INFO: Pod "pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.195376ms
Nov  5 13:22:57.854: INFO: The phase of Pod pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:22:59.858: INFO: Pod "pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f": Phase="Running", Reason="", readiness=true. Elapsed: 2.010657523s
Nov  5 13:22:59.858: INFO: The phase of Pod pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f is Running (Ready = true)
Nov  5 13:22:59.858: INFO: Pod "pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-30ab77a1-301a-42b6-9c13-42f929b61899 11/05/22 13:22:59.879
STEP: Updating secret s-test-opt-upd-1cbf48d4-697a-4f3b-b648-3674410e6dd7 11/05/22 13:22:59.886
STEP: Creating secret with name s-test-opt-create-f2dd71b6-8f70-446b-a1b0-5e983ee97f9a 11/05/22 13:22:59.89
STEP: waiting to observe update in volume 11/05/22 13:22:59.894
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov  5 13:23:01.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-315" for this suite. 11/05/22 13:23:01.924
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":325,"skipped":5876,"failed":0}
------------------------------
• [4.129 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:22:57.802
    Nov  5 13:22:57.802: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 13:22:57.802
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:22:57.816
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:22:57.82
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-30ab77a1-301a-42b6-9c13-42f929b61899 11/05/22 13:22:57.827
    STEP: Creating secret with name s-test-opt-upd-1cbf48d4-697a-4f3b-b648-3674410e6dd7 11/05/22 13:22:57.833
    STEP: Creating the pod 11/05/22 13:22:57.838
    Nov  5 13:22:57.847: INFO: Waiting up to 5m0s for pod "pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f" in namespace "secrets-315" to be "running and ready"
    Nov  5 13:22:57.854: INFO: Pod "pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.195376ms
    Nov  5 13:22:57.854: INFO: The phase of Pod pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:22:59.858: INFO: Pod "pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f": Phase="Running", Reason="", readiness=true. Elapsed: 2.010657523s
    Nov  5 13:22:59.858: INFO: The phase of Pod pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f is Running (Ready = true)
    Nov  5 13:22:59.858: INFO: Pod "pod-secrets-ec912fe7-cb60-44ed-8eff-d8cbe6de869f" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-30ab77a1-301a-42b6-9c13-42f929b61899 11/05/22 13:22:59.879
    STEP: Updating secret s-test-opt-upd-1cbf48d4-697a-4f3b-b648-3674410e6dd7 11/05/22 13:22:59.886
    STEP: Creating secret with name s-test-opt-create-f2dd71b6-8f70-446b-a1b0-5e983ee97f9a 11/05/22 13:22:59.89
    STEP: waiting to observe update in volume 11/05/22 13:22:59.894
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 13:23:01.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-315" for this suite. 11/05/22 13:23:01.924
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:23:01.931
Nov  5 13:23:01.931: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename dns 11/05/22 13:23:01.932
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:01.945
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:01.956
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 11/05/22 13:23:01.96
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
 11/05/22 13:23:01.966
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
 11/05/22 13:23:01.966
STEP: creating a pod to probe DNS 11/05/22 13:23:01.966
STEP: submitting the pod to kubernetes 11/05/22 13:23:01.966
Nov  5 13:23:01.974: INFO: Waiting up to 15m0s for pod "dns-test-2c11db8f-a52d-4137-a81c-f1215d21dfae" in namespace "dns-2212" to be "running"
Nov  5 13:23:01.978: INFO: Pod "dns-test-2c11db8f-a52d-4137-a81c-f1215d21dfae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.276448ms
Nov  5 13:23:03.982: INFO: Pod "dns-test-2c11db8f-a52d-4137-a81c-f1215d21dfae": Phase="Running", Reason="", readiness=true. Elapsed: 2.007781587s
Nov  5 13:23:03.982: INFO: Pod "dns-test-2c11db8f-a52d-4137-a81c-f1215d21dfae" satisfied condition "running"
STEP: retrieving the pod 11/05/22 13:23:03.982
STEP: looking for the results for each expected name from probers 11/05/22 13:23:03.987
Nov  5 13:23:03.997: INFO: DNS probes using dns-test-2c11db8f-a52d-4137-a81c-f1215d21dfae succeeded

STEP: deleting the pod 11/05/22 13:23:03.997
STEP: changing the externalName to bar.example.com 11/05/22 13:23:04.009
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
 11/05/22 13:23:04.018
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
 11/05/22 13:23:04.018
STEP: creating a second pod to probe DNS 11/05/22 13:23:04.018
STEP: submitting the pod to kubernetes 11/05/22 13:23:04.018
Nov  5 13:23:04.024: INFO: Waiting up to 15m0s for pod "dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741" in namespace "dns-2212" to be "running"
Nov  5 13:23:04.027: INFO: Pod "dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741": Phase="Pending", Reason="", readiness=false. Elapsed: 3.299493ms
Nov  5 13:23:06.032: INFO: Pod "dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741": Phase="Running", Reason="", readiness=true. Elapsed: 2.008075378s
Nov  5 13:23:06.032: INFO: Pod "dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741" satisfied condition "running"
STEP: retrieving the pod 11/05/22 13:23:06.032
STEP: looking for the results for each expected name from probers 11/05/22 13:23:06.036
Nov  5 13:23:06.042: INFO: File wheezy_udp@dns-test-service-3.dns-2212.svc.cluster.local from pod  dns-2212/dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  5 13:23:06.046: INFO: File jessie_udp@dns-test-service-3.dns-2212.svc.cluster.local from pod  dns-2212/dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741 contains '' instead of 'bar.example.com.'
Nov  5 13:23:06.046: INFO: Lookups using dns-2212/dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741 failed for: [wheezy_udp@dns-test-service-3.dns-2212.svc.cluster.local jessie_udp@dns-test-service-3.dns-2212.svc.cluster.local]

Nov  5 13:23:11.057: INFO: DNS probes using dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741 succeeded

STEP: deleting the pod 11/05/22 13:23:11.057
STEP: changing the service to type=ClusterIP 11/05/22 13:23:11.071
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
 11/05/22 13:23:11.085
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
 11/05/22 13:23:11.085
STEP: creating a third pod to probe DNS 11/05/22 13:23:11.086
STEP: submitting the pod to kubernetes 11/05/22 13:23:11.089
Nov  5 13:23:11.100: INFO: Waiting up to 15m0s for pod "dns-test-d6d323d9-e7dc-478f-8ded-d88554f9528b" in namespace "dns-2212" to be "running"
Nov  5 13:23:11.105: INFO: Pod "dns-test-d6d323d9-e7dc-478f-8ded-d88554f9528b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.381839ms
Nov  5 13:23:13.110: INFO: Pod "dns-test-d6d323d9-e7dc-478f-8ded-d88554f9528b": Phase="Running", Reason="", readiness=true. Elapsed: 2.009819642s
Nov  5 13:23:13.110: INFO: Pod "dns-test-d6d323d9-e7dc-478f-8ded-d88554f9528b" satisfied condition "running"
STEP: retrieving the pod 11/05/22 13:23:13.11
STEP: looking for the results for each expected name from probers 11/05/22 13:23:13.113
Nov  5 13:23:13.122: INFO: DNS probes using dns-test-d6d323d9-e7dc-478f-8ded-d88554f9528b succeeded

STEP: deleting the pod 11/05/22 13:23:13.122
STEP: deleting the test externalName service 11/05/22 13:23:13.135
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov  5 13:23:13.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2212" for this suite. 11/05/22 13:23:13.154
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":326,"skipped":5876,"failed":0}
------------------------------
• [SLOW TEST] [11.229 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:23:01.931
    Nov  5 13:23:01.931: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename dns 11/05/22 13:23:01.932
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:01.945
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:01.956
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 11/05/22 13:23:01.96
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
     11/05/22 13:23:01.966
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
     11/05/22 13:23:01.966
    STEP: creating a pod to probe DNS 11/05/22 13:23:01.966
    STEP: submitting the pod to kubernetes 11/05/22 13:23:01.966
    Nov  5 13:23:01.974: INFO: Waiting up to 15m0s for pod "dns-test-2c11db8f-a52d-4137-a81c-f1215d21dfae" in namespace "dns-2212" to be "running"
    Nov  5 13:23:01.978: INFO: Pod "dns-test-2c11db8f-a52d-4137-a81c-f1215d21dfae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.276448ms
    Nov  5 13:23:03.982: INFO: Pod "dns-test-2c11db8f-a52d-4137-a81c-f1215d21dfae": Phase="Running", Reason="", readiness=true. Elapsed: 2.007781587s
    Nov  5 13:23:03.982: INFO: Pod "dns-test-2c11db8f-a52d-4137-a81c-f1215d21dfae" satisfied condition "running"
    STEP: retrieving the pod 11/05/22 13:23:03.982
    STEP: looking for the results for each expected name from probers 11/05/22 13:23:03.987
    Nov  5 13:23:03.997: INFO: DNS probes using dns-test-2c11db8f-a52d-4137-a81c-f1215d21dfae succeeded

    STEP: deleting the pod 11/05/22 13:23:03.997
    STEP: changing the externalName to bar.example.com 11/05/22 13:23:04.009
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
     11/05/22 13:23:04.018
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
     11/05/22 13:23:04.018
    STEP: creating a second pod to probe DNS 11/05/22 13:23:04.018
    STEP: submitting the pod to kubernetes 11/05/22 13:23:04.018
    Nov  5 13:23:04.024: INFO: Waiting up to 15m0s for pod "dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741" in namespace "dns-2212" to be "running"
    Nov  5 13:23:04.027: INFO: Pod "dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741": Phase="Pending", Reason="", readiness=false. Elapsed: 3.299493ms
    Nov  5 13:23:06.032: INFO: Pod "dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741": Phase="Running", Reason="", readiness=true. Elapsed: 2.008075378s
    Nov  5 13:23:06.032: INFO: Pod "dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741" satisfied condition "running"
    STEP: retrieving the pod 11/05/22 13:23:06.032
    STEP: looking for the results for each expected name from probers 11/05/22 13:23:06.036
    Nov  5 13:23:06.042: INFO: File wheezy_udp@dns-test-service-3.dns-2212.svc.cluster.local from pod  dns-2212/dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Nov  5 13:23:06.046: INFO: File jessie_udp@dns-test-service-3.dns-2212.svc.cluster.local from pod  dns-2212/dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741 contains '' instead of 'bar.example.com.'
    Nov  5 13:23:06.046: INFO: Lookups using dns-2212/dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741 failed for: [wheezy_udp@dns-test-service-3.dns-2212.svc.cluster.local jessie_udp@dns-test-service-3.dns-2212.svc.cluster.local]

    Nov  5 13:23:11.057: INFO: DNS probes using dns-test-0165e169-39e1-42d6-b9ac-85fe2ddf2741 succeeded

    STEP: deleting the pod 11/05/22 13:23:11.057
    STEP: changing the service to type=ClusterIP 11/05/22 13:23:11.071
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
     11/05/22 13:23:11.085
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2212.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2212.svc.cluster.local; sleep 1; done
     11/05/22 13:23:11.085
    STEP: creating a third pod to probe DNS 11/05/22 13:23:11.086
    STEP: submitting the pod to kubernetes 11/05/22 13:23:11.089
    Nov  5 13:23:11.100: INFO: Waiting up to 15m0s for pod "dns-test-d6d323d9-e7dc-478f-8ded-d88554f9528b" in namespace "dns-2212" to be "running"
    Nov  5 13:23:11.105: INFO: Pod "dns-test-d6d323d9-e7dc-478f-8ded-d88554f9528b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.381839ms
    Nov  5 13:23:13.110: INFO: Pod "dns-test-d6d323d9-e7dc-478f-8ded-d88554f9528b": Phase="Running", Reason="", readiness=true. Elapsed: 2.009819642s
    Nov  5 13:23:13.110: INFO: Pod "dns-test-d6d323d9-e7dc-478f-8ded-d88554f9528b" satisfied condition "running"
    STEP: retrieving the pod 11/05/22 13:23:13.11
    STEP: looking for the results for each expected name from probers 11/05/22 13:23:13.113
    Nov  5 13:23:13.122: INFO: DNS probes using dns-test-d6d323d9-e7dc-478f-8ded-d88554f9528b succeeded

    STEP: deleting the pod 11/05/22 13:23:13.122
    STEP: deleting the test externalName service 11/05/22 13:23:13.135
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov  5 13:23:13.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2212" for this suite. 11/05/22 13:23:13.154
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:23:13.161
Nov  5 13:23:13.161: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename container-lifecycle-hook 11/05/22 13:23:13.162
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:13.177
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:13.182
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 11/05/22 13:23:13.19
Nov  5 13:23:13.199: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2624" to be "running and ready"
Nov  5 13:23:13.203: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.691276ms
Nov  5 13:23:13.203: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:23:15.208: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008566118s
Nov  5 13:23:15.208: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Nov  5 13:23:15.208: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 11/05/22 13:23:15.211
Nov  5 13:23:15.216: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-2624" to be "running and ready"
Nov  5 13:23:15.222: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.414827ms
Nov  5 13:23:15.222: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:23:17.226: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.009157928s
Nov  5 13:23:17.226: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Nov  5 13:23:17.226: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 11/05/22 13:23:17.229
Nov  5 13:23:17.243: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  5 13:23:17.246: INFO: Pod pod-with-prestop-http-hook still exists
Nov  5 13:23:19.247: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  5 13:23:19.251: INFO: Pod pod-with-prestop-http-hook still exists
Nov  5 13:23:21.246: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  5 13:23:21.250: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 11/05/22 13:23:21.25
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Nov  5 13:23:21.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2624" for this suite. 11/05/22 13:23:21.271
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":327,"skipped":5889,"failed":0}
------------------------------
• [SLOW TEST] [8.117 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:23:13.161
    Nov  5 13:23:13.161: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename container-lifecycle-hook 11/05/22 13:23:13.162
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:13.177
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:13.182
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 11/05/22 13:23:13.19
    Nov  5 13:23:13.199: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-2624" to be "running and ready"
    Nov  5 13:23:13.203: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 3.691276ms
    Nov  5 13:23:13.203: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:23:15.208: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.008566118s
    Nov  5 13:23:15.208: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Nov  5 13:23:15.208: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 11/05/22 13:23:15.211
    Nov  5 13:23:15.216: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-2624" to be "running and ready"
    Nov  5 13:23:15.222: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 5.414827ms
    Nov  5 13:23:15.222: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:23:17.226: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.009157928s
    Nov  5 13:23:17.226: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Nov  5 13:23:17.226: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 11/05/22 13:23:17.229
    Nov  5 13:23:17.243: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov  5 13:23:17.246: INFO: Pod pod-with-prestop-http-hook still exists
    Nov  5 13:23:19.247: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov  5 13:23:19.251: INFO: Pod pod-with-prestop-http-hook still exists
    Nov  5 13:23:21.246: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Nov  5 13:23:21.250: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 11/05/22 13:23:21.25
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Nov  5 13:23:21.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-2624" for this suite. 11/05/22 13:23:21.271
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:23:21.28
Nov  5 13:23:21.280: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 13:23:21.28
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:21.291
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:21.296
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 11/05/22 13:23:21.299
Nov  5 13:23:21.307: INFO: Waiting up to 5m0s for pod "pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a" in namespace "emptydir-9696" to be "Succeeded or Failed"
Nov  5 13:23:21.310: INFO: Pod "pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338354ms
Nov  5 13:23:23.315: INFO: Pod "pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00770932s
Nov  5 13:23:25.315: INFO: Pod "pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008414883s
STEP: Saw pod success 11/05/22 13:23:25.315
Nov  5 13:23:25.315: INFO: Pod "pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a" satisfied condition "Succeeded or Failed"
Nov  5 13:23:25.319: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a container test-container: <nil>
STEP: delete the pod 11/05/22 13:23:25.325
Nov  5 13:23:25.338: INFO: Waiting for pod pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a to disappear
Nov  5 13:23:25.341: INFO: Pod pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 13:23:25.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9696" for this suite. 11/05/22 13:23:25.345
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":328,"skipped":5899,"failed":0}
------------------------------
• [4.072 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:23:21.28
    Nov  5 13:23:21.280: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 13:23:21.28
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:21.291
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:21.296
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 11/05/22 13:23:21.299
    Nov  5 13:23:21.307: INFO: Waiting up to 5m0s for pod "pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a" in namespace "emptydir-9696" to be "Succeeded or Failed"
    Nov  5 13:23:21.310: INFO: Pod "pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.338354ms
    Nov  5 13:23:23.315: INFO: Pod "pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00770932s
    Nov  5 13:23:25.315: INFO: Pod "pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008414883s
    STEP: Saw pod success 11/05/22 13:23:25.315
    Nov  5 13:23:25.315: INFO: Pod "pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a" satisfied condition "Succeeded or Failed"
    Nov  5 13:23:25.319: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a container test-container: <nil>
    STEP: delete the pod 11/05/22 13:23:25.325
    Nov  5 13:23:25.338: INFO: Waiting for pod pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a to disappear
    Nov  5 13:23:25.341: INFO: Pod pod-d26738ad-45b4-49cf-95d6-7a8a67537c4a no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 13:23:25.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-9696" for this suite. 11/05/22 13:23:25.345
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:23:25.353
Nov  5 13:23:25.353: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 13:23:25.354
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:25.368
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:25.373
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-5113a759-7bfd-4891-a183-39d2c4fad8be 11/05/22 13:23:25.377
STEP: Creating a pod to test consume configMaps 11/05/22 13:23:25.382
Nov  5 13:23:25.390: INFO: Waiting up to 5m0s for pod "pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df" in namespace "configmap-2986" to be "Succeeded or Failed"
Nov  5 13:23:25.398: INFO: Pod "pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df": Phase="Pending", Reason="", readiness=false. Elapsed: 7.773178ms
Nov  5 13:23:27.402: INFO: Pod "pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01241342s
Nov  5 13:23:29.402: INFO: Pod "pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011674982s
STEP: Saw pod success 11/05/22 13:23:29.402
Nov  5 13:23:29.402: INFO: Pod "pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df" satisfied condition "Succeeded or Failed"
Nov  5 13:23:29.406: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df container agnhost-container: <nil>
STEP: delete the pod 11/05/22 13:23:29.412
Nov  5 13:23:29.424: INFO: Waiting for pod pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df to disappear
Nov  5 13:23:29.428: INFO: Pod pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 13:23:29.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2986" for this suite. 11/05/22 13:23:29.431
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":329,"skipped":5908,"failed":0}
------------------------------
• [4.085 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:23:25.353
    Nov  5 13:23:25.353: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 13:23:25.354
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:25.368
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:25.373
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-5113a759-7bfd-4891-a183-39d2c4fad8be 11/05/22 13:23:25.377
    STEP: Creating a pod to test consume configMaps 11/05/22 13:23:25.382
    Nov  5 13:23:25.390: INFO: Waiting up to 5m0s for pod "pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df" in namespace "configmap-2986" to be "Succeeded or Failed"
    Nov  5 13:23:25.398: INFO: Pod "pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df": Phase="Pending", Reason="", readiness=false. Elapsed: 7.773178ms
    Nov  5 13:23:27.402: INFO: Pod "pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01241342s
    Nov  5 13:23:29.402: INFO: Pod "pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011674982s
    STEP: Saw pod success 11/05/22 13:23:29.402
    Nov  5 13:23:29.402: INFO: Pod "pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df" satisfied condition "Succeeded or Failed"
    Nov  5 13:23:29.406: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 13:23:29.412
    Nov  5 13:23:29.424: INFO: Waiting for pod pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df to disappear
    Nov  5 13:23:29.428: INFO: Pod pod-configmaps-b27ab4a2-01d0-4e8c-ba45-6d02395f81df no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 13:23:29.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2986" for this suite. 11/05/22 13:23:29.431
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:23:29.439
Nov  5 13:23:29.439: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 13:23:29.44
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:29.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:29.455
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-1475 11/05/22 13:23:29.459
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1475 to expose endpoints map[] 11/05/22 13:23:29.471
Nov  5 13:23:29.483: INFO: successfully validated that service endpoint-test2 in namespace services-1475 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-1475 11/05/22 13:23:29.483
Nov  5 13:23:29.493: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-1475" to be "running and ready"
Nov  5 13:23:29.500: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.32324ms
Nov  5 13:23:29.500: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:23:31.504: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011305419s
Nov  5 13:23:31.504: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov  5 13:23:31.504: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1475 to expose endpoints map[pod1:[80]] 11/05/22 13:23:31.508
Nov  5 13:23:31.519: INFO: successfully validated that service endpoint-test2 in namespace services-1475 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 11/05/22 13:23:31.519
Nov  5 13:23:31.519: INFO: Creating new exec pod
Nov  5 13:23:31.526: INFO: Waiting up to 5m0s for pod "execpodz688n" in namespace "services-1475" to be "running"
Nov  5 13:23:31.531: INFO: Pod "execpodz688n": Phase="Pending", Reason="", readiness=false. Elapsed: 5.403541ms
Nov  5 13:23:33.536: INFO: Pod "execpodz688n": Phase="Running", Reason="", readiness=true. Elapsed: 2.010127423s
Nov  5 13:23:33.536: INFO: Pod "execpodz688n" satisfied condition "running"
Nov  5 13:23:34.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov  5 13:23:34.682: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov  5 13:23:34.682: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:23:34.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.250 80'
Nov  5 13:23:34.817: INFO: stderr: "+ nc -v -t -w 2 10.152.183.250 80\nConnection to 10.152.183.250 80 port [tcp/http] succeeded!\n+ echo hostName\n"
Nov  5 13:23:34.817: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-1475 11/05/22 13:23:34.817
Nov  5 13:23:34.823: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-1475" to be "running and ready"
Nov  5 13:23:34.831: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.24285ms
Nov  5 13:23:34.831: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:23:36.835: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012107432s
Nov  5 13:23:36.836: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov  5 13:23:36.836: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1475 to expose endpoints map[pod1:[80] pod2:[80]] 11/05/22 13:23:36.839
Nov  5 13:23:36.854: INFO: successfully validated that service endpoint-test2 in namespace services-1475 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 11/05/22 13:23:36.854
Nov  5 13:23:37.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov  5 13:23:37.991: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov  5 13:23:37.991: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:23:37.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.250 80'
Nov  5 13:23:38.111: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 10.152.183.250 80\nConnection to 10.152.183.250 80 port [tcp/http] succeeded!\n"
Nov  5 13:23:38.111: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-1475 11/05/22 13:23:38.111
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1475 to expose endpoints map[pod2:[80]] 11/05/22 13:23:38.131
Nov  5 13:23:38.147: INFO: successfully validated that service endpoint-test2 in namespace services-1475 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 11/05/22 13:23:38.147
Nov  5 13:23:39.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Nov  5 13:23:39.304: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Nov  5 13:23:39.304: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Nov  5 13:23:39.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.250 80'
Nov  5 13:23:39.434: INFO: stderr: "+ + echonc -v -t hostName -w\n 2 10.152.183.250 80\nConnection to 10.152.183.250 80 port [tcp/http] succeeded!\n"
Nov  5 13:23:39.434: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-1475 11/05/22 13:23:39.434
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1475 to expose endpoints map[] 11/05/22 13:23:39.449
Nov  5 13:23:40.462: INFO: successfully validated that service endpoint-test2 in namespace services-1475 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 13:23:40.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1475" for this suite. 11/05/22 13:23:40.495
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":330,"skipped":5930,"failed":0}
------------------------------
• [SLOW TEST] [11.064 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:23:29.439
    Nov  5 13:23:29.439: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 13:23:29.44
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:29.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:29.455
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-1475 11/05/22 13:23:29.459
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1475 to expose endpoints map[] 11/05/22 13:23:29.471
    Nov  5 13:23:29.483: INFO: successfully validated that service endpoint-test2 in namespace services-1475 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-1475 11/05/22 13:23:29.483
    Nov  5 13:23:29.493: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-1475" to be "running and ready"
    Nov  5 13:23:29.500: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.32324ms
    Nov  5 13:23:29.500: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:23:31.504: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011305419s
    Nov  5 13:23:31.504: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov  5 13:23:31.504: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1475 to expose endpoints map[pod1:[80]] 11/05/22 13:23:31.508
    Nov  5 13:23:31.519: INFO: successfully validated that service endpoint-test2 in namespace services-1475 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 11/05/22 13:23:31.519
    Nov  5 13:23:31.519: INFO: Creating new exec pod
    Nov  5 13:23:31.526: INFO: Waiting up to 5m0s for pod "execpodz688n" in namespace "services-1475" to be "running"
    Nov  5 13:23:31.531: INFO: Pod "execpodz688n": Phase="Pending", Reason="", readiness=false. Elapsed: 5.403541ms
    Nov  5 13:23:33.536: INFO: Pod "execpodz688n": Phase="Running", Reason="", readiness=true. Elapsed: 2.010127423s
    Nov  5 13:23:33.536: INFO: Pod "execpodz688n" satisfied condition "running"
    Nov  5 13:23:34.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov  5 13:23:34.682: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov  5 13:23:34.682: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:23:34.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.250 80'
    Nov  5 13:23:34.817: INFO: stderr: "+ nc -v -t -w 2 10.152.183.250 80\nConnection to 10.152.183.250 80 port [tcp/http] succeeded!\n+ echo hostName\n"
    Nov  5 13:23:34.817: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-1475 11/05/22 13:23:34.817
    Nov  5 13:23:34.823: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-1475" to be "running and ready"
    Nov  5 13:23:34.831: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.24285ms
    Nov  5 13:23:34.831: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:23:36.835: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.012107432s
    Nov  5 13:23:36.836: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov  5 13:23:36.836: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1475 to expose endpoints map[pod1:[80] pod2:[80]] 11/05/22 13:23:36.839
    Nov  5 13:23:36.854: INFO: successfully validated that service endpoint-test2 in namespace services-1475 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 11/05/22 13:23:36.854
    Nov  5 13:23:37.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov  5 13:23:37.991: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov  5 13:23:37.991: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:23:37.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.250 80'
    Nov  5 13:23:38.111: INFO: stderr: "+ + ncecho -v hostName\n -t -w 2 10.152.183.250 80\nConnection to 10.152.183.250 80 port [tcp/http] succeeded!\n"
    Nov  5 13:23:38.111: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-1475 11/05/22 13:23:38.111
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1475 to expose endpoints map[pod2:[80]] 11/05/22 13:23:38.131
    Nov  5 13:23:38.147: INFO: successfully validated that service endpoint-test2 in namespace services-1475 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 11/05/22 13:23:38.147
    Nov  5 13:23:39.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Nov  5 13:23:39.304: INFO: stderr: "+ nc -v -t -w 2 endpoint-test2 80\n+ echo hostName\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Nov  5 13:23:39.304: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Nov  5 13:23:39.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-1475 exec execpodz688n -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.250 80'
    Nov  5 13:23:39.434: INFO: stderr: "+ + echonc -v -t hostName -w\n 2 10.152.183.250 80\nConnection to 10.152.183.250 80 port [tcp/http] succeeded!\n"
    Nov  5 13:23:39.434: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-1475 11/05/22 13:23:39.434
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1475 to expose endpoints map[] 11/05/22 13:23:39.449
    Nov  5 13:23:40.462: INFO: successfully validated that service endpoint-test2 in namespace services-1475 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 13:23:40.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1475" for this suite. 11/05/22 13:23:40.495
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:23:40.505
Nov  5 13:23:40.506: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename hostport 11/05/22 13:23:40.506
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:40.525
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:40.529
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 11/05/22 13:23:40.538
Nov  5 13:23:40.546: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-1025" to be "running and ready"
Nov  5 13:23:40.549: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.083472ms
Nov  5 13:23:40.549: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:23:42.553: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.007129336s
Nov  5 13:23:42.553: INFO: The phase of Pod pod1 is Running (Ready = true)
Nov  5 13:23:42.553: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.41.19 on the node which pod1 resides and expect scheduled 11/05/22 13:23:42.553
Nov  5 13:23:42.559: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-1025" to be "running and ready"
Nov  5 13:23:42.563: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.470355ms
Nov  5 13:23:42.563: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:23:44.568: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.0082285s
Nov  5 13:23:44.568: INFO: The phase of Pod pod2 is Running (Ready = true)
Nov  5 13:23:44.568: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.41.19 but use UDP protocol on the node which pod2 resides 11/05/22 13:23:44.568
Nov  5 13:23:44.574: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-1025" to be "running and ready"
Nov  5 13:23:44.577: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.407191ms
Nov  5 13:23:44.577: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:23:46.582: INFO: Pod "pod3": Phase="Running", Reason="", readiness=false. Elapsed: 2.008353427s
Nov  5 13:23:46.582: INFO: The phase of Pod pod3 is Running (Ready = false)
Nov  5 13:23:48.583: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.009147872s
Nov  5 13:23:48.583: INFO: The phase of Pod pod3 is Running (Ready = true)
Nov  5 13:23:48.583: INFO: Pod "pod3" satisfied condition "running and ready"
Nov  5 13:23:48.589: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-1025" to be "running and ready"
Nov  5 13:23:48.593: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 3.677631ms
Nov  5 13:23:48.593: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:23:50.598: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.00874197s
Nov  5 13:23:50.598: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Nov  5 13:23:50.598: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 11/05/22 13:23:50.601
Nov  5 13:23:50.602: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.41.19 http://127.0.0.1:54323/hostname] Namespace:hostport-1025 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:23:50.602: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:23:50.602: INFO: ExecWithOptions: Clientset creation
Nov  5 13:23:50.602: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-1025/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.41.19+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.41.19, port: 54323 11/05/22 13:23:50.701
Nov  5 13:23:50.701: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.41.19:54323/hostname] Namespace:hostport-1025 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:23:50.701: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:23:50.702: INFO: ExecWithOptions: Clientset creation
Nov  5 13:23:50.702: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-1025/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.41.19%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.41.19, port: 54323 UDP 11/05/22 13:23:50.792
Nov  5 13:23:50.792: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.41.19 54323] Namespace:hostport-1025 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:23:50.792: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:23:50.792: INFO: ExecWithOptions: Clientset creation
Nov  5 13:23:50.792: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-1025/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.41.19+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Nov  5 13:23:55.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-1025" for this suite. 11/05/22 13:23:55.86
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":331,"skipped":5986,"failed":0}
------------------------------
• [SLOW TEST] [15.361 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:23:40.505
    Nov  5 13:23:40.506: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename hostport 11/05/22 13:23:40.506
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:40.525
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:40.529
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 11/05/22 13:23:40.538
    Nov  5 13:23:40.546: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-1025" to be "running and ready"
    Nov  5 13:23:40.549: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.083472ms
    Nov  5 13:23:40.549: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:23:42.553: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.007129336s
    Nov  5 13:23:42.553: INFO: The phase of Pod pod1 is Running (Ready = true)
    Nov  5 13:23:42.553: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 172.31.41.19 on the node which pod1 resides and expect scheduled 11/05/22 13:23:42.553
    Nov  5 13:23:42.559: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-1025" to be "running and ready"
    Nov  5 13:23:42.563: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.470355ms
    Nov  5 13:23:42.563: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:23:44.568: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.0082285s
    Nov  5 13:23:44.568: INFO: The phase of Pod pod2 is Running (Ready = true)
    Nov  5 13:23:44.568: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 172.31.41.19 but use UDP protocol on the node which pod2 resides 11/05/22 13:23:44.568
    Nov  5 13:23:44.574: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-1025" to be "running and ready"
    Nov  5 13:23:44.577: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.407191ms
    Nov  5 13:23:44.577: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:23:46.582: INFO: Pod "pod3": Phase="Running", Reason="", readiness=false. Elapsed: 2.008353427s
    Nov  5 13:23:46.582: INFO: The phase of Pod pod3 is Running (Ready = false)
    Nov  5 13:23:48.583: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 4.009147872s
    Nov  5 13:23:48.583: INFO: The phase of Pod pod3 is Running (Ready = true)
    Nov  5 13:23:48.583: INFO: Pod "pod3" satisfied condition "running and ready"
    Nov  5 13:23:48.589: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-1025" to be "running and ready"
    Nov  5 13:23:48.593: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 3.677631ms
    Nov  5 13:23:48.593: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:23:50.598: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.00874197s
    Nov  5 13:23:50.598: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Nov  5 13:23:50.598: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 11/05/22 13:23:50.601
    Nov  5 13:23:50.602: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 172.31.41.19 http://127.0.0.1:54323/hostname] Namespace:hostport-1025 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:23:50.602: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:23:50.602: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:23:50.602: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-1025/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+172.31.41.19+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.41.19, port: 54323 11/05/22 13:23:50.701
    Nov  5 13:23:50.701: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://172.31.41.19:54323/hostname] Namespace:hostport-1025 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:23:50.701: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:23:50.702: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:23:50.702: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-1025/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F172.31.41.19%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 172.31.41.19, port: 54323 UDP 11/05/22 13:23:50.792
    Nov  5 13:23:50.792: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 172.31.41.19 54323] Namespace:hostport-1025 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:23:50.792: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:23:50.792: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:23:50.792: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/hostport-1025/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+172.31.41.19+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Nov  5 13:23:55.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-1025" for this suite. 11/05/22 13:23:55.86
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:23:55.871
Nov  5 13:23:55.871: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename security-context-test 11/05/22 13:23:55.872
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:55.995
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:55.999
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Nov  5 13:23:56.009: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-25accf93-59cb-4ada-9c72-5f1bdd7d31b0" in namespace "security-context-test-1629" to be "Succeeded or Failed"
Nov  5 13:23:56.013: INFO: Pod "busybox-readonly-false-25accf93-59cb-4ada-9c72-5f1bdd7d31b0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.5285ms
Nov  5 13:23:58.017: INFO: Pod "busybox-readonly-false-25accf93-59cb-4ada-9c72-5f1bdd7d31b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007165866s
Nov  5 13:24:00.018: INFO: Pod "busybox-readonly-false-25accf93-59cb-4ada-9c72-5f1bdd7d31b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008928076s
Nov  5 13:24:00.018: INFO: Pod "busybox-readonly-false-25accf93-59cb-4ada-9c72-5f1bdd7d31b0" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Nov  5 13:24:00.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1629" for this suite. 11/05/22 13:24:00.024
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":332,"skipped":6040,"failed":0}
------------------------------
• [4.162 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:23:55.871
    Nov  5 13:23:55.871: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename security-context-test 11/05/22 13:23:55.872
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:23:55.995
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:23:55.999
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Nov  5 13:23:56.009: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-25accf93-59cb-4ada-9c72-5f1bdd7d31b0" in namespace "security-context-test-1629" to be "Succeeded or Failed"
    Nov  5 13:23:56.013: INFO: Pod "busybox-readonly-false-25accf93-59cb-4ada-9c72-5f1bdd7d31b0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.5285ms
    Nov  5 13:23:58.017: INFO: Pod "busybox-readonly-false-25accf93-59cb-4ada-9c72-5f1bdd7d31b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007165866s
    Nov  5 13:24:00.018: INFO: Pod "busybox-readonly-false-25accf93-59cb-4ada-9c72-5f1bdd7d31b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008928076s
    Nov  5 13:24:00.018: INFO: Pod "busybox-readonly-false-25accf93-59cb-4ada-9c72-5f1bdd7d31b0" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Nov  5 13:24:00.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-1629" for this suite. 11/05/22 13:24:00.024
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:24:00.033
Nov  5 13:24:00.033: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:24:00.034
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:00.061
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:00.074
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 11/05/22 13:24:00.082
Nov  5 13:24:00.096: INFO: Waiting up to 5m0s for pod "annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f" in namespace "projected-2240" to be "running and ready"
Nov  5 13:24:00.101: INFO: Pod "annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.681411ms
Nov  5 13:24:00.101: INFO: The phase of Pod annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:24:02.106: INFO: Pod "annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f": Phase="Running", Reason="", readiness=true. Elapsed: 2.010583188s
Nov  5 13:24:02.106: INFO: The phase of Pod annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f is Running (Ready = true)
Nov  5 13:24:02.106: INFO: Pod "annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f" satisfied condition "running and ready"
Nov  5 13:24:02.635: INFO: Successfully updated pod "annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 13:24:06.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2240" for this suite. 11/05/22 13:24:06.663
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":333,"skipped":6042,"failed":0}
------------------------------
• [SLOW TEST] [6.637 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:24:00.033
    Nov  5 13:24:00.033: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:24:00.034
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:00.061
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:00.074
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 11/05/22 13:24:00.082
    Nov  5 13:24:00.096: INFO: Waiting up to 5m0s for pod "annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f" in namespace "projected-2240" to be "running and ready"
    Nov  5 13:24:00.101: INFO: Pod "annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f": Phase="Pending", Reason="", readiness=false. Elapsed: 5.681411ms
    Nov  5 13:24:00.101: INFO: The phase of Pod annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:24:02.106: INFO: Pod "annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f": Phase="Running", Reason="", readiness=true. Elapsed: 2.010583188s
    Nov  5 13:24:02.106: INFO: The phase of Pod annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f is Running (Ready = true)
    Nov  5 13:24:02.106: INFO: Pod "annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f" satisfied condition "running and ready"
    Nov  5 13:24:02.635: INFO: Successfully updated pod "annotationupdate3bc76fc1-9f00-404d-88e0-4dd62c8dc78f"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 13:24:06.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2240" for this suite. 11/05/22 13:24:06.663
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:24:06.672
Nov  5 13:24:06.672: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:24:06.673
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:06.692
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:06.697
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 11/05/22 13:24:06.705
Nov  5 13:24:06.706: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 11/05/22 13:24:16.232
Nov  5 13:24:16.233: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:24:18.434: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:24:27.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8621" for this suite. 11/05/22 13:24:27.592
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":334,"skipped":6059,"failed":0}
------------------------------
• [SLOW TEST] [20.928 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:24:06.672
    Nov  5 13:24:06.672: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:24:06.673
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:06.692
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:06.697
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 11/05/22 13:24:06.705
    Nov  5 13:24:06.706: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 11/05/22 13:24:16.232
    Nov  5 13:24:16.233: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:24:18.434: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:24:27.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-8621" for this suite. 11/05/22 13:24:27.592
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:24:27.603
Nov  5 13:24:27.603: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 13:24:27.604
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:27.616
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:27.622
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 11/05/22 13:24:27.625
STEP: Creating a ResourceQuota 11/05/22 13:24:32.629
STEP: Ensuring resource quota status is calculated 11/05/22 13:24:32.635
STEP: Creating a ReplicaSet 11/05/22 13:24:34.639
STEP: Ensuring resource quota status captures replicaset creation 11/05/22 13:24:34.652
STEP: Deleting a ReplicaSet 11/05/22 13:24:36.657
STEP: Ensuring resource quota status released usage 11/05/22 13:24:36.664
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 13:24:38.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4867" for this suite. 11/05/22 13:24:38.673
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":335,"skipped":6100,"failed":0}
------------------------------
• [SLOW TEST] [11.077 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:24:27.603
    Nov  5 13:24:27.603: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 13:24:27.604
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:27.616
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:27.622
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 11/05/22 13:24:27.625
    STEP: Creating a ResourceQuota 11/05/22 13:24:32.629
    STEP: Ensuring resource quota status is calculated 11/05/22 13:24:32.635
    STEP: Creating a ReplicaSet 11/05/22 13:24:34.639
    STEP: Ensuring resource quota status captures replicaset creation 11/05/22 13:24:34.652
    STEP: Deleting a ReplicaSet 11/05/22 13:24:36.657
    STEP: Ensuring resource quota status released usage 11/05/22 13:24:36.664
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 13:24:38.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4867" for this suite. 11/05/22 13:24:38.673
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:24:38.683
Nov  5 13:24:38.683: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 13:24:38.684
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:38.696
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:38.701
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 13:24:38.719
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 13:24:39.364
STEP: Deploying the webhook pod 11/05/22 13:24:39.373
STEP: Wait for the deployment to be ready 11/05/22 13:24:39.385
Nov  5 13:24:39.393: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 13:24:41.404
STEP: Verifying the service has paired with the endpoint 11/05/22 13:24:41.415
Nov  5 13:24:42.416: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/05/22 13:24:42.42
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/05/22 13:24:42.434
STEP: Creating a dummy validating-webhook-configuration object 11/05/22 13:24:42.448
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 11/05/22 13:24:42.457
STEP: Creating a dummy mutating-webhook-configuration object 11/05/22 13:24:42.463
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 11/05/22 13:24:42.473
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:24:42.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9398" for this suite. 11/05/22 13:24:42.496
STEP: Destroying namespace "webhook-9398-markers" for this suite. 11/05/22 13:24:42.502
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":336,"skipped":6159,"failed":0}
------------------------------
• [3.984 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:24:38.683
    Nov  5 13:24:38.683: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 13:24:38.684
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:38.696
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:38.701
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 13:24:38.719
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 13:24:39.364
    STEP: Deploying the webhook pod 11/05/22 13:24:39.373
    STEP: Wait for the deployment to be ready 11/05/22 13:24:39.385
    Nov  5 13:24:39.393: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 13:24:41.404
    STEP: Verifying the service has paired with the endpoint 11/05/22 13:24:41.415
    Nov  5 13:24:42.416: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/05/22 13:24:42.42
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 11/05/22 13:24:42.434
    STEP: Creating a dummy validating-webhook-configuration object 11/05/22 13:24:42.448
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 11/05/22 13:24:42.457
    STEP: Creating a dummy mutating-webhook-configuration object 11/05/22 13:24:42.463
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 11/05/22 13:24:42.473
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:24:42.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9398" for this suite. 11/05/22 13:24:42.496
    STEP: Destroying namespace "webhook-9398-markers" for this suite. 11/05/22 13:24:42.502
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:24:42.669
Nov  5 13:24:42.669: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 13:24:42.669
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:42.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:42.695
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-4beccf96-38e3-47b1-9c84-56a80ea40815 11/05/22 13:24:42.699
STEP: Creating a pod to test consume secrets 11/05/22 13:24:42.703
Nov  5 13:24:42.711: INFO: Waiting up to 5m0s for pod "pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf" in namespace "secrets-8541" to be "Succeeded or Failed"
Nov  5 13:24:42.715: INFO: Pod "pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.70201ms
Nov  5 13:24:44.720: INFO: Pod "pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009057232s
Nov  5 13:24:46.719: INFO: Pod "pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008613586s
STEP: Saw pod success 11/05/22 13:24:46.719
Nov  5 13:24:46.720: INFO: Pod "pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf" satisfied condition "Succeeded or Failed"
Nov  5 13:24:46.723: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf container secret-volume-test: <nil>
STEP: delete the pod 11/05/22 13:24:46.734
Nov  5 13:24:46.746: INFO: Waiting for pod pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf to disappear
Nov  5 13:24:46.749: INFO: Pod pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov  5 13:24:46.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8541" for this suite. 11/05/22 13:24:46.753
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":337,"skipped":6180,"failed":0}
------------------------------
• [4.091 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:24:42.669
    Nov  5 13:24:42.669: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 13:24:42.669
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:42.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:42.695
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-4beccf96-38e3-47b1-9c84-56a80ea40815 11/05/22 13:24:42.699
    STEP: Creating a pod to test consume secrets 11/05/22 13:24:42.703
    Nov  5 13:24:42.711: INFO: Waiting up to 5m0s for pod "pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf" in namespace "secrets-8541" to be "Succeeded or Failed"
    Nov  5 13:24:42.715: INFO: Pod "pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.70201ms
    Nov  5 13:24:44.720: INFO: Pod "pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009057232s
    Nov  5 13:24:46.719: INFO: Pod "pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008613586s
    STEP: Saw pod success 11/05/22 13:24:46.719
    Nov  5 13:24:46.720: INFO: Pod "pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf" satisfied condition "Succeeded or Failed"
    Nov  5 13:24:46.723: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf container secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 13:24:46.734
    Nov  5 13:24:46.746: INFO: Waiting for pod pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf to disappear
    Nov  5 13:24:46.749: INFO: Pod pod-secrets-bdd8f994-11c7-4bb4-b3b5-ed3e288f9baf no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 13:24:46.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8541" for this suite. 11/05/22 13:24:46.753
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:24:46.761
Nov  5 13:24:46.761: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename endpointslicemirroring 11/05/22 13:24:46.762
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:46.775
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:46.779
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 11/05/22 13:24:46.793
Nov  5 13:24:46.803: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 11/05/22 13:24:48.807
Nov  5 13:24:48.817: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
STEP: mirroring deletion of a custom Endpoint 11/05/22 13:24:50.821
Nov  5 13:24:50.836: INFO: Waiting for 0 EndpointSlices to exist, got 1
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Nov  5 13:24:52.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-6928" for this suite. 11/05/22 13:24:52.844
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":338,"skipped":6196,"failed":0}
------------------------------
• [SLOW TEST] [6.089 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:24:46.761
    Nov  5 13:24:46.761: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename endpointslicemirroring 11/05/22 13:24:46.762
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:46.775
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:46.779
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 11/05/22 13:24:46.793
    Nov  5 13:24:46.803: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 11/05/22 13:24:48.807
    Nov  5 13:24:48.817: INFO: Expected EndpointSlice to have 10.2.3.4 as address, got 10.1.2.3
    STEP: mirroring deletion of a custom Endpoint 11/05/22 13:24:50.821
    Nov  5 13:24:50.836: INFO: Waiting for 0 EndpointSlices to exist, got 1
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Nov  5 13:24:52.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-6928" for this suite. 11/05/22 13:24:52.844
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:24:52.851
Nov  5 13:24:52.851: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename dns 11/05/22 13:24:52.851
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:52.868
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:52.872
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 11/05/22 13:24:52.876
Nov  5 13:24:52.884: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-1143  45f371e6-e1fa-405e-9a18-4b3408d16dac 39319 0 2022-11-05 13:24:52 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-11-05 13:24:52 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jph5t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jph5t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  5 13:24:52.884: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-1143" to be "running and ready"
Nov  5 13:24:52.889: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 5.045615ms
Nov  5 13:24:52.889: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:24:54.894: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.009351437s
Nov  5 13:24:54.894: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Nov  5 13:24:54.894: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 11/05/22 13:24:54.894
Nov  5 13:24:54.894: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-1143 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:24:54.894: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:24:54.894: INFO: ExecWithOptions: Clientset creation
Nov  5 13:24:54.894: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-1143/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 11/05/22 13:24:54.999
Nov  5 13:24:54.999: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-1143 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:24:54.999: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:24:54.999: INFO: ExecWithOptions: Clientset creation
Nov  5 13:24:54.999: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-1143/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Nov  5 13:24:55.091: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Nov  5 13:24:55.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1143" for this suite. 11/05/22 13:24:55.111
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":339,"skipped":6200,"failed":0}
------------------------------
• [2.266 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:24:52.851
    Nov  5 13:24:52.851: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename dns 11/05/22 13:24:52.851
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:52.868
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:52.872
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 11/05/22 13:24:52.876
    Nov  5 13:24:52.884: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-1143  45f371e6-e1fa-405e-9a18-4b3408d16dac 39319 0 2022-11-05 13:24:52 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2022-11-05 13:24:52 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jph5t,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jph5t,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Nov  5 13:24:52.884: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-1143" to be "running and ready"
    Nov  5 13:24:52.889: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 5.045615ms
    Nov  5 13:24:52.889: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:24:54.894: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.009351437s
    Nov  5 13:24:54.894: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Nov  5 13:24:54.894: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 11/05/22 13:24:54.894
    Nov  5 13:24:54.894: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-1143 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:24:54.894: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:24:54.894: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:24:54.894: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-1143/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 11/05/22 13:24:54.999
    Nov  5 13:24:54.999: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-1143 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:24:54.999: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:24:54.999: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:24:54.999: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/dns-1143/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Nov  5 13:24:55.091: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Nov  5 13:24:55.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-1143" for this suite. 11/05/22 13:24:55.111
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:24:55.119
Nov  5 13:24:55.119: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 13:24:55.12
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:55.131
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:55.137
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 13:24:55.156
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 13:24:56.108
STEP: Deploying the webhook pod 11/05/22 13:24:56.114
STEP: Wait for the deployment to be ready 11/05/22 13:24:56.127
Nov  5 13:24:56.135: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 11/05/22 13:24:58.147
STEP: Verifying the service has paired with the endpoint 11/05/22 13:24:58.161
Nov  5 13:24:59.162: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 11/05/22 13:24:59.166
STEP: Registering slow webhook via the AdmissionRegistration API 11/05/22 13:24:59.166
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 11/05/22 13:24:59.18
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 11/05/22 13:25:00.189
STEP: Registering slow webhook via the AdmissionRegistration API 11/05/22 13:25:00.189
STEP: Having no error when timeout is longer than webhook latency 11/05/22 13:25:01.228
STEP: Registering slow webhook via the AdmissionRegistration API 11/05/22 13:25:01.228
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 11/05/22 13:25:06.261
STEP: Registering slow webhook via the AdmissionRegistration API 11/05/22 13:25:06.261
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:25:11.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5518" for this suite. 11/05/22 13:25:11.297
STEP: Destroying namespace "webhook-5518-markers" for this suite. 11/05/22 13:25:11.303
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":340,"skipped":6235,"failed":0}
------------------------------
• [SLOW TEST] [16.241 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:24:55.119
    Nov  5 13:24:55.119: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 13:24:55.12
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:24:55.131
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:24:55.137
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 13:24:55.156
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 13:24:56.108
    STEP: Deploying the webhook pod 11/05/22 13:24:56.114
    STEP: Wait for the deployment to be ready 11/05/22 13:24:56.127
    Nov  5 13:24:56.135: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 11/05/22 13:24:58.147
    STEP: Verifying the service has paired with the endpoint 11/05/22 13:24:58.161
    Nov  5 13:24:59.162: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 11/05/22 13:24:59.166
    STEP: Registering slow webhook via the AdmissionRegistration API 11/05/22 13:24:59.166
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 11/05/22 13:24:59.18
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 11/05/22 13:25:00.189
    STEP: Registering slow webhook via the AdmissionRegistration API 11/05/22 13:25:00.189
    STEP: Having no error when timeout is longer than webhook latency 11/05/22 13:25:01.228
    STEP: Registering slow webhook via the AdmissionRegistration API 11/05/22 13:25:01.228
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 11/05/22 13:25:06.261
    STEP: Registering slow webhook via the AdmissionRegistration API 11/05/22 13:25:06.261
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:25:11.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5518" for this suite. 11/05/22 13:25:11.297
    STEP: Destroying namespace "webhook-5518-markers" for this suite. 11/05/22 13:25:11.303
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:11.361
Nov  5 13:25:11.361: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename ephemeral-containers-test 11/05/22 13:25:11.362
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:11.391
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:11.398
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 11/05/22 13:25:11.403
Nov  5 13:25:11.419: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2361" to be "running and ready"
Nov  5 13:25:11.422: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.483701ms
Nov  5 13:25:11.422: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:25:13.427: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008041517s
Nov  5 13:25:13.427: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Nov  5 13:25:13.427: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 11/05/22 13:25:13.43
Nov  5 13:25:13.442: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2361" to be "container debugger running"
Nov  5 13:25:13.445: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.171156ms
Nov  5 13:25:15.449: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007327174s
Nov  5 13:25:17.449: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.007309486s
Nov  5 13:25:17.449: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 11/05/22 13:25:17.45
Nov  5 13:25:17.450: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-2361 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:25:17.450: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:25:17.450: INFO: ExecWithOptions: Clientset creation
Nov  5 13:25:17.450: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-2361/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Nov  5 13:25:17.539: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Nov  5 13:25:17.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-2361" for this suite. 11/05/22 13:25:17.55
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":341,"skipped":6241,"failed":0}
------------------------------
• [SLOW TEST] [6.196 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:11.361
    Nov  5 13:25:11.361: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename ephemeral-containers-test 11/05/22 13:25:11.362
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:11.391
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:11.398
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 11/05/22 13:25:11.403
    Nov  5 13:25:11.419: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2361" to be "running and ready"
    Nov  5 13:25:11.422: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 3.483701ms
    Nov  5 13:25:11.422: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:25:13.427: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.008041517s
    Nov  5 13:25:13.427: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Nov  5 13:25:13.427: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 11/05/22 13:25:13.43
    Nov  5 13:25:13.442: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-2361" to be "container debugger running"
    Nov  5 13:25:13.445: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 3.171156ms
    Nov  5 13:25:15.449: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.007327174s
    Nov  5 13:25:17.449: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.007309486s
    Nov  5 13:25:17.449: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 11/05/22 13:25:17.45
    Nov  5 13:25:17.450: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-2361 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:25:17.450: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:25:17.450: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:25:17.450: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/ephemeral-containers-test-2361/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Nov  5 13:25:17.539: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov  5 13:25:17.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-2361" for this suite. 11/05/22 13:25:17.55
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:17.557
Nov  5 13:25:17.557: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:25:17.558
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:17.583
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:17.587
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-43979df4-0ce6-46f2-b351-9f110d73655c 11/05/22 13:25:17.59
STEP: Creating a pod to test consume configMaps 11/05/22 13:25:17.595
Nov  5 13:25:17.603: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f" in namespace "projected-3180" to be "Succeeded or Failed"
Nov  5 13:25:17.608: INFO: Pod "pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.934393ms
Nov  5 13:25:19.613: INFO: Pod "pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009697278s
Nov  5 13:25:21.612: INFO: Pod "pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009056593s
STEP: Saw pod success 11/05/22 13:25:21.613
Nov  5 13:25:21.613: INFO: Pod "pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f" satisfied condition "Succeeded or Failed"
Nov  5 13:25:21.616: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f container agnhost-container: <nil>
STEP: delete the pod 11/05/22 13:25:21.623
Nov  5 13:25:21.637: INFO: Waiting for pod pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f to disappear
Nov  5 13:25:21.640: INFO: Pod pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Nov  5 13:25:21.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3180" for this suite. 11/05/22 13:25:21.644
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":342,"skipped":6241,"failed":0}
------------------------------
• [4.093 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:17.557
    Nov  5 13:25:17.557: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:25:17.558
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:17.583
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:17.587
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-43979df4-0ce6-46f2-b351-9f110d73655c 11/05/22 13:25:17.59
    STEP: Creating a pod to test consume configMaps 11/05/22 13:25:17.595
    Nov  5 13:25:17.603: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f" in namespace "projected-3180" to be "Succeeded or Failed"
    Nov  5 13:25:17.608: INFO: Pod "pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.934393ms
    Nov  5 13:25:19.613: INFO: Pod "pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009697278s
    Nov  5 13:25:21.612: INFO: Pod "pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009056593s
    STEP: Saw pod success 11/05/22 13:25:21.613
    Nov  5 13:25:21.613: INFO: Pod "pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f" satisfied condition "Succeeded or Failed"
    Nov  5 13:25:21.616: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 13:25:21.623
    Nov  5 13:25:21.637: INFO: Waiting for pod pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f to disappear
    Nov  5 13:25:21.640: INFO: Pod pod-projected-configmaps-e80afc25-d889-4259-91df-c493add3788f no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Nov  5 13:25:21.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3180" for this suite. 11/05/22 13:25:21.644
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:21.651
Nov  5 13:25:21.651: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:25:21.652
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:21.664
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:21.668
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 11/05/22 13:25:21.671
Nov  5 13:25:21.679: INFO: Waiting up to 5m0s for pod "labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7" in namespace "projected-5597" to be "running and ready"
Nov  5 13:25:21.686: INFO: Pod "labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.818748ms
Nov  5 13:25:21.686: INFO: The phase of Pod labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7 is Pending, waiting for it to be Running (with Ready = true)
Nov  5 13:25:23.689: INFO: Pod "labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7": Phase="Running", Reason="", readiness=true. Elapsed: 2.010688262s
Nov  5 13:25:23.690: INFO: The phase of Pod labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7 is Running (Ready = true)
Nov  5 13:25:23.690: INFO: Pod "labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7" satisfied condition "running and ready"
Nov  5 13:25:24.219: INFO: Successfully updated pod "labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 13:25:28.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5597" for this suite. 11/05/22 13:25:28.249
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":343,"skipped":6248,"failed":0}
------------------------------
• [SLOW TEST] [6.606 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:21.651
    Nov  5 13:25:21.651: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:25:21.652
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:21.664
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:21.668
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 11/05/22 13:25:21.671
    Nov  5 13:25:21.679: INFO: Waiting up to 5m0s for pod "labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7" in namespace "projected-5597" to be "running and ready"
    Nov  5 13:25:21.686: INFO: Pod "labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.818748ms
    Nov  5 13:25:21.686: INFO: The phase of Pod labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7 is Pending, waiting for it to be Running (with Ready = true)
    Nov  5 13:25:23.689: INFO: Pod "labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7": Phase="Running", Reason="", readiness=true. Elapsed: 2.010688262s
    Nov  5 13:25:23.690: INFO: The phase of Pod labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7 is Running (Ready = true)
    Nov  5 13:25:23.690: INFO: Pod "labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7" satisfied condition "running and ready"
    Nov  5 13:25:24.219: INFO: Successfully updated pod "labelsupdatefb0b09f8-ce4a-4137-9cc1-8c693ebd18a7"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 13:25:28.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5597" for this suite. 11/05/22 13:25:28.249
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:28.259
Nov  5 13:25:28.259: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 13:25:28.259
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:28.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:28.278
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 11/05/22 13:25:28.282
Nov  5 13:25:28.292: INFO: Waiting up to 5m0s for pod "pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a" in namespace "emptydir-378" to be "Succeeded or Failed"
Nov  5 13:25:28.296: INFO: Pod "pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.192491ms
Nov  5 13:25:30.300: INFO: Pod "pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008419763s
Nov  5 13:25:32.300: INFO: Pod "pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008361595s
STEP: Saw pod success 11/05/22 13:25:32.3
Nov  5 13:25:32.300: INFO: Pod "pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a" satisfied condition "Succeeded or Failed"
Nov  5 13:25:32.304: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a container test-container: <nil>
STEP: delete the pod 11/05/22 13:25:32.31
Nov  5 13:25:32.321: INFO: Waiting for pod pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a to disappear
Nov  5 13:25:32.326: INFO: Pod pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 13:25:32.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-378" for this suite. 11/05/22 13:25:32.33
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":344,"skipped":6275,"failed":0}
------------------------------
• [4.078 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:28.259
    Nov  5 13:25:28.259: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 13:25:28.259
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:28.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:28.278
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 11/05/22 13:25:28.282
    Nov  5 13:25:28.292: INFO: Waiting up to 5m0s for pod "pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a" in namespace "emptydir-378" to be "Succeeded or Failed"
    Nov  5 13:25:28.296: INFO: Pod "pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.192491ms
    Nov  5 13:25:30.300: INFO: Pod "pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008419763s
    Nov  5 13:25:32.300: INFO: Pod "pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008361595s
    STEP: Saw pod success 11/05/22 13:25:32.3
    Nov  5 13:25:32.300: INFO: Pod "pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a" satisfied condition "Succeeded or Failed"
    Nov  5 13:25:32.304: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a container test-container: <nil>
    STEP: delete the pod 11/05/22 13:25:32.31
    Nov  5 13:25:32.321: INFO: Waiting for pod pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a to disappear
    Nov  5 13:25:32.326: INFO: Pod pod-0f7a15bf-0801-4a27-841b-9dbef8951b6a no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 13:25:32.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-378" for this suite. 11/05/22 13:25:32.33
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:32.339
Nov  5 13:25:32.339: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename secrets 11/05/22 13:25:32.34
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:32.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:32.356
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-bd26a5aa-1bf2-4627-924d-72c7a34dfb81 11/05/22 13:25:32.36
STEP: Creating a pod to test consume secrets 11/05/22 13:25:32.366
Nov  5 13:25:32.375: INFO: Waiting up to 5m0s for pod "pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae" in namespace "secrets-3655" to be "Succeeded or Failed"
Nov  5 13:25:32.378: INFO: Pod "pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.1178ms
Nov  5 13:25:34.385: INFO: Pod "pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009183951s
Nov  5 13:25:36.383: INFO: Pod "pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00759324s
STEP: Saw pod success 11/05/22 13:25:36.383
Nov  5 13:25:36.383: INFO: Pod "pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae" satisfied condition "Succeeded or Failed"
Nov  5 13:25:36.386: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae container secret-volume-test: <nil>
STEP: delete the pod 11/05/22 13:25:36.394
Nov  5 13:25:36.407: INFO: Waiting for pod pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae to disappear
Nov  5 13:25:36.410: INFO: Pod pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Nov  5 13:25:36.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3655" for this suite. 11/05/22 13:25:36.416
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":345,"skipped":6303,"failed":0}
------------------------------
• [4.083 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:32.339
    Nov  5 13:25:32.339: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename secrets 11/05/22 13:25:32.34
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:32.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:32.356
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-bd26a5aa-1bf2-4627-924d-72c7a34dfb81 11/05/22 13:25:32.36
    STEP: Creating a pod to test consume secrets 11/05/22 13:25:32.366
    Nov  5 13:25:32.375: INFO: Waiting up to 5m0s for pod "pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae" in namespace "secrets-3655" to be "Succeeded or Failed"
    Nov  5 13:25:32.378: INFO: Pod "pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.1178ms
    Nov  5 13:25:34.385: INFO: Pod "pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009183951s
    Nov  5 13:25:36.383: INFO: Pod "pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00759324s
    STEP: Saw pod success 11/05/22 13:25:36.383
    Nov  5 13:25:36.383: INFO: Pod "pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae" satisfied condition "Succeeded or Failed"
    Nov  5 13:25:36.386: INFO: Trying to get logs from node ip-172-31-0-255 pod pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae container secret-volume-test: <nil>
    STEP: delete the pod 11/05/22 13:25:36.394
    Nov  5 13:25:36.407: INFO: Waiting for pod pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae to disappear
    Nov  5 13:25:36.410: INFO: Pod pod-secrets-5a05cefb-a0c6-499c-87bd-18c8c434caae no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Nov  5 13:25:36.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3655" for this suite. 11/05/22 13:25:36.416
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:36.424
Nov  5 13:25:36.424: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename kubectl 11/05/22 13:25:36.425
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:36.437
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:36.441
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 11/05/22 13:25:36.445
Nov  5 13:25:36.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-6174 create -f -'
Nov  5 13:25:36.974: INFO: stderr: ""
Nov  5 13:25:36.974: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 11/05/22 13:25:36.974
Nov  5 13:25:37.979: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  5 13:25:37.979: INFO: Found 0 / 1
Nov  5 13:25:38.978: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  5 13:25:38.978: INFO: Found 1 / 1
Nov  5 13:25:38.978: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 11/05/22 13:25:38.978
Nov  5 13:25:38.982: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  5 13:25:38.982: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  5 13:25:38.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-6174 patch pod agnhost-primary-c4gbt -p {"metadata":{"annotations":{"x":"y"}}}'
Nov  5 13:25:39.051: INFO: stderr: ""
Nov  5 13:25:39.051: INFO: stdout: "pod/agnhost-primary-c4gbt patched\n"
STEP: checking annotations 11/05/22 13:25:39.051
Nov  5 13:25:39.055: INFO: Selector matched 1 pods for map[app:agnhost]
Nov  5 13:25:39.055: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Nov  5 13:25:39.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6174" for this suite. 11/05/22 13:25:39.06
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":346,"skipped":6321,"failed":0}
------------------------------
• [2.643 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:36.424
    Nov  5 13:25:36.424: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename kubectl 11/05/22 13:25:36.425
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:36.437
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:36.441
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 11/05/22 13:25:36.445
    Nov  5 13:25:36.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-6174 create -f -'
    Nov  5 13:25:36.974: INFO: stderr: ""
    Nov  5 13:25:36.974: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 11/05/22 13:25:36.974
    Nov  5 13:25:37.979: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov  5 13:25:37.979: INFO: Found 0 / 1
    Nov  5 13:25:38.978: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov  5 13:25:38.978: INFO: Found 1 / 1
    Nov  5 13:25:38.978: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 11/05/22 13:25:38.978
    Nov  5 13:25:38.982: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov  5 13:25:38.982: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Nov  5 13:25:38.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=kubectl-6174 patch pod agnhost-primary-c4gbt -p {"metadata":{"annotations":{"x":"y"}}}'
    Nov  5 13:25:39.051: INFO: stderr: ""
    Nov  5 13:25:39.051: INFO: stdout: "pod/agnhost-primary-c4gbt patched\n"
    STEP: checking annotations 11/05/22 13:25:39.051
    Nov  5 13:25:39.055: INFO: Selector matched 1 pods for map[app:agnhost]
    Nov  5 13:25:39.055: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Nov  5 13:25:39.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-6174" for this suite. 11/05/22 13:25:39.06
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:39.068
Nov  5 13:25:39.068: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:25:39.069
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:39.083
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:39.092
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 11/05/22 13:25:39.095
Nov  5 13:25:39.104: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded" in namespace "projected-9062" to be "Succeeded or Failed"
Nov  5 13:25:39.111: INFO: Pod "downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded": Phase="Pending", Reason="", readiness=false. Elapsed: 6.916243ms
Nov  5 13:25:41.115: INFO: Pod "downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010951528s
Nov  5 13:25:43.115: INFO: Pod "downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011245348s
STEP: Saw pod success 11/05/22 13:25:43.115
Nov  5 13:25:43.115: INFO: Pod "downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded" satisfied condition "Succeeded or Failed"
Nov  5 13:25:43.119: INFO: Trying to get logs from node ip-172-31-41-19 pod downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded container client-container: <nil>
STEP: delete the pod 11/05/22 13:25:43.126
Nov  5 13:25:43.139: INFO: Waiting for pod downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded to disappear
Nov  5 13:25:43.142: INFO: Pod downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 13:25:43.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9062" for this suite. 11/05/22 13:25:43.146
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":347,"skipped":6360,"failed":0}
------------------------------
• [4.084 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:39.068
    Nov  5 13:25:39.068: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:25:39.069
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:39.083
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:39.092
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 11/05/22 13:25:39.095
    Nov  5 13:25:39.104: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded" in namespace "projected-9062" to be "Succeeded or Failed"
    Nov  5 13:25:39.111: INFO: Pod "downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded": Phase="Pending", Reason="", readiness=false. Elapsed: 6.916243ms
    Nov  5 13:25:41.115: INFO: Pod "downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010951528s
    Nov  5 13:25:43.115: INFO: Pod "downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011245348s
    STEP: Saw pod success 11/05/22 13:25:43.115
    Nov  5 13:25:43.115: INFO: Pod "downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded" satisfied condition "Succeeded or Failed"
    Nov  5 13:25:43.119: INFO: Trying to get logs from node ip-172-31-41-19 pod downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded container client-container: <nil>
    STEP: delete the pod 11/05/22 13:25:43.126
    Nov  5 13:25:43.139: INFO: Waiting for pod downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded to disappear
    Nov  5 13:25:43.142: INFO: Pod downwardapi-volume-17522802-705f-4a88-9407-576ca3241ded no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 13:25:43.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9062" for this suite. 11/05/22 13:25:43.146
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:43.155
Nov  5 13:25:43.155: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 13:25:43.155
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:43.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:43.173
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4673 11/05/22 13:25:43.176
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/05/22 13:25:43.196
STEP: creating service externalsvc in namespace services-4673 11/05/22 13:25:43.197
STEP: creating replication controller externalsvc in namespace services-4673 11/05/22 13:25:43.216
I1105 13:25:43.226768      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4673, replica count: 2
I1105 13:25:46.277483      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 11/05/22 13:25:46.281
Nov  5 13:25:46.300: INFO: Creating new exec pod
Nov  5 13:25:46.310: INFO: Waiting up to 5m0s for pod "execpoddmd9w" in namespace "services-4673" to be "running"
Nov  5 13:25:46.317: INFO: Pod "execpoddmd9w": Phase="Pending", Reason="", readiness=false. Elapsed: 6.477814ms
Nov  5 13:25:48.320: INFO: Pod "execpoddmd9w": Phase="Running", Reason="", readiness=true. Elapsed: 2.010044572s
Nov  5 13:25:48.321: INFO: Pod "execpoddmd9w" satisfied condition "running"
Nov  5 13:25:48.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4673 exec execpoddmd9w -- /bin/sh -x -c nslookup nodeport-service.services-4673.svc.cluster.local'
Nov  5 13:25:48.482: INFO: stderr: "+ nslookup nodeport-service.services-4673.svc.cluster.local\n"
Nov  5 13:25:48.482: INFO: stdout: "Server:\t\t10.152.183.192\nAddress:\t10.152.183.192#53\n\nnodeport-service.services-4673.svc.cluster.local\tcanonical name = externalsvc.services-4673.svc.cluster.local.\nName:\texternalsvc.services-4673.svc.cluster.local\nAddress: 10.152.183.162\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4673, will wait for the garbage collector to delete the pods 11/05/22 13:25:48.482
Nov  5 13:25:48.542: INFO: Deleting ReplicationController externalsvc took: 6.04936ms
Nov  5 13:25:48.643: INFO: Terminating ReplicationController externalsvc pods took: 100.451374ms
Nov  5 13:25:50.265: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 13:25:50.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4673" for this suite. 11/05/22 13:25:50.291
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":348,"skipped":6383,"failed":0}
------------------------------
• [SLOW TEST] [7.144 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:43.155
    Nov  5 13:25:43.155: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 13:25:43.155
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:43.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:43.173
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-4673 11/05/22 13:25:43.176
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 11/05/22 13:25:43.196
    STEP: creating service externalsvc in namespace services-4673 11/05/22 13:25:43.197
    STEP: creating replication controller externalsvc in namespace services-4673 11/05/22 13:25:43.216
    I1105 13:25:43.226768      20 runners.go:193] Created replication controller with name: externalsvc, namespace: services-4673, replica count: 2
    I1105 13:25:46.277483      20 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 11/05/22 13:25:46.281
    Nov  5 13:25:46.300: INFO: Creating new exec pod
    Nov  5 13:25:46.310: INFO: Waiting up to 5m0s for pod "execpoddmd9w" in namespace "services-4673" to be "running"
    Nov  5 13:25:46.317: INFO: Pod "execpoddmd9w": Phase="Pending", Reason="", readiness=false. Elapsed: 6.477814ms
    Nov  5 13:25:48.320: INFO: Pod "execpoddmd9w": Phase="Running", Reason="", readiness=true. Elapsed: 2.010044572s
    Nov  5 13:25:48.321: INFO: Pod "execpoddmd9w" satisfied condition "running"
    Nov  5 13:25:48.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4673 exec execpoddmd9w -- /bin/sh -x -c nslookup nodeport-service.services-4673.svc.cluster.local'
    Nov  5 13:25:48.482: INFO: stderr: "+ nslookup nodeport-service.services-4673.svc.cluster.local\n"
    Nov  5 13:25:48.482: INFO: stdout: "Server:\t\t10.152.183.192\nAddress:\t10.152.183.192#53\n\nnodeport-service.services-4673.svc.cluster.local\tcanonical name = externalsvc.services-4673.svc.cluster.local.\nName:\texternalsvc.services-4673.svc.cluster.local\nAddress: 10.152.183.162\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-4673, will wait for the garbage collector to delete the pods 11/05/22 13:25:48.482
    Nov  5 13:25:48.542: INFO: Deleting ReplicationController externalsvc took: 6.04936ms
    Nov  5 13:25:48.643: INFO: Terminating ReplicationController externalsvc pods took: 100.451374ms
    Nov  5 13:25:50.265: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 13:25:50.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4673" for this suite. 11/05/22 13:25:50.291
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:50.302
Nov  5 13:25:50.302: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename configmap 11/05/22 13:25:50.303
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:50.315
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:50.319
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-26e36594-d714-4917-90e1-93d1a5bd529d 11/05/22 13:25:50.323
STEP: Creating a pod to test consume configMaps 11/05/22 13:25:50.328
Nov  5 13:25:50.337: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a" in namespace "configmap-6934" to be "Succeeded or Failed"
Nov  5 13:25:50.340: INFO: Pod "pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.599778ms
Nov  5 13:25:52.345: INFO: Pod "pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007745739s
Nov  5 13:25:54.345: INFO: Pod "pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008408459s
STEP: Saw pod success 11/05/22 13:25:54.345
Nov  5 13:25:54.345: INFO: Pod "pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a" satisfied condition "Succeeded or Failed"
Nov  5 13:25:54.349: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a container agnhost-container: <nil>
STEP: delete the pod 11/05/22 13:25:54.356
Nov  5 13:25:54.367: INFO: Waiting for pod pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a to disappear
Nov  5 13:25:54.370: INFO: Pod pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Nov  5 13:25:54.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6934" for this suite. 11/05/22 13:25:54.375
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":349,"skipped":6428,"failed":0}
------------------------------
• [4.079 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:50.302
    Nov  5 13:25:50.302: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename configmap 11/05/22 13:25:50.303
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:50.315
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:50.319
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-26e36594-d714-4917-90e1-93d1a5bd529d 11/05/22 13:25:50.323
    STEP: Creating a pod to test consume configMaps 11/05/22 13:25:50.328
    Nov  5 13:25:50.337: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a" in namespace "configmap-6934" to be "Succeeded or Failed"
    Nov  5 13:25:50.340: INFO: Pod "pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.599778ms
    Nov  5 13:25:52.345: INFO: Pod "pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007745739s
    Nov  5 13:25:54.345: INFO: Pod "pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008408459s
    STEP: Saw pod success 11/05/22 13:25:54.345
    Nov  5 13:25:54.345: INFO: Pod "pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a" satisfied condition "Succeeded or Failed"
    Nov  5 13:25:54.349: INFO: Trying to get logs from node ip-172-31-41-19 pod pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a container agnhost-container: <nil>
    STEP: delete the pod 11/05/22 13:25:54.356
    Nov  5 13:25:54.367: INFO: Waiting for pod pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a to disappear
    Nov  5 13:25:54.370: INFO: Pod pod-configmaps-8b6ed9e5-3ce1-4669-872b-a9f81db0ee0a no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Nov  5 13:25:54.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6934" for this suite. 11/05/22 13:25:54.375
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:54.383
Nov  5 13:25:54.383: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:25:54.384
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:54.395
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:54.401
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 11/05/22 13:25:54.405
Nov  5 13:25:54.413: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea" in namespace "projected-7653" to be "Succeeded or Failed"
Nov  5 13:25:54.419: INFO: Pod "downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.641844ms
Nov  5 13:25:56.423: INFO: Pod "downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009519857s
Nov  5 13:25:58.423: INFO: Pod "downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009851251s
STEP: Saw pod success 11/05/22 13:25:58.423
Nov  5 13:25:58.423: INFO: Pod "downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea" satisfied condition "Succeeded or Failed"
Nov  5 13:25:58.427: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea container client-container: <nil>
STEP: delete the pod 11/05/22 13:25:58.433
Nov  5 13:25:58.454: INFO: Waiting for pod downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea to disappear
Nov  5 13:25:58.458: INFO: Pod downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 13:25:58.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7653" for this suite. 11/05/22 13:25:58.462
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":350,"skipped":6468,"failed":0}
------------------------------
• [4.086 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:54.383
    Nov  5 13:25:54.383: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:25:54.384
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:54.395
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:54.401
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 11/05/22 13:25:54.405
    Nov  5 13:25:54.413: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea" in namespace "projected-7653" to be "Succeeded or Failed"
    Nov  5 13:25:54.419: INFO: Pod "downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea": Phase="Pending", Reason="", readiness=false. Elapsed: 5.641844ms
    Nov  5 13:25:56.423: INFO: Pod "downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009519857s
    Nov  5 13:25:58.423: INFO: Pod "downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009851251s
    STEP: Saw pod success 11/05/22 13:25:58.423
    Nov  5 13:25:58.423: INFO: Pod "downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea" satisfied condition "Succeeded or Failed"
    Nov  5 13:25:58.427: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea container client-container: <nil>
    STEP: delete the pod 11/05/22 13:25:58.433
    Nov  5 13:25:58.454: INFO: Waiting for pod downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea to disappear
    Nov  5 13:25:58.458: INFO: Pod downwardapi-volume-d7f4a248-2a4c-4087-ac68-8b8d172d9aea no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 13:25:58.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7653" for this suite. 11/05/22 13:25:58.462
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:25:58.469
Nov  5 13:25:58.469: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename emptydir 11/05/22 13:25:58.47
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:58.482
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:58.486
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 11/05/22 13:25:58.49
Nov  5 13:25:58.497: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e" in namespace "emptydir-8832" to be "running"
Nov  5 13:25:58.500: INFO: Pod "pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.317084ms
Nov  5 13:26:00.505: INFO: Pod "pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e": Phase="Running", Reason="", readiness=false. Elapsed: 2.008334289s
Nov  5 13:26:00.505: INFO: Pod "pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e" satisfied condition "running"
STEP: Reading file content from the nginx-container 11/05/22 13:26:00.505
Nov  5 13:26:00.505: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8832 PodName:pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Nov  5 13:26:00.505: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
Nov  5 13:26:00.506: INFO: ExecWithOptions: Clientset creation
Nov  5 13:26:00.506: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-8832/pods/pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Nov  5 13:26:00.595: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Nov  5 13:26:00.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8832" for this suite. 11/05/22 13:26:00.599
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":351,"skipped":6470,"failed":0}
------------------------------
• [2.137 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:25:58.469
    Nov  5 13:25:58.469: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename emptydir 11/05/22 13:25:58.47
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:25:58.482
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:25:58.486
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 11/05/22 13:25:58.49
    Nov  5 13:25:58.497: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e" in namespace "emptydir-8832" to be "running"
    Nov  5 13:25:58.500: INFO: Pod "pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.317084ms
    Nov  5 13:26:00.505: INFO: Pod "pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e": Phase="Running", Reason="", readiness=false. Elapsed: 2.008334289s
    Nov  5 13:26:00.505: INFO: Pod "pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e" satisfied condition "running"
    STEP: Reading file content from the nginx-container 11/05/22 13:26:00.505
    Nov  5 13:26:00.505: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-8832 PodName:pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Nov  5 13:26:00.505: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    Nov  5 13:26:00.506: INFO: ExecWithOptions: Clientset creation
    Nov  5 13:26:00.506: INFO: ExecWithOptions: execute(POST https://10.152.183.1:443/api/v1/namespaces/emptydir-8832/pods/pod-sharedvolume-3b769065-6743-4de2-bf7b-1e57e568aa3e/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Nov  5 13:26:00.595: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Nov  5 13:26:00.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8832" for this suite. 11/05/22 13:26:00.599
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:26:00.606
Nov  5 13:26:00.606: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename services 11/05/22 13:26:00.607
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:00.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:00.624
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-4745 11/05/22 13:26:00.627
STEP: creating replication controller nodeport-test in namespace services-4745 11/05/22 13:26:00.642
I1105 13:26:00.653425      20 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-4745, replica count: 2
I1105 13:26:03.704699      20 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  5 13:26:03.704: INFO: Creating new exec pod
Nov  5 13:26:03.712: INFO: Waiting up to 5m0s for pod "execpodgd7g5" in namespace "services-4745" to be "running"
Nov  5 13:26:03.723: INFO: Pod "execpodgd7g5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.966055ms
Nov  5 13:26:05.727: INFO: Pod "execpodgd7g5": Phase="Running", Reason="", readiness=true. Elapsed: 2.015800933s
Nov  5 13:26:05.727: INFO: Pod "execpodgd7g5" satisfied condition "running"
Nov  5 13:26:06.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Nov  5 13:26:06.878: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov  5 13:26:06.878: INFO: stdout: "nodeport-test-ptggz"
Nov  5 13:26:06.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.100 80'
Nov  5 13:26:07.002: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.100 80\nConnection to 10.152.183.100 80 port [tcp/http] succeeded!\n"
Nov  5 13:26:07.002: INFO: stdout: ""
Nov  5 13:26:08.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.100 80'
Nov  5 13:26:08.148: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.100 80\nConnection to 10.152.183.100 80 port [tcp/http] succeeded!\n"
Nov  5 13:26:08.148: INFO: stdout: "nodeport-test-ptggz"
Nov  5 13:26:08.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 30165'
Nov  5 13:26:08.299: INFO: stderr: "+ nc -v -t -w 2 172.31.41.19 30165\nConnection to 172.31.41.19 30165 port [tcp/*] succeeded!\n+ echo hostName\n"
Nov  5 13:26:08.299: INFO: stdout: ""
Nov  5 13:26:09.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 30165'
Nov  5 13:26:09.454: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.41.19 30165\nConnection to 172.31.41.19 30165 port [tcp/*] succeeded!\n"
Nov  5 13:26:09.454: INFO: stdout: ""
Nov  5 13:26:10.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 30165'
Nov  5 13:26:10.447: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.41.19 30165\nConnection to 172.31.41.19 30165 port [tcp/*] succeeded!\n"
Nov  5 13:26:10.447: INFO: stdout: ""
Nov  5 13:26:11.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 30165'
Nov  5 13:26:11.465: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.41.19 30165\nConnection to 172.31.41.19 30165 port [tcp/*] succeeded!\n"
Nov  5 13:26:11.465: INFO: stdout: "nodeport-test-ptggz"
Nov  5 13:26:11.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.27.199 30165'
Nov  5 13:26:11.586: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.27.199 30165\nConnection to 172.31.27.199 30165 port [tcp/*] succeeded!\n"
Nov  5 13:26:11.586: INFO: stdout: "nodeport-test-ptggz"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Nov  5 13:26:11.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4745" for this suite. 11/05/22 13:26:11.591
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":352,"skipped":6471,"failed":0}
------------------------------
• [SLOW TEST] [10.995 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:26:00.606
    Nov  5 13:26:00.606: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename services 11/05/22 13:26:00.607
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:00.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:00.624
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-4745 11/05/22 13:26:00.627
    STEP: creating replication controller nodeport-test in namespace services-4745 11/05/22 13:26:00.642
    I1105 13:26:00.653425      20 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-4745, replica count: 2
    I1105 13:26:03.704699      20 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Nov  5 13:26:03.704: INFO: Creating new exec pod
    Nov  5 13:26:03.712: INFO: Waiting up to 5m0s for pod "execpodgd7g5" in namespace "services-4745" to be "running"
    Nov  5 13:26:03.723: INFO: Pod "execpodgd7g5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.966055ms
    Nov  5 13:26:05.727: INFO: Pod "execpodgd7g5": Phase="Running", Reason="", readiness=true. Elapsed: 2.015800933s
    Nov  5 13:26:05.727: INFO: Pod "execpodgd7g5" satisfied condition "running"
    Nov  5 13:26:06.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Nov  5 13:26:06.878: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Nov  5 13:26:06.878: INFO: stdout: "nodeport-test-ptggz"
    Nov  5 13:26:06.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.100 80'
    Nov  5 13:26:07.002: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.100 80\nConnection to 10.152.183.100 80 port [tcp/http] succeeded!\n"
    Nov  5 13:26:07.002: INFO: stdout: ""
    Nov  5 13:26:08.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.152.183.100 80'
    Nov  5 13:26:08.148: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.152.183.100 80\nConnection to 10.152.183.100 80 port [tcp/http] succeeded!\n"
    Nov  5 13:26:08.148: INFO: stdout: "nodeport-test-ptggz"
    Nov  5 13:26:08.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 30165'
    Nov  5 13:26:08.299: INFO: stderr: "+ nc -v -t -w 2 172.31.41.19 30165\nConnection to 172.31.41.19 30165 port [tcp/*] succeeded!\n+ echo hostName\n"
    Nov  5 13:26:08.299: INFO: stdout: ""
    Nov  5 13:26:09.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 30165'
    Nov  5 13:26:09.454: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.41.19 30165\nConnection to 172.31.41.19 30165 port [tcp/*] succeeded!\n"
    Nov  5 13:26:09.454: INFO: stdout: ""
    Nov  5 13:26:10.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 30165'
    Nov  5 13:26:10.447: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.41.19 30165\nConnection to 172.31.41.19 30165 port [tcp/*] succeeded!\n"
    Nov  5 13:26:10.447: INFO: stdout: ""
    Nov  5 13:26:11.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.41.19 30165'
    Nov  5 13:26:11.465: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.41.19 30165\nConnection to 172.31.41.19 30165 port [tcp/*] succeeded!\n"
    Nov  5 13:26:11.465: INFO: stdout: "nodeport-test-ptggz"
    Nov  5 13:26:11.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-322861382 --namespace=services-4745 exec execpodgd7g5 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 172.31.27.199 30165'
    Nov  5 13:26:11.586: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 172.31.27.199 30165\nConnection to 172.31.27.199 30165 port [tcp/*] succeeded!\n"
    Nov  5 13:26:11.586: INFO: stdout: "nodeport-test-ptggz"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Nov  5 13:26:11.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-4745" for this suite. 11/05/22 13:26:11.591
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:26:11.603
Nov  5 13:26:11.603: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename webhook 11/05/22 13:26:11.604
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:11.619
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:11.626
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 11/05/22 13:26:11.644
STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 13:26:12.013
STEP: Deploying the webhook pod 11/05/22 13:26:12.022
STEP: Wait for the deployment to be ready 11/05/22 13:26:12.034
Nov  5 13:26:12.041: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 11/05/22 13:26:14.052
STEP: Verifying the service has paired with the endpoint 11/05/22 13:26:14.061
Nov  5 13:26:15.061: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 11/05/22 13:26:15.066
STEP: Creating a configMap that does not comply to the validation webhook rules 11/05/22 13:26:15.081
STEP: Updating a validating webhook configuration's rules to not include the create operation 11/05/22 13:26:15.088
STEP: Creating a configMap that does not comply to the validation webhook rules 11/05/22 13:26:15.098
STEP: Patching a validating webhook configuration's rules to include the create operation 11/05/22 13:26:15.109
STEP: Creating a configMap that does not comply to the validation webhook rules 11/05/22 13:26:15.117
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:26:15.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2541" for this suite. 11/05/22 13:26:15.13
STEP: Destroying namespace "webhook-2541-markers" for this suite. 11/05/22 13:26:15.137
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":353,"skipped":6477,"failed":0}
------------------------------
• [3.594 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:26:11.603
    Nov  5 13:26:11.603: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename webhook 11/05/22 13:26:11.604
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:11.619
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:11.626
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 11/05/22 13:26:11.644
    STEP: Create role binding to let webhook read extension-apiserver-authentication 11/05/22 13:26:12.013
    STEP: Deploying the webhook pod 11/05/22 13:26:12.022
    STEP: Wait for the deployment to be ready 11/05/22 13:26:12.034
    Nov  5 13:26:12.041: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 11/05/22 13:26:14.052
    STEP: Verifying the service has paired with the endpoint 11/05/22 13:26:14.061
    Nov  5 13:26:15.061: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 11/05/22 13:26:15.066
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/05/22 13:26:15.081
    STEP: Updating a validating webhook configuration's rules to not include the create operation 11/05/22 13:26:15.088
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/05/22 13:26:15.098
    STEP: Patching a validating webhook configuration's rules to include the create operation 11/05/22 13:26:15.109
    STEP: Creating a configMap that does not comply to the validation webhook rules 11/05/22 13:26:15.117
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:26:15.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-2541" for this suite. 11/05/22 13:26:15.13
    STEP: Destroying namespace "webhook-2541-markers" for this suite. 11/05/22 13:26:15.137
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:26:15.198
Nov  5 13:26:15.198: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename job 11/05/22 13:26:15.199
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:15.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:15.225
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 11/05/22 13:26:15.231
STEP: Ensuring job reaches completions 11/05/22 13:26:15.238
STEP: Ensuring pods with index for job exist 11/05/22 13:26:25.242
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Nov  5 13:26:25.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3479" for this suite. 11/05/22 13:26:25.25
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":354,"skipped":6520,"failed":0}
------------------------------
• [SLOW TEST] [10.058 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:26:15.198
    Nov  5 13:26:15.198: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename job 11/05/22 13:26:15.199
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:15.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:15.225
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 11/05/22 13:26:15.231
    STEP: Ensuring job reaches completions 11/05/22 13:26:15.238
    STEP: Ensuring pods with index for job exist 11/05/22 13:26:25.242
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Nov  5 13:26:25.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3479" for this suite. 11/05/22 13:26:25.25
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:26:25.259
Nov  5 13:26:25.259: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename downward-api 11/05/22 13:26:25.26
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:25.274
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:25.279
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 11/05/22 13:26:25.282
Nov  5 13:26:25.289: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b" in namespace "downward-api-5953" to be "Succeeded or Failed"
Nov  5 13:26:25.297: INFO: Pod "downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.585542ms
Nov  5 13:26:27.302: INFO: Pod "downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b": Phase="Running", Reason="", readiness=false. Elapsed: 2.013095848s
Nov  5 13:26:29.301: INFO: Pod "downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011824807s
STEP: Saw pod success 11/05/22 13:26:29.301
Nov  5 13:26:29.301: INFO: Pod "downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b" satisfied condition "Succeeded or Failed"
Nov  5 13:26:29.305: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b container client-container: <nil>
STEP: delete the pod 11/05/22 13:26:29.311
Nov  5 13:26:29.321: INFO: Waiting for pod downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b to disappear
Nov  5 13:26:29.325: INFO: Pod downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Nov  5 13:26:29.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5953" for this suite. 11/05/22 13:26:29.328
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":355,"skipped":6558,"failed":0}
------------------------------
• [4.076 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:26:25.259
    Nov  5 13:26:25.259: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename downward-api 11/05/22 13:26:25.26
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:25.274
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:25.279
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 11/05/22 13:26:25.282
    Nov  5 13:26:25.289: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b" in namespace "downward-api-5953" to be "Succeeded or Failed"
    Nov  5 13:26:25.297: INFO: Pod "downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.585542ms
    Nov  5 13:26:27.302: INFO: Pod "downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b": Phase="Running", Reason="", readiness=false. Elapsed: 2.013095848s
    Nov  5 13:26:29.301: INFO: Pod "downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011824807s
    STEP: Saw pod success 11/05/22 13:26:29.301
    Nov  5 13:26:29.301: INFO: Pod "downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b" satisfied condition "Succeeded or Failed"
    Nov  5 13:26:29.305: INFO: Trying to get logs from node ip-172-31-0-255 pod downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b container client-container: <nil>
    STEP: delete the pod 11/05/22 13:26:29.311
    Nov  5 13:26:29.321: INFO: Waiting for pod downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b to disappear
    Nov  5 13:26:29.325: INFO: Pod downwardapi-volume-9f9d946b-c979-4aeb-8be8-746570c1877b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Nov  5 13:26:29.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5953" for this suite. 11/05/22 13:26:29.328
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:26:29.335
Nov  5 13:26:29.335: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename resourcequota 11/05/22 13:26:29.336
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:29.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:29.355
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 11/05/22 13:26:29.358
STEP: Creating a ResourceQuota 11/05/22 13:26:34.362
STEP: Ensuring resource quota status is calculated 11/05/22 13:26:34.368
STEP: Creating a Pod that fits quota 11/05/22 13:26:36.372
STEP: Ensuring ResourceQuota status captures the pod usage 11/05/22 13:26:36.387
STEP: Not allowing a pod to be created that exceeds remaining quota 11/05/22 13:26:38.392
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 11/05/22 13:26:38.395
STEP: Ensuring a pod cannot update its resource requirements 11/05/22 13:26:38.398
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 11/05/22 13:26:38.402
STEP: Deleting the pod 11/05/22 13:26:40.407
STEP: Ensuring resource quota status released the pod usage 11/05/22 13:26:40.42
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Nov  5 13:26:42.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3436" for this suite. 11/05/22 13:26:42.43
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":356,"skipped":6563,"failed":0}
------------------------------
• [SLOW TEST] [13.102 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:26:29.335
    Nov  5 13:26:29.335: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename resourcequota 11/05/22 13:26:29.336
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:29.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:29.355
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 11/05/22 13:26:29.358
    STEP: Creating a ResourceQuota 11/05/22 13:26:34.362
    STEP: Ensuring resource quota status is calculated 11/05/22 13:26:34.368
    STEP: Creating a Pod that fits quota 11/05/22 13:26:36.372
    STEP: Ensuring ResourceQuota status captures the pod usage 11/05/22 13:26:36.387
    STEP: Not allowing a pod to be created that exceeds remaining quota 11/05/22 13:26:38.392
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 11/05/22 13:26:38.395
    STEP: Ensuring a pod cannot update its resource requirements 11/05/22 13:26:38.398
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 11/05/22 13:26:38.402
    STEP: Deleting the pod 11/05/22 13:26:40.407
    STEP: Ensuring resource quota status released the pod usage 11/05/22 13:26:40.42
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Nov  5 13:26:42.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3436" for this suite. 11/05/22 13:26:42.43
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:26:42.438
Nov  5 13:26:42.438: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename statefulset 11/05/22 13:26:42.439
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:42.458
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:42.464
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-446 11/05/22 13:26:42.468
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Nov  5 13:26:42.496: INFO: Found 0 stateful pods, waiting for 1
Nov  5 13:26:52.500: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 11/05/22 13:26:52.507
W1105 13:26:52.515089      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Nov  5 13:26:52.524: INFO: Found 1 stateful pods, waiting for 2
Nov  5 13:27:02.528: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  5 13:27:02.528: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 11/05/22 13:27:02.536
STEP: Delete all of the StatefulSets 11/05/22 13:27:02.539
STEP: Verify that StatefulSets have been deleted 11/05/22 13:27:02.547
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Nov  5 13:27:02.555: INFO: Deleting all statefulset in ns statefulset-446
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Nov  5 13:27:02.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-446" for this suite. 11/05/22 13:27:02.601
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":357,"skipped":6571,"failed":0}
------------------------------
• [SLOW TEST] [20.174 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:26:42.438
    Nov  5 13:26:42.438: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename statefulset 11/05/22 13:26:42.439
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:26:42.458
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:26:42.464
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-446 11/05/22 13:26:42.468
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Nov  5 13:26:42.496: INFO: Found 0 stateful pods, waiting for 1
    Nov  5 13:26:52.500: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 11/05/22 13:26:52.507
    W1105 13:26:52.515089      20 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Nov  5 13:26:52.524: INFO: Found 1 stateful pods, waiting for 2
    Nov  5 13:27:02.528: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Nov  5 13:27:02.528: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 11/05/22 13:27:02.536
    STEP: Delete all of the StatefulSets 11/05/22 13:27:02.539
    STEP: Verify that StatefulSets have been deleted 11/05/22 13:27:02.547
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Nov  5 13:27:02.555: INFO: Deleting all statefulset in ns statefulset-446
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Nov  5 13:27:02.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-446" for this suite. 11/05/22 13:27:02.601
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:27:02.613
Nov  5 13:27:02.613: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename init-container 11/05/22 13:27:02.614
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:27:02.629
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:27:02.634
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 11/05/22 13:27:02.64
Nov  5 13:27:02.640: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Nov  5 13:27:06.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2964" for this suite. 11/05/22 13:27:06.168
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":358,"skipped":6578,"failed":0}
------------------------------
• [3.562 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:27:02.613
    Nov  5 13:27:02.613: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename init-container 11/05/22 13:27:02.614
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:27:02.629
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:27:02.634
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 11/05/22 13:27:02.64
    Nov  5 13:27:02.640: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Nov  5 13:27:06.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-2964" for this suite. 11/05/22 13:27:06.168
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:27:06.175
Nov  5 13:27:06.175: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:27:06.176
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:27:06.189
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:27:06.194
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 11/05/22 13:27:06.2
Nov  5 13:27:06.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9" in namespace "projected-7176" to be "Succeeded or Failed"
Nov  5 13:27:06.211: INFO: Pod "downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.241532ms
Nov  5 13:27:08.215: INFO: Pod "downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007491714s
Nov  5 13:27:10.216: INFO: Pod "downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008526237s
STEP: Saw pod success 11/05/22 13:27:10.216
Nov  5 13:27:10.216: INFO: Pod "downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9" satisfied condition "Succeeded or Failed"
Nov  5 13:27:10.220: INFO: Trying to get logs from node ip-172-31-41-19 pod downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9 container client-container: <nil>
STEP: delete the pod 11/05/22 13:27:10.226
Nov  5 13:27:10.238: INFO: Waiting for pod downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9 to disappear
Nov  5 13:27:10.242: INFO: Pod downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 13:27:10.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7176" for this suite. 11/05/22 13:27:10.245
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":359,"skipped":6582,"failed":0}
------------------------------
• [4.076 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:27:06.175
    Nov  5 13:27:06.175: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:27:06.176
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:27:06.189
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:27:06.194
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 11/05/22 13:27:06.2
    Nov  5 13:27:06.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9" in namespace "projected-7176" to be "Succeeded or Failed"
    Nov  5 13:27:06.211: INFO: Pod "downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.241532ms
    Nov  5 13:27:08.215: INFO: Pod "downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007491714s
    Nov  5 13:27:10.216: INFO: Pod "downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008526237s
    STEP: Saw pod success 11/05/22 13:27:10.216
    Nov  5 13:27:10.216: INFO: Pod "downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9" satisfied condition "Succeeded or Failed"
    Nov  5 13:27:10.220: INFO: Trying to get logs from node ip-172-31-41-19 pod downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9 container client-container: <nil>
    STEP: delete the pod 11/05/22 13:27:10.226
    Nov  5 13:27:10.238: INFO: Waiting for pod downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9 to disappear
    Nov  5 13:27:10.242: INFO: Pod downwardapi-volume-52f5fc82-1dca-4b91-bfbd-b3e714f193c9 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 13:27:10.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7176" for this suite. 11/05/22 13:27:10.245
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:27:10.252
Nov  5 13:27:10.253: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename projected 11/05/22 13:27:10.253
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:27:10.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:27:10.269
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 11/05/22 13:27:10.272
Nov  5 13:27:10.282: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a" in namespace "projected-3970" to be "Succeeded or Failed"
Nov  5 13:27:10.287: INFO: Pod "downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.633764ms
Nov  5 13:27:12.292: INFO: Pod "downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00953557s
Nov  5 13:27:14.292: INFO: Pod "downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009622392s
STEP: Saw pod success 11/05/22 13:27:14.292
Nov  5 13:27:14.292: INFO: Pod "downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a" satisfied condition "Succeeded or Failed"
Nov  5 13:27:14.296: INFO: Trying to get logs from node ip-172-31-41-19 pod downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a container client-container: <nil>
STEP: delete the pod 11/05/22 13:27:14.303
Nov  5 13:27:14.315: INFO: Waiting for pod downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a to disappear
Nov  5 13:27:14.318: INFO: Pod downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Nov  5 13:27:14.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3970" for this suite. 11/05/22 13:27:14.322
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":360,"skipped":6608,"failed":0}
------------------------------
• [4.076 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:27:10.252
    Nov  5 13:27:10.253: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename projected 11/05/22 13:27:10.253
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:27:10.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:27:10.269
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 11/05/22 13:27:10.272
    Nov  5 13:27:10.282: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a" in namespace "projected-3970" to be "Succeeded or Failed"
    Nov  5 13:27:10.287: INFO: Pod "downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.633764ms
    Nov  5 13:27:12.292: INFO: Pod "downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00953557s
    Nov  5 13:27:14.292: INFO: Pod "downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009622392s
    STEP: Saw pod success 11/05/22 13:27:14.292
    Nov  5 13:27:14.292: INFO: Pod "downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a" satisfied condition "Succeeded or Failed"
    Nov  5 13:27:14.296: INFO: Trying to get logs from node ip-172-31-41-19 pod downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a container client-container: <nil>
    STEP: delete the pod 11/05/22 13:27:14.303
    Nov  5 13:27:14.315: INFO: Waiting for pod downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a to disappear
    Nov  5 13:27:14.318: INFO: Pod downwardapi-volume-e2a92091-1279-4867-af3a-b8acc93fe60a no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Nov  5 13:27:14.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3970" for this suite. 11/05/22 13:27:14.322
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:27:14.33
Nov  5 13:27:14.330: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:27:14.33
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:27:14.343
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:27:14.348
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 11/05/22 13:27:14.351
Nov  5 13:27:14.352: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: rename a version 11/05/22 13:27:20.317
STEP: check the new version name is served 11/05/22 13:27:20.331
STEP: check the old version name is removed 11/05/22 13:27:22.019
STEP: check the other version is not changed 11/05/22 13:27:23.267
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Nov  5 13:27:28.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6013" for this suite. 11/05/22 13:27:28.89
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":361,"skipped":6625,"failed":0}
------------------------------
• [SLOW TEST] [14.567 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:27:14.33
    Nov  5 13:27:14.330: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename crd-publish-openapi 11/05/22 13:27:14.33
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:27:14.343
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:27:14.348
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 11/05/22 13:27:14.351
    Nov  5 13:27:14.352: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: rename a version 11/05/22 13:27:20.317
    STEP: check the new version name is served 11/05/22 13:27:20.331
    STEP: check the old version name is removed 11/05/22 13:27:22.019
    STEP: check the other version is not changed 11/05/22 13:27:23.267
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Nov  5 13:27:28.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6013" for this suite. 11/05/22 13:27:28.89
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 11/05/22 13:27:28.903
Nov  5 13:27:28.903: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
STEP: Building a namespace api object, basename runtimeclass 11/05/22 13:27:28.904
STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:27:28.917
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:27:28.921
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Nov  5 13:27:28.939: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7281 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Nov  5 13:27:28.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7281" for this suite. 11/05/22 13:27:28.957
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":362,"skipped":6698,"failed":0}
------------------------------
• [0.063 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 11/05/22 13:27:28.903
    Nov  5 13:27:28.903: INFO: >>> kubeConfig: /tmp/kubeconfig-322861382
    STEP: Building a namespace api object, basename runtimeclass 11/05/22 13:27:28.904
    STEP: Waiting for a default service account to be provisioned in namespace 11/05/22 13:27:28.917
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 11/05/22 13:27:28.921
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Nov  5 13:27:28.939: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7281 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Nov  5 13:27:28.953: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7281" for this suite. 11/05/22 13:27:28.957
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":362,"skipped":6705,"failed":0}
Nov  5 13:27:28.967: INFO: Running AfterSuite actions on all nodes
Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Nov  5 13:27:28.967: INFO: Running AfterSuite actions on node 1
Nov  5 13:27:28.967: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.000 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Nov  5 13:27:28.967: INFO: Running AfterSuite actions on all nodes
    Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Nov  5 13:27:28.967: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Nov  5 13:27:28.967: INFO: Running AfterSuite actions on node 1
    Nov  5 13:27:28.967: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.072 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 362 of 7067 Specs in 5518.172 seconds
SUCCESS! -- 362 Passed | 0 Failed | 0 Pending | 6705 Skipped
PASS

Ginkgo ran 1 suite in 1h31m58.485784969s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

